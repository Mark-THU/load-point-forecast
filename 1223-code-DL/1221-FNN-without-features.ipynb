{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87c696c0",
   "metadata": {},
   "source": [
    "# FNN for forecast without features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d17cfa64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T10:46:29.095915Z",
     "start_time": "2021-12-28T10:46:26.254566Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBRegressor\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"\n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecb3610",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0212dadf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T10:46:29.146843Z",
     "start_time": "2021-12-28T10:46:29.098413Z"
    }
   },
   "outputs": [],
   "source": [
    "url = '../data/beijing.csv'\n",
    "data = pd.read_csv(url, sep=',', index_col='time')\n",
    "data = data[['load']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abcd6b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T13:42:50.888600Z",
     "start_time": "2021-12-21T13:42:50.852752Z"
    }
   },
   "source": [
    "## normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "552b4f84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T10:46:29.152116Z",
     "start_time": "2021-12-28T10:46:29.149057Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalization(data):\n",
    "    \"\"\"\n",
    "    data: original data with load\n",
    "    return: normalized data, scaler of load\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_data = scaler.fit_transform(data)\n",
    "    scaler_y = MinMaxScaler()\n",
    "    scaler_y.fit_transform(data[[data.columns[-1]]])\n",
    "    return normalized_data, scaler, scaler_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3d884c",
   "metadata": {},
   "source": [
    "## build supervised dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21c648fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T10:46:29.157408Z",
     "start_time": "2021-12-28T10:46:29.154112Z"
    }
   },
   "outputs": [],
   "source": [
    "def Series_To_Supervise(data, seq_len, target_len):\n",
    "    \"\"\"\n",
    "    convert series data to supervised data\n",
    "    :param data: original data\n",
    "    :param seq_len: length of input sequence\n",
    "    :param target_len: length of ouput sequence\n",
    "    :return: return two ndarrays-- input and output in format suitable to feed to LSTM\n",
    "    \"\"\"\n",
    "    dim_0 = data.shape[0] - seq_len - target_len + 1\n",
    "    dim_1 = data.shape[1]\n",
    "    x = np.zeros((dim_0, seq_len, dim_1))\n",
    "    y = np.zeros((dim_0, target_len))\n",
    "    for i in range(dim_0):\n",
    "        x[i] = data[i:i + seq_len]\n",
    "        y[i] = data[i + seq_len:i + seq_len + target_len, -1]\n",
    "    print(\"Supervised Data: Shape of x: {}, Shape of y: {}\".format(x.shape, y.shape))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec29dc6",
   "metadata": {},
   "source": [
    "## feature seletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e09f2f34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T10:46:29.161709Z",
     "start_time": "2021-12-28T10:46:29.158975Z"
    }
   },
   "outputs": [],
   "source": [
    "def select_feature(X, Y, feature_num=100):\n",
    "    \"\"\"\n",
    "    X: features\n",
    "    Y: labels\n",
    "    feature_num: num of selected features\n",
    "    return: index of selected features\n",
    "    \"\"\"\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "    model = XGBRegressor()\n",
    "    model.fit(X, Y)\n",
    "    model.importance_type = 'weight'\n",
    "    ind = (-model.feature_importances_).argsort()[0:feature_num]\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a661c6f2",
   "metadata": {},
   "source": [
    "## 5-folds TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2bfe3c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T10:46:29.167944Z",
     "start_time": "2021-12-28T10:46:29.164563Z"
    }
   },
   "outputs": [],
   "source": [
    "def time_series_split(X, Y, n_split=5):\n",
    "    \"\"\"\n",
    "    X: features, size * seq_len * feature_num\n",
    "    Y: labels, size * target_len\n",
    "    return: list of train_x, test_x, train_y, test_y\n",
    "    \"\"\"\n",
    "    tscv = TimeSeriesSplit(n_splits=n_split)\n",
    "    train_x_list = list()\n",
    "    valid_x_list = list()\n",
    "    train_y_list = list()\n",
    "    valid_y_list = list()\n",
    "    for train_index, valid_index in tscv.split(X):\n",
    "        train_x_list.append(X[train_index])\n",
    "        train_y_list.append(Y[train_index])\n",
    "        valid_x_list.append(X[valid_index])\n",
    "        valid_y_list.append(Y[valid_index])\n",
    "    return train_x_list, train_y_list, valid_x_list, valid_y_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e931502",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T14:02:51.856018Z",
     "start_time": "2021-12-21T14:02:51.852675Z"
    }
   },
   "source": [
    "## model define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b97aa81e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T14:19:36.436084Z",
     "start_time": "2021-12-28T14:19:36.428134Z"
    }
   },
   "outputs": [],
   "source": [
    "class FNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A fnn neural network\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, output_size, hidden_dim, drop_prob):\n",
    "        super(FNN, self).__init__()\n",
    "        \n",
    "        self.fnn = nn.Sequential(\n",
    "            nn.Linear(input_size, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_prob),\n",
    "            nn.Linear(40, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_prob),\n",
    "            nn.Linear(hidden_dim,output_size),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fnn(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44902425",
   "metadata": {},
   "source": [
    "## model training for  hyper-parameters optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e70ff1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T10:46:29.183871Z",
     "start_time": "2021-12-28T10:46:29.175647Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train_model_hpo(train_x_list, train_y_list, valid_x_list, valid_y_list,\n",
    "                    input_size, output_size, mse_thresh, batch_size, lr,\n",
    "                    number_epoch, hidden_dim, drop_prob, weight_decay):\n",
    "    valid_loss_list = []\n",
    "    for num in range(len(train_x_list)):\n",
    "        while (1):\n",
    "            model_fnn = FNN(input_size, output_size, hidden_dim, drop_prob)\n",
    "            model_fnn.to(device=device)\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = torch.optim.Adam(model_fnn.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "            scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                        step_size=1,\n",
    "                                                        gamma=0.98)\n",
    "            valid_loss_min = np.Inf\n",
    "            print('cross-validation dataset {}'.format(num))\n",
    "            train_x = train_x_list[num]\n",
    "            train_y = train_y_list[num]\n",
    "            valid_x = valid_x_list[num]\n",
    "            valid_y = valid_y_list[num]\n",
    "            train_dataset = TensorDataset(torch.FloatTensor(train_x),\n",
    "                                          torch.FloatTensor(train_y))\n",
    "            valid_dataset = TensorDataset(torch.FloatTensor(valid_x),\n",
    "                                          torch.FloatTensor(valid_y))\n",
    "            train_loader = DataLoader(dataset=train_dataset,\n",
    "                                      batch_size=batch_size,\n",
    "                                      shuffle=True,\n",
    "                                      drop_last=False)\n",
    "            valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                                      batch_size=batch_size,\n",
    "                                      shuffle=True,\n",
    "                                      drop_last=False)\n",
    "            num_without_imp = 0\n",
    "            # training process\n",
    "            for epoch in range(1, number_epoch + 1):\n",
    "                loop = tqdm(enumerate(train_loader),\n",
    "                            total=len(train_loader),\n",
    "                            leave=True)\n",
    "                for i, (inputs, labels) in loop:\n",
    "                    inputs = inputs.to(device=device)\n",
    "                    labels = labels.to(device=device)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model_fnn(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    if i % 5 == 0:\n",
    "                        num_without_imp = num_without_imp + 1\n",
    "                        valid_losses = list()\n",
    "                        model_fnn.eval()\n",
    "                        for inp, lab in valid_loader:\n",
    "                            inp = inp.to(device)\n",
    "                            lab = lab.to(device)\n",
    "                            out = model_fnn(inp)\n",
    "                            valid_loss = criterion(out, lab)\n",
    "                            valid_losses.append(valid_loss.item())\n",
    "\n",
    "                        model_fnn.train()\n",
    "                        loop.set_description(\"Epoch: {}/{}\".format(\n",
    "                            epoch, number_epoch))\n",
    "                        loop.set_postfix(train_loss=loss.item(),\n",
    "                                         valid_loss=np.mean(valid_losses))\n",
    "                        if np.mean(valid_losses) < valid_loss_min:\n",
    "                            num_without_imp = 0\n",
    "                            valid_loss_min = np.mean(valid_losses)\n",
    "                scheduler.step()\n",
    "                if num_without_imp >= 80:\n",
    "                    break\n",
    "            if valid_loss_min < mse_thresh:\n",
    "                valid_loss_list.append(valid_loss_min)\n",
    "                break\n",
    "    return np.mean(valid_loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8449b8f",
   "metadata": {},
   "source": [
    "## hyper-parameters config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3db74ce3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T10:46:29.189253Z",
     "start_time": "2021-12-28T10:46:29.185555Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_len = 72\n",
    "target_len = 24\n",
    "feature_num = 100\n",
    "mse_thresh = 0.01\n",
    "\n",
    "\n",
    "def model_config():\n",
    "    batch_sizes = [256, 128, 512]\n",
    "    lrs = [0.005, 0.001, 0.01]\n",
    "    number_epochs = [50]\n",
    "    hidden_dims = [35, 30, 25]\n",
    "    drop_probs = [0.1]\n",
    "    weight_decays = [1e-7]\n",
    "    configs = list()\n",
    "    for i in batch_sizes:\n",
    "        for j in lrs:\n",
    "            for k in number_epochs:\n",
    "                for l in hidden_dims:\n",
    "                    for m in drop_probs:\n",
    "                        for n in weight_decays:\n",
    "                            configs.append({\n",
    "                                'batch_size': i,\n",
    "                                'lr': j,\n",
    "                                'number_epoch': k,\n",
    "                                'hidden_dim': l,\n",
    "                                'drop_prob': m,\n",
    "                                'weight_decay': n\n",
    "                            })\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abd5d80",
   "metadata": {},
   "source": [
    "## random search for HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9a32d12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T10:46:29.195524Z",
     "start_time": "2021-12-28T10:46:29.190645Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_model_hpo(seq_len=seq_len,\n",
    "                  target_len=target_len,\n",
    "                  feature_num=feature_num,\n",
    "                  mse_thresh=mse_thresh):\n",
    "    train_data = data[:int(0.7 * len(data))]\n",
    "    train_data, _, _ = normalization(train_data)\n",
    "    train_x, train_y = Series_To_Supervise(train_data, seq_len, target_len)\n",
    "    #     ind = select_feature(train_x, train_y, feature_num=feature_num)\n",
    "    train_x = train_x.reshape(train_x.shape[0], -1)\n",
    "    train_x_list, train_y_list, valid_x_list, valid_y_list = time_series_split(\n",
    "        train_x, train_y)\n",
    "#     with enough data\n",
    "#     train_x_list = train_x_list[-1:]\n",
    "#     train_y_list = train_y_list[-1:]\n",
    "#     valid_x_list = valid_x_list[-1:]\n",
    "#     valid_y_list = valid_y_list[-1:]\n",
    "    \n",
    "    configs = model_config()\n",
    "    records = []\n",
    "    input_size = train_x.shape[1]\n",
    "    output_size = target_len\n",
    "    for i in range(20):\n",
    "        config = random.choice(configs)\n",
    "        configs.remove(config)\n",
    "        batch_size = config['batch_size']\n",
    "        lr = config['lr']\n",
    "        number_epoch = config['number_epoch']\n",
    "        hidden_dim = config['hidden_dim']\n",
    "        drop_prob = config['drop_prob']\n",
    "        weight_decay = config['weight_decay']\n",
    "        print(\n",
    "            \"model config: batch_size--{}, lr--{}, number_epoch--{}, hidden_dim--{},drop_prob-{},weight_decay-{}\"\n",
    "            .format(batch_size, lr, number_epoch, hidden_dim, drop_prob, weight_decay))\n",
    "        valid_loss = train_model_hpo(train_x_list, train_y_list, valid_x_list,\n",
    "                                     valid_y_list, input_size, output_size,\n",
    "                                     mse_thresh, batch_size, lr, number_epoch,\n",
    "                                     hidden_dim, drop_prob, weight_decay)\n",
    "        records.append({\n",
    "            'batch_size': batch_size,\n",
    "            'lr': lr,\n",
    "            'number_epoch': number_epoch,\n",
    "            'hidden_dim': hidden_dim,\n",
    "            'drop_prob': drop_prob,\n",
    "            'weight_decay': weight_decay,\n",
    "            'valid_loss': valid_loss\n",
    "        })\n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc55095f",
   "metadata": {},
   "source": [
    "## run random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03ecb5b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T11:07:00.157766Z",
     "start_time": "2021-12-28T10:46:32.825752Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised Data: Shape of x: (22066, 72, 1), Shape of y: (22066, 24)\n",
      "model config: batch_size--128, lr--0.005, number_epoch--50, hidden_dim--25,drop_prob-0.1,weight_decay-1e-07\n",
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 29/29 [00:01<00:00, 18.34it/s, train_loss=0.0226, valid_loss=0.0369]\n",
      "Epoch: 2/50: 100%|██████████| 29/29 [00:00<00:00, 124.94it/s, train_loss=0.0131, valid_loss=0.0206]\n",
      "Epoch: 3/50: 100%|██████████| 29/29 [00:00<00:00, 133.89it/s, train_loss=0.0105, valid_loss=0.0133] \n",
      "Epoch: 4/50: 100%|██████████| 29/29 [00:00<00:00, 143.98it/s, train_loss=0.00863, valid_loss=0.0123]\n",
      "Epoch: 5/50: 100%|██████████| 29/29 [00:00<00:00, 133.54it/s, train_loss=0.00912, valid_loss=0.0119]\n",
      "Epoch: 6/50: 100%|██████████| 29/29 [00:00<00:00, 107.22it/s, train_loss=0.0072, valid_loss=0.0117]\n",
      "Epoch: 7/50: 100%|██████████| 29/29 [00:00<00:00, 142.65it/s, train_loss=0.00438, valid_loss=0.00645]\n",
      "Epoch: 8/50: 100%|██████████| 29/29 [00:00<00:00, 140.06it/s, train_loss=0.00369, valid_loss=0.00532]\n",
      "Epoch: 9/50: 100%|██████████| 29/29 [00:00<00:00, 111.32it/s, train_loss=0.00353, valid_loss=0.00569]\n",
      "Epoch: 10/50: 100%|██████████| 29/29 [00:00<00:00, 135.44it/s, train_loss=0.00335, valid_loss=0.00496]\n",
      "Epoch: 11/50: 100%|██████████| 29/29 [00:00<00:00, 132.53it/s, train_loss=0.00274, valid_loss=0.00519]\n",
      "Epoch: 12/50: 100%|██████████| 29/29 [00:00<00:00, 124.16it/s, train_loss=0.00316, valid_loss=0.00479]\n",
      "Epoch: 13/50: 100%|██████████| 29/29 [00:00<00:00, 114.89it/s, train_loss=0.00285, valid_loss=0.00569]\n",
      "Epoch: 14/50: 100%|██████████| 29/29 [00:00<00:00, 133.62it/s, train_loss=0.00291, valid_loss=0.00498]\n",
      "Epoch: 15/50: 100%|██████████| 29/29 [00:00<00:00, 112.83it/s, train_loss=0.00323, valid_loss=0.00523]\n",
      "Epoch: 16/50: 100%|██████████| 29/29 [00:00<00:00, 122.28it/s, train_loss=0.00298, valid_loss=0.00505]\n",
      "Epoch: 17/50: 100%|██████████| 29/29 [00:00<00:00, 113.49it/s, train_loss=0.00299, valid_loss=0.00491]\n",
      "Epoch: 18/50: 100%|██████████| 29/29 [00:00<00:00, 134.21it/s, train_loss=0.003, valid_loss=0.00523]  \n",
      "Epoch: 19/50: 100%|██████████| 29/29 [00:00<00:00, 117.57it/s, train_loss=0.00313, valid_loss=0.00542]\n",
      "Epoch: 20/50: 100%|██████████| 29/29 [00:00<00:00, 125.72it/s, train_loss=0.00318, valid_loss=0.00483]\n",
      "Epoch: 21/50: 100%|██████████| 29/29 [00:00<00:00, 132.55it/s, train_loss=0.00325, valid_loss=0.00548]\n",
      "Epoch: 22/50: 100%|██████████| 29/29 [00:00<00:00, 144.64it/s, train_loss=0.00279, valid_loss=0.0051] \n",
      "Epoch: 23/50: 100%|██████████| 29/29 [00:00<00:00, 129.47it/s, train_loss=0.00306, valid_loss=0.00506]\n",
      "Epoch: 24/50: 100%|██████████| 29/29 [00:00<00:00, 142.63it/s, train_loss=0.00259, valid_loss=0.00501]\n",
      "Epoch: 25/50: 100%|██████████| 29/29 [00:00<00:00, 142.93it/s, train_loss=0.00259, valid_loss=0.00487]\n",
      "Epoch: 26/50: 100%|██████████| 29/29 [00:00<00:00, 130.30it/s, train_loss=0.00301, valid_loss=0.00492]\n",
      "Epoch: 27/50: 100%|██████████| 29/29 [00:00<00:00, 131.96it/s, train_loss=0.0026, valid_loss=0.00512]\n",
      "Epoch: 28/50: 100%|██████████| 29/29 [00:00<00:00, 136.64it/s, train_loss=0.0028, valid_loss=0.00497] \n",
      "Epoch: 29/50: 100%|██████████| 29/29 [00:00<00:00, 112.95it/s, train_loss=0.00271, valid_loss=0.00492]\n",
      "Epoch: 30/50: 100%|██████████| 29/29 [00:00<00:00, 127.68it/s, train_loss=0.00323, valid_loss=0.00473]\n",
      "Epoch: 31/50: 100%|██████████| 29/29 [00:00<00:00, 114.27it/s, train_loss=0.00305, valid_loss=0.00522]\n",
      "Epoch: 32/50: 100%|██████████| 29/29 [00:00<00:00, 144.29it/s, train_loss=0.00279, valid_loss=0.0053] \n",
      "Epoch: 33/50: 100%|██████████| 29/29 [00:00<00:00, 142.36it/s, train_loss=0.00292, valid_loss=0.00539]\n",
      "Epoch: 34/50: 100%|██████████| 29/29 [00:00<00:00, 122.77it/s, train_loss=0.00293, valid_loss=0.00505]\n",
      "Epoch: 35/50: 100%|██████████| 29/29 [00:00<00:00, 133.43it/s, train_loss=0.00258, valid_loss=0.00501]\n",
      "Epoch: 36/50: 100%|██████████| 29/29 [00:00<00:00, 144.78it/s, train_loss=0.00233, valid_loss=0.00488]\n",
      "Epoch: 37/50: 100%|██████████| 29/29 [00:00<00:00, 122.64it/s, train_loss=0.00257, valid_loss=0.00502]\n",
      "Epoch: 38/50: 100%|██████████| 29/29 [00:00<00:00, 143.45it/s, train_loss=0.00335, valid_loss=0.00483]\n",
      "Epoch: 39/50: 100%|██████████| 29/29 [00:00<00:00, 129.98it/s, train_loss=0.00232, valid_loss=0.00507]\n",
      "Epoch: 40/50: 100%|██████████| 29/29 [00:00<00:00, 143.98it/s, train_loss=0.00264, valid_loss=0.00487]\n",
      "Epoch: 41/50: 100%|██████████| 29/29 [00:00<00:00, 134.27it/s, train_loss=0.00245, valid_loss=0.00489]\n",
      "Epoch: 42/50: 100%|██████████| 29/29 [00:00<00:00, 136.68it/s, train_loss=0.00275, valid_loss=0.00489]\n",
      "Epoch: 43/50: 100%|██████████| 29/29 [00:00<00:00, 133.40it/s, train_loss=0.00255, valid_loss=0.00478]\n",
      "Epoch: 44/50: 100%|██████████| 29/29 [00:00<00:00, 125.06it/s, train_loss=0.00279, valid_loss=0.00486]\n",
      "Epoch: 45/50: 100%|██████████| 29/29 [00:00<00:00, 130.22it/s, train_loss=0.00259, valid_loss=0.00489]\n",
      "Epoch: 46/50: 100%|██████████| 29/29 [00:00<00:00, 133.71it/s, train_loss=0.00245, valid_loss=0.00494]\n",
      "Epoch: 47/50: 100%|██████████| 29/29 [00:00<00:00, 136.16it/s, train_loss=0.00254, valid_loss=0.00476]\n",
      "Epoch: 48/50: 100%|██████████| 29/29 [00:00<00:00, 131.61it/s, train_loss=0.00246, valid_loss=0.0048]\n",
      "Epoch: 49/50: 100%|██████████| 29/29 [00:00<00:00, 124.15it/s, train_loss=0.00232, valid_loss=0.00496]\n",
      "Epoch: 50/50: 100%|██████████| 29/29 [00:00<00:00, 129.00it/s, train_loss=0.00224, valid_loss=0.00478]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 58/58 [00:00<00:00, 125.58it/s, train_loss=0.0204, valid_loss=0.0268]\n",
      "Epoch: 2/50: 100%|██████████| 58/58 [00:00<00:00, 132.43it/s, train_loss=0.0114, valid_loss=0.014] \n",
      "Epoch: 3/50: 100%|██████████| 58/58 [00:00<00:00, 133.44it/s, train_loss=0.0106, valid_loss=0.0163]\n",
      "Epoch: 4/50: 100%|██████████| 58/58 [00:00<00:00, 132.84it/s, train_loss=0.0126, valid_loss=0.014] \n",
      "Epoch: 5/50: 100%|██████████| 58/58 [00:00<00:00, 143.42it/s, train_loss=0.00538, valid_loss=0.00321]\n",
      "Epoch: 6/50: 100%|██████████| 58/58 [00:00<00:00, 138.43it/s, train_loss=0.00515, valid_loss=0.00523]\n",
      "Epoch: 7/50: 100%|██████████| 58/58 [00:00<00:00, 140.66it/s, train_loss=0.00513, valid_loss=0.0032] \n",
      "Epoch: 8/50: 100%|██████████| 58/58 [00:00<00:00, 130.74it/s, train_loss=0.00436, valid_loss=0.00214]\n",
      "Epoch: 9/50: 100%|██████████| 58/58 [00:00<00:00, 144.44it/s, train_loss=0.00369, valid_loss=0.00249]\n",
      "Epoch: 10/50: 100%|██████████| 58/58 [00:00<00:00, 129.03it/s, train_loss=0.00418, valid_loss=0.00414]\n",
      "Epoch: 11/50: 100%|██████████| 58/58 [00:00<00:00, 128.72it/s, train_loss=0.00472, valid_loss=0.00405]\n",
      "Epoch: 12/50: 100%|██████████| 58/58 [00:00<00:00, 138.73it/s, train_loss=0.00433, valid_loss=0.002]  \n",
      "Epoch: 13/50: 100%|██████████| 58/58 [00:00<00:00, 131.15it/s, train_loss=0.00565, valid_loss=0.00199]\n",
      "Epoch: 14/50: 100%|██████████| 58/58 [00:00<00:00, 139.50it/s, train_loss=0.00491, valid_loss=0.0024] \n",
      "Epoch: 15/50: 100%|██████████| 58/58 [00:00<00:00, 133.74it/s, train_loss=0.00486, valid_loss=0.00242]\n",
      "Epoch: 16/50: 100%|██████████| 58/58 [00:00<00:00, 138.42it/s, train_loss=0.00502, valid_loss=0.00201]\n",
      "Epoch: 17/50: 100%|██████████| 58/58 [00:00<00:00, 133.35it/s, train_loss=0.00521, valid_loss=0.00201]\n",
      "Epoch: 18/50: 100%|██████████| 58/58 [00:00<00:00, 127.71it/s, train_loss=0.00449, valid_loss=0.00288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 87/87 [00:00<00:00, 119.67it/s, train_loss=0.0155, valid_loss=0.015] \n",
      "Epoch: 2/50: 100%|██████████| 87/87 [00:00<00:00, 135.10it/s, train_loss=0.00676, valid_loss=0.00458]\n",
      "Epoch: 3/50: 100%|██████████| 87/87 [00:00<00:00, 134.65it/s, train_loss=0.0053, valid_loss=0.00511] \n",
      "Epoch: 4/50: 100%|██████████| 87/87 [00:00<00:00, 136.76it/s, train_loss=0.00607, valid_loss=0.00437]\n",
      "Epoch: 5/50: 100%|██████████| 87/87 [00:00<00:00, 131.33it/s, train_loss=0.00484, valid_loss=0.00465]\n",
      "Epoch: 6/50: 100%|██████████| 87/87 [00:00<00:00, 135.67it/s, train_loss=0.00494, valid_loss=0.00387]\n",
      "Epoch: 7/50: 100%|██████████| 87/87 [00:00<00:00, 126.45it/s, train_loss=0.00509, valid_loss=0.00425]\n",
      "Epoch: 8/50: 100%|██████████| 87/87 [00:00<00:00, 121.36it/s, train_loss=0.00453, valid_loss=0.00406]\n",
      "Epoch: 9/50: 100%|██████████| 87/87 [00:00<00:00, 131.83it/s, train_loss=0.00507, valid_loss=0.00397]\n",
      "Epoch: 10/50: 100%|██████████| 87/87 [00:00<00:00, 131.60it/s, train_loss=0.00459, valid_loss=0.00388]\n",
      "Epoch: 11/50: 100%|██████████| 87/87 [00:00<00:00, 138.17it/s, train_loss=0.00504, valid_loss=0.00385]\n",
      "Epoch: 12/50: 100%|██████████| 87/87 [00:00<00:00, 132.97it/s, train_loss=0.0043, valid_loss=0.00362] \n",
      "Epoch: 13/50: 100%|██████████| 87/87 [00:00<00:00, 129.01it/s, train_loss=0.00407, valid_loss=0.00369]\n",
      "Epoch: 14/50: 100%|██████████| 87/87 [00:00<00:00, 131.48it/s, train_loss=0.00428, valid_loss=0.00372]\n",
      "Epoch: 15/50: 100%|██████████| 87/87 [00:00<00:00, 131.83it/s, train_loss=0.00512, valid_loss=0.00391]\n",
      "Epoch: 16/50: 100%|██████████| 87/87 [00:00<00:00, 141.03it/s, train_loss=0.00402, valid_loss=0.00399]\n",
      "Epoch: 17/50: 100%|██████████| 87/87 [00:00<00:00, 120.76it/s, train_loss=0.00438, valid_loss=0.00384]\n",
      "Epoch: 18/50: 100%|██████████| 87/87 [00:00<00:00, 112.13it/s, train_loss=0.00364, valid_loss=0.00353]\n",
      "Epoch: 19/50: 100%|██████████| 87/87 [00:00<00:00, 129.62it/s, train_loss=0.00432, valid_loss=0.00384]\n",
      "Epoch: 20/50: 100%|██████████| 87/87 [00:00<00:00, 119.33it/s, train_loss=0.00449, valid_loss=0.00348]\n",
      "Epoch: 21/50: 100%|██████████| 87/87 [00:00<00:00, 130.60it/s, train_loss=0.00413, valid_loss=0.00369]\n",
      "Epoch: 22/50: 100%|██████████| 87/87 [00:00<00:00, 130.64it/s, train_loss=0.00394, valid_loss=0.00372]\n",
      "Epoch: 23/50: 100%|██████████| 87/87 [00:00<00:00, 135.57it/s, train_loss=0.00414, valid_loss=0.00386]\n",
      "Epoch: 24/50: 100%|██████████| 87/87 [00:00<00:00, 132.21it/s, train_loss=0.00424, valid_loss=0.0035] \n",
      "Epoch: 25/50: 100%|██████████| 87/87 [00:00<00:00, 128.83it/s, train_loss=0.00398, valid_loss=0.00441]\n",
      "Epoch: 26/50: 100%|██████████| 87/87 [00:00<00:00, 129.78it/s, train_loss=0.00508, valid_loss=0.00414]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 115/115 [00:00<00:00, 135.51it/s, train_loss=0.00726, valid_loss=0.00749]\n",
      "Epoch: 2/50: 100%|██████████| 115/115 [00:00<00:00, 115.43it/s, train_loss=0.00706, valid_loss=0.00331]\n",
      "Epoch: 3/50: 100%|██████████| 115/115 [00:00<00:00, 126.24it/s, train_loss=0.00626, valid_loss=0.0024] \n",
      "Epoch: 4/50: 100%|██████████| 115/115 [00:00<00:00, 129.46it/s, train_loss=0.00647, valid_loss=0.00374]\n",
      "Epoch: 5/50: 100%|██████████| 115/115 [00:00<00:00, 127.05it/s, train_loss=0.00582, valid_loss=0.00227]\n",
      "Epoch: 6/50: 100%|██████████| 115/115 [00:00<00:00, 137.23it/s, train_loss=0.00619, valid_loss=0.0025] \n",
      "Epoch: 7/50: 100%|██████████| 115/115 [00:00<00:00, 137.00it/s, train_loss=0.00615, valid_loss=0.00221]\n",
      "Epoch: 8/50: 100%|██████████| 115/115 [00:00<00:00, 138.02it/s, train_loss=0.00468, valid_loss=0.0026] \n",
      "Epoch: 9/50: 100%|██████████| 115/115 [00:00<00:00, 139.72it/s, train_loss=0.00553, valid_loss=0.00274]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 144/144 [00:01<00:00, 126.84it/s, train_loss=0.00797, valid_loss=0.00524]\n",
      "Epoch: 2/50: 100%|██████████| 144/144 [00:01<00:00, 125.20it/s, train_loss=0.00594, valid_loss=0.00346]\n",
      "Epoch: 3/50: 100%|██████████| 144/144 [00:01<00:00, 127.51it/s, train_loss=0.00428, valid_loss=0.00296]\n",
      "Epoch: 4/50: 100%|██████████| 144/144 [00:01<00:00, 130.81it/s, train_loss=0.00431, valid_loss=0.00279]\n",
      "Epoch: 5/50: 100%|██████████| 144/144 [00:01<00:00, 132.85it/s, train_loss=0.00476, valid_loss=0.0025] \n",
      "Epoch: 6/50: 100%|██████████| 144/144 [00:01<00:00, 134.81it/s, train_loss=0.00426, valid_loss=0.0024] \n",
      "Epoch: 7/50: 100%|██████████| 144/144 [00:01<00:00, 135.95it/s, train_loss=0.00422, valid_loss=0.00236]\n",
      "Epoch: 8/50: 100%|██████████| 144/144 [00:01<00:00, 134.55it/s, train_loss=0.00475, valid_loss=0.00248]\n",
      "Epoch: 9/50: 100%|██████████| 144/144 [00:01<00:00, 124.41it/s, train_loss=0.00489, valid_loss=0.00248]\n",
      "Epoch: 10/50: 100%|██████████| 144/144 [00:01<00:00, 136.36it/s, train_loss=0.00474, valid_loss=0.00274]\n",
      "Epoch: 11/50: 100%|██████████| 144/144 [00:01<00:00, 134.43it/s, train_loss=0.00461, valid_loss=0.00234]\n",
      "Epoch: 12/50: 100%|██████████| 144/144 [00:01<00:00, 141.74it/s, train_loss=0.00422, valid_loss=0.00251]\n",
      "Epoch: 13/50: 100%|██████████| 144/144 [00:01<00:00, 135.96it/s, train_loss=0.00326, valid_loss=0.00242]\n",
      "Epoch: 14/50: 100%|██████████| 144/144 [00:01<00:00, 134.57it/s, train_loss=0.00451, valid_loss=0.00217]\n",
      "Epoch: 15/50: 100%|██████████| 144/144 [00:01<00:00, 132.20it/s, train_loss=0.0051, valid_loss=0.00222] \n",
      "Epoch: 16/50: 100%|██████████| 144/144 [00:01<00:00, 128.91it/s, train_loss=0.00535, valid_loss=0.00224]\n",
      "Epoch: 17/50: 100%|██████████| 144/144 [00:01<00:00, 134.50it/s, train_loss=0.00435, valid_loss=0.00219]\n",
      "Epoch: 18/50: 100%|██████████| 144/144 [00:01<00:00, 139.72it/s, train_loss=0.00427, valid_loss=0.00211]\n",
      "Epoch: 19/50: 100%|██████████| 144/144 [00:01<00:00, 136.13it/s, train_loss=0.00491, valid_loss=0.00208]\n",
      "Epoch: 20/50: 100%|██████████| 144/144 [00:01<00:00, 134.16it/s, train_loss=0.00384, valid_loss=0.00218]\n",
      "Epoch: 21/50: 100%|██████████| 144/144 [00:01<00:00, 131.36it/s, train_loss=0.00356, valid_loss=0.00221]\n",
      "Epoch: 22/50: 100%|██████████| 144/144 [00:01<00:00, 117.84it/s, train_loss=0.00421, valid_loss=0.00212]\n",
      "Epoch: 23/50: 100%|██████████| 144/144 [00:01<00:00, 124.62it/s, train_loss=0.00418, valid_loss=0.00219]\n",
      "Epoch: 24/50: 100%|██████████| 144/144 [00:01<00:00, 129.20it/s, train_loss=0.00359, valid_loss=0.00223]\n",
      "Epoch: 25/50: 100%|██████████| 144/144 [00:01<00:00, 134.32it/s, train_loss=0.00373, valid_loss=0.00215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config: batch_size--512, lr--0.005, number_epoch--50, hidden_dim--25,drop_prob-0.1,weight_decay-1e-07\n",
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 8/8 [00:00<00:00, 80.52it/s, train_loss=0.061, valid_loss=0.0837]\n",
      "Epoch: 2/50: 100%|██████████| 8/8 [00:00<00:00, 88.93it/s, train_loss=0.0374, valid_loss=0.0554]\n",
      "Epoch: 3/50: 100%|██████████| 8/8 [00:00<00:00, 132.94it/s, train_loss=0.0318, valid_loss=0.0473]\n",
      "Epoch: 4/50: 100%|██████████| 8/8 [00:00<00:00, 118.91it/s, train_loss=0.0262, valid_loss=0.0401]\n",
      "Epoch: 5/50: 100%|██████████| 8/8 [00:00<00:00, 54.42it/s, train_loss=0.0234, valid_loss=0.0374]\n",
      "Epoch: 6/50: 100%|██████████| 8/8 [00:00<00:00, 128.11it/s, train_loss=0.0224, valid_loss=0.0358]\n",
      "Epoch: 7/50: 100%|██████████| 8/8 [00:00<00:00, 129.85it/s, train_loss=0.0219, valid_loss=0.0343]\n",
      "Epoch: 8/50: 100%|██████████| 8/8 [00:00<00:00, 78.40it/s, train_loss=0.0204, valid_loss=0.0322]\n",
      "Epoch: 9/50: 100%|██████████| 8/8 [00:00<00:00, 102.92it/s, train_loss=0.0202, valid_loss=0.0305]\n",
      "Epoch: 10/50: 100%|██████████| 8/8 [00:00<00:00, 91.11it/s, train_loss=0.0197, valid_loss=0.0297]\n",
      "Epoch: 11/50: 100%|██████████| 8/8 [00:00<00:00, 125.41it/s, train_loss=0.0187, valid_loss=0.0288]\n",
      "Epoch: 12/50: 100%|██████████| 8/8 [00:00<00:00, 129.91it/s, train_loss=0.018, valid_loss=0.027]\n",
      "Epoch: 13/50: 100%|██████████| 8/8 [00:00<00:00, 126.98it/s, train_loss=0.0184, valid_loss=0.026]\n",
      "Epoch: 14/50: 100%|██████████| 8/8 [00:00<00:00, 67.21it/s, train_loss=0.0177, valid_loss=0.0251]\n",
      "Epoch: 15/50: 100%|██████████| 8/8 [00:00<00:00, 125.76it/s, train_loss=0.0177, valid_loss=0.0241]\n",
      "Epoch: 16/50: 100%|██████████| 8/8 [00:00<00:00, 103.75it/s, train_loss=0.0131, valid_loss=0.0192]\n",
      "Epoch: 17/50: 100%|██████████| 8/8 [00:00<00:00, 128.30it/s, train_loss=0.0132, valid_loss=0.019]\n",
      "Epoch: 18/50: 100%|██████████| 8/8 [00:00<00:00, 96.79it/s, train_loss=0.0129, valid_loss=0.0185]\n",
      "Epoch: 19/50: 100%|██████████| 8/8 [00:00<00:00, 102.30it/s, train_loss=0.0128, valid_loss=0.018]\n",
      "Epoch: 20/50: 100%|██████████| 8/8 [00:00<00:00, 127.34it/s, train_loss=0.0119, valid_loss=0.0176]\n",
      "Epoch: 21/50: 100%|██████████| 8/8 [00:00<00:00, 109.48it/s, train_loss=0.0122, valid_loss=0.0173]\n",
      "Epoch: 22/50: 100%|██████████| 8/8 [00:00<00:00, 126.16it/s, train_loss=0.0122, valid_loss=0.0174]\n",
      "Epoch: 23/50: 100%|██████████| 8/8 [00:00<00:00, 97.74it/s, train_loss=0.0122, valid_loss=0.0173]\n",
      "Epoch: 24/50: 100%|██████████| 8/8 [00:00<00:00, 127.57it/s, train_loss=0.0118, valid_loss=0.0174]\n",
      "Epoch: 25/50: 100%|██████████| 8/8 [00:00<00:00, 96.95it/s, train_loss=0.0118, valid_loss=0.0172]\n",
      "Epoch: 26/50: 100%|██████████| 8/8 [00:00<00:00, 124.48it/s, train_loss=0.0123, valid_loss=0.0172]\n",
      "Epoch: 27/50: 100%|██████████| 8/8 [00:00<00:00, 129.26it/s, train_loss=0.0121, valid_loss=0.0171]\n",
      "Epoch: 28/50: 100%|██████████| 8/8 [00:00<00:00, 126.77it/s, train_loss=0.0126, valid_loss=0.0171]\n",
      "Epoch: 29/50: 100%|██████████| 8/8 [00:00<00:00, 122.34it/s, train_loss=0.0116, valid_loss=0.0173]\n",
      "Epoch: 30/50: 100%|██████████| 8/8 [00:00<00:00, 128.39it/s, train_loss=0.0116, valid_loss=0.0173]\n",
      "Epoch: 31/50: 100%|██████████| 8/8 [00:00<00:00, 68.61it/s, train_loss=0.0109, valid_loss=0.017]\n",
      "Epoch: 32/50: 100%|██████████| 8/8 [00:00<00:00, 125.26it/s, train_loss=0.0117, valid_loss=0.0171]\n",
      "Epoch: 33/50: 100%|██████████| 8/8 [00:00<00:00, 96.27it/s, train_loss=0.0118, valid_loss=0.0174]\n",
      "Epoch: 34/50: 100%|██████████| 8/8 [00:00<00:00, 93.65it/s, train_loss=0.0119, valid_loss=0.0171]\n",
      "Epoch: 35/50: 100%|██████████| 8/8 [00:00<00:00, 97.60it/s, train_loss=0.0117, valid_loss=0.0168]\n",
      "Epoch: 36/50: 100%|██████████| 8/8 [00:00<00:00, 126.04it/s, train_loss=0.0117, valid_loss=0.0171]\n",
      "Epoch: 37/50: 100%|██████████| 8/8 [00:00<00:00, 109.50it/s, train_loss=0.0111, valid_loss=0.0171]\n",
      "Epoch: 38/50: 100%|██████████| 8/8 [00:00<00:00, 127.29it/s, train_loss=0.0111, valid_loss=0.017]\n",
      "Epoch: 39/50: 100%|██████████| 8/8 [00:00<00:00, 97.61it/s, train_loss=0.0114, valid_loss=0.0171]\n",
      "Epoch: 40/50: 100%|██████████| 8/8 [00:00<00:00, 123.43it/s, train_loss=0.0117, valid_loss=0.0173]\n",
      "Epoch: 41/50: 100%|██████████| 8/8 [00:00<00:00, 71.15it/s, train_loss=0.0114, valid_loss=0.0172]\n",
      "Epoch: 42/50: 100%|██████████| 8/8 [00:00<00:00, 102.92it/s, train_loss=0.0116, valid_loss=0.017]\n",
      "Epoch: 43/50: 100%|██████████| 8/8 [00:00<00:00, 128.99it/s, train_loss=0.0112, valid_loss=0.0171]\n",
      "Epoch: 44/50: 100%|██████████| 8/8 [00:00<00:00, 85.64it/s, train_loss=0.0115, valid_loss=0.0172]\n",
      "Epoch: 45/50: 100%|██████████| 8/8 [00:00<00:00, 128.55it/s, train_loss=0.0113, valid_loss=0.0169]\n",
      "Epoch: 46/50: 100%|██████████| 8/8 [00:00<00:00, 131.18it/s, train_loss=0.0118, valid_loss=0.0171]\n",
      "Epoch: 47/50: 100%|██████████| 8/8 [00:00<00:00, 128.01it/s, train_loss=0.0115, valid_loss=0.0169]\n",
      "Epoch: 48/50: 100%|██████████| 8/8 [00:00<00:00, 96.94it/s, train_loss=0.0113, valid_loss=0.0168]\n",
      "Epoch: 49/50: 100%|██████████| 8/8 [00:00<00:00, 126.28it/s, train_loss=0.0112, valid_loss=0.0171]\n",
      "Epoch: 50/50: 100%|██████████| 8/8 [00:00<00:00, 97.54it/s, train_loss=0.0114, valid_loss=0.0174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 8/8 [00:00<00:00, 80.78it/s, train_loss=0.056, valid_loss=0.0776]\n",
      "Epoch: 2/50: 100%|██████████| 8/8 [00:00<00:00, 88.08it/s, train_loss=0.0374, valid_loss=0.0536]\n",
      "Epoch: 3/50: 100%|██████████| 8/8 [00:00<00:00, 131.08it/s, train_loss=0.0268, valid_loss=0.0413]\n",
      "Epoch: 4/50: 100%|██████████| 8/8 [00:00<00:00, 127.69it/s, train_loss=0.0238, valid_loss=0.0357]\n",
      "Epoch: 5/50: 100%|██████████| 8/8 [00:00<00:00, 99.84it/s, train_loss=0.0187, valid_loss=0.0291]\n",
      "Epoch: 6/50: 100%|██████████| 8/8 [00:00<00:00, 111.38it/s, train_loss=0.0154, valid_loss=0.0255]\n",
      "Epoch: 7/50: 100%|██████████| 8/8 [00:00<00:00, 96.85it/s, train_loss=0.0142, valid_loss=0.0234]\n",
      "Epoch: 8/50: 100%|██████████| 8/8 [00:00<00:00, 67.01it/s, train_loss=0.0131, valid_loss=0.0213]\n",
      "Epoch: 9/50: 100%|██████████| 8/8 [00:00<00:00, 102.02it/s, train_loss=0.0118, valid_loss=0.0194]\n",
      "Epoch: 10/50: 100%|██████████| 8/8 [00:00<00:00, 111.33it/s, train_loss=0.0111, valid_loss=0.0176]\n",
      "Epoch: 11/50: 100%|██████████| 8/8 [00:00<00:00, 127.25it/s, train_loss=0.0107, valid_loss=0.0158]\n",
      "Epoch: 12/50: 100%|██████████| 8/8 [00:00<00:00, 125.56it/s, train_loss=0.00945, valid_loss=0.0138]\n",
      "Epoch: 13/50: 100%|██████████| 8/8 [00:00<00:00, 129.63it/s, train_loss=0.00715, valid_loss=0.00837]\n",
      "Epoch: 14/50: 100%|██████████| 8/8 [00:00<00:00, 126.05it/s, train_loss=0.00593, valid_loss=0.00803]\n",
      "Epoch: 15/50: 100%|██████████| 8/8 [00:00<00:00, 130.02it/s, train_loss=0.00574, valid_loss=0.00724]\n",
      "Epoch: 16/50: 100%|██████████| 8/8 [00:00<00:00, 126.66it/s, train_loss=0.00532, valid_loss=0.00688]\n",
      "Epoch: 17/50: 100%|██████████| 8/8 [00:00<00:00, 80.74it/s, train_loss=0.00495, valid_loss=0.00658]\n",
      "Epoch: 18/50: 100%|██████████| 8/8 [00:00<00:00, 101.31it/s, train_loss=0.00486, valid_loss=0.00613]\n",
      "Epoch: 19/50: 100%|██████████| 8/8 [00:00<00:00, 110.28it/s, train_loss=0.00458, valid_loss=0.00585]\n",
      "Epoch: 20/50: 100%|██████████| 8/8 [00:00<00:00, 129.01it/s, train_loss=0.00446, valid_loss=0.00574]\n",
      "Epoch: 21/50: 100%|██████████| 8/8 [00:00<00:00, 129.92it/s, train_loss=0.00442, valid_loss=0.00539]\n",
      "Epoch: 22/50: 100%|██████████| 8/8 [00:00<00:00, 129.15it/s, train_loss=0.00442, valid_loss=0.00547]\n",
      "Epoch: 23/50: 100%|██████████| 8/8 [00:00<00:00, 107.61it/s, train_loss=0.00418, valid_loss=0.00493]\n",
      "Epoch: 24/50: 100%|██████████| 8/8 [00:00<00:00, 126.57it/s, train_loss=0.00372, valid_loss=0.00501]\n",
      "Epoch: 25/50: 100%|██████████| 8/8 [00:00<00:00, 117.59it/s, train_loss=0.00375, valid_loss=0.00493]\n",
      "Epoch: 26/50: 100%|██████████| 8/8 [00:00<00:00, 74.39it/s, train_loss=0.00395, valid_loss=0.0049]\n",
      "Epoch: 27/50: 100%|██████████| 8/8 [00:00<00:00, 116.26it/s, train_loss=0.00367, valid_loss=0.00472]\n",
      "Epoch: 28/50: 100%|██████████| 8/8 [00:00<00:00, 103.27it/s, train_loss=0.00349, valid_loss=0.00483]\n",
      "Epoch: 29/50: 100%|██████████| 8/8 [00:00<00:00, 104.20it/s, train_loss=0.0036, valid_loss=0.00453]\n",
      "Epoch: 30/50: 100%|██████████| 8/8 [00:00<00:00, 103.63it/s, train_loss=0.00341, valid_loss=0.00458]\n",
      "Epoch: 31/50: 100%|██████████| 8/8 [00:00<00:00, 113.11it/s, train_loss=0.00341, valid_loss=0.00451]\n",
      "Epoch: 32/50: 100%|██████████| 8/8 [00:00<00:00, 81.83it/s, train_loss=0.00348, valid_loss=0.00473]\n",
      "Epoch: 33/50: 100%|██████████| 8/8 [00:00<00:00, 128.88it/s, train_loss=0.00344, valid_loss=0.00461]\n",
      "Epoch: 34/50: 100%|██████████| 8/8 [00:00<00:00, 129.49it/s, train_loss=0.00347, valid_loss=0.0045]\n",
      "Epoch: 35/50: 100%|██████████| 8/8 [00:00<00:00, 126.70it/s, train_loss=0.00361, valid_loss=0.00468]\n",
      "Epoch: 36/50: 100%|██████████| 8/8 [00:00<00:00, 98.38it/s, train_loss=0.00341, valid_loss=0.00435]\n",
      "Epoch: 37/50: 100%|██████████| 8/8 [00:00<00:00, 119.33it/s, train_loss=0.00333, valid_loss=0.00502]\n",
      "Epoch: 38/50: 100%|██████████| 8/8 [00:00<00:00, 113.99it/s, train_loss=0.00348, valid_loss=0.00452]\n",
      "Epoch: 39/50: 100%|██████████| 8/8 [00:00<00:00, 129.86it/s, train_loss=0.00312, valid_loss=0.00439]\n",
      "Epoch: 40/50: 100%|██████████| 8/8 [00:00<00:00, 85.45it/s, train_loss=0.00319, valid_loss=0.00469]\n",
      "Epoch: 41/50: 100%|██████████| 8/8 [00:00<00:00, 129.04it/s, train_loss=0.00299, valid_loss=0.00449]\n",
      "Epoch: 42/50: 100%|██████████| 8/8 [00:00<00:00, 128.96it/s, train_loss=0.00305, valid_loss=0.0046]\n",
      "Epoch: 43/50: 100%|██████████| 8/8 [00:00<00:00, 82.31it/s, train_loss=0.00299, valid_loss=0.00447]\n",
      "Epoch: 44/50: 100%|██████████| 8/8 [00:00<00:00, 100.99it/s, train_loss=0.00332, valid_loss=0.00474]\n",
      "Epoch: 45/50: 100%|██████████| 8/8 [00:00<00:00, 127.92it/s, train_loss=0.0029, valid_loss=0.00484]\n",
      "Epoch: 46/50: 100%|██████████| 8/8 [00:00<00:00, 98.11it/s, train_loss=0.00304, valid_loss=0.00472]\n",
      "Epoch: 47/50: 100%|██████████| 8/8 [00:00<00:00, 130.86it/s, train_loss=0.00288, valid_loss=0.0045]\n",
      "Epoch: 48/50: 100%|██████████| 8/8 [00:00<00:00, 130.60it/s, train_loss=0.00296, valid_loss=0.00451]\n",
      "Epoch: 49/50: 100%|██████████| 8/8 [00:00<00:00, 127.92it/s, train_loss=0.00306, valid_loss=0.00454]\n",
      "Epoch: 50/50: 100%|██████████| 8/8 [00:00<00:00, 127.18it/s, train_loss=0.00313, valid_loss=0.00447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 15/15 [00:00<00:00, 85.53it/s, train_loss=0.0561, valid_loss=0.0727]\n",
      "Epoch: 2/50: 100%|██████████| 15/15 [00:00<00:00, 92.58it/s, train_loss=0.0287, valid_loss=0.0253]\n",
      "Epoch: 3/50: 100%|██████████| 15/15 [00:00<00:00, 141.78it/s, train_loss=0.0189, valid_loss=0.022]\n",
      "Epoch: 4/50: 100%|██████████| 15/15 [00:00<00:00, 114.08it/s, train_loss=0.0167, valid_loss=0.0194]\n",
      "Epoch: 5/50: 100%|██████████| 15/15 [00:00<00:00, 126.36it/s, train_loss=0.0138, valid_loss=0.0179]\n",
      "Epoch: 6/50: 100%|██████████| 15/15 [00:00<00:00, 114.00it/s, train_loss=0.0138, valid_loss=0.0155]\n",
      "Epoch: 7/50: 100%|██████████| 15/15 [00:00<00:00, 129.06it/s, train_loss=0.0121, valid_loss=0.0144]\n",
      "Epoch: 8/50: 100%|██████████| 15/15 [00:00<00:00, 119.48it/s, train_loss=0.0119, valid_loss=0.0139]\n",
      "Epoch: 9/50: 100%|██████████| 15/15 [00:00<00:00, 92.64it/s, train_loss=0.0115, valid_loss=0.0141]\n",
      "Epoch: 10/50: 100%|██████████| 15/15 [00:00<00:00, 141.33it/s, train_loss=0.0121, valid_loss=0.0118]\n",
      "Epoch: 11/50: 100%|██████████| 15/15 [00:00<00:00, 136.15it/s, train_loss=0.0108, valid_loss=0.0129]\n",
      "Epoch: 12/50: 100%|██████████| 15/15 [00:00<00:00, 124.80it/s, train_loss=0.0107, valid_loss=0.0135]\n",
      "Epoch: 13/50: 100%|██████████| 15/15 [00:00<00:00, 121.61it/s, train_loss=0.0107, valid_loss=0.0123]\n",
      "Epoch: 14/50: 100%|██████████| 15/15 [00:00<00:00, 141.19it/s, train_loss=0.0106, valid_loss=0.0121]\n",
      "Epoch: 15/50: 100%|██████████| 15/15 [00:00<00:00, 139.76it/s, train_loss=0.0104, valid_loss=0.0128]\n",
      "Epoch: 16/50: 100%|██████████| 15/15 [00:00<00:00, 106.30it/s, train_loss=0.0108, valid_loss=0.0119]\n",
      "Epoch: 17/50: 100%|██████████| 15/15 [00:00<00:00, 139.87it/s, train_loss=0.0115, valid_loss=0.0121]\n",
      "Epoch: 18/50: 100%|██████████| 15/15 [00:00<00:00, 124.65it/s, train_loss=0.0108, valid_loss=0.012]\n",
      "Epoch: 19/50: 100%|██████████| 15/15 [00:00<00:00, 142.66it/s, train_loss=0.00968, valid_loss=0.0116]\n",
      "Epoch: 20/50: 100%|██████████| 15/15 [00:00<00:00, 143.03it/s, train_loss=0.0104, valid_loss=0.0116]\n",
      "Epoch: 21/50: 100%|██████████| 15/15 [00:00<00:00, 140.10it/s, train_loss=0.0102, valid_loss=0.0117]\n",
      "Epoch: 22/50: 100%|██████████| 15/15 [00:00<00:00, 124.51it/s, train_loss=0.0109, valid_loss=0.0112]\n",
      "Epoch: 23/50: 100%|██████████| 15/15 [00:00<00:00, 137.91it/s, train_loss=0.0105, valid_loss=0.0114]\n",
      "Epoch: 24/50: 100%|██████████| 15/15 [00:00<00:00, 97.92it/s, train_loss=0.0104, valid_loss=0.0112]\n",
      "Epoch: 25/50: 100%|██████████| 15/15 [00:00<00:00, 137.78it/s, train_loss=0.01, valid_loss=0.0129]\n",
      "Epoch: 26/50: 100%|██████████| 15/15 [00:00<00:00, 140.09it/s, train_loss=0.00998, valid_loss=0.0117]\n",
      "Epoch: 27/50: 100%|██████████| 15/15 [00:00<00:00, 140.92it/s, train_loss=0.00954, valid_loss=0.0118]\n",
      "Epoch: 28/50: 100%|██████████| 15/15 [00:00<00:00, 120.58it/s, train_loss=0.0101, valid_loss=0.011]\n",
      "Epoch: 29/50: 100%|██████████| 15/15 [00:00<00:00, 142.60it/s, train_loss=0.00996, valid_loss=0.0121]\n",
      "Epoch: 30/50: 100%|██████████| 15/15 [00:00<00:00, 125.50it/s, train_loss=0.00965, valid_loss=0.012]\n",
      "Epoch: 31/50: 100%|██████████| 15/15 [00:00<00:00, 103.93it/s, train_loss=0.00974, valid_loss=0.012]\n",
      "Epoch: 32/50: 100%|██████████| 15/15 [00:00<00:00, 117.95it/s, train_loss=0.0101, valid_loss=0.0116]\n",
      "Epoch: 33/50: 100%|██████████| 15/15 [00:00<00:00, 139.91it/s, train_loss=0.01, valid_loss=0.0118]\n",
      "Epoch: 34/50: 100%|██████████| 15/15 [00:00<00:00, 128.51it/s, train_loss=0.0102, valid_loss=0.0113]\n",
      "Epoch: 35/50: 100%|██████████| 15/15 [00:00<00:00, 133.76it/s, train_loss=0.0102, valid_loss=0.0115]\n",
      "Epoch: 36/50: 100%|██████████| 15/15 [00:00<00:00, 128.20it/s, train_loss=0.0099, valid_loss=0.0113]\n",
      "Epoch: 37/50: 100%|██████████| 15/15 [00:00<00:00, 110.10it/s, train_loss=0.0103, valid_loss=0.0113]\n",
      "Epoch: 38/50: 100%|██████████| 15/15 [00:00<00:00, 91.88it/s, train_loss=0.00997, valid_loss=0.0116]\n",
      "Epoch: 39/50: 100%|██████████| 15/15 [00:00<00:00, 121.01it/s, train_loss=0.00991, valid_loss=0.0113]\n",
      "Epoch: 40/50: 100%|██████████| 15/15 [00:00<00:00, 139.48it/s, train_loss=0.00941, valid_loss=0.0115]\n",
      "Epoch: 41/50: 100%|██████████| 15/15 [00:00<00:00, 137.76it/s, train_loss=0.00968, valid_loss=0.0118]\n",
      "Epoch: 42/50: 100%|██████████| 15/15 [00:00<00:00, 140.50it/s, train_loss=0.0101, valid_loss=0.0118]\n",
      "Epoch: 43/50: 100%|██████████| 15/15 [00:00<00:00, 141.40it/s, train_loss=0.00989, valid_loss=0.0116]\n",
      "Epoch: 44/50: 100%|██████████| 15/15 [00:00<00:00, 140.48it/s, train_loss=0.00953, valid_loss=0.0109]\n",
      "Epoch: 45/50: 100%|██████████| 15/15 [00:00<00:00, 100.62it/s, train_loss=0.0099, valid_loss=0.0112]\n",
      "Epoch: 46/50: 100%|██████████| 15/15 [00:00<00:00, 141.23it/s, train_loss=0.00881, valid_loss=0.0111]\n",
      "Epoch: 47/50: 100%|██████████| 15/15 [00:00<00:00, 112.33it/s, train_loss=0.0103, valid_loss=0.0113]\n",
      "Epoch: 48/50: 100%|██████████| 15/15 [00:00<00:00, 139.89it/s, train_loss=0.00963, valid_loss=0.0115]\n",
      "Epoch: 49/50: 100%|██████████| 15/15 [00:00<00:00, 121.64it/s, train_loss=0.0101, valid_loss=0.011]\n",
      "Epoch: 50/50: 100%|██████████| 15/15 [00:00<00:00, 142.64it/s, train_loss=0.0103, valid_loss=0.011]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 15/15 [00:00<00:00, 90.62it/s, train_loss=0.0412, valid_loss=0.0464]\n",
      "Epoch: 2/50: 100%|██████████| 15/15 [00:00<00:00, 87.36it/s, train_loss=0.0282, valid_loss=0.0259]\n",
      "Epoch: 3/50: 100%|██████████| 15/15 [00:00<00:00, 135.79it/s, train_loss=0.0158, valid_loss=0.0103]\n",
      "Epoch: 4/50: 100%|██████████| 15/15 [00:00<00:00, 110.15it/s, train_loss=0.011, valid_loss=0.0104]\n",
      "Epoch: 5/50: 100%|██████████| 15/15 [00:00<00:00, 141.76it/s, train_loss=0.00859, valid_loss=0.00757]\n",
      "Epoch: 6/50: 100%|██████████| 15/15 [00:00<00:00, 142.12it/s, train_loss=0.00776, valid_loss=0.00708]\n",
      "Epoch: 7/50: 100%|██████████| 15/15 [00:00<00:00, 107.85it/s, train_loss=0.0069, valid_loss=0.00965]\n",
      "Epoch: 8/50: 100%|██████████| 15/15 [00:00<00:00, 99.66it/s, train_loss=0.00704, valid_loss=0.0045]\n",
      "Epoch: 9/50: 100%|██████████| 15/15 [00:00<00:00, 98.55it/s, train_loss=0.0058, valid_loss=0.00682]\n",
      "Epoch: 10/50: 100%|██████████| 15/15 [00:00<00:00, 141.86it/s, train_loss=0.00568, valid_loss=0.00399]\n",
      "Epoch: 11/50: 100%|██████████| 15/15 [00:00<00:00, 140.90it/s, train_loss=0.00602, valid_loss=0.00475]\n",
      "Epoch: 12/50: 100%|██████████| 15/15 [00:00<00:00, 142.76it/s, train_loss=0.00565, valid_loss=0.00527]\n",
      "Epoch: 13/50: 100%|██████████| 15/15 [00:00<00:00, 128.50it/s, train_loss=0.00594, valid_loss=0.0038]\n",
      "Epoch: 14/50: 100%|██████████| 15/15 [00:00<00:00, 135.67it/s, train_loss=0.00512, valid_loss=0.00525]\n",
      "Epoch: 15/50: 100%|██████████| 15/15 [00:00<00:00, 128.75it/s, train_loss=0.00536, valid_loss=0.00349]\n",
      "Epoch: 16/50: 100%|██████████| 15/15 [00:00<00:00, 128.48it/s, train_loss=0.00556, valid_loss=0.00534]\n",
      "Epoch: 17/50: 100%|██████████| 15/15 [00:00<00:00, 101.85it/s, train_loss=0.0049, valid_loss=0.00351]\n",
      "Epoch: 18/50: 100%|██████████| 15/15 [00:00<00:00, 117.00it/s, train_loss=0.00509, valid_loss=0.0052]\n",
      "Epoch: 19/50: 100%|██████████| 15/15 [00:00<00:00, 135.68it/s, train_loss=0.00498, valid_loss=0.00301]\n",
      "Epoch: 20/50: 100%|██████████| 15/15 [00:00<00:00, 129.71it/s, train_loss=0.00521, valid_loss=0.00323]\n",
      "Epoch: 21/50: 100%|██████████| 15/15 [00:00<00:00, 134.75it/s, train_loss=0.00459, valid_loss=0.00393]\n",
      "Epoch: 22/50: 100%|██████████| 15/15 [00:00<00:00, 142.07it/s, train_loss=0.00456, valid_loss=0.00301]\n",
      "Epoch: 23/50: 100%|██████████| 15/15 [00:00<00:00, 100.00it/s, train_loss=0.00465, valid_loss=0.00472]\n",
      "Epoch: 24/50: 100%|██████████| 15/15 [00:00<00:00, 129.77it/s, train_loss=0.00451, valid_loss=0.00391]\n",
      "Epoch: 25/50: 100%|██████████| 15/15 [00:00<00:00, 133.82it/s, train_loss=0.00468, valid_loss=0.0028]\n",
      "Epoch: 26/50: 100%|██████████| 15/15 [00:00<00:00, 103.08it/s, train_loss=0.00454, valid_loss=0.00409]\n",
      "Epoch: 27/50: 100%|██████████| 15/15 [00:00<00:00, 130.60it/s, train_loss=0.00462, valid_loss=0.00452]\n",
      "Epoch: 28/50: 100%|██████████| 15/15 [00:00<00:00, 122.31it/s, train_loss=0.00466, valid_loss=0.00327]\n",
      "Epoch: 29/50: 100%|██████████| 15/15 [00:00<00:00, 124.91it/s, train_loss=0.00449, valid_loss=0.00369]\n",
      "Epoch: 30/50: 100%|██████████| 15/15 [00:00<00:00, 130.40it/s, train_loss=0.00421, valid_loss=0.00366]\n",
      "Epoch: 31/50: 100%|██████████| 15/15 [00:00<00:00, 95.17it/s, train_loss=0.00469, valid_loss=0.00318]\n",
      "Epoch: 32/50: 100%|██████████| 15/15 [00:00<00:00, 134.76it/s, train_loss=0.0046, valid_loss=0.00384]\n",
      "Epoch: 33/50: 100%|██████████| 15/15 [00:00<00:00, 141.66it/s, train_loss=0.00466, valid_loss=0.00436]\n",
      "Epoch: 34/50: 100%|██████████| 15/15 [00:00<00:00, 126.75it/s, train_loss=0.00414, valid_loss=0.0039]\n",
      "Epoch: 35/50: 100%|██████████| 15/15 [00:00<00:00, 137.07it/s, train_loss=0.00422, valid_loss=0.00356]\n",
      "Epoch: 36/50: 100%|██████████| 15/15 [00:00<00:00, 110.90it/s, train_loss=0.00499, valid_loss=0.00439]\n",
      "Epoch: 37/50: 100%|██████████| 15/15 [00:00<00:00, 141.40it/s, train_loss=0.00484, valid_loss=0.00404]\n",
      "Epoch: 38/50: 100%|██████████| 15/15 [00:00<00:00, 104.66it/s, train_loss=0.00471, valid_loss=0.00437]\n",
      "Epoch: 39/50: 100%|██████████| 15/15 [00:00<00:00, 118.06it/s, train_loss=0.00429, valid_loss=0.00359]\n",
      "Epoch: 40/50: 100%|██████████| 15/15 [00:00<00:00, 134.95it/s, train_loss=0.00437, valid_loss=0.00338]\n",
      "Epoch: 41/50: 100%|██████████| 15/15 [00:00<00:00, 129.73it/s, train_loss=0.00415, valid_loss=0.00364]\n",
      "Epoch: 42/50: 100%|██████████| 15/15 [00:00<00:00, 135.36it/s, train_loss=0.0038, valid_loss=0.0037]\n",
      "Epoch: 43/50: 100%|██████████| 15/15 [00:00<00:00, 119.15it/s, train_loss=0.00452, valid_loss=0.00322]\n",
      "Epoch: 44/50: 100%|██████████| 15/15 [00:00<00:00, 110.28it/s, train_loss=0.00433, valid_loss=0.00387]\n",
      "Epoch: 45/50: 100%|██████████| 15/15 [00:00<00:00, 98.72it/s, train_loss=0.0044, valid_loss=0.00341]\n",
      "Epoch: 46/50: 100%|██████████| 15/15 [00:00<00:00, 106.36it/s, train_loss=0.00427, valid_loss=0.00305]\n",
      "Epoch: 47/50: 100%|██████████| 15/15 [00:00<00:00, 113.81it/s, train_loss=0.00399, valid_loss=0.00339]\n",
      "Epoch: 48/50: 100%|██████████| 15/15 [00:00<00:00, 135.03it/s, train_loss=0.00413, valid_loss=0.00354]\n",
      "Epoch: 49/50: 100%|██████████| 15/15 [00:00<00:00, 138.12it/s, train_loss=0.0041, valid_loss=0.00404]\n",
      "Epoch: 50/50: 100%|██████████| 15/15 [00:00<00:00, 91.94it/s, train_loss=0.00401, valid_loss=0.00397]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 22/22 [00:00<00:00, 80.94it/s, train_loss=0.0341, valid_loss=0.0393]\n",
      "Epoch: 2/50: 100%|██████████| 22/22 [00:00<00:00, 124.00it/s, train_loss=0.0274, valid_loss=0.0341]\n",
      "Epoch: 3/50: 100%|██████████| 22/22 [00:00<00:00, 122.53it/s, train_loss=0.0239, valid_loss=0.028] \n",
      "Epoch: 4/50: 100%|██████████| 22/22 [00:00<00:00, 133.20it/s, train_loss=0.0199, valid_loss=0.0227]\n",
      "Epoch: 5/50: 100%|██████████| 22/22 [00:00<00:00, 109.47it/s, train_loss=0.0197, valid_loss=0.0212]\n",
      "Epoch: 6/50: 100%|██████████| 22/22 [00:00<00:00, 123.71it/s, train_loss=0.0203, valid_loss=0.0208]\n",
      "Epoch: 7/50: 100%|██████████| 22/22 [00:00<00:00, 127.07it/s, train_loss=0.0148, valid_loss=0.0137]\n",
      "Epoch: 8/50: 100%|██████████| 22/22 [00:00<00:00, 124.46it/s, train_loss=0.0132, valid_loss=0.0127]\n",
      "Epoch: 9/50: 100%|██████████| 22/22 [00:00<00:00, 114.65it/s, train_loss=0.0129, valid_loss=0.0121]\n",
      "Epoch: 10/50: 100%|██████████| 22/22 [00:00<00:00, 95.81it/s, train_loss=0.012, valid_loss=0.012] \n",
      "Epoch: 11/50: 100%|██████████| 22/22 [00:00<00:00, 122.77it/s, train_loss=0.012, valid_loss=0.0119] \n",
      "Epoch: 12/50: 100%|██████████| 22/22 [00:00<00:00, 120.26it/s, train_loss=0.0121, valid_loss=0.0116]\n",
      "Epoch: 13/50: 100%|██████████| 22/22 [00:00<00:00, 134.65it/s, train_loss=0.0117, valid_loss=0.0116]\n",
      "Epoch: 14/50: 100%|██████████| 22/22 [00:00<00:00, 100.01it/s, train_loss=0.0113, valid_loss=0.0116]\n",
      "Epoch: 15/50: 100%|██████████| 22/22 [00:00<00:00, 124.14it/s, train_loss=0.0113, valid_loss=0.0114]\n",
      "Epoch: 16/50: 100%|██████████| 22/22 [00:00<00:00, 111.17it/s, train_loss=0.0113, valid_loss=0.0117]\n",
      "Epoch: 17/50: 100%|██████████| 22/22 [00:00<00:00, 114.02it/s, train_loss=0.012, valid_loss=0.0115] \n",
      "Epoch: 18/50: 100%|██████████| 22/22 [00:00<00:00, 123.49it/s, train_loss=0.0111, valid_loss=0.0117]\n",
      "Epoch: 19/50: 100%|██████████| 22/22 [00:00<00:00, 94.89it/s, train_loss=0.0104, valid_loss=0.0114] \n",
      "Epoch: 20/50: 100%|██████████| 22/22 [00:00<00:00, 132.59it/s, train_loss=0.0108, valid_loss=0.0116]\n",
      "Epoch: 21/50: 100%|██████████| 22/22 [00:00<00:00, 133.65it/s, train_loss=0.0103, valid_loss=0.0119]\n",
      "Epoch: 22/50: 100%|██████████| 22/22 [00:00<00:00, 121.85it/s, train_loss=0.0112, valid_loss=0.0113]\n",
      "Epoch: 23/50: 100%|██████████| 22/22 [00:00<00:00, 102.24it/s, train_loss=0.0111, valid_loss=0.0111]\n",
      "Epoch: 24/50: 100%|██████████| 22/22 [00:00<00:00, 124.16it/s, train_loss=0.0106, valid_loss=0.0114]\n",
      "Epoch: 25/50: 100%|██████████| 22/22 [00:00<00:00, 122.06it/s, train_loss=0.011, valid_loss=0.0113] \n",
      "Epoch: 26/50: 100%|██████████| 22/22 [00:00<00:00, 119.76it/s, train_loss=0.0108, valid_loss=0.0113]\n",
      "Epoch: 27/50: 100%|██████████| 22/22 [00:00<00:00, 133.90it/s, train_loss=0.0105, valid_loss=0.0115]\n",
      "Epoch: 28/50: 100%|██████████| 22/22 [00:00<00:00, 101.04it/s, train_loss=0.0114, valid_loss=0.0113]\n",
      "Epoch: 29/50: 100%|██████████| 22/22 [00:00<00:00, 132.32it/s, train_loss=0.0106, valid_loss=0.0113]\n",
      "Epoch: 30/50: 100%|██████████| 22/22 [00:00<00:00, 133.01it/s, train_loss=0.0105, valid_loss=0.0113]\n",
      "Epoch: 31/50: 100%|██████████| 22/22 [00:00<00:00, 101.09it/s, train_loss=0.0109, valid_loss=0.011]\n",
      "Epoch: 32/50: 100%|██████████| 22/22 [00:00<00:00, 118.53it/s, train_loss=0.0106, valid_loss=0.0111]\n",
      "Epoch: 33/50: 100%|██████████| 22/22 [00:00<00:00, 106.45it/s, train_loss=0.0109, valid_loss=0.011]\n",
      "Epoch: 34/50: 100%|██████████| 22/22 [00:00<00:00, 131.10it/s, train_loss=0.0106, valid_loss=0.0111]\n",
      "Epoch: 35/50: 100%|██████████| 22/22 [00:00<00:00, 122.09it/s, train_loss=0.00994, valid_loss=0.0111]\n",
      "Epoch: 36/50: 100%|██████████| 22/22 [00:00<00:00, 116.24it/s, train_loss=0.0102, valid_loss=0.011] \n",
      "Epoch: 37/50: 100%|██████████| 22/22 [00:00<00:00, 103.40it/s, train_loss=0.0104, valid_loss=0.0112]\n",
      "Epoch: 38/50: 100%|██████████| 22/22 [00:00<00:00, 133.19it/s, train_loss=0.0109, valid_loss=0.0113] \n",
      "Epoch: 39/50: 100%|██████████| 22/22 [00:00<00:00, 116.02it/s, train_loss=0.0113, valid_loss=0.0109]\n",
      "Epoch: 40/50: 100%|██████████| 22/22 [00:00<00:00, 130.74it/s, train_loss=0.0108, valid_loss=0.0111] \n",
      "Epoch: 41/50: 100%|██████████| 22/22 [00:00<00:00, 90.60it/s, train_loss=0.0106, valid_loss=0.0111] \n",
      "Epoch: 42/50: 100%|██████████| 22/22 [00:00<00:00, 133.46it/s, train_loss=0.00987, valid_loss=0.0112]\n",
      "Epoch: 43/50: 100%|██████████| 22/22 [00:00<00:00, 132.36it/s, train_loss=0.0101, valid_loss=0.0113]\n",
      "Epoch: 44/50: 100%|██████████| 22/22 [00:00<00:00, 122.34it/s, train_loss=0.0111, valid_loss=0.0112]\n",
      "Epoch: 45/50: 100%|██████████| 22/22 [00:00<00:00, 123.77it/s, train_loss=0.0108, valid_loss=0.011] \n",
      "Epoch: 46/50: 100%|██████████| 22/22 [00:00<00:00, 101.44it/s, train_loss=0.0105, valid_loss=0.0111]\n",
      "Epoch: 47/50: 100%|██████████| 22/22 [00:00<00:00, 113.74it/s, train_loss=0.0101, valid_loss=0.0111]\n",
      "Epoch: 48/50: 100%|██████████| 22/22 [00:00<00:00, 132.52it/s, train_loss=0.0111, valid_loss=0.0113]\n",
      "Epoch: 49/50: 100%|██████████| 22/22 [00:00<00:00, 133.17it/s, train_loss=0.01, valid_loss=0.0111]   \n",
      "Epoch: 50/50: 100%|██████████| 22/22 [00:00<00:00, 133.51it/s, train_loss=0.00995, valid_loss=0.0112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 22/22 [00:00<00:00, 79.86it/s, train_loss=0.047, valid_loss=0.0545] \n",
      "Epoch: 2/50: 100%|██████████| 22/22 [00:00<00:00, 132.74it/s, train_loss=0.033, valid_loss=0.0388] \n",
      "Epoch: 3/50: 100%|██████████| 22/22 [00:00<00:00, 122.29it/s, train_loss=0.0175, valid_loss=0.0181]\n",
      "Epoch: 4/50: 100%|██████████| 22/22 [00:00<00:00, 108.75it/s, train_loss=0.0152, valid_loss=0.015]\n",
      "Epoch: 5/50: 100%|██████████| 22/22 [00:00<00:00, 109.08it/s, train_loss=0.0146, valid_loss=0.0139]\n",
      "Epoch: 6/50: 100%|██████████| 22/22 [00:00<00:00, 120.47it/s, train_loss=0.00842, valid_loss=0.00688]\n",
      "Epoch: 7/50: 100%|██████████| 22/22 [00:00<00:00, 106.52it/s, train_loss=0.00694, valid_loss=0.00592]\n",
      "Epoch: 8/50: 100%|██████████| 22/22 [00:00<00:00, 132.78it/s, train_loss=0.00719, valid_loss=0.0056] \n",
      "Epoch: 9/50: 100%|██████████| 22/22 [00:00<00:00, 134.28it/s, train_loss=0.0063, valid_loss=0.00478] \n",
      "Epoch: 10/50: 100%|██████████| 22/22 [00:00<00:00, 94.47it/s, train_loss=0.00653, valid_loss=0.00449]\n",
      "Epoch: 11/50: 100%|██████████| 22/22 [00:00<00:00, 121.15it/s, train_loss=0.00563, valid_loss=0.00427]\n",
      "Epoch: 12/50: 100%|██████████| 22/22 [00:00<00:00, 134.31it/s, train_loss=0.00537, valid_loss=0.00415]\n",
      "Epoch: 13/50: 100%|██████████| 22/22 [00:00<00:00, 133.34it/s, train_loss=0.00548, valid_loss=0.00415]\n",
      "Epoch: 14/50: 100%|██████████| 22/22 [00:00<00:00, 102.01it/s, train_loss=0.00531, valid_loss=0.00402]\n",
      "Epoch: 15/50: 100%|██████████| 22/22 [00:00<00:00, 110.84it/s, train_loss=0.00516, valid_loss=0.00399]\n",
      "Epoch: 16/50: 100%|██████████| 22/22 [00:00<00:00, 107.17it/s, train_loss=0.00537, valid_loss=0.00424]\n",
      "Epoch: 17/50: 100%|██████████| 22/22 [00:00<00:00, 118.17it/s, train_loss=0.00484, valid_loss=0.00424]\n",
      "Epoch: 18/50: 100%|██████████| 22/22 [00:00<00:00, 134.11it/s, train_loss=0.00538, valid_loss=0.00406]\n",
      "Epoch: 19/50: 100%|██████████| 22/22 [00:00<00:00, 109.06it/s, train_loss=0.00457, valid_loss=0.00416]\n",
      "Epoch: 20/50: 100%|██████████| 22/22 [00:00<00:00, 122.14it/s, train_loss=0.00465, valid_loss=0.00481]\n",
      "Epoch: 21/50: 100%|██████████| 22/22 [00:00<00:00, 113.97it/s, train_loss=0.00517, valid_loss=0.00403]\n",
      "Epoch: 22/50: 100%|██████████| 22/22 [00:00<00:00, 107.94it/s, train_loss=0.0046, valid_loss=0.00415]\n",
      "Epoch: 23/50: 100%|██████████| 22/22 [00:00<00:00, 122.07it/s, train_loss=0.00493, valid_loss=0.0045] \n",
      "Epoch: 24/50: 100%|██████████| 22/22 [00:00<00:00, 103.50it/s, train_loss=0.00462, valid_loss=0.00444]\n",
      "Epoch: 25/50: 100%|██████████| 22/22 [00:00<00:00, 134.01it/s, train_loss=0.00509, valid_loss=0.00469]\n",
      "Epoch: 26/50: 100%|██████████| 22/22 [00:00<00:00, 131.08it/s, train_loss=0.00449, valid_loss=0.004]  \n",
      "Epoch: 27/50: 100%|██████████| 22/22 [00:00<00:00, 115.00it/s, train_loss=0.00469, valid_loss=0.00515]\n",
      "Epoch: 28/50: 100%|██████████| 22/22 [00:00<00:00, 108.95it/s, train_loss=0.00442, valid_loss=0.0043]\n",
      "Epoch: 29/50: 100%|██████████| 22/22 [00:00<00:00, 114.27it/s, train_loss=0.00463, valid_loss=0.004]  \n",
      "Epoch: 30/50: 100%|██████████| 22/22 [00:00<00:00, 110.60it/s, train_loss=0.00479, valid_loss=0.00395]\n",
      "Epoch: 31/50: 100%|██████████| 22/22 [00:00<00:00, 121.50it/s, train_loss=0.00426, valid_loss=0.0046] \n",
      "Epoch: 32/50: 100%|██████████| 22/22 [00:00<00:00, 101.35it/s, train_loss=0.00416, valid_loss=0.00434]\n",
      "Epoch: 33/50: 100%|██████████| 22/22 [00:00<00:00, 131.99it/s, train_loss=0.00461, valid_loss=0.00442]\n",
      "Epoch: 34/50: 100%|██████████| 22/22 [00:00<00:00, 112.98it/s, train_loss=0.00438, valid_loss=0.00447]\n",
      "Epoch: 35/50: 100%|██████████| 22/22 [00:00<00:00, 120.15it/s, train_loss=0.00454, valid_loss=0.00461]\n",
      "Epoch: 36/50: 100%|██████████| 22/22 [00:00<00:00, 133.35it/s, train_loss=0.00425, valid_loss=0.00444]\n",
      "Epoch: 37/50: 100%|██████████| 22/22 [00:00<00:00, 99.94it/s, train_loss=0.0042, valid_loss=0.00498]  \n",
      "Epoch: 38/50: 100%|██████████| 22/22 [00:00<00:00, 120.30it/s, train_loss=0.00444, valid_loss=0.00491]\n",
      "Epoch: 39/50: 100%|██████████| 22/22 [00:00<00:00, 133.45it/s, train_loss=0.00409, valid_loss=0.00426]\n",
      "Epoch: 40/50: 100%|██████████| 22/22 [00:00<00:00, 133.77it/s, train_loss=0.00451, valid_loss=0.00421]\n",
      "Epoch: 41/50: 100%|██████████| 22/22 [00:00<00:00, 132.80it/s, train_loss=0.00435, valid_loss=0.0045] \n",
      "Epoch: 42/50: 100%|██████████| 22/22 [00:00<00:00, 102.57it/s, train_loss=0.00421, valid_loss=0.00453]\n",
      "Epoch: 43/50: 100%|██████████| 22/22 [00:00<00:00, 133.25it/s, train_loss=0.0042, valid_loss=0.00472] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 29/29 [00:00<00:00, 105.63it/s, train_loss=0.0234, valid_loss=0.0159]\n",
      "Epoch: 2/50: 100%|██████████| 29/29 [00:00<00:00, 129.45it/s, train_loss=0.0122, valid_loss=0.00959]\n",
      "Epoch: 3/50: 100%|██████████| 29/29 [00:00<00:00, 139.08it/s, train_loss=0.00971, valid_loss=0.00747]\n",
      "Epoch: 4/50: 100%|██████████| 29/29 [00:00<00:00, 98.82it/s, train_loss=0.00808, valid_loss=0.0047] \n",
      "Epoch: 5/50: 100%|██████████| 29/29 [00:00<00:00, 127.30it/s, train_loss=0.00839, valid_loss=0.00511]\n",
      "Epoch: 6/50: 100%|██████████| 29/29 [00:00<00:00, 112.13it/s, train_loss=0.00695, valid_loss=0.00451]\n",
      "Epoch: 7/50: 100%|██████████| 29/29 [00:00<00:00, 135.58it/s, train_loss=0.00684, valid_loss=0.0048] \n",
      "Epoch: 8/50: 100%|██████████| 29/29 [00:00<00:00, 133.62it/s, train_loss=0.00649, valid_loss=0.00385]\n",
      "Epoch: 9/50: 100%|██████████| 29/29 [00:00<00:00, 101.68it/s, train_loss=0.00634, valid_loss=0.00316]\n",
      "Epoch: 10/50: 100%|██████████| 29/29 [00:00<00:00, 129.85it/s, train_loss=0.00628, valid_loss=0.00273]\n",
      "Epoch: 11/50: 100%|██████████| 29/29 [00:00<00:00, 138.74it/s, train_loss=0.00585, valid_loss=0.00263]\n",
      "Epoch: 12/50: 100%|██████████| 29/29 [00:00<00:00, 108.20it/s, train_loss=0.00552, valid_loss=0.00269]\n",
      "Epoch: 13/50: 100%|██████████| 29/29 [00:00<00:00, 123.86it/s, train_loss=0.0057, valid_loss=0.0027] \n",
      "Epoch: 14/50: 100%|██████████| 29/29 [00:00<00:00, 127.89it/s, train_loss=0.00491, valid_loss=0.00225]\n",
      "Epoch: 15/50: 100%|██████████| 29/29 [00:00<00:00, 117.68it/s, train_loss=0.00488, valid_loss=0.00263]\n",
      "Epoch: 16/50: 100%|██████████| 29/29 [00:00<00:00, 130.39it/s, train_loss=0.00547, valid_loss=0.00291]\n",
      "Epoch: 17/50: 100%|██████████| 29/29 [00:00<00:00, 118.20it/s, train_loss=0.00504, valid_loss=0.00245]\n",
      "Epoch: 18/50: 100%|██████████| 29/29 [00:00<00:00, 131.86it/s, train_loss=0.00486, valid_loss=0.00291]\n",
      "Epoch: 19/50: 100%|██████████| 29/29 [00:00<00:00, 139.19it/s, train_loss=0.00515, valid_loss=0.00211]\n",
      "Epoch: 20/50: 100%|██████████| 29/29 [00:00<00:00, 126.92it/s, train_loss=0.00489, valid_loss=0.00205]\n",
      "Epoch: 21/50: 100%|██████████| 29/29 [00:00<00:00, 103.18it/s, train_loss=0.00515, valid_loss=0.0023]\n",
      "Epoch: 22/50: 100%|██████████| 29/29 [00:00<00:00, 129.89it/s, train_loss=0.00413, valid_loss=0.00256]\n",
      "Epoch: 23/50: 100%|██████████| 29/29 [00:00<00:00, 106.80it/s, train_loss=0.00504, valid_loss=0.0035] \n",
      "Epoch: 24/50: 100%|██████████| 29/29 [00:00<00:00, 137.35it/s, train_loss=0.00471, valid_loss=0.00207]\n",
      "Epoch: 25/50: 100%|██████████| 29/29 [00:00<00:00, 138.56it/s, train_loss=0.00474, valid_loss=0.00228]\n",
      "Epoch: 26/50: 100%|██████████| 29/29 [00:00<00:00, 130.55it/s, train_loss=0.0043, valid_loss=0.0028]  \n",
      "Epoch: 27/50: 100%|██████████| 29/29 [00:00<00:00, 128.63it/s, train_loss=0.00425, valid_loss=0.00228]\n",
      "Epoch: 28/50: 100%|██████████| 29/29 [00:00<00:00, 118.84it/s, train_loss=0.00433, valid_loss=0.0027] \n",
      "Epoch: 29/50: 100%|██████████| 29/29 [00:00<00:00, 123.99it/s, train_loss=0.00473, valid_loss=0.00269]\n",
      "Epoch: 30/50: 100%|██████████| 29/29 [00:00<00:00, 139.56it/s, train_loss=0.00426, valid_loss=0.00281]\n",
      "Epoch: 31/50: 100%|██████████| 29/29 [00:00<00:00, 139.05it/s, train_loss=0.00459, valid_loss=0.00292]\n",
      "Epoch: 32/50: 100%|██████████| 29/29 [00:00<00:00, 120.76it/s, train_loss=0.00406, valid_loss=0.00307]\n",
      "Epoch: 33/50: 100%|██████████| 29/29 [00:00<00:00, 101.94it/s, train_loss=0.00451, valid_loss=0.00316]\n",
      "Epoch: 34/50: 100%|██████████| 29/29 [00:00<00:00, 140.48it/s, train_loss=0.00438, valid_loss=0.00253]\n",
      "Epoch: 35/50: 100%|██████████| 29/29 [00:00<00:00, 124.47it/s, train_loss=0.00439, valid_loss=0.00248]\n",
      "Epoch: 36/50: 100%|██████████| 29/29 [00:00<00:00, 123.55it/s, train_loss=0.00407, valid_loss=0.00288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 36/36 [00:00<00:00, 95.24it/s, train_loss=0.0193, valid_loss=0.0159]\n",
      "Epoch: 2/50: 100%|██████████| 36/36 [00:00<00:00, 127.66it/s, train_loss=0.00986, valid_loss=0.00661]\n",
      "Epoch: 3/50: 100%|██████████| 36/36 [00:00<00:00, 108.34it/s, train_loss=0.00799, valid_loss=0.00474]\n",
      "Epoch: 4/50: 100%|██████████| 36/36 [00:00<00:00, 119.63it/s, train_loss=0.00756, valid_loss=0.00385]\n",
      "Epoch: 5/50: 100%|██████████| 36/36 [00:00<00:00, 123.61it/s, train_loss=0.00667, valid_loss=0.00338]\n",
      "Epoch: 6/50: 100%|██████████| 36/36 [00:00<00:00, 117.91it/s, train_loss=0.00605, valid_loss=0.00333]\n",
      "Epoch: 7/50: 100%|██████████| 36/36 [00:00<00:00, 121.51it/s, train_loss=0.00637, valid_loss=0.00339]\n",
      "Epoch: 8/50: 100%|██████████| 36/36 [00:00<00:00, 107.63it/s, train_loss=0.00556, valid_loss=0.0035] \n",
      "Epoch: 9/50: 100%|██████████| 36/36 [00:00<00:00, 127.74it/s, train_loss=0.00611, valid_loss=0.00295]\n",
      "Epoch: 10/50: 100%|██████████| 36/36 [00:00<00:00, 118.15it/s, train_loss=0.00561, valid_loss=0.00292]\n",
      "Epoch: 11/50: 100%|██████████| 36/36 [00:00<00:00, 128.35it/s, train_loss=0.00482, valid_loss=0.00302]\n",
      "Epoch: 12/50: 100%|██████████| 36/36 [00:00<00:00, 117.44it/s, train_loss=0.00507, valid_loss=0.00286]\n",
      "Epoch: 13/50: 100%|██████████| 36/36 [00:00<00:00, 128.84it/s, train_loss=0.00523, valid_loss=0.00266]\n",
      "Epoch: 14/50: 100%|██████████| 36/36 [00:00<00:00, 103.24it/s, train_loss=0.00515, valid_loss=0.00267]\n",
      "Epoch: 15/50: 100%|██████████| 36/36 [00:00<00:00, 127.46it/s, train_loss=0.00471, valid_loss=0.00282]\n",
      "Epoch: 16/50: 100%|██████████| 36/36 [00:00<00:00, 107.12it/s, train_loss=0.00472, valid_loss=0.00277]\n",
      "Epoch: 17/50: 100%|██████████| 36/36 [00:00<00:00, 134.49it/s, train_loss=0.00467, valid_loss=0.00278]\n",
      "Epoch: 18/50: 100%|██████████| 36/36 [00:00<00:00, 101.16it/s, train_loss=0.00488, valid_loss=0.00316]\n",
      "Epoch: 19/50: 100%|██████████| 36/36 [00:00<00:00, 121.23it/s, train_loss=0.00445, valid_loss=0.00316]\n",
      "Epoch: 20/50: 100%|██████████| 36/36 [00:00<00:00, 128.25it/s, train_loss=0.00487, valid_loss=0.00288]\n",
      "Epoch: 21/50: 100%|██████████| 36/36 [00:00<00:00, 126.64it/s, train_loss=0.00487, valid_loss=0.00265]\n",
      "Epoch: 22/50: 100%|██████████| 36/36 [00:00<00:00, 112.09it/s, train_loss=0.00462, valid_loss=0.00265]\n",
      "Epoch: 23/50: 100%|██████████| 36/36 [00:00<00:00, 134.27it/s, train_loss=0.00466, valid_loss=0.00273]\n",
      "Epoch: 24/50: 100%|██████████| 36/36 [00:00<00:00, 121.99it/s, train_loss=0.00442, valid_loss=0.00288]\n",
      "Epoch: 25/50: 100%|██████████| 36/36 [00:00<00:00, 127.79it/s, train_loss=0.00445, valid_loss=0.00255]\n",
      "Epoch: 26/50: 100%|██████████| 36/36 [00:00<00:00, 91.17it/s, train_loss=0.00457, valid_loss=0.00293]\n",
      "Epoch: 27/50: 100%|██████████| 36/36 [00:00<00:00, 124.85it/s, train_loss=0.00445, valid_loss=0.00265]\n",
      "Epoch: 28/50: 100%|██████████| 36/36 [00:00<00:00, 111.81it/s, train_loss=0.00436, valid_loss=0.00278]\n",
      "Epoch: 29/50: 100%|██████████| 36/36 [00:00<00:00, 114.00it/s, train_loss=0.00413, valid_loss=0.00324]\n",
      "Epoch: 30/50: 100%|██████████| 36/36 [00:00<00:00, 112.23it/s, train_loss=0.00423, valid_loss=0.00281]\n",
      "Epoch: 31/50: 100%|██████████| 36/36 [00:00<00:00, 129.04it/s, train_loss=0.00457, valid_loss=0.00262]\n",
      "Epoch: 32/50: 100%|██████████| 36/36 [00:00<00:00, 107.52it/s, train_loss=0.00388, valid_loss=0.00282]\n",
      "Epoch: 33/50: 100%|██████████| 36/36 [00:00<00:00, 133.75it/s, train_loss=0.00429, valid_loss=0.00282]\n",
      "Epoch: 34/50: 100%|██████████| 36/36 [00:00<00:00, 111.96it/s, train_loss=0.00403, valid_loss=0.00244]\n",
      "Epoch: 35/50: 100%|██████████| 36/36 [00:00<00:00, 133.14it/s, train_loss=0.00424, valid_loss=0.00264]\n",
      "Epoch: 36/50: 100%|██████████| 36/36 [00:00<00:00, 132.78it/s, train_loss=0.0041, valid_loss=0.00262] \n",
      "Epoch: 37/50: 100%|██████████| 36/36 [00:00<00:00, 129.45it/s, train_loss=0.0044, valid_loss=0.00241] \n",
      "Epoch: 38/50: 100%|██████████| 36/36 [00:00<00:00, 116.52it/s, train_loss=0.00404, valid_loss=0.00291]\n",
      "Epoch: 39/50: 100%|██████████| 36/36 [00:00<00:00, 117.64it/s, train_loss=0.00428, valid_loss=0.00254]\n",
      "Epoch: 40/50: 100%|██████████| 36/36 [00:00<00:00, 111.14it/s, train_loss=0.00431, valid_loss=0.00253]\n",
      "Epoch: 41/50: 100%|██████████| 36/36 [00:00<00:00, 124.92it/s, train_loss=0.00473, valid_loss=0.00266]\n",
      "Epoch: 42/50: 100%|██████████| 36/36 [00:00<00:00, 117.17it/s, train_loss=0.00422, valid_loss=0.00272]\n",
      "Epoch: 43/50: 100%|██████████| 36/36 [00:00<00:00, 133.25it/s, train_loss=0.00415, valid_loss=0.00263]\n",
      "Epoch: 44/50: 100%|██████████| 36/36 [00:00<00:00, 117.75it/s, train_loss=0.00448, valid_loss=0.00259]\n",
      "Epoch: 45/50: 100%|██████████| 36/36 [00:00<00:00, 116.29it/s, train_loss=0.00412, valid_loss=0.00272]\n",
      "Epoch: 46/50: 100%|██████████| 36/36 [00:00<00:00, 131.75it/s, train_loss=0.00461, valid_loss=0.00273]\n",
      "Epoch: 47/50: 100%|██████████| 36/36 [00:00<00:00, 111.62it/s, train_loss=0.00427, valid_loss=0.0026]\n",
      "Epoch: 48/50: 100%|██████████| 36/36 [00:00<00:00, 124.45it/s, train_loss=0.00429, valid_loss=0.0028] \n",
      "Epoch: 49/50: 100%|██████████| 36/36 [00:00<00:00, 112.98it/s, train_loss=0.00394, valid_loss=0.00252]\n",
      "Epoch: 50/50: 100%|██████████| 36/36 [00:00<00:00, 132.40it/s, train_loss=0.00389, valid_loss=0.00262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config: batch_size--128, lr--0.001, number_epoch--50, hidden_dim--25,drop_prob-0.1,weight_decay-1e-07\n",
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 29/29 [00:00<00:00, 112.02it/s, train_loss=0.0423, valid_loss=0.0675]\n",
      "Epoch: 2/50: 100%|██████████| 29/29 [00:00<00:00, 132.15it/s, train_loss=0.0326, valid_loss=0.0496]\n",
      "Epoch: 3/50: 100%|██████████| 29/29 [00:00<00:00, 119.64it/s, train_loss=0.0255, valid_loss=0.0372]\n",
      "Epoch: 4/50: 100%|██████████| 29/29 [00:00<00:00, 137.74it/s, train_loss=0.0218, valid_loss=0.0339]\n",
      "Epoch: 5/50: 100%|██████████| 29/29 [00:00<00:00, 123.25it/s, train_loss=0.0213, valid_loss=0.0316]\n",
      "Epoch: 6/50: 100%|██████████| 29/29 [00:00<00:00, 130.10it/s, train_loss=0.0167, valid_loss=0.0243]\n",
      "Epoch: 7/50: 100%|██████████| 29/29 [00:00<00:00, 126.37it/s, train_loss=0.00829, valid_loss=0.0107]\n",
      "Epoch: 8/50: 100%|██████████| 29/29 [00:00<00:00, 112.81it/s, train_loss=0.00629, valid_loss=0.00885]\n",
      "Epoch: 9/50: 100%|██████████| 29/29 [00:00<00:00, 131.30it/s, train_loss=0.00545, valid_loss=0.00768]\n",
      "Epoch: 10/50: 100%|██████████| 29/29 [00:00<00:00, 128.46it/s, train_loss=0.00573, valid_loss=0.00718]\n",
      "Epoch: 11/50: 100%|██████████| 29/29 [00:00<00:00, 125.22it/s, train_loss=0.00569, valid_loss=0.00666]\n",
      "Epoch: 12/50: 100%|██████████| 29/29 [00:00<00:00, 130.75it/s, train_loss=0.00517, valid_loss=0.00638]\n",
      "Epoch: 13/50: 100%|██████████| 29/29 [00:00<00:00, 130.32it/s, train_loss=0.00468, valid_loss=0.00594]\n",
      "Epoch: 14/50: 100%|██████████| 29/29 [00:00<00:00, 128.77it/s, train_loss=0.00461, valid_loss=0.00573]\n",
      "Epoch: 15/50: 100%|██████████| 29/29 [00:00<00:00, 131.02it/s, train_loss=0.0043, valid_loss=0.0055]  \n",
      "Epoch: 16/50: 100%|██████████| 29/29 [00:00<00:00, 126.65it/s, train_loss=0.0046, valid_loss=0.00541] \n",
      "Epoch: 17/50: 100%|██████████| 29/29 [00:00<00:00, 104.51it/s, train_loss=0.00429, valid_loss=0.00517]\n",
      "Epoch: 18/50: 100%|██████████| 29/29 [00:00<00:00, 107.88it/s, train_loss=0.00446, valid_loss=0.00506]\n",
      "Epoch: 19/50: 100%|██████████| 29/29 [00:00<00:00, 131.66it/s, train_loss=0.00366, valid_loss=0.0049] \n",
      "Epoch: 20/50: 100%|██████████| 29/29 [00:00<00:00, 134.51it/s, train_loss=0.00357, valid_loss=0.00482]\n",
      "Epoch: 21/50: 100%|██████████| 29/29 [00:00<00:00, 140.49it/s, train_loss=0.00353, valid_loss=0.0047] \n",
      "Epoch: 22/50: 100%|██████████| 29/29 [00:00<00:00, 109.21it/s, train_loss=0.00368, valid_loss=0.00474]\n",
      "Epoch: 23/50: 100%|██████████| 29/29 [00:00<00:00, 135.10it/s, train_loss=0.00336, valid_loss=0.00477]\n",
      "Epoch: 24/50: 100%|██████████| 29/29 [00:00<00:00, 128.18it/s, train_loss=0.00373, valid_loss=0.00468]\n",
      "Epoch: 25/50: 100%|██████████| 29/29 [00:00<00:00, 128.34it/s, train_loss=0.00337, valid_loss=0.00474]\n",
      "Epoch: 26/50: 100%|██████████| 29/29 [00:00<00:00, 122.55it/s, train_loss=0.00316, valid_loss=0.00458]\n",
      "Epoch: 27/50: 100%|██████████| 29/29 [00:00<00:00, 115.59it/s, train_loss=0.00322, valid_loss=0.00453]\n",
      "Epoch: 28/50: 100%|██████████| 29/29 [00:00<00:00, 119.00it/s, train_loss=0.00298, valid_loss=0.00457]\n",
      "Epoch: 29/50: 100%|██████████| 29/29 [00:00<00:00, 133.76it/s, train_loss=0.00333, valid_loss=0.00459]\n",
      "Epoch: 30/50: 100%|██████████| 29/29 [00:00<00:00, 114.44it/s, train_loss=0.00349, valid_loss=0.00458]\n",
      "Epoch: 31/50: 100%|██████████| 29/29 [00:00<00:00, 115.16it/s, train_loss=0.00283, valid_loss=0.00479]\n",
      "Epoch: 32/50: 100%|██████████| 29/29 [00:00<00:00, 121.58it/s, train_loss=0.00311, valid_loss=0.00446]\n",
      "Epoch: 33/50: 100%|██████████| 29/29 [00:00<00:00, 115.83it/s, train_loss=0.00262, valid_loss=0.00465]\n",
      "Epoch: 34/50: 100%|██████████| 29/29 [00:00<00:00, 128.67it/s, train_loss=0.00289, valid_loss=0.00445]\n",
      "Epoch: 35/50: 100%|██████████| 29/29 [00:00<00:00, 131.75it/s, train_loss=0.00319, valid_loss=0.00449]\n",
      "Epoch: 36/50: 100%|██████████| 29/29 [00:00<00:00, 134.79it/s, train_loss=0.00308, valid_loss=0.00446]\n",
      "Epoch: 37/50: 100%|██████████| 29/29 [00:00<00:00, 121.29it/s, train_loss=0.00297, valid_loss=0.00436]\n",
      "Epoch: 38/50: 100%|██████████| 29/29 [00:00<00:00, 119.56it/s, train_loss=0.00269, valid_loss=0.0044]\n",
      "Epoch: 39/50: 100%|██████████| 29/29 [00:00<00:00, 125.24it/s, train_loss=0.00292, valid_loss=0.00453]\n",
      "Epoch: 40/50: 100%|██████████| 29/29 [00:00<00:00, 130.69it/s, train_loss=0.00325, valid_loss=0.00439]\n",
      "Epoch: 41/50: 100%|██████████| 29/29 [00:00<00:00, 132.43it/s, train_loss=0.0031, valid_loss=0.00438] \n",
      "Epoch: 42/50: 100%|██████████| 29/29 [00:00<00:00, 129.08it/s, train_loss=0.00322, valid_loss=0.00446]\n",
      "Epoch: 43/50: 100%|██████████| 29/29 [00:00<00:00, 133.86it/s, train_loss=0.00302, valid_loss=0.00456]\n",
      "Epoch: 44/50: 100%|██████████| 29/29 [00:00<00:00, 130.14it/s, train_loss=0.00277, valid_loss=0.00445]\n",
      "Epoch: 45/50: 100%|██████████| 29/29 [00:00<00:00, 137.52it/s, train_loss=0.00291, valid_loss=0.00438]\n",
      "Epoch: 46/50: 100%|██████████| 29/29 [00:00<00:00, 132.52it/s, train_loss=0.00266, valid_loss=0.00442]\n",
      "Epoch: 47/50: 100%|██████████| 29/29 [00:00<00:00, 117.52it/s, train_loss=0.00325, valid_loss=0.00446]\n",
      "Epoch: 48/50: 100%|██████████| 29/29 [00:00<00:00, 130.38it/s, train_loss=0.00297, valid_loss=0.00439]\n",
      "Epoch: 49/50: 100%|██████████| 29/29 [00:00<00:00, 121.97it/s, train_loss=0.00291, valid_loss=0.0045] \n",
      "Epoch: 50/50: 100%|██████████| 29/29 [00:00<00:00, 130.80it/s, train_loss=0.00278, valid_loss=0.00439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 58/58 [00:00<00:00, 119.70it/s, train_loss=0.0372, valid_loss=0.0432]\n",
      "Epoch: 2/50: 100%|██████████| 58/58 [00:00<00:00, 127.98it/s, train_loss=0.0293, valid_loss=0.0364]\n",
      "Epoch: 3/50: 100%|██████████| 58/58 [00:00<00:00, 124.04it/s, train_loss=0.0181, valid_loss=0.0176]\n",
      "Epoch: 4/50: 100%|██████████| 58/58 [00:00<00:00, 139.21it/s, train_loss=0.00944, valid_loss=0.00635]\n",
      "Epoch: 5/50: 100%|██████████| 58/58 [00:00<00:00, 130.59it/s, train_loss=0.0085, valid_loss=0.00459] \n",
      "Epoch: 6/50: 100%|██████████| 58/58 [00:00<00:00, 131.07it/s, train_loss=0.00672, valid_loss=0.0036] \n",
      "Epoch: 7/50: 100%|██████████| 58/58 [00:00<00:00, 140.00it/s, train_loss=0.00737, valid_loss=0.00292]\n",
      "Epoch: 8/50: 100%|██████████| 58/58 [00:00<00:00, 125.77it/s, train_loss=0.0052, valid_loss=0.00274] \n",
      "Epoch: 9/50: 100%|██████████| 58/58 [00:00<00:00, 121.74it/s, train_loss=0.0071, valid_loss=0.00267] \n",
      "Epoch: 10/50: 100%|██████████| 58/58 [00:00<00:00, 125.03it/s, train_loss=0.006, valid_loss=0.00271]  \n",
      "Epoch: 11/50: 100%|██████████| 58/58 [00:00<00:00, 120.66it/s, train_loss=0.00696, valid_loss=0.00239]\n",
      "Epoch: 12/50: 100%|██████████| 58/58 [00:00<00:00, 122.25it/s, train_loss=0.00482, valid_loss=0.00254]\n",
      "Epoch: 13/50: 100%|██████████| 58/58 [00:00<00:00, 123.58it/s, train_loss=0.00563, valid_loss=0.00196]\n",
      "Epoch: 14/50: 100%|██████████| 58/58 [00:00<00:00, 134.39it/s, train_loss=0.00571, valid_loss=0.00255]\n",
      "Epoch: 15/50: 100%|██████████| 58/58 [00:00<00:00, 122.39it/s, train_loss=0.00471, valid_loss=0.00182]\n",
      "Epoch: 16/50: 100%|██████████| 58/58 [00:00<00:00, 136.55it/s, train_loss=0.00619, valid_loss=0.00166]\n",
      "Epoch: 17/50: 100%|██████████| 58/58 [00:00<00:00, 121.39it/s, train_loss=0.00597, valid_loss=0.00206]\n",
      "Epoch: 18/50: 100%|██████████| 58/58 [00:00<00:00, 121.34it/s, train_loss=0.00452, valid_loss=0.00268]\n",
      "Epoch: 19/50: 100%|██████████| 58/58 [00:00<00:00, 127.44it/s, train_loss=0.00491, valid_loss=0.00227]\n",
      "Epoch: 20/50: 100%|██████████| 58/58 [00:00<00:00, 135.64it/s, train_loss=0.00376, valid_loss=0.00221]\n",
      "Epoch: 21/50: 100%|██████████| 58/58 [00:00<00:00, 135.79it/s, train_loss=0.00316, valid_loss=0.00232]\n",
      "Epoch: 22/50: 100%|██████████| 58/58 [00:00<00:00, 135.65it/s, train_loss=0.00489, valid_loss=0.0023] \n",
      "Epoch: 23/50: 100%|██████████| 58/58 [00:00<00:00, 117.13it/s, train_loss=0.00426, valid_loss=0.00208]\n",
      "Epoch: 24/50: 100%|██████████| 58/58 [00:00<00:00, 128.72it/s, train_loss=0.0037, valid_loss=0.00229] \n",
      "Epoch: 25/50: 100%|██████████| 58/58 [00:00<00:00, 127.48it/s, train_loss=0.00416, valid_loss=0.00163]\n",
      "Epoch: 26/50: 100%|██████████| 58/58 [00:00<00:00, 123.85it/s, train_loss=0.00393, valid_loss=0.00168]\n",
      "Epoch: 27/50: 100%|██████████| 58/58 [00:00<00:00, 121.76it/s, train_loss=0.00474, valid_loss=0.00217]\n",
      "Epoch: 28/50: 100%|██████████| 58/58 [00:00<00:00, 126.65it/s, train_loss=0.00513, valid_loss=0.00224]\n",
      "Epoch: 29/50: 100%|██████████| 58/58 [00:00<00:00, 127.68it/s, train_loss=0.00392, valid_loss=0.0023] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 87/87 [00:00<00:00, 123.40it/s, train_loss=0.0498, valid_loss=0.062] \n",
      "Epoch: 2/50: 100%|██████████| 87/87 [00:00<00:00, 116.39it/s, train_loss=0.0259, valid_loss=0.0255]\n",
      "Epoch: 3/50: 100%|██████████| 87/87 [00:00<00:00, 117.16it/s, train_loss=0.0208, valid_loss=0.019] \n",
      "Epoch: 4/50: 100%|██████████| 87/87 [00:00<00:00, 124.75it/s, train_loss=0.0132, valid_loss=0.0127]\n",
      "Epoch: 5/50: 100%|██████████| 87/87 [00:00<00:00, 129.34it/s, train_loss=0.013, valid_loss=0.0121] \n",
      "Epoch: 6/50: 100%|██████████| 87/87 [00:00<00:00, 112.98it/s, train_loss=0.0114, valid_loss=0.0118]\n",
      "Epoch: 7/50: 100%|██████████| 87/87 [00:00<00:00, 133.71it/s, train_loss=0.0114, valid_loss=0.0114]\n",
      "Epoch: 8/50: 100%|██████████| 87/87 [00:00<00:00, 134.64it/s, train_loss=0.0109, valid_loss=0.0113]\n",
      "Epoch: 9/50: 100%|██████████| 87/87 [00:00<00:00, 126.17it/s, train_loss=0.0118, valid_loss=0.0114]\n",
      "Epoch: 10/50: 100%|██████████| 87/87 [00:00<00:00, 136.43it/s, train_loss=0.0105, valid_loss=0.0115] \n",
      "Epoch: 11/50: 100%|██████████| 87/87 [00:00<00:00, 122.84it/s, train_loss=0.0113, valid_loss=0.0113]\n",
      "Epoch: 12/50: 100%|██████████| 87/87 [00:00<00:00, 115.20it/s, train_loss=0.0117, valid_loss=0.0111]\n",
      "Epoch: 13/50: 100%|██████████| 87/87 [00:00<00:00, 124.96it/s, train_loss=0.0111, valid_loss=0.0112]\n",
      "Epoch: 14/50: 100%|██████████| 87/87 [00:00<00:00, 135.06it/s, train_loss=0.0112, valid_loss=0.0117] \n",
      "Epoch: 15/50: 100%|██████████| 87/87 [00:00<00:00, 125.22it/s, train_loss=0.0101, valid_loss=0.0111] \n",
      "Epoch: 16/50: 100%|██████████| 87/87 [00:00<00:00, 124.93it/s, train_loss=0.0111, valid_loss=0.0111] \n",
      "Epoch: 17/50: 100%|██████████| 87/87 [00:00<00:00, 122.82it/s, train_loss=0.0118, valid_loss=0.0112] \n",
      "Epoch: 18/50: 100%|██████████| 87/87 [00:00<00:00, 130.80it/s, train_loss=0.0099, valid_loss=0.0114] \n",
      "Epoch: 19/50: 100%|██████████| 87/87 [00:00<00:00, 121.45it/s, train_loss=0.00979, valid_loss=0.011] \n",
      "Epoch: 20/50: 100%|██████████| 87/87 [00:00<00:00, 132.00it/s, train_loss=0.0107, valid_loss=0.0111] \n",
      "Epoch: 21/50: 100%|██████████| 87/87 [00:00<00:00, 137.59it/s, train_loss=0.0108, valid_loss=0.0109] \n",
      "Epoch: 22/50: 100%|██████████| 87/87 [00:00<00:00, 136.58it/s, train_loss=0.011, valid_loss=0.0112]  \n",
      "Epoch: 23/50: 100%|██████████| 87/87 [00:00<00:00, 128.13it/s, train_loss=0.0102, valid_loss=0.011]  \n",
      "Epoch: 24/50: 100%|██████████| 87/87 [00:00<00:00, 133.69it/s, train_loss=0.0102, valid_loss=0.011] \n",
      "Epoch: 25/50: 100%|██████████| 87/87 [00:00<00:00, 118.18it/s, train_loss=0.00964, valid_loss=0.0111]\n",
      "Epoch: 26/50: 100%|██████████| 87/87 [00:00<00:00, 130.18it/s, train_loss=0.011, valid_loss=0.0109]  \n",
      "Epoch: 27/50: 100%|██████████| 87/87 [00:00<00:00, 121.07it/s, train_loss=0.0102, valid_loss=0.0111] \n",
      "Epoch: 28/50: 100%|██████████| 87/87 [00:00<00:00, 129.71it/s, train_loss=0.00973, valid_loss=0.0109]\n",
      "Epoch: 29/50: 100%|██████████| 87/87 [00:00<00:00, 128.79it/s, train_loss=0.0102, valid_loss=0.0112] \n",
      "Epoch: 30/50: 100%|██████████| 87/87 [00:00<00:00, 129.68it/s, train_loss=0.00991, valid_loss=0.011] \n",
      "Epoch: 31/50: 100%|██████████| 87/87 [00:00<00:00, 129.06it/s, train_loss=0.00979, valid_loss=0.0109]\n",
      "Epoch: 32/50: 100%|██████████| 87/87 [00:00<00:00, 123.46it/s, train_loss=0.00992, valid_loss=0.0109]\n",
      "Epoch: 33/50: 100%|██████████| 87/87 [00:00<00:00, 128.83it/s, train_loss=0.0109, valid_loss=0.011]  \n",
      "Epoch: 34/50: 100%|██████████| 87/87 [00:00<00:00, 128.40it/s, train_loss=0.0108, valid_loss=0.011]  \n",
      "Epoch: 35/50: 100%|██████████| 87/87 [00:00<00:00, 134.58it/s, train_loss=0.00971, valid_loss=0.011] \n",
      "Epoch: 36/50: 100%|██████████| 87/87 [00:00<00:00, 134.43it/s, train_loss=0.0099, valid_loss=0.0109] \n",
      "Epoch: 37/50: 100%|██████████| 87/87 [00:00<00:00, 125.33it/s, train_loss=0.0112, valid_loss=0.0109] \n",
      "Epoch: 38/50: 100%|██████████| 87/87 [00:00<00:00, 131.71it/s, train_loss=0.0105, valid_loss=0.0108] \n",
      "Epoch: 39/50: 100%|██████████| 87/87 [00:00<00:00, 126.03it/s, train_loss=0.00971, valid_loss=0.0108]\n",
      "Epoch: 40/50: 100%|██████████| 87/87 [00:00<00:00, 121.92it/s, train_loss=0.00967, valid_loss=0.0109]\n",
      "Epoch: 41/50: 100%|██████████| 87/87 [00:00<00:00, 127.70it/s, train_loss=0.00937, valid_loss=0.0108]\n",
      "Epoch: 42/50: 100%|██████████| 87/87 [00:00<00:00, 134.48it/s, train_loss=0.00997, valid_loss=0.0108]\n",
      "Epoch: 43/50: 100%|██████████| 87/87 [00:00<00:00, 125.53it/s, train_loss=0.0112, valid_loss=0.0108] \n",
      "Epoch: 44/50: 100%|██████████| 87/87 [00:00<00:00, 124.98it/s, train_loss=0.0099, valid_loss=0.0109] \n",
      "Epoch: 45/50: 100%|██████████| 87/87 [00:00<00:00, 129.92it/s, train_loss=0.0108, valid_loss=0.0108] \n",
      "Epoch: 46/50: 100%|██████████| 87/87 [00:00<00:00, 127.83it/s, train_loss=0.011, valid_loss=0.0107]  \n",
      "Epoch: 47/50: 100%|██████████| 87/87 [00:00<00:00, 134.06it/s, train_loss=0.0103, valid_loss=0.0108] \n",
      "Epoch: 48/50: 100%|██████████| 87/87 [00:00<00:00, 120.90it/s, train_loss=0.0108, valid_loss=0.0108] \n",
      "Epoch: 49/50: 100%|██████████| 87/87 [00:00<00:00, 128.00it/s, train_loss=0.0105, valid_loss=0.0108] \n",
      "Epoch: 50/50: 100%|██████████| 87/87 [00:00<00:00, 122.38it/s, train_loss=0.0104, valid_loss=0.0109] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 87/87 [00:00<00:00, 99.98it/s, train_loss=0.036, valid_loss=0.0407]  \n",
      "Epoch: 2/50: 100%|██████████| 87/87 [00:00<00:00, 100.16it/s, train_loss=0.0114, valid_loss=0.00953]\n",
      "Epoch: 3/50: 100%|██████████| 87/87 [00:00<00:00, 109.86it/s, train_loss=0.00879, valid_loss=0.00663]\n",
      "Epoch: 4/50: 100%|██████████| 87/87 [00:00<00:00, 128.89it/s, train_loss=0.00768, valid_loss=0.00567]\n",
      "Epoch: 5/50: 100%|██████████| 87/87 [00:00<00:00, 125.40it/s, train_loss=0.00777, valid_loss=0.00517]\n",
      "Epoch: 6/50: 100%|██████████| 87/87 [00:00<00:00, 127.65it/s, train_loss=0.00565, valid_loss=0.0049] \n",
      "Epoch: 7/50: 100%|██████████| 87/87 [00:00<00:00, 134.98it/s, train_loss=0.0064, valid_loss=0.00457] \n",
      "Epoch: 8/50: 100%|██████████| 87/87 [00:00<00:00, 133.06it/s, train_loss=0.00578, valid_loss=0.0043] \n",
      "Epoch: 9/50: 100%|██████████| 87/87 [00:00<00:00, 133.19it/s, train_loss=0.00525, valid_loss=0.00398]\n",
      "Epoch: 10/50: 100%|██████████| 87/87 [00:00<00:00, 115.41it/s, train_loss=0.00578, valid_loss=0.0039] \n",
      "Epoch: 11/50: 100%|██████████| 87/87 [00:00<00:00, 131.57it/s, train_loss=0.00522, valid_loss=0.00414]\n",
      "Epoch: 12/50: 100%|██████████| 87/87 [00:00<00:00, 134.36it/s, train_loss=0.00515, valid_loss=0.00383]\n",
      "Epoch: 13/50: 100%|██████████| 87/87 [00:00<00:00, 131.81it/s, train_loss=0.00593, valid_loss=0.0037] \n",
      "Epoch: 14/50: 100%|██████████| 87/87 [00:00<00:00, 134.50it/s, train_loss=0.00475, valid_loss=0.00357]\n",
      "Epoch: 15/50: 100%|██████████| 87/87 [00:00<00:00, 121.76it/s, train_loss=0.00507, valid_loss=0.00364]\n",
      "Epoch: 16/50: 100%|██████████| 87/87 [00:00<00:00, 133.60it/s, train_loss=0.00435, valid_loss=0.00362]\n",
      "Epoch: 17/50: 100%|██████████| 87/87 [00:00<00:00, 123.43it/s, train_loss=0.00415, valid_loss=0.00375]\n",
      "Epoch: 18/50: 100%|██████████| 87/87 [00:00<00:00, 127.30it/s, train_loss=0.00449, valid_loss=0.00379]\n",
      "Epoch: 19/50: 100%|██████████| 87/87 [00:00<00:00, 123.13it/s, train_loss=0.00458, valid_loss=0.00374]\n",
      "Epoch: 20/50: 100%|██████████| 87/87 [00:00<00:00, 124.33it/s, train_loss=0.00461, valid_loss=0.00361]\n",
      "Epoch: 21/50: 100%|██████████| 87/87 [00:00<00:00, 138.01it/s, train_loss=0.00519, valid_loss=0.00368]\n",
      "Epoch: 22/50: 100%|██████████| 87/87 [00:00<00:00, 132.41it/s, train_loss=0.00407, valid_loss=0.00346]\n",
      "Epoch: 23/50: 100%|██████████| 87/87 [00:00<00:00, 134.27it/s, train_loss=0.0046, valid_loss=0.00343] \n",
      "Epoch: 24/50: 100%|██████████| 87/87 [00:00<00:00, 133.53it/s, train_loss=0.00423, valid_loss=0.00345]\n",
      "Epoch: 25/50: 100%|██████████| 87/87 [00:00<00:00, 130.07it/s, train_loss=0.0045, valid_loss=0.00351] \n",
      "Epoch: 26/50: 100%|██████████| 87/87 [00:00<00:00, 132.95it/s, train_loss=0.00479, valid_loss=0.00351]\n",
      "Epoch: 27/50: 100%|██████████| 87/87 [00:00<00:00, 138.55it/s, train_loss=0.00448, valid_loss=0.00372]\n",
      "Epoch: 28/50: 100%|██████████| 87/87 [00:00<00:00, 127.26it/s, train_loss=0.00398, valid_loss=0.00347]\n",
      "Epoch: 29/50: 100%|██████████| 87/87 [00:00<00:00, 123.21it/s, train_loss=0.0032, valid_loss=0.00343] \n",
      "Epoch: 30/50: 100%|██████████| 87/87 [00:00<00:00, 139.02it/s, train_loss=0.00413, valid_loss=0.00353]\n",
      "Epoch: 31/50: 100%|██████████| 87/87 [00:00<00:00, 128.67it/s, train_loss=0.005, valid_loss=0.00348]  \n",
      "Epoch: 32/50: 100%|██████████| 87/87 [00:00<00:00, 138.67it/s, train_loss=0.00373, valid_loss=0.00337]\n",
      "Epoch: 33/50: 100%|██████████| 87/87 [00:00<00:00, 131.55it/s, train_loss=0.00353, valid_loss=0.00359]\n",
      "Epoch: 34/50: 100%|██████████| 87/87 [00:00<00:00, 120.88it/s, train_loss=0.00334, valid_loss=0.00341]\n",
      "Epoch: 35/50: 100%|██████████| 87/87 [00:00<00:00, 119.69it/s, train_loss=0.00387, valid_loss=0.00356]\n",
      "Epoch: 36/50: 100%|██████████| 87/87 [00:00<00:00, 120.89it/s, train_loss=0.005, valid_loss=0.0036]   \n",
      "Epoch: 37/50: 100%|██████████| 87/87 [00:00<00:00, 124.67it/s, train_loss=0.00445, valid_loss=0.00347]\n",
      "Epoch: 38/50: 100%|██████████| 87/87 [00:00<00:00, 139.53it/s, train_loss=0.00371, valid_loss=0.0034] \n",
      "Epoch: 39/50: 100%|██████████| 87/87 [00:00<00:00, 129.41it/s, train_loss=0.00377, valid_loss=0.00337]\n",
      "Epoch: 40/50: 100%|██████████| 87/87 [00:00<00:00, 125.45it/s, train_loss=0.00476, valid_loss=0.00323]\n",
      "Epoch: 41/50: 100%|██████████| 87/87 [00:00<00:00, 132.06it/s, train_loss=0.00481, valid_loss=0.00328]\n",
      "Epoch: 42/50: 100%|██████████| 87/87 [00:00<00:00, 132.29it/s, train_loss=0.00524, valid_loss=0.00321]\n",
      "Epoch: 43/50: 100%|██████████| 87/87 [00:00<00:00, 132.21it/s, train_loss=0.00487, valid_loss=0.00321]\n",
      "Epoch: 44/50: 100%|██████████| 87/87 [00:00<00:00, 127.02it/s, train_loss=0.00433, valid_loss=0.0033] \n",
      "Epoch: 45/50: 100%|██████████| 87/87 [00:00<00:00, 125.01it/s, train_loss=0.0041, valid_loss=0.00327] \n",
      "Epoch: 46/50: 100%|██████████| 87/87 [00:00<00:00, 131.89it/s, train_loss=0.00377, valid_loss=0.00323]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 115/115 [00:00<00:00, 130.03it/s, train_loss=0.0325, valid_loss=0.0363]\n",
      "Epoch: 2/50: 100%|██████████| 115/115 [00:00<00:00, 137.62it/s, train_loss=0.0139, valid_loss=0.016] \n",
      "Epoch: 3/50: 100%|██████████| 115/115 [00:00<00:00, 132.69it/s, train_loss=0.0148, valid_loss=0.0128]\n",
      "Epoch: 4/50: 100%|██████████| 115/115 [00:00<00:00, 127.68it/s, train_loss=0.0144, valid_loss=0.0126]\n",
      "Epoch: 5/50: 100%|██████████| 115/115 [00:00<00:00, 134.39it/s, train_loss=0.0135, valid_loss=0.0117]\n",
      "Epoch: 6/50: 100%|██████████| 115/115 [00:00<00:00, 138.15it/s, train_loss=0.0123, valid_loss=0.0116]\n",
      "Epoch: 7/50: 100%|██████████| 115/115 [00:00<00:00, 132.19it/s, train_loss=0.0112, valid_loss=0.0116] \n",
      "Epoch: 8/50: 100%|██████████| 115/115 [00:00<00:00, 131.04it/s, train_loss=0.0124, valid_loss=0.0115]\n",
      "Epoch: 9/50: 100%|██████████| 115/115 [00:00<00:00, 128.47it/s, train_loss=0.012, valid_loss=0.0113] \n",
      "Epoch: 10/50: 100%|██████████| 115/115 [00:00<00:00, 141.55it/s, train_loss=0.0111, valid_loss=0.0112]\n",
      "Epoch: 11/50: 100%|██████████| 115/115 [00:00<00:00, 135.33it/s, train_loss=0.0112, valid_loss=0.0112]\n",
      "Epoch: 12/50: 100%|██████████| 115/115 [00:00<00:00, 137.32it/s, train_loss=0.0113, valid_loss=0.0112]\n",
      "Epoch: 13/50: 100%|██████████| 115/115 [00:00<00:00, 144.78it/s, train_loss=0.0112, valid_loss=0.0106]\n",
      "Epoch: 14/50: 100%|██████████| 115/115 [00:00<00:00, 134.92it/s, train_loss=0.0121, valid_loss=0.011] \n",
      "Epoch: 15/50: 100%|██████████| 115/115 [00:00<00:00, 128.33it/s, train_loss=0.0114, valid_loss=0.0109]\n",
      "Epoch: 16/50: 100%|██████████| 115/115 [00:00<00:00, 125.87it/s, train_loss=0.0107, valid_loss=0.0107]\n",
      "Epoch: 17/50: 100%|██████████| 115/115 [00:00<00:00, 137.67it/s, train_loss=0.0127, valid_loss=0.0106]\n",
      "Epoch: 18/50: 100%|██████████| 115/115 [00:00<00:00, 136.30it/s, train_loss=0.012, valid_loss=0.0109] \n",
      "Epoch: 19/50: 100%|██████████| 115/115 [00:00<00:00, 134.92it/s, train_loss=0.0111, valid_loss=0.011]  \n",
      "Epoch: 20/50: 100%|██████████| 115/115 [00:00<00:00, 130.24it/s, train_loss=0.0109, valid_loss=0.0105]\n",
      "Epoch: 21/50: 100%|██████████| 115/115 [00:00<00:00, 131.00it/s, train_loss=0.00988, valid_loss=0.0112]\n",
      "Epoch: 22/50: 100%|██████████| 115/115 [00:00<00:00, 125.18it/s, train_loss=0.0113, valid_loss=0.011] \n",
      "Epoch: 23/50: 100%|██████████| 115/115 [00:00<00:00, 135.08it/s, train_loss=0.011, valid_loss=0.0107] \n",
      "Epoch: 24/50: 100%|██████████| 115/115 [00:00<00:00, 133.20it/s, train_loss=0.0098, valid_loss=0.0107]\n",
      "Epoch: 25/50: 100%|██████████| 115/115 [00:00<00:00, 128.51it/s, train_loss=0.014, valid_loss=0.0106] \n",
      "Epoch: 26/50: 100%|██████████| 115/115 [00:00<00:00, 141.86it/s, train_loss=0.0103, valid_loss=0.0108]\n",
      "Epoch: 27/50: 100%|██████████| 115/115 [00:00<00:00, 133.08it/s, train_loss=0.011, valid_loss=0.0112] \n",
      "Epoch: 28/50: 100%|██████████| 115/115 [00:00<00:00, 135.40it/s, train_loss=0.0102, valid_loss=0.0109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 115/115 [00:00<00:00, 127.82it/s, train_loss=0.0212, valid_loss=0.0114]\n",
      "Epoch: 2/50: 100%|██████████| 115/115 [00:00<00:00, 126.07it/s, train_loss=0.0122, valid_loss=0.00623]\n",
      "Epoch: 3/50: 100%|██████████| 115/115 [00:00<00:00, 133.37it/s, train_loss=0.00775, valid_loss=0.00432]\n",
      "Epoch: 4/50: 100%|██████████| 115/115 [00:00<00:00, 134.03it/s, train_loss=0.00855, valid_loss=0.00386]\n",
      "Epoch: 5/50: 100%|██████████| 115/115 [00:00<00:00, 135.85it/s, train_loss=0.00653, valid_loss=0.00332]\n",
      "Epoch: 6/50: 100%|██████████| 115/115 [00:00<00:00, 133.66it/s, train_loss=0.00609, valid_loss=0.00252]\n",
      "Epoch: 7/50: 100%|██████████| 115/115 [00:00<00:00, 130.62it/s, train_loss=0.00563, valid_loss=0.00306]\n",
      "Epoch: 8/50: 100%|██████████| 115/115 [00:00<00:00, 123.93it/s, train_loss=0.00575, valid_loss=0.00209]\n",
      "Epoch: 9/50: 100%|██████████| 115/115 [00:00<00:00, 119.24it/s, train_loss=0.00514, valid_loss=0.00363]\n",
      "Epoch: 10/50: 100%|██████████| 115/115 [00:00<00:00, 123.23it/s, train_loss=0.00631, valid_loss=0.00217]\n",
      "Epoch: 11/50: 100%|██████████| 115/115 [00:00<00:00, 124.92it/s, train_loss=0.00468, valid_loss=0.00244]\n",
      "Epoch: 12/50: 100%|██████████| 115/115 [00:00<00:00, 129.93it/s, train_loss=0.0051, valid_loss=0.00203] \n",
      "Epoch: 13/50: 100%|██████████| 115/115 [00:00<00:00, 129.55it/s, train_loss=0.00513, valid_loss=0.00214]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 144/144 [00:01<00:00, 117.37it/s, train_loss=0.0269, valid_loss=0.0214]\n",
      "Epoch: 2/50: 100%|██████████| 144/144 [00:01<00:00, 123.09it/s, train_loss=0.019, valid_loss=0.0164] \n",
      "Epoch: 3/50: 100%|██████████| 144/144 [00:01<00:00, 119.30it/s, train_loss=0.0217, valid_loss=0.0153]\n",
      "Epoch: 4/50: 100%|██████████| 144/144 [00:01<00:00, 124.38it/s, train_loss=0.0189, valid_loss=0.0147]\n",
      "Epoch: 5/50: 100%|██████████| 144/144 [00:01<00:00, 129.79it/s, train_loss=0.0208, valid_loss=0.0143]\n",
      "Epoch: 6/50: 100%|██████████| 144/144 [00:01<00:00, 126.24it/s, train_loss=0.0203, valid_loss=0.014] \n",
      "Epoch: 7/50: 100%|██████████| 144/144 [00:01<00:00, 129.96it/s, train_loss=0.0196, valid_loss=0.0139]\n",
      "Epoch: 8/50: 100%|██████████| 144/144 [00:01<00:00, 123.56it/s, train_loss=0.0163, valid_loss=0.0137]\n",
      "Epoch: 9/50: 100%|██████████| 144/144 [00:01<00:00, 118.47it/s, train_loss=0.0126, valid_loss=0.00819]\n",
      "Epoch: 10/50: 100%|██████████| 144/144 [00:01<00:00, 129.44it/s, train_loss=0.0118, valid_loss=0.00809]\n",
      "Epoch: 11/50: 100%|██████████| 144/144 [00:01<00:00, 120.74it/s, train_loss=0.012, valid_loss=0.00804] \n",
      "Epoch: 12/50: 100%|██████████| 144/144 [00:01<00:00, 124.99it/s, train_loss=0.0116, valid_loss=0.00792]\n",
      "Epoch: 13/50: 100%|██████████| 144/144 [00:01<00:00, 129.35it/s, train_loss=0.0118, valid_loss=0.00796]\n",
      "Epoch: 14/50: 100%|██████████| 144/144 [00:01<00:00, 123.28it/s, train_loss=0.0108, valid_loss=0.0079] \n",
      "Epoch: 15/50: 100%|██████████| 144/144 [00:01<00:00, 129.71it/s, train_loss=0.0114, valid_loss=0.0079] \n",
      "Epoch: 16/50: 100%|██████████| 144/144 [00:01<00:00, 126.96it/s, train_loss=0.0121, valid_loss=0.00786]\n",
      "Epoch: 17/50: 100%|██████████| 144/144 [00:01<00:00, 128.61it/s, train_loss=0.0116, valid_loss=0.00792]\n",
      "Epoch: 18/50: 100%|██████████| 144/144 [00:01<00:00, 123.25it/s, train_loss=0.0134, valid_loss=0.0079] \n",
      "Epoch: 19/50: 100%|██████████| 144/144 [00:01<00:00, 123.03it/s, train_loss=0.0117, valid_loss=0.00783] \n",
      "Epoch: 20/50: 100%|██████████| 144/144 [00:01<00:00, 124.77it/s, train_loss=0.0119, valid_loss=0.00783]\n",
      "Epoch: 21/50: 100%|██████████| 144/144 [00:01<00:00, 125.32it/s, train_loss=0.0121, valid_loss=0.00778]\n",
      "Epoch: 22/50: 100%|██████████| 144/144 [00:01<00:00, 131.91it/s, train_loss=0.0123, valid_loss=0.00789]\n",
      "Epoch: 23/50: 100%|██████████| 144/144 [00:01<00:00, 125.34it/s, train_loss=0.0113, valid_loss=0.00779]\n",
      "Epoch: 24/50: 100%|██████████| 144/144 [00:01<00:00, 125.96it/s, train_loss=0.0118, valid_loss=0.00772] \n",
      "Epoch: 25/50: 100%|██████████| 144/144 [00:01<00:00, 128.45it/s, train_loss=0.0111, valid_loss=0.00773]\n",
      "Epoch: 26/50: 100%|██████████| 144/144 [00:01<00:00, 124.22it/s, train_loss=0.0113, valid_loss=0.00775]\n",
      "Epoch: 27/50: 100%|██████████| 144/144 [00:01<00:00, 130.55it/s, train_loss=0.0111, valid_loss=0.00773]\n",
      "Epoch: 28/50: 100%|██████████| 144/144 [00:01<00:00, 124.61it/s, train_loss=0.011, valid_loss=0.00782] \n",
      "Epoch: 29/50: 100%|██████████| 144/144 [00:01<00:00, 125.01it/s, train_loss=0.0114, valid_loss=0.00775]\n",
      "Epoch: 30/50: 100%|██████████| 144/144 [00:01<00:00, 131.89it/s, train_loss=0.0107, valid_loss=0.00767]\n",
      "Epoch: 31/50: 100%|██████████| 144/144 [00:01<00:00, 122.84it/s, train_loss=0.0107, valid_loss=0.0077] \n",
      "Epoch: 32/50: 100%|██████████| 144/144 [00:01<00:00, 121.93it/s, train_loss=0.0106, valid_loss=0.00765] \n",
      "Epoch: 33/50: 100%|██████████| 144/144 [00:01<00:00, 124.11it/s, train_loss=0.0107, valid_loss=0.00763]\n",
      "Epoch: 34/50: 100%|██████████| 144/144 [00:01<00:00, 126.80it/s, train_loss=0.0108, valid_loss=0.00772]\n",
      "Epoch: 35/50: 100%|██████████| 144/144 [00:01<00:00, 129.79it/s, train_loss=0.011, valid_loss=0.00774] \n",
      "Epoch: 36/50: 100%|██████████| 144/144 [00:01<00:00, 127.34it/s, train_loss=0.0116, valid_loss=0.00766]\n",
      "Epoch: 37/50: 100%|██████████| 144/144 [00:01<00:00, 129.09it/s, train_loss=0.0113, valid_loss=0.00764]\n",
      "Epoch: 38/50: 100%|██████████| 144/144 [00:01<00:00, 122.53it/s, train_loss=0.011, valid_loss=0.0077]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config: batch_size--128, lr--0.005, number_epoch--50, hidden_dim--35,drop_prob-0.1,weight_decay-1e-07\n",
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 29/29 [00:00<00:00, 110.88it/s, train_loss=0.0221, valid_loss=0.0388]\n",
      "Epoch: 2/50: 100%|██████████| 29/29 [00:00<00:00, 135.71it/s, train_loss=0.0193, valid_loss=0.0316]\n",
      "Epoch: 3/50: 100%|██████████| 29/29 [00:00<00:00, 117.57it/s, train_loss=0.0156, valid_loss=0.0217]\n",
      "Epoch: 4/50: 100%|██████████| 29/29 [00:00<00:00, 134.61it/s, train_loss=0.0105, valid_loss=0.0145]\n",
      "Epoch: 5/50: 100%|██████████| 29/29 [00:00<00:00, 135.15it/s, train_loss=0.00982, valid_loss=0.0128]\n",
      "Epoch: 6/50: 100%|██████████| 29/29 [00:00<00:00, 116.39it/s, train_loss=0.00868, valid_loss=0.012] \n",
      "Epoch: 7/50: 100%|██████████| 29/29 [00:00<00:00, 125.64it/s, train_loss=0.00596, valid_loss=0.00652]\n",
      "Epoch: 8/50: 100%|██████████| 29/29 [00:00<00:00, 115.99it/s, train_loss=0.00374, valid_loss=0.00516]\n",
      "Epoch: 9/50: 100%|██████████| 29/29 [00:00<00:00, 116.37it/s, train_loss=0.00306, valid_loss=0.00499]\n",
      "Epoch: 10/50: 100%|██████████| 29/29 [00:00<00:00, 107.12it/s, train_loss=0.00304, valid_loss=0.00482]\n",
      "Epoch: 11/50: 100%|██████████| 29/29 [00:00<00:00, 118.11it/s, train_loss=0.00278, valid_loss=0.00557]\n",
      "Epoch: 12/50: 100%|██████████| 29/29 [00:00<00:00, 110.69it/s, train_loss=0.00295, valid_loss=0.00478]\n",
      "Epoch: 13/50: 100%|██████████| 29/29 [00:00<00:00, 130.17it/s, train_loss=0.00412, valid_loss=0.00536]\n",
      "Epoch: 14/50: 100%|██████████| 29/29 [00:00<00:00, 121.17it/s, train_loss=0.00283, valid_loss=0.00477]\n",
      "Epoch: 15/50: 100%|██████████| 29/29 [00:00<00:00, 112.39it/s, train_loss=0.00255, valid_loss=0.00492]\n",
      "Epoch: 16/50: 100%|██████████| 29/29 [00:00<00:00, 126.79it/s, train_loss=0.00269, valid_loss=0.00492]\n",
      "Epoch: 17/50: 100%|██████████| 29/29 [00:00<00:00, 116.68it/s, train_loss=0.00273, valid_loss=0.0049] \n",
      "Epoch: 18/50: 100%|██████████| 29/29 [00:00<00:00, 124.09it/s, train_loss=0.00251, valid_loss=0.00471]\n",
      "Epoch: 19/50: 100%|██████████| 29/29 [00:00<00:00, 128.16it/s, train_loss=0.00293, valid_loss=0.00505]\n",
      "Epoch: 20/50: 100%|██████████| 29/29 [00:00<00:00, 126.22it/s, train_loss=0.00236, valid_loss=0.00468]\n",
      "Epoch: 21/50: 100%|██████████| 29/29 [00:00<00:00, 130.80it/s, train_loss=0.00289, valid_loss=0.00507]\n",
      "Epoch: 22/50: 100%|██████████| 29/29 [00:00<00:00, 128.19it/s, train_loss=0.00275, valid_loss=0.00469]\n",
      "Epoch: 23/50: 100%|██████████| 29/29 [00:00<00:00, 130.59it/s, train_loss=0.00304, valid_loss=0.00479]\n",
      "Epoch: 24/50: 100%|██████████| 29/29 [00:00<00:00, 130.93it/s, train_loss=0.00246, valid_loss=0.00518]\n",
      "Epoch: 25/50: 100%|██████████| 29/29 [00:00<00:00, 105.84it/s, train_loss=0.00244, valid_loss=0.00461]\n",
      "Epoch: 26/50: 100%|██████████| 29/29 [00:00<00:00, 130.45it/s, train_loss=0.00237, valid_loss=0.00534]\n",
      "Epoch: 27/50: 100%|██████████| 29/29 [00:00<00:00, 111.42it/s, train_loss=0.00221, valid_loss=0.00475]\n",
      "Epoch: 28/50: 100%|██████████| 29/29 [00:00<00:00, 112.78it/s, train_loss=0.00255, valid_loss=0.00463]\n",
      "Epoch: 29/50: 100%|██████████| 29/29 [00:00<00:00, 130.18it/s, train_loss=0.00274, valid_loss=0.00475]\n",
      "Epoch: 30/50: 100%|██████████| 29/29 [00:00<00:00, 126.96it/s, train_loss=0.00221, valid_loss=0.00526]\n",
      "Epoch: 31/50: 100%|██████████| 29/29 [00:00<00:00, 130.11it/s, train_loss=0.00268, valid_loss=0.00474]\n",
      "Epoch: 32/50: 100%|██████████| 29/29 [00:00<00:00, 116.49it/s, train_loss=0.00246, valid_loss=0.00504]\n",
      "Epoch: 33/50: 100%|██████████| 29/29 [00:00<00:00, 126.67it/s, train_loss=0.00216, valid_loss=0.0051]\n",
      "Epoch: 34/50: 100%|██████████| 29/29 [00:00<00:00, 117.75it/s, train_loss=0.00272, valid_loss=0.00464]\n",
      "Epoch: 35/50: 100%|██████████| 29/29 [00:00<00:00, 124.55it/s, train_loss=0.00234, valid_loss=0.00503]\n",
      "Epoch: 36/50: 100%|██████████| 29/29 [00:00<00:00, 136.52it/s, train_loss=0.00256, valid_loss=0.00492]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 58/58 [00:00<00:00, 122.33it/s, train_loss=0.0171, valid_loss=0.016] \n",
      "Epoch: 2/50: 100%|██████████| 58/58 [00:00<00:00, 130.66it/s, train_loss=0.00677, valid_loss=0.00575]\n",
      "Epoch: 3/50: 100%|██████████| 58/58 [00:00<00:00, 130.12it/s, train_loss=0.00553, valid_loss=0.0034] \n",
      "Epoch: 4/50: 100%|██████████| 58/58 [00:00<00:00, 135.18it/s, train_loss=0.00681, valid_loss=0.00607]\n",
      "Epoch: 5/50: 100%|██████████| 58/58 [00:00<00:00, 129.64it/s, train_loss=0.00409, valid_loss=0.00291]\n",
      "Epoch: 6/50: 100%|██████████| 58/58 [00:00<00:00, 103.80it/s, train_loss=0.00517, valid_loss=0.00321]\n",
      "Epoch: 7/50: 100%|██████████| 58/58 [00:00<00:00, 116.55it/s, train_loss=0.00393, valid_loss=0.00348]\n",
      "Epoch: 8/50: 100%|██████████| 58/58 [00:00<00:00, 130.23it/s, train_loss=0.00376, valid_loss=0.00586]\n",
      "Epoch: 9/50: 100%|██████████| 58/58 [00:00<00:00, 122.38it/s, train_loss=0.00328, valid_loss=0.00306]\n",
      "Epoch: 10/50: 100%|██████████| 58/58 [00:00<00:00, 116.09it/s, train_loss=0.00356, valid_loss=0.00378]\n",
      "Epoch: 11/50: 100%|██████████| 58/58 [00:00<00:00, 119.36it/s, train_loss=0.00281, valid_loss=0.00378]\n",
      "Epoch: 12/50: 100%|██████████| 58/58 [00:00<00:00, 135.95it/s, train_loss=0.00429, valid_loss=0.00362]\n",
      "Epoch: 13/50: 100%|██████████| 58/58 [00:00<00:00, 119.38it/s, train_loss=0.00502, valid_loss=0.00256]\n",
      "Epoch: 14/50: 100%|██████████| 58/58 [00:00<00:00, 129.73it/s, train_loss=0.00517, valid_loss=0.00338]\n",
      "Epoch: 15/50: 100%|██████████| 58/58 [00:00<00:00, 125.59it/s, train_loss=0.00435, valid_loss=0.00233]\n",
      "Epoch: 16/50: 100%|██████████| 58/58 [00:00<00:00, 122.86it/s, train_loss=0.00336, valid_loss=0.00371]\n",
      "Epoch: 17/50: 100%|██████████| 58/58 [00:00<00:00, 124.45it/s, train_loss=0.00385, valid_loss=0.00276]\n",
      "Epoch: 18/50: 100%|██████████| 58/58 [00:00<00:00, 126.91it/s, train_loss=0.0038, valid_loss=0.00282] \n",
      "Epoch: 19/50: 100%|██████████| 58/58 [00:00<00:00, 120.09it/s, train_loss=0.00355, valid_loss=0.00252]\n",
      "Epoch: 20/50: 100%|██████████| 58/58 [00:00<00:00, 116.68it/s, train_loss=0.00321, valid_loss=0.00335]\n",
      "Epoch: 21/50: 100%|██████████| 58/58 [00:00<00:00, 130.50it/s, train_loss=0.00467, valid_loss=0.00334]\n",
      "Epoch: 22/50: 100%|██████████| 58/58 [00:00<00:00, 131.12it/s, train_loss=0.00368, valid_loss=0.00291]\n",
      "Epoch: 23/50: 100%|██████████| 58/58 [00:00<00:00, 134.07it/s, train_loss=0.00379, valid_loss=0.00289]\n",
      "Epoch: 24/50: 100%|██████████| 58/58 [00:00<00:00, 112.29it/s, train_loss=0.00437, valid_loss=0.00366]\n",
      "Epoch: 25/50: 100%|██████████| 58/58 [00:00<00:00, 123.66it/s, train_loss=0.00431, valid_loss=0.00344]\n",
      "Epoch: 26/50: 100%|██████████| 58/58 [00:00<00:00, 119.21it/s, train_loss=0.00364, valid_loss=0.0053] \n",
      "Epoch: 27/50: 100%|██████████| 58/58 [00:00<00:00, 125.83it/s, train_loss=0.00342, valid_loss=0.0031] \n",
      "Epoch: 28/50: 100%|██████████| 58/58 [00:00<00:00, 123.43it/s, train_loss=0.00391, valid_loss=0.00261]\n",
      "Epoch: 29/50: 100%|██████████| 58/58 [00:00<00:00, 112.08it/s, train_loss=0.00374, valid_loss=0.00297]\n",
      "Epoch: 30/50: 100%|██████████| 58/58 [00:00<00:00, 120.57it/s, train_loss=0.00394, valid_loss=0.00251]\n",
      "Epoch: 31/50: 100%|██████████| 58/58 [00:00<00:00, 125.80it/s, train_loss=0.0044, valid_loss=0.00338] \n",
      "Epoch: 32/50: 100%|██████████| 58/58 [00:00<00:00, 122.03it/s, train_loss=0.0035, valid_loss=0.00358] \n",
      "Epoch: 33/50: 100%|██████████| 58/58 [00:00<00:00, 126.08it/s, train_loss=0.00317, valid_loss=0.00289]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 87/87 [00:00<00:00, 122.98it/s, train_loss=0.0142, valid_loss=0.0144]\n",
      "Epoch: 2/50: 100%|██████████| 87/87 [00:00<00:00, 122.73it/s, train_loss=0.00645, valid_loss=0.00531]\n",
      "Epoch: 3/50: 100%|██████████| 87/87 [00:00<00:00, 125.48it/s, train_loss=0.00529, valid_loss=0.00379]\n",
      "Epoch: 4/50: 100%|██████████| 87/87 [00:00<00:00, 119.95it/s, train_loss=0.00455, valid_loss=0.00374]\n",
      "Epoch: 5/50: 100%|██████████| 87/87 [00:00<00:00, 123.47it/s, train_loss=0.00459, valid_loss=0.00518]\n",
      "Epoch: 6/50: 100%|██████████| 87/87 [00:00<00:00, 124.02it/s, train_loss=0.0052, valid_loss=0.00412] \n",
      "Epoch: 7/50: 100%|██████████| 87/87 [00:00<00:00, 129.13it/s, train_loss=0.00428, valid_loss=0.00341]\n",
      "Epoch: 8/50: 100%|██████████| 87/87 [00:00<00:00, 122.03it/s, train_loss=0.00433, valid_loss=0.00348]\n",
      "Epoch: 9/50: 100%|██████████| 87/87 [00:00<00:00, 119.84it/s, train_loss=0.00317, valid_loss=0.00341]\n",
      "Epoch: 10/50: 100%|██████████| 87/87 [00:00<00:00, 118.97it/s, train_loss=0.00427, valid_loss=0.00339]\n",
      "Epoch: 11/50: 100%|██████████| 87/87 [00:00<00:00, 132.95it/s, train_loss=0.00376, valid_loss=0.00329]\n",
      "Epoch: 12/50: 100%|██████████| 87/87 [00:00<00:00, 111.09it/s, train_loss=0.00464, valid_loss=0.00358]\n",
      "Epoch: 13/50: 100%|██████████| 87/87 [00:00<00:00, 120.67it/s, train_loss=0.00383, valid_loss=0.00326]\n",
      "Epoch: 14/50: 100%|██████████| 87/87 [00:00<00:00, 117.23it/s, train_loss=0.00377, valid_loss=0.00343]\n",
      "Epoch: 15/50: 100%|██████████| 87/87 [00:00<00:00, 120.16it/s, train_loss=0.00306, valid_loss=0.00374]\n",
      "Epoch: 16/50: 100%|██████████| 87/87 [00:00<00:00, 124.01it/s, train_loss=0.00336, valid_loss=0.00369]\n",
      "Epoch: 17/50: 100%|██████████| 87/87 [00:00<00:00, 130.03it/s, train_loss=0.00345, valid_loss=0.00349]\n",
      "Epoch: 18/50: 100%|██████████| 87/87 [00:00<00:00, 128.75it/s, train_loss=0.00379, valid_loss=0.0035] \n",
      "Epoch: 19/50: 100%|██████████| 87/87 [00:00<00:00, 125.32it/s, train_loss=0.0029, valid_loss=0.00346] \n",
      "Epoch: 20/50: 100%|██████████| 87/87 [00:00<00:00, 123.42it/s, train_loss=0.00299, valid_loss=0.00347]\n",
      "Epoch: 21/50: 100%|██████████| 87/87 [00:00<00:00, 128.90it/s, train_loss=0.00311, valid_loss=0.00334]\n",
      "Epoch: 22/50: 100%|██████████| 87/87 [00:00<00:00, 114.51it/s, train_loss=0.00387, valid_loss=0.00334]\n",
      "Epoch: 23/50: 100%|██████████| 87/87 [00:00<00:00, 121.76it/s, train_loss=0.003, valid_loss=0.00371]  \n",
      "Epoch: 24/50: 100%|██████████| 87/87 [00:00<00:00, 123.66it/s, train_loss=0.0028, valid_loss=0.00357] \n",
      "Epoch: 25/50: 100%|██████████| 87/87 [00:00<00:00, 122.74it/s, train_loss=0.00298, valid_loss=0.00363]\n",
      "Epoch: 26/50: 100%|██████████| 87/87 [00:00<00:00, 128.45it/s, train_loss=0.00313, valid_loss=0.00334]\n",
      "Epoch: 27/50: 100%|██████████| 87/87 [00:00<00:00, 120.79it/s, train_loss=0.00294, valid_loss=0.00354]\n",
      "Epoch: 28/50: 100%|██████████| 87/87 [00:00<00:00, 120.75it/s, train_loss=0.00294, valid_loss=0.00339]\n",
      "Epoch: 29/50: 100%|██████████| 87/87 [00:00<00:00, 116.73it/s, train_loss=0.0039, valid_loss=0.00406] \n",
      "Epoch: 30/50: 100%|██████████| 87/87 [00:00<00:00, 130.01it/s, train_loss=0.00323, valid_loss=0.00328]\n",
      "Epoch: 31/50: 100%|██████████| 87/87 [00:00<00:00, 132.86it/s, train_loss=0.0033, valid_loss=0.00307] \n",
      "Epoch: 32/50: 100%|██████████| 87/87 [00:00<00:00, 125.00it/s, train_loss=0.00272, valid_loss=0.00339]\n",
      "Epoch: 33/50: 100%|██████████| 87/87 [00:00<00:00, 129.43it/s, train_loss=0.00321, valid_loss=0.00314]\n",
      "Epoch: 34/50: 100%|██████████| 87/87 [00:00<00:00, 129.28it/s, train_loss=0.00297, valid_loss=0.00345]\n",
      "Epoch: 35/50: 100%|██████████| 87/87 [00:00<00:00, 119.80it/s, train_loss=0.00425, valid_loss=0.00357]\n",
      "Epoch: 36/50: 100%|██████████| 87/87 [00:00<00:00, 121.82it/s, train_loss=0.00385, valid_loss=0.00354]\n",
      "Epoch: 37/50: 100%|██████████| 87/87 [00:00<00:00, 125.09it/s, train_loss=0.00308, valid_loss=0.00321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 115/115 [00:00<00:00, 119.97it/s, train_loss=0.00801, valid_loss=0.0057] \n",
      "Epoch: 2/50: 100%|██████████| 115/115 [00:00<00:00, 133.94it/s, train_loss=0.00567, valid_loss=0.00362]\n",
      "Epoch: 3/50: 100%|██████████| 115/115 [00:00<00:00, 124.55it/s, train_loss=0.00574, valid_loss=0.00209]\n",
      "Epoch: 4/50: 100%|██████████| 115/115 [00:00<00:00, 127.77it/s, train_loss=0.00444, valid_loss=0.00215]\n",
      "Epoch: 5/50: 100%|██████████| 115/115 [00:00<00:00, 123.84it/s, train_loss=0.00518, valid_loss=0.00315]\n",
      "Epoch: 6/50: 100%|██████████| 115/115 [00:00<00:00, 127.74it/s, train_loss=0.00473, valid_loss=0.00374]\n",
      "Epoch: 7/50: 100%|██████████| 115/115 [00:00<00:00, 127.50it/s, train_loss=0.00431, valid_loss=0.00299]\n",
      "Epoch: 8/50: 100%|██████████| 115/115 [00:00<00:00, 124.28it/s, train_loss=0.00371, valid_loss=0.00324]\n",
      "Epoch: 9/50: 100%|██████████| 115/115 [00:00<00:00, 120.01it/s, train_loss=0.00344, valid_loss=0.00325]\n",
      "Epoch: 10/50: 100%|██████████| 115/115 [00:00<00:00, 128.45it/s, train_loss=0.00368, valid_loss=0.00199]\n",
      "Epoch: 11/50: 100%|██████████| 115/115 [00:00<00:00, 131.63it/s, train_loss=0.00403, valid_loss=0.00215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 144/144 [00:01<00:00, 113.82it/s, train_loss=0.00754, valid_loss=0.00419]\n",
      "Epoch: 2/50: 100%|██████████| 144/144 [00:01<00:00, 130.10it/s, train_loss=0.00545, valid_loss=0.00271]\n",
      "Epoch: 3/50: 100%|██████████| 144/144 [00:01<00:00, 125.31it/s, train_loss=0.00364, valid_loss=0.00247]\n",
      "Epoch: 4/50: 100%|██████████| 144/144 [00:01<00:00, 121.81it/s, train_loss=0.00414, valid_loss=0.00266]\n",
      "Epoch: 5/50: 100%|██████████| 144/144 [00:01<00:00, 125.77it/s, train_loss=0.00379, valid_loss=0.00248]\n",
      "Epoch: 6/50: 100%|██████████| 144/144 [00:01<00:00, 126.82it/s, train_loss=0.00341, valid_loss=0.00244]\n",
      "Epoch: 7/50: 100%|██████████| 144/144 [00:01<00:00, 120.50it/s, train_loss=0.00407, valid_loss=0.00221]\n",
      "Epoch: 8/50: 100%|██████████| 144/144 [00:01<00:00, 120.47it/s, train_loss=0.00417, valid_loss=0.00224]\n",
      "Epoch: 9/50: 100%|██████████| 144/144 [00:01<00:00, 132.90it/s, train_loss=0.00378, valid_loss=0.00245]\n",
      "Epoch: 10/50: 100%|██████████| 144/144 [00:01<00:00, 125.98it/s, train_loss=0.00345, valid_loss=0.00223]\n",
      "Epoch: 11/50: 100%|██████████| 144/144 [00:01<00:00, 123.80it/s, train_loss=0.00387, valid_loss=0.00215]\n",
      "Epoch: 12/50: 100%|██████████| 144/144 [00:01<00:00, 122.61it/s, train_loss=0.00356, valid_loss=0.00215]\n",
      "Epoch: 13/50: 100%|██████████| 144/144 [00:01<00:00, 126.88it/s, train_loss=0.00422, valid_loss=0.00251]\n",
      "Epoch: 14/50: 100%|██████████| 144/144 [00:01<00:00, 118.77it/s, train_loss=0.00423, valid_loss=0.00287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config: batch_size--512, lr--0.01, number_epoch--50, hidden_dim--30,drop_prob-0.1,weight_decay-1e-07\n",
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 8/8 [00:00<00:00, 81.77it/s, train_loss=0.0511, valid_loss=0.0754]\n",
      "Epoch: 2/50: 100%|██████████| 8/8 [00:00<00:00, 88.68it/s, train_loss=0.0204, valid_loss=0.032]\n",
      "Epoch: 3/50: 100%|██████████| 8/8 [00:00<00:00, 54.52it/s, train_loss=0.0143, valid_loss=0.0237]\n",
      "Epoch: 4/50: 100%|██████████| 8/8 [00:00<00:00, 128.30it/s, train_loss=0.011, valid_loss=0.0232]\n",
      "Epoch: 5/50: 100%|██████████| 8/8 [00:00<00:00, 98.93it/s, train_loss=0.00973, valid_loss=0.0207]\n",
      "Epoch: 6/50: 100%|██████████| 8/8 [00:00<00:00, 117.41it/s, train_loss=0.00832, valid_loss=0.017]\n",
      "Epoch: 7/50: 100%|██████████| 8/8 [00:00<00:00, 103.69it/s, train_loss=0.00697, valid_loss=0.0115]\n",
      "Epoch: 8/50: 100%|██████████| 8/8 [00:00<00:00, 103.29it/s, train_loss=0.00623, valid_loss=0.00809]\n",
      "Epoch: 9/50: 100%|██████████| 8/8 [00:00<00:00, 111.89it/s, train_loss=0.0056, valid_loss=0.00744]\n",
      "Epoch: 10/50: 100%|██████████| 8/8 [00:00<00:00, 99.20it/s, train_loss=0.00499, valid_loss=0.00649]\n",
      "Epoch: 11/50: 100%|██████████| 8/8 [00:00<00:00, 100.10it/s, train_loss=0.00514, valid_loss=0.00637]\n",
      "Epoch: 12/50: 100%|██████████| 8/8 [00:00<00:00, 117.62it/s, train_loss=0.0047, valid_loss=0.00597]\n",
      "Epoch: 13/50: 100%|██████████| 8/8 [00:00<00:00, 111.57it/s, train_loss=0.00465, valid_loss=0.00603]\n",
      "Epoch: 14/50: 100%|██████████| 8/8 [00:00<00:00, 129.10it/s, train_loss=0.00439, valid_loss=0.00582]\n",
      "Epoch: 15/50: 100%|██████████| 8/8 [00:00<00:00, 120.38it/s, train_loss=0.00423, valid_loss=0.00582]\n",
      "Epoch: 16/50: 100%|██████████| 8/8 [00:00<00:00, 109.99it/s, train_loss=0.00372, valid_loss=0.00546]\n",
      "Epoch: 17/50: 100%|██████████| 8/8 [00:00<00:00, 120.95it/s, train_loss=0.00383, valid_loss=0.00574]\n",
      "Epoch: 18/50: 100%|██████████| 8/8 [00:00<00:00, 129.09it/s, train_loss=0.00371, valid_loss=0.00533]\n",
      "Epoch: 19/50: 100%|██████████| 8/8 [00:00<00:00, 130.90it/s, train_loss=0.00342, valid_loss=0.00572]\n",
      "Epoch: 20/50: 100%|██████████| 8/8 [00:00<00:00, 81.56it/s, train_loss=0.00351, valid_loss=0.00569]\n",
      "Epoch: 21/50: 100%|██████████| 8/8 [00:00<00:00, 127.13it/s, train_loss=0.00352, valid_loss=0.00531]\n",
      "Epoch: 22/50: 100%|██████████| 8/8 [00:00<00:00, 97.54it/s, train_loss=0.00371, valid_loss=0.0051]\n",
      "Epoch: 23/50: 100%|██████████| 8/8 [00:00<00:00, 118.73it/s, train_loss=0.00355, valid_loss=0.00499]\n",
      "Epoch: 24/50: 100%|██████████| 8/8 [00:00<00:00, 90.07it/s, train_loss=0.00301, valid_loss=0.00498]\n",
      "Epoch: 25/50: 100%|██████████| 8/8 [00:00<00:00, 127.16it/s, train_loss=0.00319, valid_loss=0.00508]\n",
      "Epoch: 26/50: 100%|██████████| 8/8 [00:00<00:00, 94.89it/s, train_loss=0.00322, valid_loss=0.00507]\n",
      "Epoch: 27/50: 100%|██████████| 8/8 [00:00<00:00, 105.82it/s, train_loss=0.00305, valid_loss=0.00485]\n",
      "Epoch: 28/50: 100%|██████████| 8/8 [00:00<00:00, 130.28it/s, train_loss=0.00302, valid_loss=0.00505]\n",
      "Epoch: 29/50: 100%|██████████| 8/8 [00:00<00:00, 97.05it/s, train_loss=0.00305, valid_loss=0.00493]\n",
      "Epoch: 30/50: 100%|██████████| 8/8 [00:00<00:00, 127.31it/s, train_loss=0.00344, valid_loss=0.00472]\n",
      "Epoch: 31/50: 100%|██████████| 8/8 [00:00<00:00, 108.80it/s, train_loss=0.00315, valid_loss=0.0053]\n",
      "Epoch: 32/50: 100%|██████████| 8/8 [00:00<00:00, 128.34it/s, train_loss=0.00312, valid_loss=0.00502]\n",
      "Epoch: 33/50: 100%|██████████| 8/8 [00:00<00:00, 125.65it/s, train_loss=0.00278, valid_loss=0.00487]\n",
      "Epoch: 34/50: 100%|██████████| 8/8 [00:00<00:00, 106.92it/s, train_loss=0.00315, valid_loss=0.00505]\n",
      "Epoch: 35/50: 100%|██████████| 8/8 [00:00<00:00, 128.00it/s, train_loss=0.00296, valid_loss=0.00473]\n",
      "Epoch: 36/50: 100%|██████████| 8/8 [00:00<00:00, 78.55it/s, train_loss=0.00332, valid_loss=0.00492]\n",
      "Epoch: 37/50: 100%|██████████| 8/8 [00:00<00:00, 112.44it/s, train_loss=0.00312, valid_loss=0.00492]\n",
      "Epoch: 38/50: 100%|██████████| 8/8 [00:00<00:00, 77.31it/s, train_loss=0.00294, valid_loss=0.00472]\n",
      "Epoch: 39/50: 100%|██████████| 8/8 [00:00<00:00, 127.44it/s, train_loss=0.00283, valid_loss=0.00488]\n",
      "Epoch: 40/50: 100%|██████████| 8/8 [00:00<00:00, 108.43it/s, train_loss=0.00278, valid_loss=0.00471]\n",
      "Epoch: 41/50: 100%|██████████| 8/8 [00:00<00:00, 117.58it/s, train_loss=0.00319, valid_loss=0.00498]\n",
      "Epoch: 42/50: 100%|██████████| 8/8 [00:00<00:00, 113.69it/s, train_loss=0.00316, valid_loss=0.00481]\n",
      "Epoch: 43/50: 100%|██████████| 8/8 [00:00<00:00, 128.19it/s, train_loss=0.00286, valid_loss=0.00487]\n",
      "Epoch: 44/50: 100%|██████████| 8/8 [00:00<00:00, 91.41it/s, train_loss=0.00285, valid_loss=0.00455]\n",
      "Epoch: 45/50: 100%|██████████| 8/8 [00:00<00:00, 100.84it/s, train_loss=0.00274, valid_loss=0.00511]\n",
      "Epoch: 46/50: 100%|██████████| 8/8 [00:00<00:00, 113.33it/s, train_loss=0.00277, valid_loss=0.0047]\n",
      "Epoch: 47/50: 100%|██████████| 8/8 [00:00<00:00, 60.11it/s, train_loss=0.00304, valid_loss=0.00494]\n",
      "Epoch: 48/50: 100%|██████████| 8/8 [00:00<00:00, 127.23it/s, train_loss=0.00279, valid_loss=0.00496]\n",
      "Epoch: 49/50: 100%|██████████| 8/8 [00:00<00:00, 105.50it/s, train_loss=0.00291, valid_loss=0.0048]\n",
      "Epoch: 50/50: 100%|██████████| 8/8 [00:00<00:00, 126.64it/s, train_loss=0.00294, valid_loss=0.00491]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 15/15 [00:00<00:00, 89.63it/s, train_loss=0.0346, valid_loss=0.0393]\n",
      "Epoch: 2/50: 100%|██████████| 15/15 [00:00<00:00, 140.72it/s, train_loss=0.0261, valid_loss=0.0275]\n",
      "Epoch: 3/50: 100%|██████████| 15/15 [00:00<00:00, 140.78it/s, train_loss=0.0105, valid_loss=0.00897]\n",
      "Epoch: 4/50: 100%|██████████| 15/15 [00:00<00:00, 141.45it/s, train_loss=0.00808, valid_loss=0.00733]\n",
      "Epoch: 5/50: 100%|██████████| 15/15 [00:00<00:00, 120.79it/s, train_loss=0.00623, valid_loss=0.00464]\n",
      "Epoch: 6/50: 100%|██████████| 15/15 [00:00<00:00, 95.39it/s, train_loss=0.00592, valid_loss=0.00818]\n",
      "Epoch: 7/50: 100%|██████████| 15/15 [00:00<00:00, 98.91it/s, train_loss=0.00607, valid_loss=0.00559]\n",
      "Epoch: 8/50: 100%|██████████| 15/15 [00:00<00:00, 131.12it/s, train_loss=0.00494, valid_loss=0.00525]\n",
      "Epoch: 9/50: 100%|██████████| 15/15 [00:00<00:00, 111.74it/s, train_loss=0.00557, valid_loss=0.00459]\n",
      "Epoch: 10/50: 100%|██████████| 15/15 [00:00<00:00, 139.72it/s, train_loss=0.00558, valid_loss=0.00249]\n",
      "Epoch: 11/50: 100%|██████████| 15/15 [00:00<00:00, 142.72it/s, train_loss=0.00522, valid_loss=0.00298]\n",
      "Epoch: 12/50: 100%|██████████| 15/15 [00:00<00:00, 139.33it/s, train_loss=0.00514, valid_loss=0.00247]\n",
      "Epoch: 13/50: 100%|██████████| 15/15 [00:00<00:00, 142.31it/s, train_loss=0.00527, valid_loss=0.00211]\n",
      "Epoch: 14/50: 100%|██████████| 15/15 [00:00<00:00, 105.43it/s, train_loss=0.00444, valid_loss=0.00341]\n",
      "Epoch: 15/50: 100%|██████████| 15/15 [00:00<00:00, 136.42it/s, train_loss=0.00482, valid_loss=0.0023]\n",
      "Epoch: 16/50: 100%|██████████| 15/15 [00:00<00:00, 119.64it/s, train_loss=0.00468, valid_loss=0.00185]\n",
      "Epoch: 17/50: 100%|██████████| 15/15 [00:00<00:00, 110.82it/s, train_loss=0.00467, valid_loss=0.00286]\n",
      "Epoch: 18/50: 100%|██████████| 15/15 [00:00<00:00, 126.27it/s, train_loss=0.00478, valid_loss=0.00222]\n",
      "Epoch: 19/50: 100%|██████████| 15/15 [00:00<00:00, 142.11it/s, train_loss=0.00509, valid_loss=0.00183]\n",
      "Epoch: 20/50: 100%|██████████| 15/15 [00:00<00:00, 101.10it/s, train_loss=0.00456, valid_loss=0.00277]\n",
      "Epoch: 21/50: 100%|██████████| 15/15 [00:00<00:00, 140.37it/s, train_loss=0.00404, valid_loss=0.0024]\n",
      "Epoch: 22/50: 100%|██████████| 15/15 [00:00<00:00, 119.88it/s, train_loss=0.00467, valid_loss=0.00228]\n",
      "Epoch: 23/50: 100%|██████████| 15/15 [00:00<00:00, 141.15it/s, train_loss=0.00464, valid_loss=0.00221]\n",
      "Epoch: 24/50: 100%|██████████| 15/15 [00:00<00:00, 141.93it/s, train_loss=0.00426, valid_loss=0.00198]\n",
      "Epoch: 25/50: 100%|██████████| 15/15 [00:00<00:00, 141.48it/s, train_loss=0.00456, valid_loss=0.00251]\n",
      "Epoch: 26/50: 100%|██████████| 15/15 [00:00<00:00, 119.26it/s, train_loss=0.00433, valid_loss=0.0021]\n",
      "Epoch: 27/50: 100%|██████████| 15/15 [00:00<00:00, 96.96it/s, train_loss=0.00478, valid_loss=0.00339] \n",
      "Epoch: 28/50: 100%|██████████| 15/15 [00:00<00:00, 138.80it/s, train_loss=0.00486, valid_loss=0.00332]\n",
      "Epoch: 29/50: 100%|██████████| 15/15 [00:00<00:00, 114.44it/s, train_loss=0.00456, valid_loss=0.00285]\n",
      "Epoch: 30/50: 100%|██████████| 15/15 [00:00<00:00, 118.42it/s, train_loss=0.00429, valid_loss=0.00265]\n",
      "Epoch: 31/50: 100%|██████████| 15/15 [00:00<00:00, 118.23it/s, train_loss=0.00417, valid_loss=0.00274]\n",
      "Epoch: 32/50: 100%|██████████| 15/15 [00:00<00:00, 125.18it/s, train_loss=0.00433, valid_loss=0.00285]\n",
      "Epoch: 33/50: 100%|██████████| 15/15 [00:00<00:00, 143.17it/s, train_loss=0.00383, valid_loss=0.00329]\n",
      "Epoch: 34/50: 100%|██████████| 15/15 [00:00<00:00, 125.68it/s, train_loss=0.00405, valid_loss=0.00269]\n",
      "Epoch: 35/50: 100%|██████████| 15/15 [00:00<00:00, 105.08it/s, train_loss=0.004, valid_loss=0.00321]\n",
      "Epoch: 36/50: 100%|██████████| 15/15 [00:00<00:00, 137.18it/s, train_loss=0.00449, valid_loss=0.00262]\n",
      "Epoch: 37/50: 100%|██████████| 15/15 [00:00<00:00, 122.98it/s, train_loss=0.00426, valid_loss=0.00282]\n",
      "Epoch: 38/50: 100%|██████████| 15/15 [00:00<00:00, 143.34it/s, train_loss=0.00425, valid_loss=0.00253]\n",
      "Epoch: 39/50: 100%|██████████| 15/15 [00:00<00:00, 95.18it/s, train_loss=0.00442, valid_loss=0.00326]\n",
      "Epoch: 40/50: 100%|██████████| 15/15 [00:00<00:00, 112.89it/s, train_loss=0.00437, valid_loss=0.00363]\n",
      "Epoch: 41/50: 100%|██████████| 15/15 [00:00<00:00, 142.35it/s, train_loss=0.00429, valid_loss=0.00314]\n",
      "Epoch: 42/50: 100%|██████████| 15/15 [00:00<00:00, 92.48it/s, train_loss=0.00429, valid_loss=0.00209]\n",
      "Epoch: 43/50: 100%|██████████| 15/15 [00:00<00:00, 141.22it/s, train_loss=0.00428, valid_loss=0.00235]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 22/22 [00:00<00:00, 94.02it/s, train_loss=0.0191, valid_loss=0.024] \n",
      "Epoch: 2/50: 100%|██████████| 22/22 [00:00<00:00, 116.52it/s, train_loss=0.0122, valid_loss=0.0138]\n",
      "Epoch: 3/50: 100%|██████████| 22/22 [00:00<00:00, 114.02it/s, train_loss=0.00742, valid_loss=0.00655]\n",
      "Epoch: 4/50: 100%|██████████| 22/22 [00:00<00:00, 106.80it/s, train_loss=0.00751, valid_loss=0.00583]\n",
      "Epoch: 5/50: 100%|██████████| 22/22 [00:00<00:00, 112.98it/s, train_loss=0.00647, valid_loss=0.00639]\n",
      "Epoch: 6/50: 100%|██████████| 22/22 [00:00<00:00, 131.48it/s, train_loss=0.00645, valid_loss=0.00501]\n",
      "Epoch: 7/50: 100%|██████████| 22/22 [00:00<00:00, 119.88it/s, train_loss=0.0061, valid_loss=0.00475] \n",
      "Epoch: 8/50: 100%|██████████| 22/22 [00:00<00:00, 124.26it/s, train_loss=0.00576, valid_loss=0.00443]\n",
      "Epoch: 9/50: 100%|██████████| 22/22 [00:00<00:00, 107.12it/s, train_loss=0.00539, valid_loss=0.00433]\n",
      "Epoch: 10/50: 100%|██████████| 22/22 [00:00<00:00, 119.96it/s, train_loss=0.00526, valid_loss=0.00493]\n",
      "Epoch: 11/50: 100%|██████████| 22/22 [00:00<00:00, 112.64it/s, train_loss=0.00485, valid_loss=0.00455]\n",
      "Epoch: 12/50: 100%|██████████| 22/22 [00:00<00:00, 133.73it/s, train_loss=0.00457, valid_loss=0.0042] \n",
      "Epoch: 13/50: 100%|██████████| 22/22 [00:00<00:00, 99.13it/s, train_loss=0.00546, valid_loss=0.0042] \n",
      "Epoch: 14/50: 100%|██████████| 22/22 [00:00<00:00, 132.30it/s, train_loss=0.00463, valid_loss=0.00448]\n",
      "Epoch: 15/50: 100%|██████████| 22/22 [00:00<00:00, 112.38it/s, train_loss=0.00421, valid_loss=0.0042] \n",
      "Epoch: 16/50: 100%|██████████| 22/22 [00:00<00:00, 122.58it/s, train_loss=0.00475, valid_loss=0.00395]\n",
      "Epoch: 17/50: 100%|██████████| 22/22 [00:00<00:00, 110.29it/s, train_loss=0.00446, valid_loss=0.00393]\n",
      "Epoch: 18/50: 100%|██████████| 22/22 [00:00<00:00, 102.26it/s, train_loss=0.00488, valid_loss=0.00382]\n",
      "Epoch: 19/50: 100%|██████████| 22/22 [00:00<00:00, 113.08it/s, train_loss=0.00419, valid_loss=0.00416]\n",
      "Epoch: 20/50: 100%|██████████| 22/22 [00:00<00:00, 115.49it/s, train_loss=0.00439, valid_loss=0.00368]\n",
      "Epoch: 21/50: 100%|██████████| 22/22 [00:00<00:00, 122.11it/s, train_loss=0.00449, valid_loss=0.00413]\n",
      "Epoch: 22/50: 100%|██████████| 22/22 [00:00<00:00, 101.37it/s, train_loss=0.00444, valid_loss=0.00479]\n",
      "Epoch: 23/50: 100%|██████████| 22/22 [00:00<00:00, 118.83it/s, train_loss=0.004, valid_loss=0.00428]  \n",
      "Epoch: 24/50: 100%|██████████| 22/22 [00:00<00:00, 132.56it/s, train_loss=0.00391, valid_loss=0.0047] \n",
      "Epoch: 25/50: 100%|██████████| 22/22 [00:00<00:00, 104.14it/s, train_loss=0.00373, valid_loss=0.00475]\n",
      "Epoch: 26/50: 100%|██████████| 22/22 [00:00<00:00, 116.37it/s, train_loss=0.00466, valid_loss=0.00465]\n",
      "Epoch: 27/50: 100%|██████████| 22/22 [00:00<00:00, 107.27it/s, train_loss=0.00422, valid_loss=0.00365]\n",
      "Epoch: 28/50: 100%|██████████| 22/22 [00:00<00:00, 131.88it/s, train_loss=0.00407, valid_loss=0.00465]\n",
      "Epoch: 29/50: 100%|██████████| 22/22 [00:00<00:00, 111.52it/s, train_loss=0.00408, valid_loss=0.00412]\n",
      "Epoch: 30/50: 100%|██████████| 22/22 [00:00<00:00, 122.78it/s, train_loss=0.00416, valid_loss=0.00426]\n",
      "Epoch: 31/50: 100%|██████████| 22/22 [00:00<00:00, 100.53it/s, train_loss=0.00418, valid_loss=0.00406]\n",
      "Epoch: 32/50: 100%|██████████| 22/22 [00:00<00:00, 119.97it/s, train_loss=0.00424, valid_loss=0.00418]\n",
      "Epoch: 33/50: 100%|██████████| 22/22 [00:00<00:00, 131.29it/s, train_loss=0.00415, valid_loss=0.004] \n",
      "Epoch: 34/50: 100%|██████████| 22/22 [00:00<00:00, 121.35it/s, train_loss=0.00384, valid_loss=0.00378]\n",
      "Epoch: 35/50: 100%|██████████| 22/22 [00:00<00:00, 114.61it/s, train_loss=0.0038, valid_loss=0.0044]  \n",
      "Epoch: 36/50: 100%|██████████| 22/22 [00:00<00:00, 100.83it/s, train_loss=0.00361, valid_loss=0.00434]\n",
      "Epoch: 37/50: 100%|██████████| 22/22 [00:00<00:00, 120.47it/s, train_loss=0.00434, valid_loss=0.00446]\n",
      "Epoch: 38/50: 100%|██████████| 22/22 [00:00<00:00, 123.49it/s, train_loss=0.00404, valid_loss=0.00407]\n",
      "Epoch: 39/50: 100%|██████████| 22/22 [00:00<00:00, 132.89it/s, train_loss=0.00369, valid_loss=0.00385]\n",
      "Epoch: 40/50: 100%|██████████| 22/22 [00:00<00:00, 97.05it/s, train_loss=0.00358, valid_loss=0.00442]\n",
      "Epoch: 41/50: 100%|██████████| 22/22 [00:00<00:00, 133.26it/s, train_loss=0.00418, valid_loss=0.00402]\n",
      "Epoch: 42/50: 100%|██████████| 22/22 [00:00<00:00, 132.40it/s, train_loss=0.00393, valid_loss=0.00384]\n",
      "Epoch: 43/50: 100%|██████████| 22/22 [00:00<00:00, 134.76it/s, train_loss=0.00365, valid_loss=0.00452]\n",
      "Epoch: 44/50: 100%|██████████| 22/22 [00:00<00:00, 133.76it/s, train_loss=0.00381, valid_loss=0.00435]\n",
      "Epoch: 45/50: 100%|██████████| 22/22 [00:00<00:00, 98.67it/s, train_loss=0.00357, valid_loss=0.00519]\n",
      "Epoch: 46/50: 100%|██████████| 22/22 [00:00<00:00, 121.97it/s, train_loss=0.00399, valid_loss=0.00428]\n",
      "Epoch: 47/50: 100%|██████████| 22/22 [00:00<00:00, 133.77it/s, train_loss=0.00364, valid_loss=0.0045] \n",
      "Epoch: 48/50: 100%|██████████| 22/22 [00:00<00:00, 108.56it/s, train_loss=0.0038, valid_loss=0.00425]\n",
      "Epoch: 49/50: 100%|██████████| 22/22 [00:00<00:00, 102.06it/s, train_loss=0.00367, valid_loss=0.00402]\n",
      "Epoch: 50/50: 100%|██████████| 22/22 [00:00<00:00, 127.72it/s, train_loss=0.00339, valid_loss=0.00381]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 29/29 [00:00<00:00, 103.85it/s, train_loss=0.0202, valid_loss=0.0135]\n",
      "Epoch: 2/50: 100%|██████████| 29/29 [00:00<00:00, 107.87it/s, train_loss=0.00962, valid_loss=0.00677]\n",
      "Epoch: 3/50: 100%|██████████| 29/29 [00:00<00:00, 122.61it/s, train_loss=0.00788, valid_loss=0.0044] \n",
      "Epoch: 4/50: 100%|██████████| 29/29 [00:00<00:00, 110.32it/s, train_loss=0.00715, valid_loss=0.00738]\n",
      "Epoch: 5/50: 100%|██████████| 29/29 [00:00<00:00, 112.49it/s, train_loss=0.00728, valid_loss=0.004]  \n",
      "Epoch: 6/50: 100%|██████████| 29/29 [00:00<00:00, 130.01it/s, train_loss=0.00658, valid_loss=0.00289]\n",
      "Epoch: 7/50: 100%|██████████| 29/29 [00:00<00:00, 139.08it/s, train_loss=0.00513, valid_loss=0.0028] \n",
      "Epoch: 8/50: 100%|██████████| 29/29 [00:00<00:00, 106.01it/s, train_loss=0.00571, valid_loss=0.00224]\n",
      "Epoch: 9/50: 100%|██████████| 29/29 [00:00<00:00, 129.47it/s, train_loss=0.00511, valid_loss=0.00254]\n",
      "Epoch: 10/50: 100%|██████████| 29/29 [00:00<00:00, 110.01it/s, train_loss=0.00502, valid_loss=0.00247]\n",
      "Epoch: 11/50: 100%|██████████| 29/29 [00:00<00:00, 122.51it/s, train_loss=0.0052, valid_loss=0.00292] \n",
      "Epoch: 12/50: 100%|██████████| 29/29 [00:00<00:00, 138.46it/s, train_loss=0.00539, valid_loss=0.00248]\n",
      "Epoch: 13/50: 100%|██████████| 29/29 [00:00<00:00, 104.51it/s, train_loss=0.005, valid_loss=0.00245]  \n",
      "Epoch: 14/50: 100%|██████████| 29/29 [00:00<00:00, 126.22it/s, train_loss=0.0049, valid_loss=0.00298] \n",
      "Epoch: 15/50: 100%|██████████| 29/29 [00:00<00:00, 135.58it/s, train_loss=0.00468, valid_loss=0.00287]\n",
      "Epoch: 16/50: 100%|██████████| 29/29 [00:00<00:00, 118.46it/s, train_loss=0.00476, valid_loss=0.00271]\n",
      "Epoch: 17/50: 100%|██████████| 29/29 [00:00<00:00, 120.09it/s, train_loss=0.00443, valid_loss=0.00364]\n",
      "Epoch: 18/50: 100%|██████████| 29/29 [00:00<00:00, 117.96it/s, train_loss=0.00508, valid_loss=0.00444]\n",
      "Epoch: 19/50: 100%|██████████| 29/29 [00:00<00:00, 137.49it/s, train_loss=0.00499, valid_loss=0.0028] \n",
      "Epoch: 20/50: 100%|██████████| 29/29 [00:00<00:00, 111.03it/s, train_loss=0.00465, valid_loss=0.00323]\n",
      "Epoch: 21/50: 100%|██████████| 29/29 [00:00<00:00, 115.77it/s, train_loss=0.00473, valid_loss=0.00376]\n",
      "Epoch: 22/50: 100%|██████████| 29/29 [00:00<00:00, 131.82it/s, train_loss=0.00433, valid_loss=0.00297]\n",
      "Epoch: 23/50: 100%|██████████| 29/29 [00:00<00:00, 117.35it/s, train_loss=0.0046, valid_loss=0.00243]\n",
      "Epoch: 24/50: 100%|██████████| 29/29 [00:00<00:00, 121.66it/s, train_loss=0.00491, valid_loss=0.00279]\n",
      "Epoch: 25/50: 100%|██████████| 29/29 [00:00<00:00, 121.12it/s, train_loss=0.00507, valid_loss=0.00353]\n",
      "Epoch: 26/50: 100%|██████████| 29/29 [00:00<00:00, 104.93it/s, train_loss=0.00477, valid_loss=0.0034] \n",
      "Epoch: 27/50: 100%|██████████| 29/29 [00:00<00:00, 128.16it/s, train_loss=0.0046, valid_loss=0.0033]  \n",
      "Epoch: 28/50: 100%|██████████| 29/29 [00:00<00:00, 130.71it/s, train_loss=0.00452, valid_loss=0.00284]\n",
      "Epoch: 29/50: 100%|██████████| 29/29 [00:00<00:00, 133.90it/s, train_loss=0.00449, valid_loss=0.00288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 36/36 [00:00<00:00, 102.52it/s, train_loss=0.0256, valid_loss=0.0205]\n",
      "Epoch: 2/50: 100%|██████████| 36/36 [00:00<00:00, 108.19it/s, train_loss=0.00825, valid_loss=0.00616]\n",
      "Epoch: 3/50: 100%|██████████| 36/36 [00:00<00:00, 128.08it/s, train_loss=0.00655, valid_loss=0.00565]\n",
      "Epoch: 4/50: 100%|██████████| 36/36 [00:00<00:00, 120.60it/s, train_loss=0.00612, valid_loss=0.00425]\n",
      "Epoch: 5/50: 100%|██████████| 36/36 [00:00<00:00, 119.90it/s, train_loss=0.00558, valid_loss=0.00352]\n",
      "Epoch: 6/50: 100%|██████████| 36/36 [00:00<00:00, 106.21it/s, train_loss=0.00556, valid_loss=0.00388]\n",
      "Epoch: 7/50: 100%|██████████| 36/36 [00:00<00:00, 114.40it/s, train_loss=0.00564, valid_loss=0.00335]\n",
      "Epoch: 8/50: 100%|██████████| 36/36 [00:00<00:00, 107.56it/s, train_loss=0.0052, valid_loss=0.00271] \n",
      "Epoch: 9/50: 100%|██████████| 36/36 [00:00<00:00, 134.56it/s, train_loss=0.00507, valid_loss=0.00384]\n",
      "Epoch: 10/50: 100%|██████████| 36/36 [00:00<00:00, 107.74it/s, train_loss=0.00462, valid_loss=0.00325]\n",
      "Epoch: 11/50: 100%|██████████| 36/36 [00:00<00:00, 127.05it/s, train_loss=0.00531, valid_loss=0.00343]\n",
      "Epoch: 12/50: 100%|██████████| 36/36 [00:00<00:00, 113.58it/s, train_loss=0.00499, valid_loss=0.00302]\n",
      "Epoch: 13/50: 100%|██████████| 36/36 [00:00<00:00, 127.64it/s, train_loss=0.00538, valid_loss=0.00319]\n",
      "Epoch: 14/50: 100%|██████████| 36/36 [00:00<00:00, 128.23it/s, train_loss=0.0048, valid_loss=0.00322] \n",
      "Epoch: 15/50: 100%|██████████| 36/36 [00:00<00:00, 110.53it/s, train_loss=0.00442, valid_loss=0.00265]\n",
      "Epoch: 16/50: 100%|██████████| 36/36 [00:00<00:00, 121.44it/s, train_loss=0.00443, valid_loss=0.00297]\n",
      "Epoch: 17/50: 100%|██████████| 36/36 [00:00<00:00, 107.91it/s, train_loss=0.00479, valid_loss=0.00332]\n",
      "Epoch: 18/50: 100%|██████████| 36/36 [00:00<00:00, 128.84it/s, train_loss=0.00535, valid_loss=0.00294]\n",
      "Epoch: 19/50: 100%|██████████| 36/36 [00:00<00:00, 114.62it/s, train_loss=0.00458, valid_loss=0.00267]\n",
      "Epoch: 20/50: 100%|██████████| 36/36 [00:00<00:00, 122.01it/s, train_loss=0.00485, valid_loss=0.00298]\n",
      "Epoch: 21/50: 100%|██████████| 36/36 [00:00<00:00, 112.15it/s, train_loss=0.00503, valid_loss=0.00277]\n",
      "Epoch: 22/50: 100%|██████████| 36/36 [00:00<00:00, 129.19it/s, train_loss=0.00445, valid_loss=0.00284]\n",
      "Epoch: 23/50: 100%|██████████| 36/36 [00:00<00:00, 122.05it/s, train_loss=0.00412, valid_loss=0.00293]\n",
      "Epoch: 24/50: 100%|██████████| 36/36 [00:00<00:00, 134.90it/s, train_loss=0.00489, valid_loss=0.00271]\n",
      "Epoch: 25/50: 100%|██████████| 36/36 [00:00<00:00, 108.99it/s, train_loss=0.00465, valid_loss=0.00273]\n",
      "Epoch: 26/50: 100%|██████████| 36/36 [00:00<00:00, 128.06it/s, train_loss=0.004, valid_loss=0.00306]  \n",
      "Epoch: 27/50: 100%|██████████| 36/36 [00:00<00:00, 123.62it/s, train_loss=0.00513, valid_loss=0.00326]\n",
      "Epoch: 28/50: 100%|██████████| 36/36 [00:00<00:00, 125.96it/s, train_loss=0.00423, valid_loss=0.00263]\n",
      "Epoch: 29/50: 100%|██████████| 36/36 [00:00<00:00, 117.99it/s, train_loss=0.00434, valid_loss=0.0026] \n",
      "Epoch: 30/50: 100%|██████████| 36/36 [00:00<00:00, 120.01it/s, train_loss=0.00456, valid_loss=0.00264]\n",
      "Epoch: 31/50: 100%|██████████| 36/36 [00:00<00:00, 134.25it/s, train_loss=0.00438, valid_loss=0.00275]\n",
      "Epoch: 32/50: 100%|██████████| 36/36 [00:00<00:00, 122.40it/s, train_loss=0.00444, valid_loss=0.00266]\n",
      "Epoch: 33/50: 100%|██████████| 36/36 [00:00<00:00, 112.07it/s, train_loss=0.00453, valid_loss=0.00301]\n",
      "Epoch: 34/50: 100%|██████████| 36/36 [00:00<00:00, 128.30it/s, train_loss=0.00454, valid_loss=0.00269]\n",
      "Epoch: 35/50: 100%|██████████| 36/36 [00:00<00:00, 133.22it/s, train_loss=0.0044, valid_loss=0.00293] \n",
      "Epoch: 36/50: 100%|██████████| 36/36 [00:00<00:00, 135.32it/s, train_loss=0.00417, valid_loss=0.00268]\n",
      "Epoch: 37/50: 100%|██████████| 36/36 [00:00<00:00, 111.87it/s, train_loss=0.00409, valid_loss=0.00314]\n",
      "Epoch: 38/50: 100%|██████████| 36/36 [00:00<00:00, 135.96it/s, train_loss=0.00437, valid_loss=0.00272]\n",
      "Epoch: 39/50: 100%|██████████| 36/36 [00:00<00:00, 137.48it/s, train_loss=0.00458, valid_loss=0.0026] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config: batch_size--512, lr--0.001, number_epoch--50, hidden_dim--25,drop_prob-0.1,weight_decay-1e-07\n",
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 8/8 [00:00<00:00, 80.87it/s, train_loss=0.0767, valid_loss=0.117]\n",
      "Epoch: 2/50: 100%|██████████| 8/8 [00:00<00:00, 131.73it/s, train_loss=0.0664, valid_loss=0.0993]\n",
      "Epoch: 3/50: 100%|██████████| 8/8 [00:00<00:00, 121.53it/s, train_loss=0.0609, valid_loss=0.0869]\n",
      "Epoch: 4/50: 100%|██████████| 8/8 [00:00<00:00, 52.89it/s, train_loss=0.0535, valid_loss=0.0759]\n",
      "Epoch: 5/50: 100%|██████████| 8/8 [00:00<00:00, 127.04it/s, train_loss=0.0463, valid_loss=0.0664]\n",
      "Epoch: 6/50: 100%|██████████| 8/8 [00:00<00:00, 129.34it/s, train_loss=0.0434, valid_loss=0.0612]\n",
      "Epoch: 7/50: 100%|██████████| 8/8 [00:00<00:00, 127.83it/s, train_loss=0.0403, valid_loss=0.0573]\n",
      "Epoch: 8/50: 100%|██████████| 8/8 [00:00<00:00, 103.60it/s, train_loss=0.0343, valid_loss=0.0514]\n",
      "Epoch: 9/50: 100%|██████████| 8/8 [00:00<00:00, 109.37it/s, train_loss=0.0302, valid_loss=0.043]\n",
      "Epoch: 10/50: 100%|██████████| 8/8 [00:00<00:00, 127.33it/s, train_loss=0.0269, valid_loss=0.0393]\n",
      "Epoch: 11/50: 100%|██████████| 8/8 [00:00<00:00, 129.58it/s, train_loss=0.0248, valid_loss=0.038]\n",
      "Epoch: 12/50: 100%|██████████| 8/8 [00:00<00:00, 127.65it/s, train_loss=0.0227, valid_loss=0.0353]\n",
      "Epoch: 13/50: 100%|██████████| 8/8 [00:00<00:00, 98.92it/s, train_loss=0.0215, valid_loss=0.0328]\n",
      "Epoch: 14/50: 100%|██████████| 8/8 [00:00<00:00, 117.72it/s, train_loss=0.0205, valid_loss=0.0312]\n",
      "Epoch: 15/50: 100%|██████████| 8/8 [00:00<00:00, 113.03it/s, train_loss=0.019, valid_loss=0.031]\n",
      "Epoch: 16/50: 100%|██████████| 8/8 [00:00<00:00, 128.50it/s, train_loss=0.0192, valid_loss=0.0303]\n",
      "Epoch: 17/50: 100%|██████████| 8/8 [00:00<00:00, 128.69it/s, train_loss=0.0192, valid_loss=0.0297]\n",
      "Epoch: 18/50: 100%|██████████| 8/8 [00:00<00:00, 92.46it/s, train_loss=0.018, valid_loss=0.0289]\n",
      "Epoch: 19/50: 100%|██████████| 8/8 [00:00<00:00, 99.57it/s, train_loss=0.0173, valid_loss=0.028]\n",
      "Epoch: 20/50: 100%|██████████| 8/8 [00:00<00:00, 98.33it/s, train_loss=0.0177, valid_loss=0.0277]\n",
      "Epoch: 21/50: 100%|██████████| 8/8 [00:00<00:00, 64.91it/s, train_loss=0.017, valid_loss=0.0273]\n",
      "Epoch: 22/50: 100%|██████████| 8/8 [00:00<00:00, 122.57it/s, train_loss=0.0165, valid_loss=0.0258]\n",
      "Epoch: 23/50: 100%|██████████| 8/8 [00:00<00:00, 125.57it/s, train_loss=0.0165, valid_loss=0.0251]\n",
      "Epoch: 24/50: 100%|██████████| 8/8 [00:00<00:00, 98.73it/s, train_loss=0.016, valid_loss=0.0243]\n",
      "Epoch: 25/50: 100%|██████████| 8/8 [00:00<00:00, 127.77it/s, train_loss=0.0153, valid_loss=0.0232]\n",
      "Epoch: 26/50: 100%|██████████| 8/8 [00:00<00:00, 99.03it/s, train_loss=0.0154, valid_loss=0.0228]\n",
      "Epoch: 27/50: 100%|██████████| 8/8 [00:00<00:00, 99.01it/s, train_loss=0.0148, valid_loss=0.0226]\n",
      "Epoch: 28/50: 100%|██████████| 8/8 [00:00<00:00, 105.65it/s, train_loss=0.0156, valid_loss=0.022]\n",
      "Epoch: 29/50: 100%|██████████| 8/8 [00:00<00:00, 97.00it/s, train_loss=0.0152, valid_loss=0.0218]\n",
      "Epoch: 30/50: 100%|██████████| 8/8 [00:00<00:00, 125.81it/s, train_loss=0.0152, valid_loss=0.0215]\n",
      "Epoch: 31/50: 100%|██████████| 8/8 [00:00<00:00, 94.07it/s, train_loss=0.0147, valid_loss=0.021]\n",
      "Epoch: 32/50: 100%|██████████| 8/8 [00:00<00:00, 98.35it/s, train_loss=0.0147, valid_loss=0.0207]\n",
      "Epoch: 33/50: 100%|██████████| 8/8 [00:00<00:00, 113.83it/s, train_loss=0.0146, valid_loss=0.0202]\n",
      "Epoch: 34/50: 100%|██████████| 8/8 [00:00<00:00, 113.98it/s, train_loss=0.0144, valid_loss=0.0199]\n",
      "Epoch: 35/50: 100%|██████████| 8/8 [00:00<00:00, 117.39it/s, train_loss=0.0139, valid_loss=0.0197]\n",
      "Epoch: 36/50: 100%|██████████| 8/8 [00:00<00:00, 118.29it/s, train_loss=0.014, valid_loss=0.0194]\n",
      "Epoch: 37/50: 100%|██████████| 8/8 [00:00<00:00, 117.45it/s, train_loss=0.0134, valid_loss=0.0193]\n",
      "Epoch: 38/50: 100%|██████████| 8/8 [00:00<00:00, 72.59it/s, train_loss=0.0137, valid_loss=0.0192]\n",
      "Epoch: 39/50: 100%|██████████| 8/8 [00:00<00:00, 115.70it/s, train_loss=0.0136, valid_loss=0.0191]\n",
      "Epoch: 40/50: 100%|██████████| 8/8 [00:00<00:00, 117.66it/s, train_loss=0.0138, valid_loss=0.019]\n",
      "Epoch: 41/50: 100%|██████████| 8/8 [00:00<00:00, 117.29it/s, train_loss=0.0134, valid_loss=0.0188]\n",
      "Epoch: 42/50: 100%|██████████| 8/8 [00:00<00:00, 116.88it/s, train_loss=0.0138, valid_loss=0.0184]\n",
      "Epoch: 43/50: 100%|██████████| 8/8 [00:00<00:00, 117.08it/s, train_loss=0.0136, valid_loss=0.0186]\n",
      "Epoch: 44/50: 100%|██████████| 8/8 [00:00<00:00, 118.72it/s, train_loss=0.0134, valid_loss=0.0186]\n",
      "Epoch: 45/50: 100%|██████████| 8/8 [00:00<00:00, 114.86it/s, train_loss=0.0135, valid_loss=0.0182]\n",
      "Epoch: 46/50: 100%|██████████| 8/8 [00:00<00:00, 118.32it/s, train_loss=0.0137, valid_loss=0.0182]\n",
      "Epoch: 47/50: 100%|██████████| 8/8 [00:00<00:00, 76.75it/s, train_loss=0.0128, valid_loss=0.0183]\n",
      "Epoch: 48/50: 100%|██████████| 8/8 [00:00<00:00, 115.64it/s, train_loss=0.0134, valid_loss=0.0181]\n",
      "Epoch: 49/50: 100%|██████████| 8/8 [00:00<00:00, 118.19it/s, train_loss=0.013, valid_loss=0.0181]\n",
      "Epoch: 50/50: 100%|██████████| 8/8 [00:00<00:00, 98.53it/s, train_loss=0.0133, valid_loss=0.0182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 8/8 [00:00<00:00, 63.06it/s, train_loss=0.0795, valid_loss=0.116]\n",
      "Epoch: 2/50: 100%|██████████| 8/8 [00:00<00:00, 89.87it/s, train_loss=0.0675, valid_loss=0.103]\n",
      "Epoch: 3/50: 100%|██████████| 8/8 [00:00<00:00, 118.47it/s, train_loss=0.0584, valid_loss=0.0878]\n",
      "Epoch: 4/50: 100%|██████████| 8/8 [00:00<00:00, 116.41it/s, train_loss=0.0483, valid_loss=0.0729]\n",
      "Epoch: 5/50: 100%|██████████| 8/8 [00:00<00:00, 119.06it/s, train_loss=0.0423, valid_loss=0.0595]\n",
      "Epoch: 6/50: 100%|██████████| 8/8 [00:00<00:00, 118.56it/s, train_loss=0.0334, valid_loss=0.0489]\n",
      "Epoch: 7/50: 100%|██████████| 8/8 [00:00<00:00, 117.77it/s, train_loss=0.0277, valid_loss=0.0416]\n",
      "Epoch: 8/50: 100%|██████████| 8/8 [00:00<00:00, 116.89it/s, train_loss=0.0245, valid_loss=0.0366]\n",
      "Epoch: 9/50: 100%|██████████| 8/8 [00:00<00:00, 117.57it/s, train_loss=0.0222, valid_loss=0.034]\n",
      "Epoch: 10/50: 100%|██████████| 8/8 [00:00<00:00, 117.06it/s, train_loss=0.0217, valid_loss=0.033]\n",
      "Epoch: 11/50: 100%|██████████| 8/8 [00:00<00:00, 116.97it/s, train_loss=0.0218, valid_loss=0.0323]\n",
      "Epoch: 12/50: 100%|██████████| 8/8 [00:00<00:00, 117.00it/s, train_loss=0.0202, valid_loss=0.0323]\n",
      "Epoch: 13/50: 100%|██████████| 8/8 [00:00<00:00, 116.93it/s, train_loss=0.0196, valid_loss=0.0316]\n",
      "Epoch: 14/50: 100%|██████████| 8/8 [00:00<00:00, 116.06it/s, train_loss=0.0196, valid_loss=0.031]\n",
      "Epoch: 15/50: 100%|██████████| 8/8 [00:00<00:00, 74.25it/s, train_loss=0.019, valid_loss=0.0307]\n",
      "Epoch: 16/50: 100%|██████████| 8/8 [00:00<00:00, 110.05it/s, train_loss=0.0193, valid_loss=0.0302]\n",
      "Epoch: 17/50: 100%|██████████| 8/8 [00:00<00:00, 115.71it/s, train_loss=0.0187, valid_loss=0.0294]\n",
      "Epoch: 18/50: 100%|██████████| 8/8 [00:00<00:00, 116.73it/s, train_loss=0.0188, valid_loss=0.0296]\n",
      "Epoch: 19/50: 100%|██████████| 8/8 [00:00<00:00, 116.22it/s, train_loss=0.018, valid_loss=0.0288]\n",
      "Epoch: 20/50: 100%|██████████| 8/8 [00:00<00:00, 116.87it/s, train_loss=0.0176, valid_loss=0.0279]\n",
      "Epoch: 21/50: 100%|██████████| 8/8 [00:00<00:00, 117.07it/s, train_loss=0.0174, valid_loss=0.0273]\n",
      "Epoch: 22/50: 100%|██████████| 8/8 [00:00<00:00, 117.84it/s, train_loss=0.0162, valid_loss=0.0263]\n",
      "Epoch: 23/50: 100%|██████████| 8/8 [00:00<00:00, 116.94it/s, train_loss=0.0171, valid_loss=0.0255]\n",
      "Epoch: 24/50: 100%|██████████| 8/8 [00:00<00:00, 112.68it/s, train_loss=0.0164, valid_loss=0.0248]\n",
      "Epoch: 25/50: 100%|██████████| 8/8 [00:00<00:00, 117.79it/s, train_loss=0.016, valid_loss=0.0238]\n",
      "Epoch: 26/50: 100%|██████████| 8/8 [00:00<00:00, 117.91it/s, train_loss=0.0156, valid_loss=0.0235]\n",
      "Epoch: 27/50: 100%|██████████| 8/8 [00:00<00:00, 118.21it/s, train_loss=0.016, valid_loss=0.0226]\n",
      "Epoch: 28/50: 100%|██████████| 8/8 [00:00<00:00, 113.57it/s, train_loss=0.0156, valid_loss=0.0225]\n",
      "Epoch: 29/50: 100%|██████████| 8/8 [00:00<00:00, 113.14it/s, train_loss=0.0149, valid_loss=0.0217]\n",
      "Epoch: 30/50: 100%|██████████| 8/8 [00:00<00:00, 115.81it/s, train_loss=0.0148, valid_loss=0.0211]\n",
      "Epoch: 31/50: 100%|██████████| 8/8 [00:00<00:00, 115.47it/s, train_loss=0.0149, valid_loss=0.021]\n",
      "Epoch: 32/50: 100%|██████████| 8/8 [00:00<00:00, 76.37it/s, train_loss=0.0144, valid_loss=0.0204]\n",
      "Epoch: 33/50: 100%|██████████| 8/8 [00:00<00:00, 115.52it/s, train_loss=0.0148, valid_loss=0.0201]\n",
      "Epoch: 34/50: 100%|██████████| 8/8 [00:00<00:00, 117.26it/s, train_loss=0.0148, valid_loss=0.0203]\n",
      "Epoch: 35/50: 100%|██████████| 8/8 [00:00<00:00, 113.67it/s, train_loss=0.0145, valid_loss=0.0196]\n",
      "Epoch: 36/50: 100%|██████████| 8/8 [00:00<00:00, 117.42it/s, train_loss=0.0149, valid_loss=0.0192]\n",
      "Epoch: 37/50: 100%|██████████| 8/8 [00:00<00:00, 116.65it/s, train_loss=0.0141, valid_loss=0.0192]\n",
      "Epoch: 38/50: 100%|██████████| 8/8 [00:00<00:00, 117.58it/s, train_loss=0.0146, valid_loss=0.0196]\n",
      "Epoch: 39/50: 100%|██████████| 8/8 [00:00<00:00, 116.97it/s, train_loss=0.0147, valid_loss=0.019]\n",
      "Epoch: 40/50: 100%|██████████| 8/8 [00:00<00:00, 117.06it/s, train_loss=0.0137, valid_loss=0.0189]\n",
      "Epoch: 41/50: 100%|██████████| 8/8 [00:00<00:00, 76.98it/s, train_loss=0.0138, valid_loss=0.0189]\n",
      "Epoch: 42/50: 100%|██████████| 8/8 [00:00<00:00, 115.00it/s, train_loss=0.0147, valid_loss=0.0188]\n",
      "Epoch: 43/50: 100%|██████████| 8/8 [00:00<00:00, 116.33it/s, train_loss=0.014, valid_loss=0.0184]\n",
      "Epoch: 44/50: 100%|██████████| 8/8 [00:00<00:00, 116.75it/s, train_loss=0.0142, valid_loss=0.0184]\n",
      "Epoch: 45/50: 100%|██████████| 8/8 [00:00<00:00, 115.18it/s, train_loss=0.0147, valid_loss=0.0184]\n",
      "Epoch: 46/50: 100%|██████████| 8/8 [00:00<00:00, 116.63it/s, train_loss=0.0136, valid_loss=0.0186]\n",
      "Epoch: 47/50: 100%|██████████| 8/8 [00:00<00:00, 118.31it/s, train_loss=0.0134, valid_loss=0.0185]\n",
      "Epoch: 48/50: 100%|██████████| 8/8 [00:00<00:00, 116.53it/s, train_loss=0.0134, valid_loss=0.0183]\n",
      "Epoch: 49/50: 100%|██████████| 8/8 [00:00<00:00, 118.36it/s, train_loss=0.0134, valid_loss=0.0182]\n",
      "Epoch: 50/50: 100%|██████████| 8/8 [00:00<00:00, 114.55it/s, train_loss=0.0133, valid_loss=0.0182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 8/8 [00:00<00:00, 54.13it/s, train_loss=0.0589, valid_loss=0.0914]\n",
      "Epoch: 2/50: 100%|██████████| 8/8 [00:00<00:00, 94.77it/s, train_loss=0.045, valid_loss=0.0679]\n",
      "Epoch: 3/50: 100%|██████████| 8/8 [00:00<00:00, 97.57it/s, train_loss=0.0345, valid_loss=0.0502]\n",
      "Epoch: 4/50: 100%|██████████| 8/8 [00:00<00:00, 98.14it/s, train_loss=0.0311, valid_loss=0.0456]\n",
      "Epoch: 5/50: 100%|██████████| 8/8 [00:00<00:00, 123.86it/s, train_loss=0.0302, valid_loss=0.0454]\n",
      "Epoch: 6/50: 100%|██████████| 8/8 [00:00<00:00, 124.76it/s, train_loss=0.0276, valid_loss=0.045]\n",
      "Epoch: 7/50: 100%|██████████| 8/8 [00:00<00:00, 122.49it/s, train_loss=0.0285, valid_loss=0.0425]\n",
      "Epoch: 8/50: 100%|██████████| 8/8 [00:00<00:00, 111.69it/s, train_loss=0.026, valid_loss=0.0388]\n",
      "Epoch: 9/50: 100%|██████████| 8/8 [00:00<00:00, 57.86it/s, train_loss=0.0238, valid_loss=0.0374]\n",
      "Epoch: 10/50: 100%|██████████| 8/8 [00:00<00:00, 115.76it/s, train_loss=0.0237, valid_loss=0.0375]\n",
      "Epoch: 11/50: 100%|██████████| 8/8 [00:00<00:00, 117.46it/s, train_loss=0.0233, valid_loss=0.0368]\n",
      "Epoch: 12/50: 100%|██████████| 8/8 [00:00<00:00, 115.96it/s, train_loss=0.0229, valid_loss=0.0366]\n",
      "Epoch: 13/50: 100%|██████████| 8/8 [00:00<00:00, 116.92it/s, train_loss=0.0227, valid_loss=0.0358]\n",
      "Epoch: 14/50: 100%|██████████| 8/8 [00:00<00:00, 116.76it/s, train_loss=0.0224, valid_loss=0.0349]\n",
      "Epoch: 15/50: 100%|██████████| 8/8 [00:00<00:00, 117.72it/s, train_loss=0.0223, valid_loss=0.0339]\n",
      "Epoch: 16/50: 100%|██████████| 8/8 [00:00<00:00, 117.31it/s, train_loss=0.0225, valid_loss=0.0334]\n",
      "Epoch: 17/50: 100%|██████████| 8/8 [00:00<00:00, 116.55it/s, train_loss=0.0213, valid_loss=0.0327]\n",
      "Epoch: 18/50: 100%|██████████| 8/8 [00:00<00:00, 117.95it/s, train_loss=0.0218, valid_loss=0.0314]\n",
      "Epoch: 19/50: 100%|██████████| 8/8 [00:00<00:00, 117.41it/s, train_loss=0.0203, valid_loss=0.031]\n",
      "Epoch: 20/50: 100%|██████████| 8/8 [00:00<00:00, 117.32it/s, train_loss=0.0187, valid_loss=0.0285]\n",
      "Epoch: 21/50: 100%|██████████| 8/8 [00:00<00:00, 117.60it/s, train_loss=0.0167, valid_loss=0.0256]\n",
      "Epoch: 22/50: 100%|██████████| 8/8 [00:00<00:00, 117.37it/s, train_loss=0.0166, valid_loss=0.0248]\n",
      "Epoch: 23/50: 100%|██████████| 8/8 [00:00<00:00, 115.79it/s, train_loss=0.0163, valid_loss=0.0235]\n",
      "Epoch: 24/50: 100%|██████████| 8/8 [00:00<00:00, 117.60it/s, train_loss=0.0149, valid_loss=0.0217]\n",
      "Epoch: 25/50: 100%|██████████| 8/8 [00:00<00:00, 118.39it/s, train_loss=0.0134, valid_loss=0.0199]\n",
      "Epoch: 26/50: 100%|██████████| 8/8 [00:00<00:00, 75.87it/s, train_loss=0.0125, valid_loss=0.0188]\n",
      "Epoch: 27/50: 100%|██████████| 8/8 [00:00<00:00, 113.52it/s, train_loss=0.0121, valid_loss=0.0178]\n",
      "Epoch: 28/50: 100%|██████████| 8/8 [00:00<00:00, 117.41it/s, train_loss=0.0114, valid_loss=0.0175]\n",
      "Epoch: 29/50: 100%|██████████| 8/8 [00:00<00:00, 115.43it/s, train_loss=0.0115, valid_loss=0.0171]\n",
      "Epoch: 30/50: 100%|██████████| 8/8 [00:00<00:00, 117.65it/s, train_loss=0.0118, valid_loss=0.0167]\n",
      "Epoch: 31/50: 100%|██████████| 8/8 [00:00<00:00, 116.60it/s, train_loss=0.0118, valid_loss=0.0164]\n",
      "Epoch: 32/50: 100%|██████████| 8/8 [00:00<00:00, 115.94it/s, train_loss=0.0112, valid_loss=0.0161]\n",
      "Epoch: 33/50: 100%|██████████| 8/8 [00:00<00:00, 118.51it/s, train_loss=0.0116, valid_loss=0.016]\n",
      "Epoch: 34/50: 100%|██████████| 8/8 [00:00<00:00, 116.62it/s, train_loss=0.0108, valid_loss=0.0153]\n",
      "Epoch: 35/50: 100%|██████████| 8/8 [00:00<00:00, 117.59it/s, train_loss=0.0112, valid_loss=0.0156]\n",
      "Epoch: 36/50: 100%|██████████| 8/8 [00:00<00:00, 117.76it/s, train_loss=0.0108, valid_loss=0.0153]\n",
      "Epoch: 37/50: 100%|██████████| 8/8 [00:00<00:00, 115.86it/s, train_loss=0.011, valid_loss=0.0149]\n",
      "Epoch: 38/50: 100%|██████████| 8/8 [00:00<00:00, 117.79it/s, train_loss=0.0105, valid_loss=0.0146]\n",
      "Epoch: 39/50: 100%|██████████| 8/8 [00:00<00:00, 118.39it/s, train_loss=0.0102, valid_loss=0.0146]\n",
      "Epoch: 40/50: 100%|██████████| 8/8 [00:00<00:00, 119.00it/s, train_loss=0.0107, valid_loss=0.0143]\n",
      "Epoch: 41/50: 100%|██████████| 8/8 [00:00<00:00, 117.84it/s, train_loss=0.0102, valid_loss=0.0144]\n",
      "Epoch: 42/50: 100%|██████████| 8/8 [00:00<00:00, 117.15it/s, train_loss=0.0108, valid_loss=0.0139]\n",
      "Epoch: 43/50: 100%|██████████| 8/8 [00:00<00:00, 76.87it/s, train_loss=0.0104, valid_loss=0.0138]\n",
      "Epoch: 44/50: 100%|██████████| 8/8 [00:00<00:00, 113.34it/s, train_loss=0.00969, valid_loss=0.0139]\n",
      "Epoch: 45/50: 100%|██████████| 8/8 [00:00<00:00, 116.48it/s, train_loss=0.00984, valid_loss=0.0136]\n",
      "Epoch: 46/50: 100%|██████████| 8/8 [00:00<00:00, 116.21it/s, train_loss=0.00995, valid_loss=0.0135]\n",
      "Epoch: 47/50: 100%|██████████| 8/8 [00:00<00:00, 115.88it/s, train_loss=0.00939, valid_loss=0.0135]\n",
      "Epoch: 48/50: 100%|██████████| 8/8 [00:00<00:00, 116.19it/s, train_loss=0.01, valid_loss=0.0133]\n",
      "Epoch: 49/50: 100%|██████████| 8/8 [00:00<00:00, 118.00it/s, train_loss=0.00988, valid_loss=0.0134]\n",
      "Epoch: 50/50: 100%|██████████| 8/8 [00:00<00:00, 117.03it/s, train_loss=0.00936, valid_loss=0.0129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 8/8 [00:00<00:00, 62.62it/s, train_loss=0.0756, valid_loss=0.118]\n",
      "Epoch: 2/50: 100%|██████████| 8/8 [00:00<00:00, 62.18it/s, train_loss=0.065, valid_loss=0.098]\n",
      "Epoch: 3/50: 100%|██████████| 8/8 [00:00<00:00, 112.54it/s, train_loss=0.0533, valid_loss=0.0765]\n",
      "Epoch: 4/50: 100%|██████████| 8/8 [00:00<00:00, 118.82it/s, train_loss=0.0422, valid_loss=0.0603]\n",
      "Epoch: 5/50: 100%|██████████| 8/8 [00:00<00:00, 116.93it/s, train_loss=0.0318, valid_loss=0.0473]\n",
      "Epoch: 6/50: 100%|██████████| 8/8 [00:00<00:00, 117.12it/s, train_loss=0.0251, valid_loss=0.0358]\n",
      "Epoch: 7/50: 100%|██████████| 8/8 [00:00<00:00, 117.20it/s, train_loss=0.022, valid_loss=0.0306]\n",
      "Epoch: 8/50: 100%|██████████| 8/8 [00:00<00:00, 117.72it/s, train_loss=0.0181, valid_loss=0.0283]\n",
      "Epoch: 9/50: 100%|██████████| 8/8 [00:00<00:00, 118.24it/s, train_loss=0.0185, valid_loss=0.0276]\n",
      "Epoch: 10/50: 100%|██████████| 8/8 [00:00<00:00, 118.45it/s, train_loss=0.0165, valid_loss=0.0267]\n",
      "Epoch: 11/50: 100%|██████████| 8/8 [00:00<00:00, 118.33it/s, train_loss=0.0151, valid_loss=0.0239]\n",
      "Epoch: 12/50: 100%|██████████| 8/8 [00:00<00:00, 71.22it/s, train_loss=0.0131, valid_loss=0.0223]\n",
      "Epoch: 13/50: 100%|██████████| 8/8 [00:00<00:00, 116.71it/s, train_loss=0.0125, valid_loss=0.0207]\n",
      "Epoch: 14/50: 100%|██████████| 8/8 [00:00<00:00, 117.04it/s, train_loss=0.0118, valid_loss=0.0202]\n",
      "Epoch: 15/50: 100%|██████████| 8/8 [00:00<00:00, 116.00it/s, train_loss=0.0116, valid_loss=0.0196]\n",
      "Epoch: 16/50: 100%|██████████| 8/8 [00:00<00:00, 115.64it/s, train_loss=0.0111, valid_loss=0.0192]\n",
      "Epoch: 17/50: 100%|██████████| 8/8 [00:00<00:00, 117.76it/s, train_loss=0.0106, valid_loss=0.0184]\n",
      "Epoch: 18/50: 100%|██████████| 8/8 [00:00<00:00, 117.49it/s, train_loss=0.0102, valid_loss=0.018]\n",
      "Epoch: 19/50: 100%|██████████| 8/8 [00:00<00:00, 113.65it/s, train_loss=0.0106, valid_loss=0.0169]\n",
      "Epoch: 20/50: 100%|██████████| 8/8 [00:00<00:00, 115.69it/s, train_loss=0.00965, valid_loss=0.0164]\n",
      "Epoch: 21/50: 100%|██████████| 8/8 [00:00<00:00, 62.62it/s, train_loss=0.009, valid_loss=0.0153]\n",
      "Epoch: 22/50: 100%|██████████| 8/8 [00:00<00:00, 115.57it/s, train_loss=0.00962, valid_loss=0.0145]\n",
      "Epoch: 23/50: 100%|██████████| 8/8 [00:00<00:00, 117.72it/s, train_loss=0.00889, valid_loss=0.0135]\n",
      "Epoch: 24/50: 100%|██████████| 8/8 [00:00<00:00, 117.05it/s, train_loss=0.0085, valid_loss=0.0129]\n",
      "Epoch: 25/50: 100%|██████████| 8/8 [00:00<00:00, 111.90it/s, train_loss=0.00831, valid_loss=0.0122]\n",
      "Epoch: 26/50: 100%|██████████| 8/8 [00:00<00:00, 115.79it/s, train_loss=0.00771, valid_loss=0.0117]\n",
      "Epoch: 27/50: 100%|██████████| 8/8 [00:00<00:00, 114.57it/s, train_loss=0.00735, valid_loss=0.0108]\n",
      "Epoch: 28/50: 100%|██████████| 8/8 [00:00<00:00, 115.48it/s, train_loss=0.00763, valid_loss=0.0103]\n",
      "Epoch: 29/50: 100%|██████████| 8/8 [00:00<00:00, 116.58it/s, train_loss=0.00755, valid_loss=0.00981]\n",
      "Epoch: 30/50: 100%|██████████| 8/8 [00:00<00:00, 76.27it/s, train_loss=0.00686, valid_loss=0.00948]\n",
      "Epoch: 31/50: 100%|██████████| 8/8 [00:00<00:00, 114.65it/s, train_loss=0.00679, valid_loss=0.00888]\n",
      "Epoch: 32/50: 100%|██████████| 8/8 [00:00<00:00, 115.55it/s, train_loss=0.00698, valid_loss=0.00886]\n",
      "Epoch: 33/50: 100%|██████████| 8/8 [00:00<00:00, 117.17it/s, train_loss=0.00659, valid_loss=0.00821]\n",
      "Epoch: 34/50: 100%|██████████| 8/8 [00:00<00:00, 117.59it/s, train_loss=0.00668, valid_loss=0.00809]\n",
      "Epoch: 35/50: 100%|██████████| 8/8 [00:00<00:00, 116.92it/s, train_loss=0.00657, valid_loss=0.00786]\n",
      "Epoch: 36/50: 100%|██████████| 8/8 [00:00<00:00, 115.48it/s, train_loss=0.00628, valid_loss=0.00771]\n",
      "Epoch: 37/50: 100%|██████████| 8/8 [00:00<00:00, 117.97it/s, train_loss=0.00596, valid_loss=0.00761]\n",
      "Epoch: 38/50: 100%|██████████| 8/8 [00:00<00:00, 117.45it/s, train_loss=0.00603, valid_loss=0.00742]\n",
      "Epoch: 39/50: 100%|██████████| 8/8 [00:00<00:00, 117.12it/s, train_loss=0.00626, valid_loss=0.00737]\n",
      "Epoch: 40/50: 100%|██████████| 8/8 [00:00<00:00, 117.59it/s, train_loss=0.0059, valid_loss=0.00724]\n",
      "Epoch: 41/50: 100%|██████████| 8/8 [00:00<00:00, 117.82it/s, train_loss=0.00551, valid_loss=0.007]\n",
      "Epoch: 42/50: 100%|██████████| 8/8 [00:00<00:00, 118.78it/s, train_loss=0.00587, valid_loss=0.0069]\n",
      "Epoch: 43/50: 100%|██████████| 8/8 [00:00<00:00, 117.28it/s, train_loss=0.00562, valid_loss=0.00686]\n",
      "Epoch: 44/50: 100%|██████████| 8/8 [00:00<00:00, 117.93it/s, train_loss=0.00578, valid_loss=0.00669]\n",
      "Epoch: 45/50: 100%|██████████| 8/8 [00:00<00:00, 117.33it/s, train_loss=0.00593, valid_loss=0.00686]\n",
      "Epoch: 46/50: 100%|██████████| 8/8 [00:00<00:00, 117.08it/s, train_loss=0.00531, valid_loss=0.00664]\n",
      "Epoch: 47/50: 100%|██████████| 8/8 [00:00<00:00, 75.59it/s, train_loss=0.00541, valid_loss=0.00649]\n",
      "Epoch: 48/50: 100%|██████████| 8/8 [00:00<00:00, 113.66it/s, train_loss=0.00513, valid_loss=0.0066]\n",
      "Epoch: 49/50: 100%|██████████| 8/8 [00:00<00:00, 117.60it/s, train_loss=0.00543, valid_loss=0.00642]\n",
      "Epoch: 50/50: 100%|██████████| 8/8 [00:00<00:00, 117.09it/s, train_loss=0.00535, valid_loss=0.00656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 15/15 [00:00<00:00, 76.51it/s, train_loss=0.101, valid_loss=0.169]\n",
      "Epoch: 2/50: 100%|██████████| 15/15 [00:00<00:00, 132.58it/s, train_loss=0.0851, valid_loss=0.135]\n",
      "Epoch: 3/50: 100%|██████████| 15/15 [00:00<00:00, 129.43it/s, train_loss=0.0688, valid_loss=0.118]\n",
      "Epoch: 4/50: 100%|██████████| 15/15 [00:00<00:00, 129.48it/s, train_loss=0.0586, valid_loss=0.0777]\n",
      "Epoch: 5/50: 100%|██████████| 15/15 [00:00<00:00, 97.07it/s, train_loss=0.0438, valid_loss=0.0516]\n",
      "Epoch: 6/50: 100%|██████████| 15/15 [00:00<00:00, 129.17it/s, train_loss=0.031, valid_loss=0.0298]\n",
      "Epoch: 7/50: 100%|██████████| 15/15 [00:00<00:00, 129.28it/s, train_loss=0.0262, valid_loss=0.0205]\n",
      "Epoch: 8/50: 100%|██████████| 15/15 [00:00<00:00, 130.18it/s, train_loss=0.0209, valid_loss=0.0171]\n",
      "Epoch: 9/50: 100%|██████████| 15/15 [00:00<00:00, 128.48it/s, train_loss=0.019, valid_loss=0.0162]\n",
      "Epoch: 10/50: 100%|██████████| 15/15 [00:00<00:00, 129.80it/s, train_loss=0.0168, valid_loss=0.0164]\n",
      "Epoch: 11/50: 100%|██████████| 15/15 [00:00<00:00, 129.30it/s, train_loss=0.0153, valid_loss=0.0153]\n",
      "Epoch: 12/50: 100%|██████████| 15/15 [00:00<00:00, 99.91it/s, train_loss=0.0154, valid_loss=0.0152]\n",
      "Epoch: 13/50: 100%|██████████| 15/15 [00:00<00:00, 128.82it/s, train_loss=0.0149, valid_loss=0.0151]\n",
      "Epoch: 14/50: 100%|██████████| 15/15 [00:00<00:00, 130.08it/s, train_loss=0.0134, valid_loss=0.0144]\n",
      "Epoch: 15/50: 100%|██████████| 15/15 [00:00<00:00, 128.60it/s, train_loss=0.0124, valid_loss=0.015]\n",
      "Epoch: 16/50: 100%|██████████| 15/15 [00:00<00:00, 129.02it/s, train_loss=0.0139, valid_loss=0.0139]\n",
      "Epoch: 17/50: 100%|██████████| 15/15 [00:00<00:00, 129.17it/s, train_loss=0.0123, valid_loss=0.0123]\n",
      "Epoch: 18/50: 100%|██████████| 15/15 [00:00<00:00, 130.37it/s, train_loss=0.00867, valid_loss=0.00555]\n",
      "Epoch: 19/50: 100%|██████████| 15/15 [00:00<00:00, 98.70it/s, train_loss=0.00808, valid_loss=0.00451]\n",
      "Epoch: 20/50: 100%|██████████| 15/15 [00:00<00:00, 128.67it/s, train_loss=0.00746, valid_loss=0.00431]\n",
      "Epoch: 21/50: 100%|██████████| 15/15 [00:00<00:00, 123.74it/s, train_loss=0.00775, valid_loss=0.00555]\n",
      "Epoch: 22/50: 100%|██████████| 15/15 [00:00<00:00, 116.25it/s, train_loss=0.00687, valid_loss=0.00364]\n",
      "Epoch: 23/50: 100%|██████████| 15/15 [00:00<00:00, 130.52it/s, train_loss=0.00693, valid_loss=0.00444]\n",
      "Epoch: 24/50: 100%|██████████| 15/15 [00:00<00:00, 130.05it/s, train_loss=0.00664, valid_loss=0.00328]\n",
      "Epoch: 25/50: 100%|██████████| 15/15 [00:00<00:00, 129.22it/s, train_loss=0.00614, valid_loss=0.00391]\n",
      "Epoch: 26/50: 100%|██████████| 15/15 [00:00<00:00, 128.39it/s, train_loss=0.00634, valid_loss=0.00325]\n",
      "Epoch: 27/50: 100%|██████████| 15/15 [00:00<00:00, 87.31it/s, train_loss=0.00605, valid_loss=0.00329]\n",
      "Epoch: 28/50: 100%|██████████| 15/15 [00:00<00:00, 145.24it/s, train_loss=0.00666, valid_loss=0.00397]\n",
      "Epoch: 29/50: 100%|██████████| 15/15 [00:00<00:00, 139.26it/s, train_loss=0.00628, valid_loss=0.00324]\n",
      "Epoch: 30/50: 100%|██████████| 15/15 [00:00<00:00, 124.18it/s, train_loss=0.00662, valid_loss=0.00304]\n",
      "Epoch: 31/50: 100%|██████████| 15/15 [00:00<00:00, 146.17it/s, train_loss=0.00616, valid_loss=0.00344]\n",
      "Epoch: 32/50: 100%|██████████| 15/15 [00:00<00:00, 139.73it/s, train_loss=0.00584, valid_loss=0.00413]\n",
      "Epoch: 33/50: 100%|██████████| 15/15 [00:00<00:00, 143.99it/s, train_loss=0.0061, valid_loss=0.00283]\n",
      "Epoch: 34/50: 100%|██████████| 15/15 [00:00<00:00, 100.93it/s, train_loss=0.0065, valid_loss=0.00331]\n",
      "Epoch: 35/50: 100%|██████████| 15/15 [00:00<00:00, 143.97it/s, train_loss=0.0056, valid_loss=0.0033]\n",
      "Epoch: 36/50: 100%|██████████| 15/15 [00:00<00:00, 142.99it/s, train_loss=0.00549, valid_loss=0.00292]\n",
      "Epoch: 37/50: 100%|██████████| 15/15 [00:00<00:00, 146.02it/s, train_loss=0.00585, valid_loss=0.00265]\n",
      "Epoch: 38/50: 100%|██████████| 15/15 [00:00<00:00, 143.38it/s, train_loss=0.00568, valid_loss=0.0036]\n",
      "Epoch: 39/50: 100%|██████████| 15/15 [00:00<00:00, 146.67it/s, train_loss=0.00557, valid_loss=0.00287]\n",
      "Epoch: 40/50: 100%|██████████| 15/15 [00:00<00:00, 144.01it/s, train_loss=0.00561, valid_loss=0.0031]\n",
      "Epoch: 41/50: 100%|██████████| 15/15 [00:00<00:00, 108.84it/s, train_loss=0.00607, valid_loss=0.00254]\n",
      "Epoch: 42/50: 100%|██████████| 15/15 [00:00<00:00, 146.06it/s, train_loss=0.00518, valid_loss=0.00259]\n",
      "Epoch: 43/50: 100%|██████████| 15/15 [00:00<00:00, 143.70it/s, train_loss=0.00558, valid_loss=0.00244]\n",
      "Epoch: 44/50: 100%|██████████| 15/15 [00:00<00:00, 146.17it/s, train_loss=0.00525, valid_loss=0.00252]\n",
      "Epoch: 45/50: 100%|██████████| 15/15 [00:00<00:00, 143.00it/s, train_loss=0.00524, valid_loss=0.00372]\n",
      "Epoch: 46/50: 100%|██████████| 15/15 [00:00<00:00, 144.20it/s, train_loss=0.00552, valid_loss=0.00229]\n",
      "Epoch: 47/50: 100%|██████████| 15/15 [00:00<00:00, 143.77it/s, train_loss=0.0053, valid_loss=0.00241]\n",
      "Epoch: 48/50: 100%|██████████| 15/15 [00:00<00:00, 107.25it/s, train_loss=0.00515, valid_loss=0.00284]\n",
      "Epoch: 49/50: 100%|██████████| 15/15 [00:00<00:00, 142.71it/s, train_loss=0.00522, valid_loss=0.0028]\n",
      "Epoch: 50/50: 100%|██████████| 15/15 [00:00<00:00, 144.33it/s, train_loss=0.00574, valid_loss=0.00262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 22/22 [00:00<00:00, 96.95it/s, train_loss=0.0735, valid_loss=0.0868] \n",
      "Epoch: 2/50: 100%|██████████| 22/22 [00:00<00:00, 132.45it/s, train_loss=0.0488, valid_loss=0.0585]\n",
      "Epoch: 3/50: 100%|██████████| 22/22 [00:00<00:00, 106.13it/s, train_loss=0.0247, valid_loss=0.027] \n",
      "Epoch: 4/50: 100%|██████████| 22/22 [00:00<00:00, 135.63it/s, train_loss=0.019, valid_loss=0.0218] \n",
      "Epoch: 5/50: 100%|██████████| 22/22 [00:00<00:00, 135.37it/s, train_loss=0.0163, valid_loss=0.0184]\n",
      "Epoch: 6/50: 100%|██████████| 22/22 [00:00<00:00, 135.52it/s, train_loss=0.0149, valid_loss=0.0154]\n",
      "Epoch: 7/50: 100%|██████████| 22/22 [00:00<00:00, 136.35it/s, train_loss=0.013, valid_loss=0.0128] \n",
      "Epoch: 8/50: 100%|██████████| 22/22 [00:00<00:00, 109.45it/s, train_loss=0.0119, valid_loss=0.0115]\n",
      "Epoch: 9/50: 100%|██████████| 22/22 [00:00<00:00, 134.58it/s, train_loss=0.0106, valid_loss=0.00976]\n",
      "Epoch: 10/50: 100%|██████████| 22/22 [00:00<00:00, 135.34it/s, train_loss=0.0104, valid_loss=0.00845] \n",
      "Epoch: 11/50: 100%|██████████| 22/22 [00:00<00:00, 136.40it/s, train_loss=0.00964, valid_loss=0.00713]\n",
      "Epoch: 12/50: 100%|██████████| 22/22 [00:00<00:00, 110.27it/s, train_loss=0.00854, valid_loss=0.00649]\n",
      "Epoch: 13/50: 100%|██████████| 22/22 [00:00<00:00, 134.60it/s, train_loss=0.00834, valid_loss=0.00614]\n",
      "Epoch: 14/50: 100%|██████████| 22/22 [00:00<00:00, 134.17it/s, train_loss=0.00801, valid_loss=0.00563]\n",
      "Epoch: 15/50: 100%|██████████| 22/22 [00:00<00:00, 135.52it/s, train_loss=0.00768, valid_loss=0.00542]\n",
      "Epoch: 16/50: 100%|██████████| 22/22 [00:00<00:00, 124.59it/s, train_loss=0.00722, valid_loss=0.00538]\n",
      "Epoch: 17/50: 100%|██████████| 22/22 [00:00<00:00, 107.71it/s, train_loss=0.00771, valid_loss=0.00512]\n",
      "Epoch: 18/50: 100%|██████████| 22/22 [00:00<00:00, 134.04it/s, train_loss=0.00646, valid_loss=0.00521]\n",
      "Epoch: 19/50: 100%|██████████| 22/22 [00:00<00:00, 114.37it/s, train_loss=0.00693, valid_loss=0.00484]\n",
      "Epoch: 20/50: 100%|██████████| 22/22 [00:00<00:00, 134.97it/s, train_loss=0.00686, valid_loss=0.00483]\n",
      "Epoch: 21/50: 100%|██████████| 22/22 [00:00<00:00, 109.81it/s, train_loss=0.00621, valid_loss=0.00474]\n",
      "Epoch: 22/50: 100%|██████████| 22/22 [00:00<00:00, 136.19it/s, train_loss=0.00632, valid_loss=0.00455]\n",
      "Epoch: 23/50: 100%|██████████| 22/22 [00:00<00:00, 122.72it/s, train_loss=0.00583, valid_loss=0.0045]\n",
      "Epoch: 24/50: 100%|██████████| 22/22 [00:00<00:00, 135.00it/s, train_loss=0.00641, valid_loss=0.00437]\n",
      "Epoch: 25/50: 100%|██████████| 22/22 [00:00<00:00, 135.54it/s, train_loss=0.00621, valid_loss=0.00439]\n",
      "Epoch: 26/50: 100%|██████████| 22/22 [00:00<00:00, 110.53it/s, train_loss=0.00597, valid_loss=0.00435]\n",
      "Epoch: 27/50: 100%|██████████| 22/22 [00:00<00:00, 135.70it/s, train_loss=0.00619, valid_loss=0.00433]\n",
      "Epoch: 28/50: 100%|██████████| 22/22 [00:00<00:00, 135.20it/s, train_loss=0.00629, valid_loss=0.00408]\n",
      "Epoch: 29/50: 100%|██████████| 22/22 [00:00<00:00, 134.37it/s, train_loss=0.00619, valid_loss=0.00427]\n",
      "Epoch: 30/50: 100%|██████████| 22/22 [00:00<00:00, 103.15it/s, train_loss=0.0059, valid_loss=0.00412] \n",
      "Epoch: 31/50: 100%|██████████| 22/22 [00:00<00:00, 120.40it/s, train_loss=0.00611, valid_loss=0.00423]\n",
      "Epoch: 32/50: 100%|██████████| 22/22 [00:00<00:00, 135.61it/s, train_loss=0.00563, valid_loss=0.00389]\n",
      "Epoch: 33/50: 100%|██████████| 22/22 [00:00<00:00, 136.29it/s, train_loss=0.00584, valid_loss=0.00398]\n",
      "Epoch: 34/50: 100%|██████████| 22/22 [00:00<00:00, 135.67it/s, train_loss=0.00511, valid_loss=0.00402]\n",
      "Epoch: 35/50: 100%|██████████| 22/22 [00:00<00:00, 110.23it/s, train_loss=0.00538, valid_loss=0.0041]\n",
      "Epoch: 36/50: 100%|██████████| 22/22 [00:00<00:00, 134.81it/s, train_loss=0.00544, valid_loss=0.00407]\n",
      "Epoch: 37/50: 100%|██████████| 22/22 [00:00<00:00, 135.22it/s, train_loss=0.00553, valid_loss=0.00388]\n",
      "Epoch: 38/50: 100%|██████████| 22/22 [00:00<00:00, 135.82it/s, train_loss=0.00539, valid_loss=0.0039] \n",
      "Epoch: 39/50: 100%|██████████| 22/22 [00:00<00:00, 135.18it/s, train_loss=0.00595, valid_loss=0.00395]\n",
      "Epoch: 40/50: 100%|██████████| 22/22 [00:00<00:00, 110.19it/s, train_loss=0.0051, valid_loss=0.00378]\n",
      "Epoch: 41/50: 100%|██████████| 22/22 [00:00<00:00, 136.03it/s, train_loss=0.0059, valid_loss=0.0039]  \n",
      "Epoch: 42/50: 100%|██████████| 22/22 [00:00<00:00, 136.26it/s, train_loss=0.005, valid_loss=0.00378]  \n",
      "Epoch: 43/50: 100%|██████████| 22/22 [00:00<00:00, 134.76it/s, train_loss=0.00591, valid_loss=0.00368]\n",
      "Epoch: 44/50: 100%|██████████| 22/22 [00:00<00:00, 109.99it/s, train_loss=0.00504, valid_loss=0.00373]\n",
      "Epoch: 45/50: 100%|██████████| 22/22 [00:00<00:00, 135.00it/s, train_loss=0.0052, valid_loss=0.00393] \n",
      "Epoch: 46/50: 100%|██████████| 22/22 [00:00<00:00, 135.25it/s, train_loss=0.00491, valid_loss=0.00374]\n",
      "Epoch: 47/50: 100%|██████████| 22/22 [00:00<00:00, 134.95it/s, train_loss=0.00517, valid_loss=0.0038] \n",
      "Epoch: 48/50: 100%|██████████| 22/22 [00:00<00:00, 110.66it/s, train_loss=0.00538, valid_loss=0.00363]\n",
      "Epoch: 49/50: 100%|██████████| 22/22 [00:00<00:00, 134.22it/s, train_loss=0.00468, valid_loss=0.00366]\n",
      "Epoch: 50/50: 100%|██████████| 22/22 [00:00<00:00, 134.94it/s, train_loss=0.00528, valid_loss=0.00367]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 29/29 [00:00<00:00, 109.40it/s, train_loss=0.0611, valid_loss=0.0646]\n",
      "Epoch: 2/50: 100%|██████████| 29/29 [00:00<00:00, 117.64it/s, train_loss=0.0467, valid_loss=0.0455]\n",
      "Epoch: 3/50: 100%|██████████| 29/29 [00:00<00:00, 141.87it/s, train_loss=0.0421, valid_loss=0.043]\n",
      "Epoch: 4/50: 100%|██████████| 29/29 [00:00<00:00, 142.94it/s, train_loss=0.0362, valid_loss=0.035] \n",
      "Epoch: 5/50: 100%|██████████| 29/29 [00:00<00:00, 119.67it/s, train_loss=0.033, valid_loss=0.0333] \n",
      "Epoch: 6/50: 100%|██████████| 29/29 [00:00<00:00, 141.13it/s, train_loss=0.0312, valid_loss=0.0324]\n",
      "Epoch: 7/50: 100%|██████████| 29/29 [00:00<00:00, 120.33it/s, train_loss=0.0253, valid_loss=0.0256]\n",
      "Epoch: 8/50: 100%|██████████| 29/29 [00:00<00:00, 141.62it/s, train_loss=0.0234, valid_loss=0.0226]\n",
      "Epoch: 9/50: 100%|██████████| 29/29 [00:00<00:00, 140.89it/s, train_loss=0.0225, valid_loss=0.0225]\n",
      "Epoch: 10/50: 100%|██████████| 29/29 [00:00<00:00, 143.28it/s, train_loss=0.0206, valid_loss=0.0219]\n",
      "Epoch: 11/50: 100%|██████████| 29/29 [00:00<00:00, 142.54it/s, train_loss=0.021, valid_loss=0.0215] \n",
      "Epoch: 12/50: 100%|██████████| 29/29 [00:00<00:00, 142.36it/s, train_loss=0.0208, valid_loss=0.0213]\n",
      "Epoch: 13/50: 100%|██████████| 29/29 [00:00<00:00, 119.09it/s, train_loss=0.0144, valid_loss=0.0129]\n",
      "Epoch: 14/50: 100%|██████████| 29/29 [00:00<00:00, 141.56it/s, train_loss=0.0147, valid_loss=0.0126]\n",
      "Epoch: 15/50: 100%|██████████| 29/29 [00:00<00:00, 140.50it/s, train_loss=0.0137, valid_loss=0.012] \n",
      "Epoch: 16/50: 100%|██████████| 29/29 [00:00<00:00, 130.63it/s, train_loss=0.0131, valid_loss=0.0121]\n",
      "Epoch: 17/50: 100%|██████████| 29/29 [00:00<00:00, 125.17it/s, train_loss=0.0135, valid_loss=0.0122]\n",
      "Epoch: 18/50: 100%|██████████| 29/29 [00:00<00:00, 116.50it/s, train_loss=0.0132, valid_loss=0.0117]\n",
      "Epoch: 19/50: 100%|██████████| 29/29 [00:00<00:00, 141.08it/s, train_loss=0.0136, valid_loss=0.0118]\n",
      "Epoch: 20/50: 100%|██████████| 29/29 [00:00<00:00, 141.12it/s, train_loss=0.0134, valid_loss=0.0117]\n",
      "Epoch: 21/50: 100%|██████████| 29/29 [00:00<00:00, 119.41it/s, train_loss=0.0132, valid_loss=0.0113]\n",
      "Epoch: 22/50: 100%|██████████| 29/29 [00:00<00:00, 141.33it/s, train_loss=0.0132, valid_loss=0.0114]\n",
      "Epoch: 23/50: 100%|██████████| 29/29 [00:00<00:00, 119.33it/s, train_loss=0.0127, valid_loss=0.0112]\n",
      "Epoch: 24/50: 100%|██████████| 29/29 [00:00<00:00, 140.94it/s, train_loss=0.0121, valid_loss=0.0109]\n",
      "Epoch: 25/50: 100%|██████████| 29/29 [00:00<00:00, 143.01it/s, train_loss=0.0129, valid_loss=0.011] \n",
      "Epoch: 26/50: 100%|██████████| 29/29 [00:00<00:00, 141.91it/s, train_loss=0.013, valid_loss=0.0109] \n",
      "Epoch: 27/50: 100%|██████████| 29/29 [00:00<00:00, 141.31it/s, train_loss=0.0127, valid_loss=0.0114]\n",
      "Epoch: 28/50: 100%|██████████| 29/29 [00:00<00:00, 141.62it/s, train_loss=0.0132, valid_loss=0.0109]\n",
      "Epoch: 29/50: 100%|██████████| 29/29 [00:00<00:00, 116.30it/s, train_loss=0.0131, valid_loss=0.0107]\n",
      "Epoch: 30/50: 100%|██████████| 29/29 [00:00<00:00, 142.76it/s, train_loss=0.0124, valid_loss=0.0108]\n",
      "Epoch: 31/50: 100%|██████████| 29/29 [00:00<00:00, 130.27it/s, train_loss=0.0119, valid_loss=0.0107]\n",
      "Epoch: 32/50: 100%|██████████| 29/29 [00:00<00:00, 143.01it/s, train_loss=0.0118, valid_loss=0.0111]\n",
      "Epoch: 33/50: 100%|██████████| 29/29 [00:00<00:00, 140.83it/s, train_loss=0.0124, valid_loss=0.011] \n",
      "Epoch: 34/50: 100%|██████████| 29/29 [00:00<00:00, 118.90it/s, train_loss=0.0124, valid_loss=0.0109]\n",
      "Epoch: 35/50: 100%|██████████| 29/29 [00:00<00:00, 141.38it/s, train_loss=0.0124, valid_loss=0.0108]\n",
      "Epoch: 36/50: 100%|██████████| 29/29 [00:00<00:00, 141.08it/s, train_loss=0.0123, valid_loss=0.0108]\n",
      "Epoch: 37/50: 100%|██████████| 29/29 [00:00<00:00, 141.65it/s, train_loss=0.0124, valid_loss=0.0107]\n",
      "Epoch: 38/50: 100%|██████████| 29/29 [00:00<00:00, 139.76it/s, train_loss=0.0126, valid_loss=0.0109]\n",
      "Epoch: 39/50: 100%|██████████| 29/29 [00:00<00:00, 119.26it/s, train_loss=0.0118, valid_loss=0.0106]\n",
      "Epoch: 40/50: 100%|██████████| 29/29 [00:00<00:00, 141.22it/s, train_loss=0.0118, valid_loss=0.0106]\n",
      "Epoch: 41/50: 100%|██████████| 29/29 [00:00<00:00, 140.09it/s, train_loss=0.0113, valid_loss=0.0108]\n",
      "Epoch: 42/50: 100%|██████████| 29/29 [00:00<00:00, 141.97it/s, train_loss=0.0122, valid_loss=0.0108]\n",
      "Epoch: 43/50: 100%|██████████| 29/29 [00:00<00:00, 141.32it/s, train_loss=0.0121, valid_loss=0.0106]\n",
      "Epoch: 44/50: 100%|██████████| 29/29 [00:00<00:00, 117.54it/s, train_loss=0.0118, valid_loss=0.0108]\n",
      "Epoch: 45/50: 100%|██████████| 29/29 [00:00<00:00, 140.82it/s, train_loss=0.0125, valid_loss=0.0109]\n",
      "Epoch: 46/50: 100%|██████████| 29/29 [00:00<00:00, 142.00it/s, train_loss=0.0118, valid_loss=0.0108]\n",
      "Epoch: 47/50: 100%|██████████| 29/29 [00:00<00:00, 119.71it/s, train_loss=0.0118, valid_loss=0.0109]\n",
      "Epoch: 48/50: 100%|██████████| 29/29 [00:00<00:00, 141.30it/s, train_loss=0.012, valid_loss=0.0106] \n",
      "Epoch: 49/50: 100%|██████████| 29/29 [00:00<00:00, 120.23it/s, train_loss=0.0119, valid_loss=0.0109]\n",
      "Epoch: 50/50: 100%|██████████| 29/29 [00:00<00:00, 132.80it/s, train_loss=0.0111, valid_loss=0.0108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 29/29 [00:00<00:00, 107.81it/s, train_loss=0.0578, valid_loss=0.0545]\n",
      "Epoch: 2/50: 100%|██████████| 29/29 [00:00<00:00, 141.09it/s, train_loss=0.0306, valid_loss=0.0229]\n",
      "Epoch: 3/50: 100%|██████████| 29/29 [00:00<00:00, 140.88it/s, train_loss=0.0254, valid_loss=0.0196]\n",
      "Epoch: 4/50: 100%|██████████| 29/29 [00:00<00:00, 141.30it/s, train_loss=0.0226, valid_loss=0.0176]\n",
      "Epoch: 5/50: 100%|██████████| 29/29 [00:00<00:00, 116.46it/s, train_loss=0.0206, valid_loss=0.016]\n",
      "Epoch: 6/50: 100%|██████████| 29/29 [00:00<00:00, 140.96it/s, train_loss=0.0175, valid_loss=0.0152]\n",
      "Epoch: 7/50: 100%|██████████| 29/29 [00:00<00:00, 143.07it/s, train_loss=0.0169, valid_loss=0.0146]\n",
      "Epoch: 8/50: 100%|██████████| 29/29 [00:00<00:00, 142.13it/s, train_loss=0.0157, valid_loss=0.0141]\n",
      "Epoch: 9/50: 100%|██████████| 29/29 [00:00<00:00, 142.22it/s, train_loss=0.0148, valid_loss=0.0137]\n",
      "Epoch: 10/50: 100%|██████████| 29/29 [00:00<00:00, 119.09it/s, train_loss=0.0149, valid_loss=0.0135]\n",
      "Epoch: 11/50: 100%|██████████| 29/29 [00:00<00:00, 141.21it/s, train_loss=0.00857, valid_loss=0.00477]\n",
      "Epoch: 12/50: 100%|██████████| 29/29 [00:00<00:00, 141.10it/s, train_loss=0.0081, valid_loss=0.00435] \n",
      "Epoch: 13/50: 100%|██████████| 29/29 [00:00<00:00, 118.92it/s, train_loss=0.00788, valid_loss=0.00432]\n",
      "Epoch: 14/50: 100%|██████████| 29/29 [00:00<00:00, 141.60it/s, train_loss=0.00747, valid_loss=0.0039] \n",
      "Epoch: 15/50: 100%|██████████| 29/29 [00:00<00:00, 119.74it/s, train_loss=0.00807, valid_loss=0.00389]\n",
      "Epoch: 16/50: 100%|██████████| 29/29 [00:00<00:00, 140.23it/s, train_loss=0.00696, valid_loss=0.00378]\n",
      "Epoch: 17/50: 100%|██████████| 29/29 [00:00<00:00, 140.43it/s, train_loss=0.00627, valid_loss=0.00327]\n",
      "Epoch: 18/50: 100%|██████████| 29/29 [00:00<00:00, 140.42it/s, train_loss=0.00704, valid_loss=0.00298]\n",
      "Epoch: 19/50: 100%|██████████| 29/29 [00:00<00:00, 140.75it/s, train_loss=0.00695, valid_loss=0.003]  \n",
      "Epoch: 20/50: 100%|██████████| 29/29 [00:00<00:00, 140.85it/s, train_loss=0.00664, valid_loss=0.0026] \n",
      "Epoch: 21/50: 100%|██████████| 29/29 [00:00<00:00, 118.68it/s, train_loss=0.0068, valid_loss=0.00277] \n",
      "Epoch: 22/50: 100%|██████████| 29/29 [00:00<00:00, 129.24it/s, train_loss=0.00595, valid_loss=0.00242]\n",
      "Epoch: 23/50: 100%|██████████| 29/29 [00:00<00:00, 140.86it/s, train_loss=0.0065, valid_loss=0.00239] \n",
      "Epoch: 24/50: 100%|██████████| 29/29 [00:00<00:00, 141.66it/s, train_loss=0.00582, valid_loss=0.00261]\n",
      "Epoch: 25/50: 100%|██████████| 29/29 [00:00<00:00, 140.22it/s, train_loss=0.0063, valid_loss=0.00218] \n",
      "Epoch: 26/50: 100%|██████████| 29/29 [00:00<00:00, 119.37it/s, train_loss=0.0063, valid_loss=0.00222]\n",
      "Epoch: 27/50: 100%|██████████| 29/29 [00:00<00:00, 141.12it/s, train_loss=0.00615, valid_loss=0.00227]\n",
      "Epoch: 28/50: 100%|██████████| 29/29 [00:00<00:00, 140.87it/s, train_loss=0.00623, valid_loss=0.00217]\n",
      "Epoch: 29/50: 100%|██████████| 29/29 [00:00<00:00, 119.21it/s, train_loss=0.00592, valid_loss=0.0022] \n",
      "Epoch: 30/50: 100%|██████████| 29/29 [00:00<00:00, 132.71it/s, train_loss=0.00561, valid_loss=0.00208]\n",
      "Epoch: 31/50: 100%|██████████| 29/29 [00:00<00:00, 119.86it/s, train_loss=0.00583, valid_loss=0.00225]\n",
      "Epoch: 32/50: 100%|██████████| 29/29 [00:00<00:00, 141.15it/s, train_loss=0.00569, valid_loss=0.00207]\n",
      "Epoch: 33/50: 100%|██████████| 29/29 [00:00<00:00, 141.14it/s, train_loss=0.00592, valid_loss=0.00219]\n",
      "Epoch: 34/50: 100%|██████████| 29/29 [00:00<00:00, 141.51it/s, train_loss=0.00599, valid_loss=0.00216]\n",
      "Epoch: 35/50: 100%|██████████| 29/29 [00:00<00:00, 141.29it/s, train_loss=0.00552, valid_loss=0.0021] \n",
      "Epoch: 36/50: 100%|██████████| 29/29 [00:00<00:00, 141.47it/s, train_loss=0.00582, valid_loss=0.00187]\n",
      "Epoch: 37/50: 100%|██████████| 29/29 [00:00<00:00, 119.20it/s, train_loss=0.00561, valid_loss=0.00199]\n",
      "Epoch: 38/50: 100%|██████████| 29/29 [00:00<00:00, 140.35it/s, train_loss=0.00497, valid_loss=0.00198]\n",
      "Epoch: 39/50: 100%|██████████| 29/29 [00:00<00:00, 141.64it/s, train_loss=0.00524, valid_loss=0.0021] \n",
      "Epoch: 40/50: 100%|██████████| 29/29 [00:00<00:00, 142.00it/s, train_loss=0.00571, valid_loss=0.00218]\n",
      "Epoch: 41/50: 100%|██████████| 29/29 [00:00<00:00, 141.39it/s, train_loss=0.0054, valid_loss=0.00202] \n",
      "Epoch: 42/50: 100%|██████████| 29/29 [00:00<00:00, 118.47it/s, train_loss=0.00547, valid_loss=0.00185]\n",
      "Epoch: 43/50: 100%|██████████| 29/29 [00:00<00:00, 140.57it/s, train_loss=0.00559, valid_loss=0.0019] \n",
      "Epoch: 44/50: 100%|██████████| 29/29 [00:00<00:00, 141.21it/s, train_loss=0.00559, valid_loss=0.00197]\n",
      "Epoch: 45/50: 100%|██████████| 29/29 [00:00<00:00, 131.96it/s, train_loss=0.00481, valid_loss=0.00194]\n",
      "Epoch: 46/50: 100%|██████████| 29/29 [00:00<00:00, 143.06it/s, train_loss=0.00526, valid_loss=0.00213]\n",
      "Epoch: 47/50: 100%|██████████| 29/29 [00:00<00:00, 118.95it/s, train_loss=0.00507, valid_loss=0.0018]\n",
      "Epoch: 48/50: 100%|██████████| 29/29 [00:00<00:00, 141.10it/s, train_loss=0.00516, valid_loss=0.00197]\n",
      "Epoch: 49/50: 100%|██████████| 29/29 [00:00<00:00, 141.60it/s, train_loss=0.00526, valid_loss=0.00189]\n",
      "Epoch: 50/50: 100%|██████████| 29/29 [00:00<00:00, 142.03it/s, train_loss=0.00487, valid_loss=0.00202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 36/36 [00:00<00:00, 95.84it/s, train_loss=0.0691, valid_loss=0.054]  \n",
      "Epoch: 2/50: 100%|██████████| 36/36 [00:00<00:00, 136.63it/s, train_loss=0.0362, valid_loss=0.028] \n",
      "Epoch: 3/50: 100%|██████████| 36/36 [00:00<00:00, 119.18it/s, train_loss=0.0328, valid_loss=0.0261]\n",
      "Epoch: 4/50: 100%|██████████| 36/36 [00:00<00:00, 135.12it/s, train_loss=0.0237, valid_loss=0.0196]\n",
      "Epoch: 5/50: 100%|██████████| 36/36 [00:00<00:00, 135.83it/s, train_loss=0.022, valid_loss=0.0164] \n",
      "Epoch: 6/50: 100%|██████████| 36/36 [00:00<00:00, 118.08it/s, train_loss=0.019, valid_loss=0.0137] \n",
      "Epoch: 7/50: 100%|██████████| 36/36 [00:00<00:00, 136.29it/s, train_loss=0.0176, valid_loss=0.0118]\n",
      "Epoch: 8/50: 100%|██████████| 36/36 [00:00<00:00, 118.45it/s, train_loss=0.0163, valid_loss=0.011] \n",
      "Epoch: 9/50: 100%|██████████| 36/36 [00:00<00:00, 136.42it/s, train_loss=0.0156, valid_loss=0.0108]\n",
      "Epoch: 10/50: 100%|██████████| 36/36 [00:00<00:00, 118.12it/s, train_loss=0.0151, valid_loss=0.0105]\n",
      "Epoch: 11/50: 100%|██████████| 36/36 [00:00<00:00, 125.34it/s, train_loss=0.0144, valid_loss=0.0101]\n",
      "Epoch: 12/50: 100%|██████████| 36/36 [00:00<00:00, 113.51it/s, train_loss=0.0141, valid_loss=0.00986]\n",
      "Epoch: 13/50: 100%|██████████| 36/36 [00:00<00:00, 136.49it/s, train_loss=0.0147, valid_loss=0.0095] \n",
      "Epoch: 14/50: 100%|██████████| 36/36 [00:00<00:00, 136.50it/s, train_loss=0.0141, valid_loss=0.00923]\n",
      "Epoch: 15/50: 100%|██████████| 36/36 [00:00<00:00, 136.16it/s, train_loss=0.0135, valid_loss=0.00908]\n",
      "Epoch: 16/50: 100%|██████████| 36/36 [00:00<00:00, 118.45it/s, train_loss=0.0139, valid_loss=0.00886]\n",
      "Epoch: 17/50: 100%|██████████| 36/36 [00:00<00:00, 136.58it/s, train_loss=0.0137, valid_loss=0.00884]\n",
      "Epoch: 18/50: 100%|██████████| 36/36 [00:00<00:00, 136.86it/s, train_loss=0.0129, valid_loss=0.00867]\n",
      "Epoch: 19/50: 100%|██████████| 36/36 [00:00<00:00, 136.39it/s, train_loss=0.0139, valid_loss=0.00843]\n",
      "Epoch: 20/50: 100%|██████████| 36/36 [00:00<00:00, 118.45it/s, train_loss=0.0134, valid_loss=0.00834]\n",
      "Epoch: 21/50: 100%|██████████| 36/36 [00:00<00:00, 136.47it/s, train_loss=0.0136, valid_loss=0.00841]\n",
      "Epoch: 22/50: 100%|██████████| 36/36 [00:00<00:00, 113.96it/s, train_loss=0.0132, valid_loss=0.00829]\n",
      "Epoch: 23/50: 100%|██████████| 36/36 [00:00<00:00, 136.44it/s, train_loss=0.0133, valid_loss=0.00827]\n",
      "Epoch: 24/50: 100%|██████████| 36/36 [00:00<00:00, 136.25it/s, train_loss=0.0131, valid_loss=0.00832]\n",
      "Epoch: 25/50: 100%|██████████| 36/36 [00:00<00:00, 136.27it/s, train_loss=0.0122, valid_loss=0.0082] \n",
      "Epoch: 26/50: 100%|██████████| 36/36 [00:00<00:00, 108.86it/s, train_loss=0.0132, valid_loss=0.00818]\n",
      "Epoch: 27/50: 100%|██████████| 36/36 [00:00<00:00, 134.68it/s, train_loss=0.0123, valid_loss=0.00821]\n",
      "Epoch: 28/50: 100%|██████████| 36/36 [00:00<00:00, 118.44it/s, train_loss=0.0129, valid_loss=0.00835]\n",
      "Epoch: 29/50: 100%|██████████| 36/36 [00:00<00:00, 135.72it/s, train_loss=0.012, valid_loss=0.00816] \n",
      "Epoch: 30/50: 100%|██████████| 36/36 [00:00<00:00, 118.48it/s, train_loss=0.0128, valid_loss=0.00819]\n",
      "Epoch: 31/50: 100%|██████████| 36/36 [00:00<00:00, 135.32it/s, train_loss=0.0127, valid_loss=0.00816]\n",
      "Epoch: 32/50: 100%|██████████| 36/36 [00:00<00:00, 118.22it/s, train_loss=0.0118, valid_loss=0.00808]\n",
      "Epoch: 33/50: 100%|██████████| 36/36 [00:00<00:00, 128.23it/s, train_loss=0.0124, valid_loss=0.00815]\n",
      "Epoch: 34/50: 100%|██████████| 36/36 [00:00<00:00, 113.19it/s, train_loss=0.0119, valid_loss=0.00814]\n",
      "Epoch: 35/50: 100%|██████████| 36/36 [00:00<00:00, 135.80it/s, train_loss=0.0124, valid_loss=0.0081] \n",
      "Epoch: 36/50: 100%|██████████| 36/36 [00:00<00:00, 135.59it/s, train_loss=0.0138, valid_loss=0.00801]\n",
      "Epoch: 37/50: 100%|██████████| 36/36 [00:00<00:00, 128.08it/s, train_loss=0.0119, valid_loss=0.00811]\n",
      "Epoch: 38/50: 100%|██████████| 36/36 [00:00<00:00, 115.31it/s, train_loss=0.0132, valid_loss=0.00801]\n",
      "Epoch: 39/50: 100%|██████████| 36/36 [00:00<00:00, 134.18it/s, train_loss=0.0115, valid_loss=0.00813]\n",
      "Epoch: 40/50: 100%|██████████| 36/36 [00:00<00:00, 133.86it/s, train_loss=0.0121, valid_loss=0.00801]\n",
      "Epoch: 41/50: 100%|██████████| 36/36 [00:00<00:00, 136.14it/s, train_loss=0.0122, valid_loss=0.0082] \n",
      "Epoch: 42/50: 100%|██████████| 36/36 [00:00<00:00, 117.10it/s, train_loss=0.012, valid_loss=0.00804] \n",
      "Epoch: 43/50: 100%|██████████| 36/36 [00:00<00:00, 136.01it/s, train_loss=0.0119, valid_loss=0.00809]\n",
      "Epoch: 44/50: 100%|██████████| 36/36 [00:00<00:00, 133.98it/s, train_loss=0.0112, valid_loss=0.00824]\n",
      "Epoch: 45/50: 100%|██████████| 36/36 [00:00<00:00, 135.57it/s, train_loss=0.0122, valid_loss=0.00805]\n",
      "Epoch: 46/50: 100%|██████████| 36/36 [00:00<00:00, 116.20it/s, train_loss=0.0122, valid_loss=0.00803]\n",
      "Epoch: 47/50: 100%|██████████| 36/36 [00:00<00:00, 135.10it/s, train_loss=0.0125, valid_loss=0.00807]\n",
      "Epoch: 48/50: 100%|██████████| 36/36 [00:00<00:00, 135.58it/s, train_loss=0.012, valid_loss=0.008]   \n",
      "Epoch: 49/50: 100%|██████████| 36/36 [00:00<00:00, 136.04it/s, train_loss=0.0117, valid_loss=0.00802]\n",
      "Epoch: 50/50: 100%|██████████| 36/36 [00:00<00:00, 117.85it/s, train_loss=0.0117, valid_loss=0.00799]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config: batch_size--256, lr--0.001, number_epoch--50, hidden_dim--30,drop_prob-0.1,weight_decay-1e-07\n",
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 15/15 [00:00<00:00, 103.30it/s, train_loss=0.0633, valid_loss=0.0933]\n",
      "Epoch: 2/50: 100%|██████████| 15/15 [00:00<00:00, 148.70it/s, train_loss=0.0413, valid_loss=0.0596]\n",
      "Epoch: 3/50: 100%|██████████| 15/15 [00:00<00:00, 155.90it/s, train_loss=0.0257, valid_loss=0.0355]\n",
      "Epoch: 4/50: 100%|██████████| 15/15 [00:00<00:00, 159.93it/s, train_loss=0.0171, valid_loss=0.028]\n",
      "Epoch: 5/50: 100%|██████████| 15/15 [00:00<00:00, 156.02it/s, train_loss=0.0138, valid_loss=0.0226]\n",
      "Epoch: 6/50: 100%|██████████| 15/15 [00:00<00:00, 155.77it/s, train_loss=0.012, valid_loss=0.021]\n",
      "Epoch: 7/50: 100%|██████████| 15/15 [00:00<00:00, 157.45it/s, train_loss=0.0112, valid_loss=0.0201]\n",
      "Epoch: 8/50: 100%|██████████| 15/15 [00:00<00:00, 157.02it/s, train_loss=0.0106, valid_loss=0.0193]\n",
      "Epoch: 9/50: 100%|██████████| 15/15 [00:00<00:00, 156.64it/s, train_loss=0.0101, valid_loss=0.018]\n",
      "Epoch: 10/50: 100%|██████████| 15/15 [00:00<00:00, 152.28it/s, train_loss=0.00919, valid_loss=0.016]\n",
      "Epoch: 11/50: 100%|██████████| 15/15 [00:00<00:00, 155.99it/s, train_loss=0.00832, valid_loss=0.0139]\n",
      "Epoch: 12/50: 100%|██████████| 15/15 [00:00<00:00, 157.50it/s, train_loss=0.0077, valid_loss=0.0121]\n",
      "Epoch: 13/50: 100%|██████████| 15/15 [00:00<00:00, 107.04it/s, train_loss=0.00674, valid_loss=0.0107]\n",
      "Epoch: 14/50: 100%|██████████| 15/15 [00:00<00:00, 157.32it/s, train_loss=0.00662, valid_loss=0.00927]\n",
      "Epoch: 15/50: 100%|██████████| 15/15 [00:00<00:00, 156.74it/s, train_loss=0.00615, valid_loss=0.00831]\n",
      "Epoch: 16/50: 100%|██████████| 15/15 [00:00<00:00, 156.59it/s, train_loss=0.00605, valid_loss=0.00756]\n",
      "Epoch: 17/50: 100%|██████████| 15/15 [00:00<00:00, 157.30it/s, train_loss=0.00568, valid_loss=0.00731]\n",
      "Epoch: 18/50: 100%|██████████| 15/15 [00:00<00:00, 158.90it/s, train_loss=0.00545, valid_loss=0.00699]\n",
      "Epoch: 19/50: 100%|██████████| 15/15 [00:00<00:00, 156.16it/s, train_loss=0.00543, valid_loss=0.00675]\n",
      "Epoch: 20/50: 100%|██████████| 15/15 [00:00<00:00, 157.39it/s, train_loss=0.00529, valid_loss=0.00662]\n",
      "Epoch: 21/50: 100%|██████████| 15/15 [00:00<00:00, 159.44it/s, train_loss=0.00513, valid_loss=0.00658]\n",
      "Epoch: 22/50: 100%|██████████| 15/15 [00:00<00:00, 156.65it/s, train_loss=0.00474, valid_loss=0.00632]\n",
      "Epoch: 23/50: 100%|██████████| 15/15 [00:00<00:00, 143.33it/s, train_loss=0.00494, valid_loss=0.00611]\n",
      "Epoch: 24/50: 100%|██████████| 15/15 [00:00<00:00, 143.58it/s, train_loss=0.00471, valid_loss=0.00607]\n",
      "Epoch: 25/50: 100%|██████████| 15/15 [00:00<00:00, 156.69it/s, train_loss=0.00477, valid_loss=0.00591]\n",
      "Epoch: 26/50: 100%|██████████| 15/15 [00:00<00:00, 113.53it/s, train_loss=0.00474, valid_loss=0.00582]\n",
      "Epoch: 27/50: 100%|██████████| 15/15 [00:00<00:00, 155.07it/s, train_loss=0.00443, valid_loss=0.0057]\n",
      "Epoch: 28/50: 100%|██████████| 15/15 [00:00<00:00, 155.01it/s, train_loss=0.00441, valid_loss=0.00555]\n",
      "Epoch: 29/50: 100%|██████████| 15/15 [00:00<00:00, 153.83it/s, train_loss=0.00442, valid_loss=0.00541]\n",
      "Epoch: 30/50: 100%|██████████| 15/15 [00:00<00:00, 155.54it/s, train_loss=0.00445, valid_loss=0.00539]\n",
      "Epoch: 31/50: 100%|██████████| 15/15 [00:00<00:00, 157.02it/s, train_loss=0.00429, valid_loss=0.00528]\n",
      "Epoch: 32/50: 100%|██████████| 15/15 [00:00<00:00, 158.70it/s, train_loss=0.0045, valid_loss=0.00527]\n",
      "Epoch: 33/50: 100%|██████████| 15/15 [00:00<00:00, 156.51it/s, train_loss=0.00431, valid_loss=0.00523]\n",
      "Epoch: 34/50: 100%|██████████| 15/15 [00:00<00:00, 155.95it/s, train_loss=0.00407, valid_loss=0.00507]\n",
      "Epoch: 35/50: 100%|██████████| 15/15 [00:00<00:00, 158.61it/s, train_loss=0.00441, valid_loss=0.0051]\n",
      "Epoch: 36/50: 100%|██████████| 15/15 [00:00<00:00, 156.75it/s, train_loss=0.00366, valid_loss=0.00513]\n",
      "Epoch: 37/50: 100%|██████████| 15/15 [00:00<00:00, 156.61it/s, train_loss=0.00369, valid_loss=0.00501]\n",
      "Epoch: 38/50: 100%|██████████| 15/15 [00:00<00:00, 158.32it/s, train_loss=0.00383, valid_loss=0.00504]\n",
      "Epoch: 39/50: 100%|██████████| 15/15 [00:00<00:00, 113.50it/s, train_loss=0.00379, valid_loss=0.005]\n",
      "Epoch: 40/50: 100%|██████████| 15/15 [00:00<00:00, 157.40it/s, train_loss=0.00346, valid_loss=0.00492]\n",
      "Epoch: 41/50: 100%|██████████| 15/15 [00:00<00:00, 158.46it/s, train_loss=0.00382, valid_loss=0.0049]\n",
      "Epoch: 42/50: 100%|██████████| 15/15 [00:00<00:00, 156.43it/s, train_loss=0.00388, valid_loss=0.00489]\n",
      "Epoch: 43/50: 100%|██████████| 15/15 [00:00<00:00, 157.61it/s, train_loss=0.00405, valid_loss=0.00488]\n",
      "Epoch: 44/50: 100%|██████████| 15/15 [00:00<00:00, 157.13it/s, train_loss=0.00334, valid_loss=0.00489]\n",
      "Epoch: 45/50: 100%|██████████| 15/15 [00:00<00:00, 156.40it/s, train_loss=0.00366, valid_loss=0.0049]\n",
      "Epoch: 46/50: 100%|██████████| 15/15 [00:00<00:00, 157.64it/s, train_loss=0.0031, valid_loss=0.00483]\n",
      "Epoch: 47/50: 100%|██████████| 15/15 [00:00<00:00, 157.68it/s, train_loss=0.00392, valid_loss=0.00488]\n",
      "Epoch: 48/50: 100%|██████████| 15/15 [00:00<00:00, 156.58it/s, train_loss=0.00341, valid_loss=0.00484]\n",
      "Epoch: 49/50: 100%|██████████| 15/15 [00:00<00:00, 156.07it/s, train_loss=0.00348, valid_loss=0.00482]\n",
      "Epoch: 50/50: 100%|██████████| 15/15 [00:00<00:00, 158.26it/s, train_loss=0.00314, valid_loss=0.00481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 29/29 [00:00<00:00, 100.94it/s, train_loss=0.0571, valid_loss=0.0715]\n",
      "Epoch: 2/50: 100%|██████████| 29/29 [00:00<00:00, 153.42it/s, train_loss=0.0317, valid_loss=0.0255]\n",
      "Epoch: 3/50: 100%|██████████| 29/29 [00:00<00:00, 153.55it/s, train_loss=0.0222, valid_loss=0.0139]\n",
      "Epoch: 4/50: 100%|██████████| 29/29 [00:00<00:00, 152.33it/s, train_loss=0.0164, valid_loss=0.00827]\n",
      "Epoch: 5/50: 100%|██████████| 29/29 [00:00<00:00, 147.79it/s, train_loss=0.0113, valid_loss=0.0066] \n",
      "Epoch: 6/50: 100%|██████████| 29/29 [00:00<00:00, 144.52it/s, train_loss=0.0083, valid_loss=0.00611] \n",
      "Epoch: 7/50: 100%|██████████| 29/29 [00:00<00:00, 153.32it/s, train_loss=0.00894, valid_loss=0.00561]\n",
      "Epoch: 8/50: 100%|██████████| 29/29 [00:00<00:00, 126.94it/s, train_loss=0.00655, valid_loss=0.00478]\n",
      "Epoch: 9/50: 100%|██████████| 29/29 [00:00<00:00, 152.24it/s, train_loss=0.00733, valid_loss=0.00435]\n",
      "Epoch: 10/50: 100%|██████████| 29/29 [00:00<00:00, 151.64it/s, train_loss=0.00679, valid_loss=0.00356]\n",
      "Epoch: 11/50: 100%|██████████| 29/29 [00:00<00:00, 142.48it/s, train_loss=0.00573, valid_loss=0.00519]\n",
      "Epoch: 12/50: 100%|██████████| 29/29 [00:00<00:00, 154.12it/s, train_loss=0.00626, valid_loss=0.005]  \n",
      "Epoch: 13/50: 100%|██████████| 29/29 [00:00<00:00, 152.87it/s, train_loss=0.00484, valid_loss=0.00362]\n",
      "Epoch: 14/50: 100%|██████████| 29/29 [00:00<00:00, 152.82it/s, train_loss=0.00532, valid_loss=0.00308]\n",
      "Epoch: 15/50: 100%|██████████| 29/29 [00:00<00:00, 124.36it/s, train_loss=0.00494, valid_loss=0.00249]\n",
      "Epoch: 16/50: 100%|██████████| 29/29 [00:00<00:00, 138.60it/s, train_loss=0.00491, valid_loss=0.00291]\n",
      "Epoch: 17/50: 100%|██████████| 29/29 [00:00<00:00, 154.67it/s, train_loss=0.00522, valid_loss=0.00317]\n",
      "Epoch: 18/50: 100%|██████████| 29/29 [00:00<00:00, 153.67it/s, train_loss=0.00482, valid_loss=0.00292]\n",
      "Epoch: 19/50: 100%|██████████| 29/29 [00:00<00:00, 152.68it/s, train_loss=0.00529, valid_loss=0.00207]\n",
      "Epoch: 20/50: 100%|██████████| 29/29 [00:00<00:00, 152.55it/s, train_loss=0.00568, valid_loss=0.00198]\n",
      "Epoch: 21/50: 100%|██████████| 29/29 [00:00<00:00, 128.04it/s, train_loss=0.00493, valid_loss=0.00266]\n",
      "Epoch: 22/50: 100%|██████████| 29/29 [00:00<00:00, 151.78it/s, train_loss=0.00458, valid_loss=0.00329]\n",
      "Epoch: 23/50: 100%|██████████| 29/29 [00:00<00:00, 152.52it/s, train_loss=0.00384, valid_loss=0.00296]\n",
      "Epoch: 24/50: 100%|██████████| 29/29 [00:00<00:00, 152.15it/s, train_loss=0.00478, valid_loss=0.00235]\n",
      "Epoch: 25/50: 100%|██████████| 29/29 [00:00<00:00, 138.16it/s, train_loss=0.00505, valid_loss=0.00181]\n",
      "Epoch: 26/50: 100%|██████████| 29/29 [00:00<00:00, 152.91it/s, train_loss=0.00414, valid_loss=0.00221]\n",
      "Epoch: 27/50: 100%|██████████| 29/29 [00:00<00:00, 152.16it/s, train_loss=0.00487, valid_loss=0.00216]\n",
      "Epoch: 28/50: 100%|██████████| 29/29 [00:00<00:00, 127.45it/s, train_loss=0.00462, valid_loss=0.00241]\n",
      "Epoch: 29/50: 100%|██████████| 29/29 [00:00<00:00, 153.06it/s, train_loss=0.00513, valid_loss=0.00206]\n",
      "Epoch: 30/50: 100%|██████████| 29/29 [00:00<00:00, 152.81it/s, train_loss=0.00501, valid_loss=0.00225]\n",
      "Epoch: 31/50: 100%|██████████| 29/29 [00:00<00:00, 152.61it/s, train_loss=0.0047, valid_loss=0.00235] \n",
      "Epoch: 32/50: 100%|██████████| 29/29 [00:00<00:00, 152.99it/s, train_loss=0.00423, valid_loss=0.00169]\n",
      "Epoch: 33/50: 100%|██████████| 29/29 [00:00<00:00, 152.53it/s, train_loss=0.00523, valid_loss=0.00161]\n",
      "Epoch: 34/50: 100%|██████████| 29/29 [00:00<00:00, 128.25it/s, train_loss=0.00431, valid_loss=0.00207]\n",
      "Epoch: 35/50: 100%|██████████| 29/29 [00:00<00:00, 153.00it/s, train_loss=0.00422, valid_loss=0.00216]\n",
      "Epoch: 36/50: 100%|██████████| 29/29 [00:00<00:00, 152.68it/s, train_loss=0.00391, valid_loss=0.00179]\n",
      "Epoch: 37/50: 100%|██████████| 29/29 [00:00<00:00, 136.62it/s, train_loss=0.00378, valid_loss=0.00212]\n",
      "Epoch: 38/50: 100%|██████████| 29/29 [00:00<00:00, 152.49it/s, train_loss=0.00382, valid_loss=0.00195]\n",
      "Epoch: 39/50: 100%|██████████| 29/29 [00:00<00:00, 152.31it/s, train_loss=0.00395, valid_loss=0.00187]\n",
      "Epoch: 40/50: 100%|██████████| 29/29 [00:00<00:00, 153.08it/s, train_loss=0.00406, valid_loss=0.00251]\n",
      "Epoch: 41/50: 100%|██████████| 29/29 [00:00<00:00, 127.58it/s, train_loss=0.00411, valid_loss=0.00181]\n",
      "Epoch: 42/50: 100%|██████████| 29/29 [00:00<00:00, 148.72it/s, train_loss=0.00412, valid_loss=0.00217]\n",
      "Epoch: 43/50: 100%|██████████| 29/29 [00:00<00:00, 152.99it/s, train_loss=0.00469, valid_loss=0.00189]\n",
      "Epoch: 44/50: 100%|██████████| 29/29 [00:00<00:00, 153.85it/s, train_loss=0.00401, valid_loss=0.00235]\n",
      "Epoch: 45/50: 100%|██████████| 29/29 [00:00<00:00, 153.34it/s, train_loss=0.00431, valid_loss=0.00254]\n",
      "Epoch: 46/50: 100%|██████████| 29/29 [00:00<00:00, 152.80it/s, train_loss=0.00397, valid_loss=0.00232]\n",
      "Epoch: 47/50: 100%|██████████| 29/29 [00:00<00:00, 153.28it/s, train_loss=0.00435, valid_loss=0.00191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 44/44 [00:00<00:00, 116.95it/s, train_loss=0.0491, valid_loss=0.0534]\n",
      "Epoch: 2/50: 100%|██████████| 44/44 [00:00<00:00, 153.18it/s, train_loss=0.0243, valid_loss=0.0265]\n",
      "Epoch: 3/50: 100%|██████████| 44/44 [00:00<00:00, 153.99it/s, train_loss=0.02, valid_loss=0.0222]  \n",
      "Epoch: 4/50: 100%|██████████| 44/44 [00:00<00:00, 153.92it/s, train_loss=0.0183, valid_loss=0.0183]\n",
      "Epoch: 5/50: 100%|██████████| 44/44 [00:00<00:00, 128.67it/s, train_loss=0.0151, valid_loss=0.0154]\n",
      "Epoch: 6/50: 100%|██████████| 44/44 [00:00<00:00, 154.56it/s, train_loss=0.0147, valid_loss=0.0133]\n",
      "Epoch: 7/50: 100%|██████████| 44/44 [00:00<00:00, 143.57it/s, train_loss=0.0131, valid_loss=0.0126]\n",
      "Epoch: 8/50: 100%|██████████| 44/44 [00:00<00:00, 153.34it/s, train_loss=0.0137, valid_loss=0.0124]\n",
      "Epoch: 9/50: 100%|██████████| 44/44 [00:00<00:00, 134.24it/s, train_loss=0.0129, valid_loss=0.0122]\n",
      "Epoch: 10/50: 100%|██████████| 44/44 [00:00<00:00, 153.76it/s, train_loss=0.0123, valid_loss=0.012] \n",
      "Epoch: 11/50: 100%|██████████| 44/44 [00:00<00:00, 153.42it/s, train_loss=0.0119, valid_loss=0.0117]\n",
      "Epoch: 12/50: 100%|██████████| 44/44 [00:00<00:00, 154.42it/s, train_loss=0.0123, valid_loss=0.0118]\n",
      "Epoch: 13/50: 100%|██████████| 44/44 [00:00<00:00, 154.54it/s, train_loss=0.0119, valid_loss=0.0118]\n",
      "Epoch: 14/50: 100%|██████████| 44/44 [00:00<00:00, 135.71it/s, train_loss=0.0114, valid_loss=0.0116]\n",
      "Epoch: 15/50: 100%|██████████| 44/44 [00:00<00:00, 153.56it/s, train_loss=0.012, valid_loss=0.0115] \n",
      "Epoch: 16/50: 100%|██████████| 44/44 [00:00<00:00, 153.31it/s, train_loss=0.0122, valid_loss=0.0114]\n",
      "Epoch: 17/50: 100%|██████████| 44/44 [00:00<00:00, 154.34it/s, train_loss=0.0114, valid_loss=0.0115]\n",
      "Epoch: 18/50: 100%|██████████| 44/44 [00:00<00:00, 136.14it/s, train_loss=0.0111, valid_loss=0.0114]\n",
      "Epoch: 19/50: 100%|██████████| 44/44 [00:00<00:00, 152.87it/s, train_loss=0.0102, valid_loss=0.0113]\n",
      "Epoch: 20/50: 100%|██████████| 44/44 [00:00<00:00, 144.17it/s, train_loss=0.0106, valid_loss=0.0112]\n",
      "Epoch: 21/50: 100%|██████████| 44/44 [00:00<00:00, 153.68it/s, train_loss=0.0105, valid_loss=0.0112]\n",
      "Epoch: 22/50: 100%|██████████| 44/44 [00:00<00:00, 154.34it/s, train_loss=0.0112, valid_loss=0.0112]\n",
      "Epoch: 23/50: 100%|██████████| 44/44 [00:00<00:00, 135.39it/s, train_loss=0.0111, valid_loss=0.0112]\n",
      "Epoch: 24/50: 100%|██████████| 44/44 [00:00<00:00, 153.54it/s, train_loss=0.0111, valid_loss=0.0114]\n",
      "Epoch: 25/50: 100%|██████████| 44/44 [00:00<00:00, 151.34it/s, train_loss=0.0108, valid_loss=0.0111]\n",
      "Epoch: 26/50: 100%|██████████| 44/44 [00:00<00:00, 153.54it/s, train_loss=0.0109, valid_loss=0.0112] \n",
      "Epoch: 27/50: 100%|██████████| 44/44 [00:00<00:00, 136.52it/s, train_loss=0.0108, valid_loss=0.0113]\n",
      "Epoch: 28/50: 100%|██████████| 44/44 [00:00<00:00, 153.27it/s, train_loss=0.011, valid_loss=0.0112] \n",
      "Epoch: 29/50: 100%|██████████| 44/44 [00:00<00:00, 153.01it/s, train_loss=0.0112, valid_loss=0.0111]\n",
      "Epoch: 30/50: 100%|██████████| 44/44 [00:00<00:00, 142.58it/s, train_loss=0.0104, valid_loss=0.0112] \n",
      "Epoch: 31/50: 100%|██████████| 44/44 [00:00<00:00, 136.47it/s, train_loss=0.0106, valid_loss=0.0112]\n",
      "Epoch: 32/50: 100%|██████████| 44/44 [00:00<00:00, 153.22it/s, train_loss=0.01, valid_loss=0.0111]  \n",
      "Epoch: 33/50: 100%|██████████| 44/44 [00:00<00:00, 154.08it/s, train_loss=0.00993, valid_loss=0.0112]\n",
      "Epoch: 34/50: 100%|██████████| 44/44 [00:00<00:00, 154.57it/s, train_loss=0.0101, valid_loss=0.0112]\n",
      "Epoch: 35/50: 100%|██████████| 44/44 [00:00<00:00, 153.12it/s, train_loss=0.0105, valid_loss=0.0111]\n",
      "Epoch: 36/50: 100%|██████████| 44/44 [00:00<00:00, 136.79it/s, train_loss=0.0114, valid_loss=0.0112]\n",
      "Epoch: 37/50: 100%|██████████| 44/44 [00:00<00:00, 153.75it/s, train_loss=0.0111, valid_loss=0.011] \n",
      "Epoch: 38/50: 100%|██████████| 44/44 [00:00<00:00, 153.90it/s, train_loss=0.0111, valid_loss=0.0111]\n",
      "Epoch: 39/50: 100%|██████████| 44/44 [00:00<00:00, 146.41it/s, train_loss=0.0112, valid_loss=0.0113]\n",
      "Epoch: 40/50: 100%|██████████| 44/44 [00:00<00:00, 136.85it/s, train_loss=0.00982, valid_loss=0.0112]\n",
      "Epoch: 41/50: 100%|██████████| 44/44 [00:00<00:00, 154.06it/s, train_loss=0.0105, valid_loss=0.0109]\n",
      "Epoch: 42/50: 100%|██████████| 44/44 [00:00<00:00, 152.62it/s, train_loss=0.00983, valid_loss=0.011] \n",
      "Epoch: 43/50: 100%|██████████| 44/44 [00:00<00:00, 142.77it/s, train_loss=0.0104, valid_loss=0.0111]\n",
      "Epoch: 44/50: 100%|██████████| 44/44 [00:00<00:00, 153.47it/s, train_loss=0.0108, valid_loss=0.011] \n",
      "Epoch: 45/50: 100%|██████████| 44/44 [00:00<00:00, 126.98it/s, train_loss=0.01, valid_loss=0.0109]  \n",
      "Epoch: 46/50: 100%|██████████| 44/44 [00:00<00:00, 153.36it/s, train_loss=0.0102, valid_loss=0.0109]\n",
      "Epoch: 47/50: 100%|██████████| 44/44 [00:00<00:00, 153.75it/s, train_loss=0.0107, valid_loss=0.011]  \n",
      "Epoch: 48/50: 100%|██████████| 44/44 [00:00<00:00, 153.14it/s, train_loss=0.01, valid_loss=0.0111]  \n",
      "Epoch: 49/50: 100%|██████████| 44/44 [00:00<00:00, 136.51it/s, train_loss=0.00961, valid_loss=0.011] \n",
      "Epoch: 50/50: 100%|██████████| 44/44 [00:00<00:00, 154.59it/s, train_loss=0.0101, valid_loss=0.0109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 44/44 [00:00<00:00, 127.50it/s, train_loss=0.0216, valid_loss=0.026] \n",
      "Epoch: 2/50: 100%|██████████| 44/44 [00:00<00:00, 144.23it/s, train_loss=0.0147, valid_loss=0.0164]\n",
      "Epoch: 3/50: 100%|██████████| 44/44 [00:00<00:00, 134.64it/s, train_loss=0.0107, valid_loss=0.0101]\n",
      "Epoch: 4/50: 100%|██████████| 44/44 [00:00<00:00, 153.75it/s, train_loss=0.00848, valid_loss=0.00707]\n",
      "Epoch: 5/50: 100%|██████████| 44/44 [00:00<00:00, 153.64it/s, train_loss=0.00772, valid_loss=0.00606]\n",
      "Epoch: 6/50: 100%|██████████| 44/44 [00:00<00:00, 153.43it/s, train_loss=0.0067, valid_loss=0.00545] \n",
      "Epoch: 7/50: 100%|██████████| 44/44 [00:00<00:00, 153.85it/s, train_loss=0.00757, valid_loss=0.00511]\n",
      "Epoch: 8/50: 100%|██████████| 44/44 [00:00<00:00, 136.91it/s, train_loss=0.00686, valid_loss=0.00463]\n",
      "Epoch: 9/50: 100%|██████████| 44/44 [00:00<00:00, 153.74it/s, train_loss=0.00636, valid_loss=0.00444]\n",
      "Epoch: 10/50: 100%|██████████| 44/44 [00:00<00:00, 153.95it/s, train_loss=0.00539, valid_loss=0.00419]\n",
      "Epoch: 11/50: 100%|██████████| 44/44 [00:00<00:00, 153.92it/s, train_loss=0.00545, valid_loss=0.00418]\n",
      "Epoch: 12/50: 100%|██████████| 44/44 [00:00<00:00, 136.87it/s, train_loss=0.00458, valid_loss=0.00403]\n",
      "Epoch: 13/50: 100%|██████████| 44/44 [00:00<00:00, 153.82it/s, train_loss=0.00558, valid_loss=0.00387]\n",
      "Epoch: 14/50: 100%|██████████| 44/44 [00:00<00:00, 154.17it/s, train_loss=0.00573, valid_loss=0.00381]\n",
      "Epoch: 15/50: 100%|██████████| 44/44 [00:00<00:00, 154.61it/s, train_loss=0.00641, valid_loss=0.00401]\n",
      "Epoch: 16/50: 100%|██████████| 44/44 [00:00<00:00, 153.72it/s, train_loss=0.00555, valid_loss=0.00435]\n",
      "Epoch: 17/50: 100%|██████████| 44/44 [00:00<00:00, 136.18it/s, train_loss=0.00483, valid_loss=0.00367]\n",
      "Epoch: 18/50: 100%|██████████| 44/44 [00:00<00:00, 153.24it/s, train_loss=0.00494, valid_loss=0.00366]\n",
      "Epoch: 19/50: 100%|██████████| 44/44 [00:00<00:00, 153.05it/s, train_loss=0.00587, valid_loss=0.00364]\n",
      "Epoch: 20/50: 100%|██████████| 44/44 [00:00<00:00, 154.22it/s, train_loss=0.0055, valid_loss=0.00364] \n",
      "Epoch: 21/50: 100%|██████████| 44/44 [00:00<00:00, 135.82it/s, train_loss=0.0044, valid_loss=0.0036]  \n",
      "Epoch: 22/50: 100%|██████████| 44/44 [00:00<00:00, 153.56it/s, train_loss=0.00498, valid_loss=0.0036] \n",
      "Epoch: 23/50: 100%|██████████| 44/44 [00:00<00:00, 143.14it/s, train_loss=0.00489, valid_loss=0.00363]\n",
      "Epoch: 24/50: 100%|██████████| 44/44 [00:00<00:00, 154.53it/s, train_loss=0.00477, valid_loss=0.00351]\n",
      "Epoch: 25/50: 100%|██████████| 44/44 [00:00<00:00, 138.09it/s, train_loss=0.00506, valid_loss=0.00353]\n",
      "Epoch: 26/50: 100%|██████████| 44/44 [00:00<00:00, 154.58it/s, train_loss=0.00452, valid_loss=0.00361]\n",
      "Epoch: 27/50: 100%|██████████| 44/44 [00:00<00:00, 153.85it/s, train_loss=0.005, valid_loss=0.00357]  \n",
      "Epoch: 28/50: 100%|██████████| 44/44 [00:00<00:00, 154.30it/s, train_loss=0.0049, valid_loss=0.00348] \n",
      "Epoch: 29/50: 100%|██████████| 44/44 [00:00<00:00, 135.02it/s, train_loss=0.00412, valid_loss=0.00343]\n",
      "Epoch: 30/50: 100%|██████████| 44/44 [00:00<00:00, 136.13it/s, train_loss=0.0046, valid_loss=0.00349] \n",
      "Epoch: 31/50: 100%|██████████| 44/44 [00:00<00:00, 154.18it/s, train_loss=0.00404, valid_loss=0.00352]\n",
      "Epoch: 32/50: 100%|██████████| 44/44 [00:00<00:00, 154.08it/s, train_loss=0.004, valid_loss=0.00361]  \n",
      "Epoch: 33/50: 100%|██████████| 44/44 [00:00<00:00, 154.85it/s, train_loss=0.00437, valid_loss=0.00354]\n",
      "Epoch: 34/50: 100%|██████████| 44/44 [00:00<00:00, 137.19it/s, train_loss=0.00406, valid_loss=0.00359]\n",
      "Epoch: 35/50: 100%|██████████| 44/44 [00:00<00:00, 153.42it/s, train_loss=0.0042, valid_loss=0.00338] \n",
      "Epoch: 36/50: 100%|██████████| 44/44 [00:00<00:00, 155.19it/s, train_loss=0.00465, valid_loss=0.0034] \n",
      "Epoch: 37/50: 100%|██████████| 44/44 [00:00<00:00, 154.19it/s, train_loss=0.00385, valid_loss=0.00348]\n",
      "Epoch: 38/50: 100%|██████████| 44/44 [00:00<00:00, 155.15it/s, train_loss=0.00439, valid_loss=0.00341]\n",
      "Epoch: 39/50: 100%|██████████| 44/44 [00:00<00:00, 135.58it/s, train_loss=0.00426, valid_loss=0.00339]\n",
      "Epoch: 40/50: 100%|██████████| 44/44 [00:00<00:00, 152.67it/s, train_loss=0.00456, valid_loss=0.00346]\n",
      "Epoch: 41/50: 100%|██████████| 44/44 [00:00<00:00, 138.00it/s, train_loss=0.00407, valid_loss=0.00357]\n",
      "Epoch: 42/50: 100%|██████████| 44/44 [00:00<00:00, 139.64it/s, train_loss=0.00464, valid_loss=0.00345]\n",
      "Epoch: 43/50: 100%|██████████| 44/44 [00:00<00:00, 117.90it/s, train_loss=0.00413, valid_loss=0.00345]\n",
      "Epoch: 44/50: 100%|██████████| 44/44 [00:00<00:00, 144.44it/s, train_loss=0.00469, valid_loss=0.00354]\n",
      "Epoch: 45/50: 100%|██████████| 44/44 [00:00<00:00, 140.93it/s, train_loss=0.0043, valid_loss=0.00343] \n",
      "Epoch: 46/50: 100%|██████████| 44/44 [00:00<00:00, 132.14it/s, train_loss=0.00414, valid_loss=0.00344]\n",
      "Epoch: 47/50: 100%|██████████| 44/44 [00:00<00:00, 133.23it/s, train_loss=0.00385, valid_loss=0.00367]\n",
      "Epoch: 48/50: 100%|██████████| 44/44 [00:00<00:00, 121.98it/s, train_loss=0.00385, valid_loss=0.00347]\n",
      "Epoch: 49/50: 100%|██████████| 44/44 [00:00<00:00, 128.80it/s, train_loss=0.0041, valid_loss=0.00341] \n",
      "Epoch: 50/50: 100%|██████████| 44/44 [00:00<00:00, 145.20it/s, train_loss=0.00405, valid_loss=0.00344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 58/58 [00:00<00:00, 118.77it/s, train_loss=0.026, valid_loss=0.0158] \n",
      "Epoch: 2/50: 100%|██████████| 58/58 [00:00<00:00, 126.84it/s, train_loss=0.0153, valid_loss=0.00861]\n",
      "Epoch: 3/50: 100%|██████████| 58/58 [00:00<00:00, 148.28it/s, train_loss=0.0113, valid_loss=0.00698]\n",
      "Epoch: 4/50: 100%|██████████| 58/58 [00:00<00:00, 131.78it/s, train_loss=0.00945, valid_loss=0.00582]\n",
      "Epoch: 5/50: 100%|██████████| 58/58 [00:00<00:00, 135.34it/s, train_loss=0.00834, valid_loss=0.00445]\n",
      "Epoch: 6/50: 100%|██████████| 58/58 [00:00<00:00, 131.28it/s, train_loss=0.0085, valid_loss=0.0038]  \n",
      "Epoch: 7/50: 100%|██████████| 58/58 [00:00<00:00, 143.64it/s, train_loss=0.00741, valid_loss=0.00332]\n",
      "Epoch: 8/50: 100%|██████████| 58/58 [00:00<00:00, 123.61it/s, train_loss=0.00688, valid_loss=0.0025] \n",
      "Epoch: 9/50: 100%|██████████| 58/58 [00:00<00:00, 127.97it/s, train_loss=0.00556, valid_loss=0.00231]\n",
      "Epoch: 10/50: 100%|██████████| 58/58 [00:00<00:00, 135.60it/s, train_loss=0.007, valid_loss=0.00224]  \n",
      "Epoch: 11/50: 100%|██████████| 58/58 [00:00<00:00, 125.65it/s, train_loss=0.00694, valid_loss=0.00206]\n",
      "Epoch: 12/50: 100%|██████████| 58/58 [00:00<00:00, 146.43it/s, train_loss=0.00548, valid_loss=0.00261]\n",
      "Epoch: 13/50: 100%|██████████| 58/58 [00:00<00:00, 139.12it/s, train_loss=0.00559, valid_loss=0.00197]\n",
      "Epoch: 14/50: 100%|██████████| 58/58 [00:00<00:00, 136.85it/s, train_loss=0.00529, valid_loss=0.00178]\n",
      "Epoch: 15/50: 100%|██████████| 58/58 [00:00<00:00, 120.45it/s, train_loss=0.00516, valid_loss=0.00198]\n",
      "Epoch: 16/50: 100%|██████████| 58/58 [00:00<00:00, 136.09it/s, train_loss=0.00478, valid_loss=0.00188]\n",
      "Epoch: 17/50: 100%|██████████| 58/58 [00:00<00:00, 125.23it/s, train_loss=0.00594, valid_loss=0.0018] \n",
      "Epoch: 18/50: 100%|██████████| 58/58 [00:00<00:00, 132.24it/s, train_loss=0.00534, valid_loss=0.00223]\n",
      "Epoch: 19/50: 100%|██████████| 58/58 [00:00<00:00, 130.75it/s, train_loss=0.00492, valid_loss=0.00208]\n",
      "Epoch: 20/50: 100%|██████████| 58/58 [00:00<00:00, 138.96it/s, train_loss=0.00484, valid_loss=0.00186]\n",
      "Epoch: 21/50: 100%|██████████| 58/58 [00:00<00:00, 127.19it/s, train_loss=0.00454, valid_loss=0.00195]\n",
      "Epoch: 22/50: 100%|██████████| 58/58 [00:00<00:00, 149.03it/s, train_loss=0.0048, valid_loss=0.00185] \n",
      "Epoch: 23/50: 100%|██████████| 58/58 [00:00<00:00, 140.91it/s, train_loss=0.00516, valid_loss=0.00177]\n",
      "Epoch: 24/50: 100%|██████████| 58/58 [00:00<00:00, 150.15it/s, train_loss=0.00477, valid_loss=0.00191]\n",
      "Epoch: 25/50: 100%|██████████| 58/58 [00:00<00:00, 128.70it/s, train_loss=0.00465, valid_loss=0.00186]\n",
      "Epoch: 26/50: 100%|██████████| 58/58 [00:00<00:00, 123.66it/s, train_loss=0.00483, valid_loss=0.00166]\n",
      "Epoch: 27/50: 100%|██████████| 58/58 [00:00<00:00, 133.71it/s, train_loss=0.00543, valid_loss=0.00197]\n",
      "Epoch: 28/50: 100%|██████████| 58/58 [00:00<00:00, 133.06it/s, train_loss=0.00501, valid_loss=0.00167]\n",
      "Epoch: 29/50: 100%|██████████| 58/58 [00:00<00:00, 123.58it/s, train_loss=0.00492, valid_loss=0.00183]\n",
      "Epoch: 30/50: 100%|██████████| 58/58 [00:00<00:00, 130.28it/s, train_loss=0.00538, valid_loss=0.00202]\n",
      "Epoch: 31/50: 100%|██████████| 58/58 [00:00<00:00, 118.67it/s, train_loss=0.00522, valid_loss=0.00165]\n",
      "Epoch: 32/50: 100%|██████████| 58/58 [00:00<00:00, 128.34it/s, train_loss=0.00408, valid_loss=0.00168]\n",
      "Epoch: 33/50: 100%|██████████| 58/58 [00:00<00:00, 136.95it/s, train_loss=0.00434, valid_loss=0.0017] \n",
      "Epoch: 34/50: 100%|██████████| 58/58 [00:00<00:00, 126.26it/s, train_loss=0.00387, valid_loss=0.0018] \n",
      "Epoch: 35/50: 100%|██████████| 58/58 [00:00<00:00, 125.35it/s, train_loss=0.00422, valid_loss=0.00182]\n",
      "Epoch: 36/50: 100%|██████████| 58/58 [00:00<00:00, 130.53it/s, train_loss=0.00438, valid_loss=0.00161]\n",
      "Epoch: 37/50: 100%|██████████| 58/58 [00:00<00:00, 131.59it/s, train_loss=0.00429, valid_loss=0.00159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 72/72 [00:00<00:00, 122.95it/s, train_loss=0.0297, valid_loss=0.0196]\n",
      "Epoch: 2/50: 100%|██████████| 72/72 [00:00<00:00, 136.19it/s, train_loss=0.0164, valid_loss=0.0133]\n",
      "Epoch: 3/50: 100%|██████████| 72/72 [00:00<00:00, 139.16it/s, train_loss=0.011, valid_loss=0.00684] \n",
      "Epoch: 4/50: 100%|██████████| 72/72 [00:00<00:00, 120.02it/s, train_loss=0.00859, valid_loss=0.00525]\n",
      "Epoch: 5/50: 100%|██████████| 72/72 [00:00<00:00, 140.03it/s, train_loss=0.00704, valid_loss=0.00437]\n",
      "Epoch: 6/50: 100%|██████████| 72/72 [00:00<00:00, 123.08it/s, train_loss=0.00719, valid_loss=0.00366]\n",
      "Epoch: 7/50: 100%|██████████| 72/72 [00:00<00:00, 129.16it/s, train_loss=0.00675, valid_loss=0.00308]\n",
      "Epoch: 8/50: 100%|██████████| 72/72 [00:00<00:00, 126.48it/s, train_loss=0.00609, valid_loss=0.00287]\n",
      "Epoch: 9/50: 100%|██████████| 72/72 [00:00<00:00, 124.79it/s, train_loss=0.00633, valid_loss=0.00273]\n",
      "Epoch: 10/50: 100%|██████████| 72/72 [00:00<00:00, 140.07it/s, train_loss=0.00571, valid_loss=0.00268]\n",
      "Epoch: 11/50: 100%|██████████| 72/72 [00:00<00:00, 119.88it/s, train_loss=0.00546, valid_loss=0.00258]\n",
      "Epoch: 12/50: 100%|██████████| 72/72 [00:00<00:00, 145.19it/s, train_loss=0.0055, valid_loss=0.0026]  \n",
      "Epoch: 13/50: 100%|██████████| 72/72 [00:00<00:00, 146.39it/s, train_loss=0.00569, valid_loss=0.00255]\n",
      "Epoch: 14/50: 100%|██████████| 72/72 [00:00<00:00, 127.96it/s, train_loss=0.00539, valid_loss=0.00253]\n",
      "Epoch: 15/50: 100%|██████████| 72/72 [00:00<00:00, 144.16it/s, train_loss=0.00559, valid_loss=0.00251]\n",
      "Epoch: 16/50: 100%|██████████| 72/72 [00:00<00:00, 137.42it/s, train_loss=0.00497, valid_loss=0.00249]\n",
      "Epoch: 17/50: 100%|██████████| 72/72 [00:00<00:00, 131.57it/s, train_loss=0.00488, valid_loss=0.00243]\n",
      "Epoch: 18/50: 100%|██████████| 72/72 [00:00<00:00, 127.87it/s, train_loss=0.00497, valid_loss=0.00242]\n",
      "Epoch: 19/50: 100%|██████████| 72/72 [00:00<00:00, 127.83it/s, train_loss=0.00464, valid_loss=0.00241]\n",
      "Epoch: 20/50: 100%|██████████| 72/72 [00:00<00:00, 132.67it/s, train_loss=0.00495, valid_loss=0.00242]\n",
      "Epoch: 21/50: 100%|██████████| 72/72 [00:00<00:00, 135.95it/s, train_loss=0.00406, valid_loss=0.00232]\n",
      "Epoch: 22/50: 100%|██████████| 72/72 [00:00<00:00, 123.17it/s, train_loss=0.0048, valid_loss=0.00235] \n",
      "Epoch: 23/50: 100%|██████████| 72/72 [00:00<00:00, 135.01it/s, train_loss=0.00495, valid_loss=0.00232]\n",
      "Epoch: 24/50: 100%|██████████| 72/72 [00:00<00:00, 146.74it/s, train_loss=0.00485, valid_loss=0.00232]\n",
      "Epoch: 25/50: 100%|██████████| 72/72 [00:00<00:00, 120.02it/s, train_loss=0.00472, valid_loss=0.00225]\n",
      "Epoch: 26/50: 100%|██████████| 72/72 [00:00<00:00, 136.25it/s, train_loss=0.00412, valid_loss=0.00224]\n",
      "Epoch: 27/50: 100%|██████████| 72/72 [00:00<00:00, 121.67it/s, train_loss=0.00434, valid_loss=0.00226]\n",
      "Epoch: 28/50: 100%|██████████| 72/72 [00:00<00:00, 129.51it/s, train_loss=0.00436, valid_loss=0.00228]\n",
      "Epoch: 29/50: 100%|██████████| 72/72 [00:00<00:00, 141.11it/s, train_loss=0.00405, valid_loss=0.00227]\n",
      "Epoch: 30/50: 100%|██████████| 72/72 [00:00<00:00, 130.36it/s, train_loss=0.00399, valid_loss=0.0023] \n",
      "Epoch: 31/50: 100%|██████████| 72/72 [00:00<00:00, 129.34it/s, train_loss=0.00392, valid_loss=0.00225]\n",
      "Epoch: 32/50: 100%|██████████| 72/72 [00:00<00:00, 137.79it/s, train_loss=0.00452, valid_loss=0.00228]\n",
      "Epoch: 33/50: 100%|██████████| 72/72 [00:00<00:00, 119.73it/s, train_loss=0.00438, valid_loss=0.00223]\n",
      "Epoch: 34/50: 100%|██████████| 72/72 [00:00<00:00, 136.67it/s, train_loss=0.00482, valid_loss=0.00222]\n",
      "Epoch: 35/50: 100%|██████████| 72/72 [00:00<00:00, 128.67it/s, train_loss=0.00384, valid_loss=0.00219]\n",
      "Epoch: 36/50: 100%|██████████| 72/72 [00:00<00:00, 128.68it/s, train_loss=0.00457, valid_loss=0.00223]\n",
      "Epoch: 37/50: 100%|██████████| 72/72 [00:00<00:00, 133.73it/s, train_loss=0.00398, valid_loss=0.00216]\n",
      "Epoch: 38/50: 100%|██████████| 72/72 [00:00<00:00, 128.58it/s, train_loss=0.00413, valid_loss=0.00217]\n",
      "Epoch: 39/50: 100%|██████████| 72/72 [00:00<00:00, 148.82it/s, train_loss=0.0043, valid_loss=0.0022]  \n",
      "Epoch: 40/50: 100%|██████████| 72/72 [00:00<00:00, 128.04it/s, train_loss=0.00388, valid_loss=0.00218]\n",
      "Epoch: 41/50: 100%|██████████| 72/72 [00:00<00:00, 127.73it/s, train_loss=0.00392, valid_loss=0.00216]\n",
      "Epoch: 42/50: 100%|██████████| 72/72 [00:00<00:00, 132.90it/s, train_loss=0.00382, valid_loss=0.00219]\n",
      "Epoch: 43/50: 100%|██████████| 72/72 [00:00<00:00, 127.08it/s, train_loss=0.00399, valid_loss=0.00219]\n",
      "Epoch: 44/50: 100%|██████████| 72/72 [00:00<00:00, 130.53it/s, train_loss=0.00396, valid_loss=0.00217]\n",
      "Epoch: 45/50: 100%|██████████| 72/72 [00:00<00:00, 142.03it/s, train_loss=0.00426, valid_loss=0.00218]\n",
      "Epoch: 46/50: 100%|██████████| 72/72 [00:00<00:00, 125.84it/s, train_loss=0.00408, valid_loss=0.00212]\n",
      "Epoch: 47/50: 100%|██████████| 72/72 [00:00<00:00, 136.70it/s, train_loss=0.00474, valid_loss=0.00217]\n",
      "Epoch: 48/50: 100%|██████████| 72/72 [00:00<00:00, 131.92it/s, train_loss=0.00427, valid_loss=0.00216]\n",
      "Epoch: 49/50: 100%|██████████| 72/72 [00:00<00:00, 138.89it/s, train_loss=0.00415, valid_loss=0.00217]\n",
      "Epoch: 50/50: 100%|██████████| 72/72 [00:00<00:00, 135.74it/s, train_loss=0.0039, valid_loss=0.00218] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config: batch_size--256, lr--0.001, number_epoch--50, hidden_dim--35,drop_prob-0.1,weight_decay-1e-07\n",
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 15/15 [00:00<00:00, 94.17it/s, train_loss=0.0619, valid_loss=0.0989]\n",
      "Epoch: 2/50: 100%|██████████| 15/15 [00:00<00:00, 144.59it/s, train_loss=0.0384, valid_loss=0.0588]\n",
      "Epoch: 3/50: 100%|██████████| 15/15 [00:00<00:00, 107.62it/s, train_loss=0.0242, valid_loss=0.0365]\n",
      "Epoch: 4/50: 100%|██████████| 15/15 [00:00<00:00, 153.47it/s, train_loss=0.0177, valid_loss=0.0284]\n",
      "Epoch: 5/50: 100%|██████████| 15/15 [00:00<00:00, 119.54it/s, train_loss=0.0165, valid_loss=0.028]\n",
      "Epoch: 6/50: 100%|██████████| 15/15 [00:00<00:00, 123.77it/s, train_loss=0.0118, valid_loss=0.0219]\n",
      "Epoch: 7/50: 100%|██████████| 15/15 [00:00<00:00, 154.55it/s, train_loss=0.0109, valid_loss=0.0209]\n",
      "Epoch: 8/50: 100%|██████████| 15/15 [00:00<00:00, 137.23it/s, train_loss=0.0106, valid_loss=0.0197]\n",
      "Epoch: 9/50: 100%|██████████| 15/15 [00:00<00:00, 128.47it/s, train_loss=0.01, valid_loss=0.0183]\n",
      "Epoch: 10/50: 100%|██████████| 15/15 [00:00<00:00, 153.33it/s, train_loss=0.00905, valid_loss=0.0168]\n",
      "Epoch: 11/50: 100%|██████████| 15/15 [00:00<00:00, 115.72it/s, train_loss=0.00837, valid_loss=0.0147]\n",
      "Epoch: 12/50: 100%|██████████| 15/15 [00:00<00:00, 129.17it/s, train_loss=0.00773, valid_loss=0.0132]\n",
      "Epoch: 13/50: 100%|██████████| 15/15 [00:00<00:00, 153.46it/s, train_loss=0.007, valid_loss=0.0114]\n",
      "Epoch: 14/50: 100%|██████████| 15/15 [00:00<00:00, 152.88it/s, train_loss=0.00676, valid_loss=0.00973]\n",
      "Epoch: 15/50: 100%|██████████| 15/15 [00:00<00:00, 154.38it/s, train_loss=0.00607, valid_loss=0.00875]\n",
      "Epoch: 16/50: 100%|██████████| 15/15 [00:00<00:00, 100.60it/s, train_loss=0.00586, valid_loss=0.00809]\n",
      "Epoch: 17/50: 100%|██████████| 15/15 [00:00<00:00, 146.66it/s, train_loss=0.00574, valid_loss=0.00753]\n",
      "Epoch: 18/50: 100%|██████████| 15/15 [00:00<00:00, 136.63it/s, train_loss=0.00555, valid_loss=0.007]\n",
      "Epoch: 19/50: 100%|██████████| 15/15 [00:00<00:00, 154.60it/s, train_loss=0.00563, valid_loss=0.00693]\n",
      "Epoch: 20/50: 100%|██████████| 15/15 [00:00<00:00, 156.91it/s, train_loss=0.00534, valid_loss=0.00701]\n",
      "Epoch: 21/50: 100%|██████████| 15/15 [00:00<00:00, 154.56it/s, train_loss=0.00534, valid_loss=0.00643]\n",
      "Epoch: 22/50: 100%|██████████| 15/15 [00:00<00:00, 113.84it/s, train_loss=0.00495, valid_loss=0.00636]\n",
      "Epoch: 23/50: 100%|██████████| 15/15 [00:00<00:00, 155.19it/s, train_loss=0.00512, valid_loss=0.00632]\n",
      "Epoch: 24/50: 100%|██████████| 15/15 [00:00<00:00, 128.57it/s, train_loss=0.00468, valid_loss=0.0061]\n",
      "Epoch: 25/50: 100%|██████████| 15/15 [00:00<00:00, 154.25it/s, train_loss=0.00442, valid_loss=0.00602]\n",
      "Epoch: 26/50: 100%|██████████| 15/15 [00:00<00:00, 154.57it/s, train_loss=0.00481, valid_loss=0.00582]\n",
      "Epoch: 27/50: 100%|██████████| 15/15 [00:00<00:00, 114.54it/s, train_loss=0.00477, valid_loss=0.00567]\n",
      "Epoch: 28/50: 100%|██████████| 15/15 [00:00<00:00, 128.94it/s, train_loss=0.00437, valid_loss=0.00578]\n",
      "Epoch: 29/50: 100%|██████████| 15/15 [00:00<00:00, 98.33it/s, train_loss=0.00408, valid_loss=0.00539]\n",
      "Epoch: 30/50: 100%|██████████| 15/15 [00:00<00:00, 121.23it/s, train_loss=0.00405, valid_loss=0.00557]\n",
      "Epoch: 31/50: 100%|██████████| 15/15 [00:00<00:00, 154.30it/s, train_loss=0.00424, valid_loss=0.00518]\n",
      "Epoch: 32/50: 100%|██████████| 15/15 [00:00<00:00, 133.15it/s, train_loss=0.00398, valid_loss=0.00522]\n",
      "Epoch: 33/50: 100%|██████████| 15/15 [00:00<00:00, 127.71it/s, train_loss=0.00454, valid_loss=0.00522]\n",
      "Epoch: 34/50: 100%|██████████| 15/15 [00:00<00:00, 127.19it/s, train_loss=0.00413, valid_loss=0.00507]\n",
      "Epoch: 35/50: 100%|██████████| 15/15 [00:00<00:00, 127.24it/s, train_loss=0.00397, valid_loss=0.00506]\n",
      "Epoch: 36/50: 100%|██████████| 15/15 [00:00<00:00, 139.54it/s, train_loss=0.0042, valid_loss=0.0049]\n",
      "Epoch: 37/50: 100%|██████████| 15/15 [00:00<00:00, 154.93it/s, train_loss=0.0038, valid_loss=0.00482]\n",
      "Epoch: 38/50: 100%|██████████| 15/15 [00:00<00:00, 154.96it/s, train_loss=0.00397, valid_loss=0.0049]\n",
      "Epoch: 39/50: 100%|██████████| 15/15 [00:00<00:00, 155.73it/s, train_loss=0.00387, valid_loss=0.00492]\n",
      "Epoch: 40/50: 100%|██████████| 15/15 [00:00<00:00, 132.72it/s, train_loss=0.00368, valid_loss=0.00482]\n",
      "Epoch: 41/50: 100%|██████████| 15/15 [00:00<00:00, 138.83it/s, train_loss=0.00354, valid_loss=0.0049]\n",
      "Epoch: 42/50: 100%|██████████| 15/15 [00:00<00:00, 99.79it/s, train_loss=0.00382, valid_loss=0.00486] \n",
      "Epoch: 43/50: 100%|██████████| 15/15 [00:00<00:00, 130.64it/s, train_loss=0.00369, valid_loss=0.00472]\n",
      "Epoch: 44/50: 100%|██████████| 15/15 [00:00<00:00, 114.35it/s, train_loss=0.00385, valid_loss=0.00481]\n",
      "Epoch: 45/50: 100%|██████████| 15/15 [00:00<00:00, 128.96it/s, train_loss=0.00327, valid_loss=0.00476]\n",
      "Epoch: 46/50: 100%|██████████| 15/15 [00:00<00:00, 152.37it/s, train_loss=0.00343, valid_loss=0.00479]\n",
      "Epoch: 47/50: 100%|██████████| 15/15 [00:00<00:00, 155.15it/s, train_loss=0.00371, valid_loss=0.00466]\n",
      "Epoch: 48/50: 100%|██████████| 15/15 [00:00<00:00, 152.62it/s, train_loss=0.00364, valid_loss=0.00485]\n",
      "Epoch: 49/50: 100%|██████████| 15/15 [00:00<00:00, 115.58it/s, train_loss=0.0036, valid_loss=0.00477]\n",
      "Epoch: 50/50: 100%|██████████| 15/15 [00:00<00:00, 127.29it/s, train_loss=0.00331, valid_loss=0.00465]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 29/29 [00:00<00:00, 113.51it/s, train_loss=0.0522, valid_loss=0.0626]\n",
      "Epoch: 2/50: 100%|██████████| 29/29 [00:00<00:00, 130.80it/s, train_loss=0.0214, valid_loss=0.0109]\n",
      "Epoch: 3/50: 100%|██████████| 29/29 [00:00<00:00, 121.74it/s, train_loss=0.016, valid_loss=0.00951] \n",
      "Epoch: 4/50: 100%|██████████| 29/29 [00:00<00:00, 125.56it/s, train_loss=0.0135, valid_loss=0.00745]\n",
      "Epoch: 5/50: 100%|██████████| 29/29 [00:00<00:00, 121.62it/s, train_loss=0.01, valid_loss=0.0072]  \n",
      "Epoch: 6/50: 100%|██████████| 29/29 [00:00<00:00, 133.67it/s, train_loss=0.00848, valid_loss=0.00543]\n",
      "Epoch: 7/50: 100%|██████████| 29/29 [00:00<00:00, 135.23it/s, train_loss=0.00796, valid_loss=0.00514]\n",
      "Epoch: 8/50: 100%|██████████| 29/29 [00:00<00:00, 126.25it/s, train_loss=0.00749, valid_loss=0.00505]\n",
      "Epoch: 9/50: 100%|██████████| 29/29 [00:00<00:00, 139.45it/s, train_loss=0.00735, valid_loss=0.00428]\n",
      "Epoch: 10/50: 100%|██████████| 29/29 [00:00<00:00, 115.98it/s, train_loss=0.00603, valid_loss=0.00413]\n",
      "Epoch: 11/50: 100%|██████████| 29/29 [00:00<00:00, 115.32it/s, train_loss=0.00699, valid_loss=0.00387]\n",
      "Epoch: 12/50: 100%|██████████| 29/29 [00:00<00:00, 145.21it/s, train_loss=0.0061, valid_loss=0.00348] \n",
      "Epoch: 13/50: 100%|██████████| 29/29 [00:00<00:00, 134.14it/s, train_loss=0.00582, valid_loss=0.0033] \n",
      "Epoch: 14/50: 100%|██████████| 29/29 [00:00<00:00, 138.30it/s, train_loss=0.00609, valid_loss=0.00393]\n",
      "Epoch: 15/50: 100%|██████████| 29/29 [00:00<00:00, 128.84it/s, train_loss=0.00556, valid_loss=0.00382]\n",
      "Epoch: 16/50: 100%|██████████| 29/29 [00:00<00:00, 120.13it/s, train_loss=0.00486, valid_loss=0.00303]\n",
      "Epoch: 17/50: 100%|██████████| 29/29 [00:00<00:00, 122.38it/s, train_loss=0.00525, valid_loss=0.00227]\n",
      "Epoch: 18/50: 100%|██████████| 29/29 [00:00<00:00, 139.48it/s, train_loss=0.00526, valid_loss=0.00213]\n",
      "Epoch: 19/50: 100%|██████████| 29/29 [00:00<00:00, 138.66it/s, train_loss=0.00473, valid_loss=0.00271]\n",
      "Epoch: 20/50: 100%|██████████| 29/29 [00:00<00:00, 144.86it/s, train_loss=0.00521, valid_loss=0.00299]\n",
      "Epoch: 21/50: 100%|██████████| 29/29 [00:00<00:00, 125.50it/s, train_loss=0.0047, valid_loss=0.00327] \n",
      "Epoch: 22/50: 100%|██████████| 29/29 [00:00<00:00, 145.75it/s, train_loss=0.00457, valid_loss=0.00229]\n",
      "Epoch: 23/50: 100%|██████████| 29/29 [00:00<00:00, 106.83it/s, train_loss=0.00465, valid_loss=0.00247]\n",
      "Epoch: 24/50: 100%|██████████| 29/29 [00:00<00:00, 139.13it/s, train_loss=0.00543, valid_loss=0.00193]\n",
      "Epoch: 25/50: 100%|██████████| 29/29 [00:00<00:00, 138.85it/s, train_loss=0.00416, valid_loss=0.00279]\n",
      "Epoch: 26/50: 100%|██████████| 29/29 [00:00<00:00, 124.87it/s, train_loss=0.0045, valid_loss=0.00218]\n",
      "Epoch: 27/50: 100%|██████████| 29/29 [00:00<00:00, 136.57it/s, train_loss=0.00491, valid_loss=0.00256]\n",
      "Epoch: 28/50: 100%|██████████| 29/29 [00:00<00:00, 126.71it/s, train_loss=0.0046, valid_loss=0.00206] \n",
      "Epoch: 29/50: 100%|██████████| 29/29 [00:00<00:00, 112.87it/s, train_loss=0.0047, valid_loss=0.00207] \n",
      "Epoch: 30/50: 100%|██████████| 29/29 [00:00<00:00, 130.53it/s, train_loss=0.00463, valid_loss=0.00183]\n",
      "Epoch: 31/50: 100%|██████████| 29/29 [00:00<00:00, 138.63it/s, train_loss=0.0048, valid_loss=0.00223] \n",
      "Epoch: 32/50: 100%|██████████| 29/29 [00:00<00:00, 146.93it/s, train_loss=0.0047, valid_loss=0.00239] \n",
      "Epoch: 33/50: 100%|██████████| 29/29 [00:00<00:00, 130.92it/s, train_loss=0.00414, valid_loss=0.00205]\n",
      "Epoch: 34/50: 100%|██████████| 29/29 [00:00<00:00, 141.84it/s, train_loss=0.00436, valid_loss=0.0023] \n",
      "Epoch: 35/50: 100%|██████████| 29/29 [00:00<00:00, 140.12it/s, train_loss=0.00431, valid_loss=0.0018] \n",
      "Epoch: 36/50: 100%|██████████| 29/29 [00:00<00:00, 121.37it/s, train_loss=0.00436, valid_loss=0.00167]\n",
      "Epoch: 37/50: 100%|██████████| 29/29 [00:00<00:00, 141.77it/s, train_loss=0.00452, valid_loss=0.00208]\n",
      "Epoch: 38/50: 100%|██████████| 29/29 [00:00<00:00, 135.15it/s, train_loss=0.00422, valid_loss=0.00227]\n",
      "Epoch: 39/50: 100%|██████████| 29/29 [00:00<00:00, 139.70it/s, train_loss=0.00384, valid_loss=0.00228]\n",
      "Epoch: 40/50: 100%|██████████| 29/29 [00:00<00:00, 145.20it/s, train_loss=0.00393, valid_loss=0.0018] \n",
      "Epoch: 41/50: 100%|██████████| 29/29 [00:00<00:00, 120.83it/s, train_loss=0.0044, valid_loss=0.00223]\n",
      "Epoch: 42/50: 100%|██████████| 29/29 [00:00<00:00, 138.48it/s, train_loss=0.00466, valid_loss=0.00185]\n",
      "Epoch: 43/50: 100%|██████████| 29/29 [00:00<00:00, 107.67it/s, train_loss=0.00437, valid_loss=0.00238]\n",
      "Epoch: 44/50: 100%|██████████| 29/29 [00:00<00:00, 140.94it/s, train_loss=0.00364, valid_loss=0.00173]\n",
      "Epoch: 45/50: 100%|██████████| 29/29 [00:00<00:00, 151.07it/s, train_loss=0.00479, valid_loss=0.002]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 44/44 [00:00<00:00, 118.87it/s, train_loss=0.0355, valid_loss=0.041] \n",
      "Epoch: 2/50: 100%|██████████| 44/44 [00:00<00:00, 112.66it/s, train_loss=0.0234, valid_loss=0.0277]\n",
      "Epoch: 3/50: 100%|██████████| 44/44 [00:00<00:00, 115.82it/s, train_loss=0.0153, valid_loss=0.0183]\n",
      "Epoch: 4/50: 100%|██████████| 44/44 [00:00<00:00, 141.47it/s, train_loss=0.0108, valid_loss=0.0117]\n",
      "Epoch: 5/50: 100%|██████████| 44/44 [00:00<00:00, 144.38it/s, train_loss=0.00812, valid_loss=0.0067] \n",
      "Epoch: 6/50: 100%|██████████| 44/44 [00:00<00:00, 144.14it/s, train_loss=0.00848, valid_loss=0.00572]\n",
      "Epoch: 7/50: 100%|██████████| 44/44 [00:00<00:00, 120.96it/s, train_loss=0.00726, valid_loss=0.00534]\n",
      "Epoch: 8/50: 100%|██████████| 44/44 [00:00<00:00, 137.24it/s, train_loss=0.00701, valid_loss=0.00501]\n",
      "Epoch: 9/50: 100%|██████████| 44/44 [00:00<00:00, 119.18it/s, train_loss=0.00632, valid_loss=0.00472]\n",
      "Epoch: 10/50: 100%|██████████| 44/44 [00:00<00:00, 131.31it/s, train_loss=0.00679, valid_loss=0.00449]\n",
      "Epoch: 11/50: 100%|██████████| 44/44 [00:00<00:00, 139.58it/s, train_loss=0.00628, valid_loss=0.00457]\n",
      "Epoch: 12/50: 100%|██████████| 44/44 [00:00<00:00, 135.30it/s, train_loss=0.00579, valid_loss=0.00411]\n",
      "Epoch: 13/50: 100%|██████████| 44/44 [00:00<00:00, 137.10it/s, train_loss=0.00542, valid_loss=0.00403]\n",
      "Epoch: 14/50: 100%|██████████| 44/44 [00:00<00:00, 146.44it/s, train_loss=0.00519, valid_loss=0.00387]\n",
      "Epoch: 15/50: 100%|██████████| 44/44 [00:00<00:00, 138.38it/s, train_loss=0.00516, valid_loss=0.00386]\n",
      "Epoch: 16/50: 100%|██████████| 44/44 [00:00<00:00, 124.88it/s, train_loss=0.00502, valid_loss=0.00375]\n",
      "Epoch: 17/50: 100%|██████████| 44/44 [00:00<00:00, 132.03it/s, train_loss=0.00499, valid_loss=0.00375]\n",
      "Epoch: 18/50: 100%|██████████| 44/44 [00:00<00:00, 142.86it/s, train_loss=0.00553, valid_loss=0.00376]\n",
      "Epoch: 19/50: 100%|██████████| 44/44 [00:00<00:00, 128.70it/s, train_loss=0.00413, valid_loss=0.00385]\n",
      "Epoch: 20/50: 100%|██████████| 44/44 [00:00<00:00, 132.87it/s, train_loss=0.00461, valid_loss=0.0036] \n",
      "Epoch: 21/50: 100%|██████████| 44/44 [00:00<00:00, 120.08it/s, train_loss=0.00475, valid_loss=0.00377]\n",
      "Epoch: 22/50: 100%|██████████| 44/44 [00:00<00:00, 145.19it/s, train_loss=0.00486, valid_loss=0.00359]\n",
      "Epoch: 23/50: 100%|██████████| 44/44 [00:00<00:00, 144.54it/s, train_loss=0.00465, valid_loss=0.00354]\n",
      "Epoch: 24/50: 100%|██████████| 44/44 [00:00<00:00, 145.55it/s, train_loss=0.00423, valid_loss=0.0036] \n",
      "Epoch: 25/50: 100%|██████████| 44/44 [00:00<00:00, 132.11it/s, train_loss=0.00435, valid_loss=0.00359]\n",
      "Epoch: 26/50: 100%|██████████| 44/44 [00:00<00:00, 140.40it/s, train_loss=0.00417, valid_loss=0.00353]\n",
      "Epoch: 27/50: 100%|██████████| 44/44 [00:00<00:00, 141.89it/s, train_loss=0.00467, valid_loss=0.00368]\n",
      "Epoch: 28/50: 100%|██████████| 44/44 [00:00<00:00, 152.38it/s, train_loss=0.00395, valid_loss=0.00355]\n",
      "Epoch: 29/50: 100%|██████████| 44/44 [00:00<00:00, 117.90it/s, train_loss=0.0047, valid_loss=0.00358] \n",
      "Epoch: 30/50: 100%|██████████| 44/44 [00:00<00:00, 135.14it/s, train_loss=0.00496, valid_loss=0.00356]\n",
      "Epoch: 31/50: 100%|██████████| 44/44 [00:00<00:00, 144.61it/s, train_loss=0.00485, valid_loss=0.00349]\n",
      "Epoch: 32/50: 100%|██████████| 44/44 [00:00<00:00, 132.44it/s, train_loss=0.00513, valid_loss=0.00341]\n",
      "Epoch: 33/50: 100%|██████████| 44/44 [00:00<00:00, 138.39it/s, train_loss=0.0056, valid_loss=0.00341] \n",
      "Epoch: 34/50: 100%|██████████| 44/44 [00:00<00:00, 129.63it/s, train_loss=0.00361, valid_loss=0.00344]\n",
      "Epoch: 35/50: 100%|██████████| 44/44 [00:00<00:00, 127.56it/s, train_loss=0.00419, valid_loss=0.00341]\n",
      "Epoch: 36/50: 100%|██████████| 44/44 [00:00<00:00, 128.91it/s, train_loss=0.00422, valid_loss=0.00351]\n",
      "Epoch: 37/50: 100%|██████████| 44/44 [00:00<00:00, 142.44it/s, train_loss=0.00434, valid_loss=0.00349]\n",
      "Epoch: 38/50: 100%|██████████| 44/44 [00:00<00:00, 124.82it/s, train_loss=0.00419, valid_loss=0.00334]\n",
      "Epoch: 39/50: 100%|██████████| 44/44 [00:00<00:00, 153.41it/s, train_loss=0.00437, valid_loss=0.00343]\n",
      "Epoch: 40/50: 100%|██████████| 44/44 [00:00<00:00, 131.53it/s, train_loss=0.00403, valid_loss=0.00338]\n",
      "Epoch: 41/50: 100%|██████████| 44/44 [00:00<00:00, 141.28it/s, train_loss=0.00399, valid_loss=0.00345]\n",
      "Epoch: 42/50: 100%|██████████| 44/44 [00:00<00:00, 138.01it/s, train_loss=0.00396, valid_loss=0.00333]\n",
      "Epoch: 43/50: 100%|██████████| 44/44 [00:00<00:00, 121.59it/s, train_loss=0.00418, valid_loss=0.00339]\n",
      "Epoch: 44/50: 100%|██████████| 44/44 [00:00<00:00, 132.85it/s, train_loss=0.00442, valid_loss=0.00357]\n",
      "Epoch: 45/50: 100%|██████████| 44/44 [00:00<00:00, 133.90it/s, train_loss=0.00407, valid_loss=0.0034] \n",
      "Epoch: 46/50: 100%|██████████| 44/44 [00:00<00:00, 145.95it/s, train_loss=0.00394, valid_loss=0.00327]\n",
      "Epoch: 47/50: 100%|██████████| 44/44 [00:00<00:00, 124.22it/s, train_loss=0.00476, valid_loss=0.00333]\n",
      "Epoch: 48/50: 100%|██████████| 44/44 [00:00<00:00, 126.02it/s, train_loss=0.00434, valid_loss=0.00346]\n",
      "Epoch: 49/50: 100%|██████████| 44/44 [00:00<00:00, 152.86it/s, train_loss=0.00356, valid_loss=0.00358]\n",
      "Epoch: 50/50: 100%|██████████| 44/44 [00:00<00:00, 131.46it/s, train_loss=0.00431, valid_loss=0.00351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 58/58 [00:00<00:00, 119.35it/s, train_loss=0.0351, valid_loss=0.0312]\n",
      "Epoch: 2/50: 100%|██████████| 58/58 [00:00<00:00, 148.49it/s, train_loss=0.0239, valid_loss=0.019] \n",
      "Epoch: 3/50: 100%|██████████| 58/58 [00:00<00:00, 127.89it/s, train_loss=0.0161, valid_loss=0.0127]\n",
      "Epoch: 4/50: 100%|██████████| 58/58 [00:00<00:00, 126.57it/s, train_loss=0.00914, valid_loss=0.005]  \n",
      "Epoch: 5/50: 100%|██████████| 58/58 [00:00<00:00, 130.06it/s, train_loss=0.00787, valid_loss=0.00452]\n",
      "Epoch: 6/50: 100%|██████████| 58/58 [00:00<00:00, 131.18it/s, train_loss=0.0072, valid_loss=0.00379] \n",
      "Epoch: 7/50: 100%|██████████| 58/58 [00:00<00:00, 123.82it/s, train_loss=0.00669, valid_loss=0.00326]\n",
      "Epoch: 8/50: 100%|██████████| 58/58 [00:00<00:00, 134.01it/s, train_loss=0.00599, valid_loss=0.00285]\n",
      "Epoch: 9/50: 100%|██████████| 58/58 [00:00<00:00, 127.48it/s, train_loss=0.00645, valid_loss=0.00258]\n",
      "Epoch: 10/50: 100%|██████████| 58/58 [00:00<00:00, 138.73it/s, train_loss=0.00568, valid_loss=0.0024] \n",
      "Epoch: 11/50: 100%|██████████| 58/58 [00:00<00:00, 135.06it/s, train_loss=0.00504, valid_loss=0.00248]\n",
      "Epoch: 12/50: 100%|██████████| 58/58 [00:00<00:00, 146.10it/s, train_loss=0.00576, valid_loss=0.00312]\n",
      "Epoch: 13/50: 100%|██████████| 58/58 [00:00<00:00, 145.31it/s, train_loss=0.00508, valid_loss=0.00232]\n",
      "Epoch: 14/50: 100%|██████████| 58/58 [00:00<00:00, 133.46it/s, train_loss=0.00512, valid_loss=0.00213]\n",
      "Epoch: 15/50: 100%|██████████| 58/58 [00:00<00:00, 124.08it/s, train_loss=0.00485, valid_loss=0.00256]\n",
      "Epoch: 16/50: 100%|██████████| 58/58 [00:00<00:00, 135.87it/s, train_loss=0.00465, valid_loss=0.00209]\n",
      "Epoch: 17/50: 100%|██████████| 58/58 [00:00<00:00, 129.11it/s, train_loss=0.00503, valid_loss=0.00263]\n",
      "Epoch: 18/50: 100%|██████████| 58/58 [00:00<00:00, 131.30it/s, train_loss=0.00409, valid_loss=0.00212]\n",
      "Epoch: 19/50: 100%|██████████| 58/58 [00:00<00:00, 150.88it/s, train_loss=0.00507, valid_loss=0.00269]\n",
      "Epoch: 20/50: 100%|██████████| 58/58 [00:00<00:00, 145.78it/s, train_loss=0.0052, valid_loss=0.00235] \n",
      "Epoch: 21/50: 100%|██████████| 58/58 [00:00<00:00, 125.30it/s, train_loss=0.0041, valid_loss=0.00282] \n",
      "Epoch: 22/50: 100%|██████████| 58/58 [00:00<00:00, 131.68it/s, train_loss=0.00399, valid_loss=0.00218]\n",
      "Epoch: 23/50: 100%|██████████| 58/58 [00:00<00:00, 130.56it/s, train_loss=0.00479, valid_loss=0.00233]\n",
      "Epoch: 24/50: 100%|██████████| 58/58 [00:00<00:00, 128.52it/s, train_loss=0.00429, valid_loss=0.00294]\n",
      "Epoch: 25/50: 100%|██████████| 58/58 [00:00<00:00, 127.74it/s, train_loss=0.00432, valid_loss=0.0028] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 72/72 [00:00<00:00, 131.60it/s, train_loss=0.033, valid_loss=0.0258] \n",
      "Epoch: 2/50: 100%|██████████| 72/72 [00:00<00:00, 125.19it/s, train_loss=0.0138, valid_loss=0.0117]\n",
      "Epoch: 3/50: 100%|██████████| 72/72 [00:00<00:00, 132.38it/s, train_loss=0.00916, valid_loss=0.00556]\n",
      "Epoch: 4/50: 100%|██████████| 72/72 [00:00<00:00, 137.84it/s, train_loss=0.00786, valid_loss=0.00423]\n",
      "Epoch: 5/50: 100%|██████████| 72/72 [00:00<00:00, 139.01it/s, train_loss=0.0068, valid_loss=0.00353] \n",
      "Epoch: 6/50: 100%|██████████| 72/72 [00:00<00:00, 130.80it/s, train_loss=0.00605, valid_loss=0.00308]\n",
      "Epoch: 7/50: 100%|██████████| 72/72 [00:00<00:00, 126.45it/s, train_loss=0.00661, valid_loss=0.00282]\n",
      "Epoch: 8/50: 100%|██████████| 72/72 [00:00<00:00, 137.62it/s, train_loss=0.00579, valid_loss=0.00269]\n",
      "Epoch: 9/50: 100%|██████████| 72/72 [00:00<00:00, 145.45it/s, train_loss=0.00467, valid_loss=0.00257]\n",
      "Epoch: 10/50: 100%|██████████| 72/72 [00:00<00:00, 130.22it/s, train_loss=0.00492, valid_loss=0.0025] \n",
      "Epoch: 11/50: 100%|██████████| 72/72 [00:00<00:00, 140.45it/s, train_loss=0.00557, valid_loss=0.00247]\n",
      "Epoch: 12/50: 100%|██████████| 72/72 [00:00<00:00, 140.13it/s, train_loss=0.00456, valid_loss=0.00235]\n",
      "Epoch: 13/50: 100%|██████████| 72/72 [00:00<00:00, 122.15it/s, train_loss=0.00467, valid_loss=0.00245]\n",
      "Epoch: 14/50: 100%|██████████| 72/72 [00:00<00:00, 141.20it/s, train_loss=0.00477, valid_loss=0.00227]\n",
      "Epoch: 15/50: 100%|██████████| 72/72 [00:00<00:00, 131.62it/s, train_loss=0.00468, valid_loss=0.00233]\n",
      "Epoch: 16/50: 100%|██████████| 72/72 [00:00<00:00, 144.49it/s, train_loss=0.00382, valid_loss=0.00223]\n",
      "Epoch: 17/50: 100%|██████████| 72/72 [00:00<00:00, 141.52it/s, train_loss=0.00407, valid_loss=0.00229]\n",
      "Epoch: 18/50: 100%|██████████| 72/72 [00:00<00:00, 138.47it/s, train_loss=0.00407, valid_loss=0.00219]\n",
      "Epoch: 19/50: 100%|██████████| 72/72 [00:00<00:00, 137.15it/s, train_loss=0.00447, valid_loss=0.00243]\n",
      "Epoch: 20/50: 100%|██████████| 72/72 [00:00<00:00, 123.13it/s, train_loss=0.00393, valid_loss=0.00224]\n",
      "Epoch: 21/50: 100%|██████████| 72/72 [00:00<00:00, 125.58it/s, train_loss=0.00395, valid_loss=0.00221]\n",
      "Epoch: 22/50: 100%|██████████| 72/72 [00:00<00:00, 143.94it/s, train_loss=0.00435, valid_loss=0.00214]\n",
      "Epoch: 23/50: 100%|██████████| 72/72 [00:00<00:00, 127.47it/s, train_loss=0.00374, valid_loss=0.00224]\n",
      "Epoch: 24/50: 100%|██████████| 72/72 [00:00<00:00, 132.16it/s, train_loss=0.00346, valid_loss=0.00222]\n",
      "Epoch: 25/50: 100%|██████████| 72/72 [00:00<00:00, 140.22it/s, train_loss=0.0037, valid_loss=0.00229] \n",
      "Epoch: 26/50: 100%|██████████| 72/72 [00:00<00:00, 131.29it/s, train_loss=0.00344, valid_loss=0.00221]\n",
      "Epoch: 27/50: 100%|██████████| 72/72 [00:00<00:00, 136.62it/s, train_loss=0.00344, valid_loss=0.00219]\n",
      "Epoch: 28/50: 100%|██████████| 72/72 [00:00<00:00, 132.02it/s, train_loss=0.00417, valid_loss=0.00214]\n",
      "Epoch: 29/50: 100%|██████████| 72/72 [00:00<00:00, 121.44it/s, train_loss=0.00356, valid_loss=0.00238]\n",
      "Epoch: 30/50: 100%|██████████| 72/72 [00:00<00:00, 130.22it/s, train_loss=0.00405, valid_loss=0.00215]\n",
      "Epoch: 31/50: 100%|██████████| 72/72 [00:00<00:00, 135.17it/s, train_loss=0.00356, valid_loss=0.00228]\n",
      "Epoch: 32/50: 100%|██████████| 72/72 [00:00<00:00, 140.17it/s, train_loss=0.00375, valid_loss=0.0023] \n",
      "Epoch: 33/50: 100%|██████████| 72/72 [00:00<00:00, 139.04it/s, train_loss=0.00375, valid_loss=0.00222]\n",
      "Epoch: 34/50: 100%|██████████| 72/72 [00:00<00:00, 134.86it/s, train_loss=0.00397, valid_loss=0.00217]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config: batch_size--128, lr--0.01, number_epoch--50, hidden_dim--25,drop_prob-0.1,weight_decay-1e-07\n",
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 29/29 [00:00<00:00, 110.23it/s, train_loss=0.0159, valid_loss=0.0299]\n",
      "Epoch: 2/50: 100%|██████████| 29/29 [00:00<00:00, 135.81it/s, train_loss=0.00869, valid_loss=0.0165]\n",
      "Epoch: 3/50: 100%|██████████| 29/29 [00:00<00:00, 131.45it/s, train_loss=0.0062, valid_loss=0.0112] \n",
      "Epoch: 4/50: 100%|██████████| 29/29 [00:00<00:00, 130.22it/s, train_loss=0.00529, valid_loss=0.00704]\n",
      "Epoch: 5/50: 100%|██████████| 29/29 [00:00<00:00, 135.75it/s, train_loss=0.00464, valid_loss=0.00614]\n",
      "Epoch: 6/50: 100%|██████████| 29/29 [00:00<00:00, 122.20it/s, train_loss=0.00476, valid_loss=0.00572]\n",
      "Epoch: 7/50: 100%|██████████| 29/29 [00:00<00:00, 133.12it/s, train_loss=0.00409, valid_loss=0.00521]\n",
      "Epoch: 8/50: 100%|██████████| 29/29 [00:00<00:00, 136.36it/s, train_loss=0.00389, valid_loss=0.00508]\n",
      "Epoch: 9/50: 100%|██████████| 29/29 [00:00<00:00, 100.30it/s, train_loss=0.00328, valid_loss=0.00569]\n",
      "Epoch: 10/50: 100%|██████████| 29/29 [00:00<00:00, 140.93it/s, train_loss=0.0033, valid_loss=0.00502] \n",
      "Epoch: 11/50: 100%|██████████| 29/29 [00:00<00:00, 114.46it/s, train_loss=0.00371, valid_loss=0.00497]\n",
      "Epoch: 12/50: 100%|██████████| 29/29 [00:00<00:00, 122.83it/s, train_loss=0.00361, valid_loss=0.00514]\n",
      "Epoch: 13/50: 100%|██████████| 29/29 [00:00<00:00, 138.24it/s, train_loss=0.00358, valid_loss=0.00542]\n",
      "Epoch: 14/50: 100%|██████████| 29/29 [00:00<00:00, 116.15it/s, train_loss=0.00344, valid_loss=0.0053] \n",
      "Epoch: 15/50: 100%|██████████| 29/29 [00:00<00:00, 131.71it/s, train_loss=0.00344, valid_loss=0.00476]\n",
      "Epoch: 16/50: 100%|██████████| 29/29 [00:00<00:00, 137.38it/s, train_loss=0.003, valid_loss=0.00484]  \n",
      "Epoch: 17/50: 100%|██████████| 29/29 [00:00<00:00, 121.35it/s, train_loss=0.0028, valid_loss=0.0049]  \n",
      "Epoch: 18/50: 100%|██████████| 29/29 [00:00<00:00, 130.50it/s, train_loss=0.00276, valid_loss=0.00488]\n",
      "Epoch: 19/50: 100%|██████████| 29/29 [00:00<00:00, 140.35it/s, train_loss=0.00278, valid_loss=0.00496]\n",
      "Epoch: 20/50: 100%|██████████| 29/29 [00:00<00:00, 127.66it/s, train_loss=0.00316, valid_loss=0.00543]\n",
      "Epoch: 21/50: 100%|██████████| 29/29 [00:00<00:00, 133.28it/s, train_loss=0.0033, valid_loss=0.00489] \n",
      "Epoch: 22/50: 100%|██████████| 29/29 [00:00<00:00, 137.65it/s, train_loss=0.00238, valid_loss=0.00547]\n",
      "Epoch: 23/50: 100%|██████████| 29/29 [00:00<00:00, 126.57it/s, train_loss=0.00278, valid_loss=0.00488]\n",
      "Epoch: 24/50: 100%|██████████| 29/29 [00:00<00:00, 134.72it/s, train_loss=0.00274, valid_loss=0.00539]\n",
      "Epoch: 25/50: 100%|██████████| 29/29 [00:00<00:00, 130.79it/s, train_loss=0.00287, valid_loss=0.00549]\n",
      "Epoch: 26/50: 100%|██████████| 29/29 [00:00<00:00, 137.88it/s, train_loss=0.00242, valid_loss=0.00543]\n",
      "Epoch: 27/50: 100%|██████████| 29/29 [00:00<00:00, 133.80it/s, train_loss=0.00313, valid_loss=0.00506]\n",
      "Epoch: 28/50: 100%|██████████| 29/29 [00:00<00:00, 116.03it/s, train_loss=0.00258, valid_loss=0.00526]\n",
      "Epoch: 29/50: 100%|██████████| 29/29 [00:00<00:00, 127.69it/s, train_loss=0.00249, valid_loss=0.00556]\n",
      "Epoch: 30/50: 100%|██████████| 29/29 [00:00<00:00, 119.53it/s, train_loss=0.00266, valid_loss=0.00489]\n",
      "Epoch: 31/50: 100%|██████████| 29/29 [00:00<00:00, 139.57it/s, train_loss=0.0033, valid_loss=0.00537] \n",
      "Epoch: 32/50: 100%|██████████| 29/29 [00:00<00:00, 136.46it/s, train_loss=0.00265, valid_loss=0.00542]\n",
      "Epoch: 33/50: 100%|██████████| 29/29 [00:00<00:00, 125.15it/s, train_loss=0.0026, valid_loss=0.00491] \n",
      "Epoch: 34/50: 100%|██████████| 29/29 [00:00<00:00, 136.58it/s, train_loss=0.00252, valid_loss=0.00503]\n",
      "Epoch: 35/50: 100%|██████████| 29/29 [00:00<00:00, 134.59it/s, train_loss=0.00252, valid_loss=0.00506]\n",
      "Epoch: 36/50: 100%|██████████| 29/29 [00:00<00:00, 130.50it/s, train_loss=0.00238, valid_loss=0.00513]\n",
      "Epoch: 37/50: 100%|██████████| 29/29 [00:00<00:00, 104.98it/s, train_loss=0.00238, valid_loss=0.00504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 58/58 [00:00<00:00, 123.97it/s, train_loss=0.00907, valid_loss=0.00573]\n",
      "Epoch: 2/50: 100%|██████████| 58/58 [00:00<00:00, 117.99it/s, train_loss=0.00775, valid_loss=0.00477]\n",
      "Epoch: 3/50: 100%|██████████| 58/58 [00:00<00:00, 127.67it/s, train_loss=0.00703, valid_loss=0.0102] \n",
      "Epoch: 4/50: 100%|██████████| 58/58 [00:00<00:00, 122.37it/s, train_loss=0.00547, valid_loss=0.0058] \n",
      "Epoch: 5/50: 100%|██████████| 58/58 [00:00<00:00, 123.77it/s, train_loss=0.00514, valid_loss=0.0027] \n",
      "Epoch: 6/50: 100%|██████████| 58/58 [00:00<00:00, 135.88it/s, train_loss=0.0057, valid_loss=0.0025]  \n",
      "Epoch: 7/50: 100%|██████████| 58/58 [00:00<00:00, 129.30it/s, train_loss=0.00466, valid_loss=0.00341]\n",
      "Epoch: 8/50: 100%|██████████| 58/58 [00:00<00:00, 137.12it/s, train_loss=0.0045, valid_loss=0.00493] \n",
      "Epoch: 9/50: 100%|██████████| 58/58 [00:00<00:00, 142.72it/s, train_loss=0.00524, valid_loss=0.00464]\n",
      "Epoch: 10/50: 100%|██████████| 58/58 [00:00<00:00, 140.22it/s, train_loss=0.00513, valid_loss=0.00607]\n",
      "Epoch: 11/50: 100%|██████████| 58/58 [00:00<00:00, 141.42it/s, train_loss=0.00501, valid_loss=0.00422]\n",
      "Epoch: 12/50: 100%|██████████| 58/58 [00:00<00:00, 135.43it/s, train_loss=0.00516, valid_loss=0.0022] \n",
      "Epoch: 13/50: 100%|██████████| 58/58 [00:00<00:00, 142.30it/s, train_loss=0.00449, valid_loss=0.00225]\n",
      "Epoch: 14/50: 100%|██████████| 58/58 [00:00<00:00, 141.36it/s, train_loss=0.00419, valid_loss=0.00326]\n",
      "Epoch: 15/50: 100%|██████████| 58/58 [00:00<00:00, 142.63it/s, train_loss=0.00319, valid_loss=0.00215]\n",
      "Epoch: 16/50: 100%|██████████| 58/58 [00:00<00:00, 142.04it/s, train_loss=0.00404, valid_loss=0.00353]\n",
      "Epoch: 17/50: 100%|██████████| 58/58 [00:00<00:00, 142.66it/s, train_loss=0.00487, valid_loss=0.00303]\n",
      "Epoch: 18/50: 100%|██████████| 58/58 [00:00<00:00, 140.99it/s, train_loss=0.00472, valid_loss=0.00418]\n",
      "Epoch: 19/50: 100%|██████████| 58/58 [00:00<00:00, 141.57it/s, train_loss=0.00426, valid_loss=0.00213]\n",
      "Epoch: 20/50: 100%|██████████| 58/58 [00:00<00:00, 135.41it/s, train_loss=0.00435, valid_loss=0.00272]\n",
      "Epoch: 21/50: 100%|██████████| 58/58 [00:00<00:00, 141.48it/s, train_loss=0.00366, valid_loss=0.00345]\n",
      "Epoch: 22/50: 100%|██████████| 58/58 [00:00<00:00, 141.36it/s, train_loss=0.00341, valid_loss=0.00277]\n",
      "Epoch: 23/50: 100%|██████████| 58/58 [00:00<00:00, 141.55it/s, train_loss=0.00386, valid_loss=0.00252]\n",
      "Epoch: 24/50: 100%|██████████| 58/58 [00:00<00:00, 140.84it/s, train_loss=0.00368, valid_loss=0.003]  \n",
      "Epoch: 25/50: 100%|██████████| 58/58 [00:00<00:00, 141.97it/s, train_loss=0.0042, valid_loss=0.0048]  \n",
      "Epoch: 26/50: 100%|██████████| 58/58 [00:00<00:00, 142.01it/s, train_loss=0.00381, valid_loss=0.00274]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 87/87 [00:00<00:00, 131.65it/s, train_loss=0.00801, valid_loss=0.00662]\n",
      "Epoch: 2/50: 100%|██████████| 87/87 [00:00<00:00, 143.02it/s, train_loss=0.00545, valid_loss=0.00594]\n",
      "Epoch: 3/50: 100%|██████████| 87/87 [00:00<00:00, 142.83it/s, train_loss=0.00472, valid_loss=0.00413]\n",
      "Epoch: 4/50: 100%|██████████| 87/87 [00:00<00:00, 138.90it/s, train_loss=0.00609, valid_loss=0.00489]\n",
      "Epoch: 5/50: 100%|██████████| 87/87 [00:00<00:00, 143.22it/s, train_loss=0.0069, valid_loss=0.00387] \n",
      "Epoch: 6/50: 100%|██████████| 87/87 [00:00<00:00, 143.34it/s, train_loss=0.00418, valid_loss=0.0037] \n",
      "Epoch: 7/50: 100%|██████████| 87/87 [00:00<00:00, 138.92it/s, train_loss=0.00534, valid_loss=0.00439]\n",
      "Epoch: 8/50: 100%|██████████| 87/87 [00:00<00:00, 143.04it/s, train_loss=0.00414, valid_loss=0.00431]\n",
      "Epoch: 9/50: 100%|██████████| 87/87 [00:00<00:00, 138.96it/s, train_loss=0.00443, valid_loss=0.00405]\n",
      "Epoch: 10/50: 100%|██████████| 87/87 [00:00<00:00, 139.10it/s, train_loss=0.00408, valid_loss=0.00487]\n",
      "Epoch: 11/50: 100%|██████████| 87/87 [00:00<00:00, 143.44it/s, train_loss=0.00432, valid_loss=0.00427]\n",
      "Epoch: 12/50: 100%|██████████| 87/87 [00:00<00:00, 138.79it/s, train_loss=0.00505, valid_loss=0.00369]\n",
      "Epoch: 13/50: 100%|██████████| 87/87 [00:00<00:00, 143.58it/s, train_loss=0.00377, valid_loss=0.00376]\n",
      "Epoch: 14/50: 100%|██████████| 87/87 [00:00<00:00, 133.39it/s, train_loss=0.00429, valid_loss=0.00363]\n",
      "Epoch: 15/50: 100%|██████████| 87/87 [00:00<00:00, 138.95it/s, train_loss=0.00484, valid_loss=0.00371]\n",
      "Epoch: 16/50: 100%|██████████| 87/87 [00:00<00:00, 142.14it/s, train_loss=0.00484, valid_loss=0.00368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 115/115 [00:00<00:00, 138.47it/s, train_loss=0.00761, valid_loss=0.00611]\n",
      "Epoch: 2/50: 100%|██████████| 115/115 [00:00<00:00, 143.61it/s, train_loss=0.00623, valid_loss=0.00496]\n",
      "Epoch: 3/50: 100%|██████████| 115/115 [00:00<00:00, 147.53it/s, train_loss=0.0061, valid_loss=0.00351] \n",
      "Epoch: 4/50: 100%|██████████| 115/115 [00:00<00:00, 143.65it/s, train_loss=0.0043, valid_loss=0.00335] \n",
      "Epoch: 5/50: 100%|██████████| 115/115 [00:00<00:00, 146.44it/s, train_loss=0.00511, valid_loss=0.00441]\n",
      "Epoch: 6/50: 100%|██████████| 115/115 [00:00<00:00, 146.87it/s, train_loss=0.00504, valid_loss=0.00319]\n",
      "Epoch: 7/50: 100%|██████████| 115/115 [00:00<00:00, 146.42it/s, train_loss=0.00417, valid_loss=0.00332]\n",
      "Epoch: 8/50: 100%|██████████| 115/115 [00:00<00:00, 146.49it/s, train_loss=0.00503, valid_loss=0.00257]\n",
      "Epoch: 9/50: 100%|██████████| 115/115 [00:00<00:00, 144.21it/s, train_loss=0.00428, valid_loss=0.00258]\n",
      "Epoch: 10/50: 100%|██████████| 115/115 [00:00<00:00, 142.66it/s, train_loss=0.00531, valid_loss=0.003]  \n",
      "Epoch: 11/50: 100%|██████████| 115/115 [00:00<00:00, 139.82it/s, train_loss=0.00413, valid_loss=0.00299]\n",
      "Epoch: 12/50: 100%|██████████| 115/115 [00:00<00:00, 143.26it/s, train_loss=0.00416, valid_loss=0.0029] \n",
      "Epoch: 13/50: 100%|██████████| 115/115 [00:00<00:00, 146.12it/s, train_loss=0.00484, valid_loss=0.00451]\n",
      "Epoch: 14/50: 100%|██████████| 115/115 [00:00<00:00, 143.76it/s, train_loss=0.0046, valid_loss=0.00319] \n",
      "Epoch: 15/50: 100%|██████████| 115/115 [00:00<00:00, 144.39it/s, train_loss=0.00544, valid_loss=0.00356]\n",
      "Epoch: 16/50: 100%|██████████| 115/115 [00:00<00:00, 143.26it/s, train_loss=0.00477, valid_loss=0.00512]\n",
      "Epoch: 17/50: 100%|██████████| 115/115 [00:00<00:00, 146.60it/s, train_loss=0.00393, valid_loss=0.00367]\n",
      "Epoch: 18/50: 100%|██████████| 115/115 [00:00<00:00, 146.33it/s, train_loss=0.0051, valid_loss=0.00462] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 144/144 [00:01<00:00, 136.72it/s, train_loss=0.00831, valid_loss=0.00454]\n",
      "Epoch: 2/50: 100%|██████████| 144/144 [00:00<00:00, 145.60it/s, train_loss=0.00611, valid_loss=0.00357]\n",
      "Epoch: 3/50: 100%|██████████| 144/144 [00:00<00:00, 145.02it/s, train_loss=0.00531, valid_loss=0.00305]\n",
      "Epoch: 4/50: 100%|██████████| 144/144 [00:00<00:00, 145.85it/s, train_loss=0.0042, valid_loss=0.00327] \n",
      "Epoch: 5/50: 100%|██████████| 144/144 [00:00<00:00, 145.37it/s, train_loss=0.00524, valid_loss=0.00325]\n",
      "Epoch: 6/50: 100%|██████████| 144/144 [00:00<00:00, 145.52it/s, train_loss=0.00485, valid_loss=0.0029] \n",
      "Epoch: 7/50: 100%|██████████| 144/144 [00:01<00:00, 143.59it/s, train_loss=0.00417, valid_loss=0.00264]\n",
      "Epoch: 8/50: 100%|██████████| 144/144 [00:00<00:00, 144.11it/s, train_loss=0.00475, valid_loss=0.00306]\n",
      "Epoch: 9/50: 100%|██████████| 144/144 [00:01<00:00, 143.06it/s, train_loss=0.00498, valid_loss=0.00309]\n",
      "Epoch: 10/50: 100%|██████████| 144/144 [00:00<00:00, 145.65it/s, train_loss=0.0046, valid_loss=0.00317] \n",
      "Epoch: 11/50: 100%|██████████| 144/144 [00:01<00:00, 142.65it/s, train_loss=0.0038, valid_loss=0.00302] \n",
      "Epoch: 12/50: 100%|██████████| 144/144 [00:01<00:00, 142.61it/s, train_loss=0.00469, valid_loss=0.00304]\n",
      "Epoch: 13/50: 100%|██████████| 144/144 [00:00<00:00, 145.42it/s, train_loss=0.0048, valid_loss=0.00261] \n",
      "Epoch: 14/50: 100%|██████████| 144/144 [00:01<00:00, 143.80it/s, train_loss=0.00427, valid_loss=0.00304]\n",
      "Epoch: 15/50: 100%|██████████| 144/144 [00:01<00:00, 143.38it/s, train_loss=0.0052, valid_loss=0.00289] \n",
      "Epoch: 16/50: 100%|██████████| 144/144 [00:01<00:00, 143.60it/s, train_loss=0.00463, valid_loss=0.00271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config: batch_size--256, lr--0.01, number_epoch--50, hidden_dim--35,drop_prob-0.1,weight_decay-1e-07\n",
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 15/15 [00:00<00:00, 99.88it/s, train_loss=0.0203, valid_loss=0.032] \n",
      "Epoch: 2/50: 100%|██████████| 15/15 [00:00<00:00, 143.88it/s, train_loss=0.014, valid_loss=0.025]\n",
      "Epoch: 3/50: 100%|██████████| 15/15 [00:00<00:00, 154.33it/s, train_loss=0.0101, valid_loss=0.0163]\n",
      "Epoch: 4/50: 100%|██████████| 15/15 [00:00<00:00, 124.70it/s, train_loss=0.00625, valid_loss=0.0103]\n",
      "Epoch: 5/50: 100%|██████████| 15/15 [00:00<00:00, 111.14it/s, train_loss=0.00501, valid_loss=0.0068]\n",
      "Epoch: 6/50: 100%|██████████| 15/15 [00:00<00:00, 115.95it/s, train_loss=0.00441, valid_loss=0.00569]\n",
      "Epoch: 7/50: 100%|██████████| 15/15 [00:00<00:00, 138.43it/s, train_loss=0.00405, valid_loss=0.00517]\n",
      "Epoch: 8/50: 100%|██████████| 15/15 [00:00<00:00, 156.46it/s, train_loss=0.00361, valid_loss=0.00483]\n",
      "Epoch: 9/50: 100%|██████████| 15/15 [00:00<00:00, 134.34it/s, train_loss=0.00423, valid_loss=0.00479]\n",
      "Epoch: 10/50: 100%|██████████| 15/15 [00:00<00:00, 91.44it/s, train_loss=0.0034, valid_loss=0.00575] \n",
      "Epoch: 11/50: 100%|██████████| 15/15 [00:00<00:00, 133.19it/s, train_loss=0.00367, valid_loss=0.00485]\n",
      "Epoch: 12/50: 100%|██████████| 15/15 [00:00<00:00, 128.21it/s, train_loss=0.00324, valid_loss=0.00476]\n",
      "Epoch: 13/50: 100%|██████████| 15/15 [00:00<00:00, 154.15it/s, train_loss=0.0031, valid_loss=0.00471]\n",
      "Epoch: 14/50: 100%|██████████| 15/15 [00:00<00:00, 138.32it/s, train_loss=0.00344, valid_loss=0.0045]\n",
      "Epoch: 15/50: 100%|██████████| 15/15 [00:00<00:00, 127.15it/s, train_loss=0.00336, valid_loss=0.00466]\n",
      "Epoch: 16/50: 100%|██████████| 15/15 [00:00<00:00, 128.28it/s, train_loss=0.00334, valid_loss=0.00458]\n",
      "Epoch: 17/50: 100%|██████████| 15/15 [00:00<00:00, 157.53it/s, train_loss=0.00302, valid_loss=0.00472]\n",
      "Epoch: 18/50: 100%|██████████| 15/15 [00:00<00:00, 133.44it/s, train_loss=0.00305, valid_loss=0.00448]\n",
      "Epoch: 19/50: 100%|██████████| 15/15 [00:00<00:00, 128.19it/s, train_loss=0.00294, valid_loss=0.00429]\n",
      "Epoch: 20/50: 100%|██████████| 15/15 [00:00<00:00, 155.98it/s, train_loss=0.00279, valid_loss=0.00504]\n",
      "Epoch: 21/50: 100%|██████████| 15/15 [00:00<00:00, 107.69it/s, train_loss=0.00281, valid_loss=0.00442]\n",
      "Epoch: 22/50: 100%|██████████| 15/15 [00:00<00:00, 140.55it/s, train_loss=0.00262, valid_loss=0.00439]\n",
      "Epoch: 23/50: 100%|██████████| 15/15 [00:00<00:00, 154.84it/s, train_loss=0.00266, valid_loss=0.00443]\n",
      "Epoch: 24/50: 100%|██████████| 15/15 [00:00<00:00, 113.23it/s, train_loss=0.00337, valid_loss=0.00469]\n",
      "Epoch: 25/50: 100%|██████████| 15/15 [00:00<00:00, 150.80it/s, train_loss=0.00273, valid_loss=0.00454]\n",
      "Epoch: 26/50: 100%|██████████| 15/15 [00:00<00:00, 158.67it/s, train_loss=0.0028, valid_loss=0.00487]\n",
      "Epoch: 27/50: 100%|██████████| 15/15 [00:00<00:00, 157.84it/s, train_loss=0.00287, valid_loss=0.00459]\n",
      "Epoch: 28/50: 100%|██████████| 15/15 [00:00<00:00, 157.32it/s, train_loss=0.00293, valid_loss=0.00463]\n",
      "Epoch: 29/50: 100%|██████████| 15/15 [00:00<00:00, 158.38it/s, train_loss=0.00262, valid_loss=0.00454]\n",
      "Epoch: 30/50: 100%|██████████| 15/15 [00:00<00:00, 156.40it/s, train_loss=0.00256, valid_loss=0.00461]\n",
      "Epoch: 31/50: 100%|██████████| 15/15 [00:00<00:00, 156.51it/s, train_loss=0.00305, valid_loss=0.00496]\n",
      "Epoch: 32/50: 100%|██████████| 15/15 [00:00<00:00, 158.72it/s, train_loss=0.00272, valid_loss=0.00447]\n",
      "Epoch: 33/50: 100%|██████████| 15/15 [00:00<00:00, 159.59it/s, train_loss=0.00252, valid_loss=0.00437]\n",
      "Epoch: 34/50: 100%|██████████| 15/15 [00:00<00:00, 154.90it/s, train_loss=0.00297, valid_loss=0.00453]\n",
      "Epoch: 35/50: 100%|██████████| 15/15 [00:00<00:00, 157.72it/s, train_loss=0.00297, valid_loss=0.00459]\n",
      "Epoch: 36/50: 100%|██████████| 15/15 [00:00<00:00, 158.98it/s, train_loss=0.00278, valid_loss=0.00471]\n",
      "Epoch: 37/50: 100%|██████████| 15/15 [00:00<00:00, 109.18it/s, train_loss=0.00296, valid_loss=0.00471]\n",
      "Epoch: 38/50: 100%|██████████| 15/15 [00:00<00:00, 155.74it/s, train_loss=0.00283, valid_loss=0.00496]\n",
      "Epoch: 39/50: 100%|██████████| 15/15 [00:00<00:00, 156.26it/s, train_loss=0.00275, valid_loss=0.00459]\n",
      "Epoch: 40/50: 100%|██████████| 15/15 [00:00<00:00, 158.04it/s, train_loss=0.00266, valid_loss=0.00512]\n",
      "Epoch: 41/50: 100%|██████████| 15/15 [00:00<00:00, 157.36it/s, train_loss=0.00277, valid_loss=0.00475]\n",
      "Epoch: 42/50: 100%|██████████| 15/15 [00:00<00:00, 157.61it/s, train_loss=0.0027, valid_loss=0.00457]\n",
      "Epoch: 43/50: 100%|██████████| 15/15 [00:00<00:00, 154.25it/s, train_loss=0.0025, valid_loss=0.00485]\n",
      "Epoch: 44/50: 100%|██████████| 15/15 [00:00<00:00, 157.68it/s, train_loss=0.00264, valid_loss=0.0047]\n",
      "Epoch: 45/50: 100%|██████████| 15/15 [00:00<00:00, 159.16it/s, train_loss=0.0025, valid_loss=0.00488]\n",
      "Epoch: 46/50: 100%|██████████| 15/15 [00:00<00:00, 156.19it/s, train_loss=0.00255, valid_loss=0.00472]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 29/29 [00:00<00:00, 116.60it/s, train_loss=0.0184, valid_loss=0.0221]\n",
      "Epoch: 2/50: 100%|██████████| 29/29 [00:00<00:00, 122.40it/s, train_loss=0.00811, valid_loss=0.00783]\n",
      "Epoch: 3/50: 100%|██████████| 29/29 [00:00<00:00, 152.87it/s, train_loss=0.0065, valid_loss=0.00552] \n",
      "Epoch: 4/50: 100%|██████████| 29/29 [00:00<00:00, 152.79it/s, train_loss=0.00617, valid_loss=0.00305]\n",
      "Epoch: 5/50: 100%|██████████| 29/29 [00:00<00:00, 153.96it/s, train_loss=0.00531, valid_loss=0.00378]\n",
      "Epoch: 6/50: 100%|██████████| 29/29 [00:00<00:00, 153.78it/s, train_loss=0.00537, valid_loss=0.00202]\n",
      "Epoch: 7/50: 100%|██████████| 29/29 [00:00<00:00, 153.25it/s, train_loss=0.00505, valid_loss=0.00252]\n",
      "Epoch: 8/50: 100%|██████████| 29/29 [00:00<00:00, 153.89it/s, train_loss=0.00447, valid_loss=0.00243]\n",
      "Epoch: 9/50: 100%|██████████| 29/29 [00:00<00:00, 127.11it/s, train_loss=0.00524, valid_loss=0.00209]\n",
      "Epoch: 10/50: 100%|██████████| 29/29 [00:00<00:00, 152.67it/s, train_loss=0.00465, valid_loss=0.00272]\n",
      "Epoch: 11/50: 100%|██████████| 29/29 [00:00<00:00, 152.61it/s, train_loss=0.00525, valid_loss=0.00441]\n",
      "Epoch: 12/50: 100%|██████████| 29/29 [00:00<00:00, 153.19it/s, train_loss=0.00494, valid_loss=0.00332]\n",
      "Epoch: 13/50: 100%|██████████| 29/29 [00:00<00:00, 152.71it/s, train_loss=0.00469, valid_loss=0.00374]\n",
      "Epoch: 14/50: 100%|██████████| 29/29 [00:00<00:00, 152.53it/s, train_loss=0.00492, valid_loss=0.00205]\n",
      "Epoch: 15/50: 100%|██████████| 29/29 [00:00<00:00, 128.18it/s, train_loss=0.00423, valid_loss=0.00281]\n",
      "Epoch: 16/50: 100%|██████████| 29/29 [00:00<00:00, 152.72it/s, train_loss=0.0039, valid_loss=0.00231] \n",
      "Epoch: 17/50: 100%|██████████| 29/29 [00:00<00:00, 152.18it/s, train_loss=0.00547, valid_loss=0.00249]\n",
      "Epoch: 18/50: 100%|██████████| 29/29 [00:00<00:00, 152.29it/s, train_loss=0.00516, valid_loss=0.0033] \n",
      "Epoch: 19/50: 100%|██████████| 29/29 [00:00<00:00, 152.35it/s, train_loss=0.00439, valid_loss=0.00295]\n",
      "Epoch: 20/50: 100%|██████████| 29/29 [00:00<00:00, 152.89it/s, train_loss=0.00439, valid_loss=0.00256]\n",
      "Epoch: 21/50: 100%|██████████| 29/29 [00:00<00:00, 153.34it/s, train_loss=0.00355, valid_loss=0.00206]\n",
      "Epoch: 22/50: 100%|██████████| 29/29 [00:00<00:00, 127.14it/s, train_loss=0.00462, valid_loss=0.00358]\n",
      "Epoch: 23/50: 100%|██████████| 29/29 [00:00<00:00, 153.10it/s, train_loss=0.00477, valid_loss=0.00372]\n",
      "Epoch: 24/50: 100%|██████████| 29/29 [00:00<00:00, 152.19it/s, train_loss=0.00379, valid_loss=0.0027] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 44/44 [00:00<00:00, 128.25it/s, train_loss=0.0128, valid_loss=0.0156]\n",
      "Epoch: 2/50: 100%|██████████| 44/44 [00:00<00:00, 155.48it/s, train_loss=0.00629, valid_loss=0.00575]\n",
      "Epoch: 3/50: 100%|██████████| 44/44 [00:00<00:00, 135.27it/s, train_loss=0.00598, valid_loss=0.00491]\n",
      "Epoch: 4/50: 100%|██████████| 44/44 [00:00<00:00, 153.70it/s, train_loss=0.00556, valid_loss=0.00475]\n",
      "Epoch: 5/50: 100%|██████████| 44/44 [00:00<00:00, 152.30it/s, train_loss=0.00476, valid_loss=0.00427]\n",
      "Epoch: 6/50: 100%|██████████| 44/44 [00:00<00:00, 154.84it/s, train_loss=0.00504, valid_loss=0.0041] \n",
      "Epoch: 7/50: 100%|██████████| 44/44 [00:00<00:00, 136.42it/s, train_loss=0.00504, valid_loss=0.00449]\n",
      "Epoch: 8/50: 100%|██████████| 44/44 [00:00<00:00, 154.43it/s, train_loss=0.00431, valid_loss=0.00473]\n",
      "Epoch: 9/50: 100%|██████████| 44/44 [00:00<00:00, 153.79it/s, train_loss=0.00504, valid_loss=0.00447]\n",
      "Epoch: 10/50: 100%|██████████| 44/44 [00:00<00:00, 154.12it/s, train_loss=0.00418, valid_loss=0.00439]\n",
      "Epoch: 11/50: 100%|██████████| 44/44 [00:00<00:00, 153.67it/s, train_loss=0.00472, valid_loss=0.00523]\n",
      "Epoch: 12/50: 100%|██████████| 44/44 [00:00<00:00, 136.89it/s, train_loss=0.00371, valid_loss=0.00403]\n",
      "Epoch: 13/50: 100%|██████████| 44/44 [00:00<00:00, 154.66it/s, train_loss=0.00449, valid_loss=0.00362]\n",
      "Epoch: 14/50: 100%|██████████| 44/44 [00:00<00:00, 153.40it/s, train_loss=0.00441, valid_loss=0.00386]\n",
      "Epoch: 15/50: 100%|██████████| 44/44 [00:00<00:00, 154.38it/s, train_loss=0.00387, valid_loss=0.00407]\n",
      "Epoch: 16/50: 100%|██████████| 44/44 [00:00<00:00, 136.15it/s, train_loss=0.00393, valid_loss=0.00451]\n",
      "Epoch: 17/50: 100%|██████████| 44/44 [00:00<00:00, 154.15it/s, train_loss=0.00359, valid_loss=0.00427]\n",
      "Epoch: 18/50: 100%|██████████| 44/44 [00:00<00:00, 153.68it/s, train_loss=0.00421, valid_loss=0.00432]\n",
      "Epoch: 19/50: 100%|██████████| 44/44 [00:00<00:00, 153.46it/s, train_loss=0.00414, valid_loss=0.00379]\n",
      "Epoch: 20/50: 100%|██████████| 44/44 [00:00<00:00, 154.96it/s, train_loss=0.00379, valid_loss=0.00434]\n",
      "Epoch: 21/50: 100%|██████████| 44/44 [00:00<00:00, 135.92it/s, train_loss=0.00357, valid_loss=0.00462]\n",
      "Epoch: 22/50: 100%|██████████| 44/44 [00:00<00:00, 153.33it/s, train_loss=0.00398, valid_loss=0.00394]\n",
      "Epoch: 23/50: 100%|██████████| 44/44 [00:00<00:00, 154.27it/s, train_loss=0.00383, valid_loss=0.00403]\n",
      "Epoch: 24/50: 100%|██████████| 44/44 [00:00<00:00, 154.51it/s, train_loss=0.00313, valid_loss=0.00518]\n",
      "Epoch: 25/50: 100%|██████████| 44/44 [00:00<00:00, 136.15it/s, train_loss=0.00349, valid_loss=0.00378]\n",
      "Epoch: 26/50: 100%|██████████| 44/44 [00:00<00:00, 153.87it/s, train_loss=0.00399, valid_loss=0.00453]\n",
      "Epoch: 27/50: 100%|██████████| 44/44 [00:00<00:00, 154.10it/s, train_loss=0.00387, valid_loss=0.00426]\n",
      "Epoch: 28/50: 100%|██████████| 44/44 [00:00<00:00, 153.76it/s, train_loss=0.00345, valid_loss=0.00466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 58/58 [00:00<00:00, 121.38it/s, train_loss=0.00939, valid_loss=0.00737]\n",
      "Epoch: 2/50: 100%|██████████| 58/58 [00:00<00:00, 146.67it/s, train_loss=0.00617, valid_loss=0.00448]\n",
      "Epoch: 3/50: 100%|██████████| 58/58 [00:00<00:00, 152.77it/s, train_loss=0.00895, valid_loss=0.00285]\n",
      "Epoch: 4/50: 100%|██████████| 58/58 [00:00<00:00, 150.92it/s, train_loss=0.00559, valid_loss=0.0025] \n",
      "Epoch: 5/50: 100%|██████████| 58/58 [00:00<00:00, 138.31it/s, train_loss=0.00683, valid_loss=0.00345]\n",
      "Epoch: 6/50: 100%|██████████| 58/58 [00:00<00:00, 153.06it/s, train_loss=0.00539, valid_loss=0.00222]\n",
      "Epoch: 7/50: 100%|██████████| 58/58 [00:00<00:00, 145.77it/s, train_loss=0.00532, valid_loss=0.00204]\n",
      "Epoch: 8/50: 100%|██████████| 58/58 [00:00<00:00, 139.15it/s, train_loss=0.00519, valid_loss=0.00229]\n",
      "Epoch: 9/50: 100%|██████████| 58/58 [00:00<00:00, 152.10it/s, train_loss=0.00464, valid_loss=0.00217]\n",
      "Epoch: 10/50: 100%|██████████| 58/58 [00:00<00:00, 152.24it/s, train_loss=0.00548, valid_loss=0.00216]\n",
      "Epoch: 11/50: 100%|██████████| 58/58 [00:00<00:00, 138.66it/s, train_loss=0.00428, valid_loss=0.00209]\n",
      "Epoch: 12/50: 100%|██████████| 58/58 [00:00<00:00, 152.66it/s, train_loss=0.00484, valid_loss=0.00246]\n",
      "Epoch: 13/50: 100%|██████████| 58/58 [00:00<00:00, 153.41it/s, train_loss=0.00483, valid_loss=0.00208]\n",
      "Epoch: 14/50: 100%|██████████| 58/58 [00:00<00:00, 147.53it/s, train_loss=0.00457, valid_loss=0.00198]\n",
      "Epoch: 15/50: 100%|██████████| 58/58 [00:00<00:00, 133.50it/s, train_loss=0.00474, valid_loss=0.00257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 72/72 [00:00<00:00, 136.56it/s, train_loss=0.00996, valid_loss=0.00667]\n",
      "Epoch: 2/50: 100%|██████████| 72/72 [00:00<00:00, 140.17it/s, train_loss=0.00665, valid_loss=0.00446]\n",
      "Epoch: 3/50: 100%|██████████| 72/72 [00:00<00:00, 152.15it/s, train_loss=0.00589, valid_loss=0.00314]\n",
      "Epoch: 4/50: 100%|██████████| 72/72 [00:00<00:00, 152.35it/s, train_loss=0.00624, valid_loss=0.00286]\n",
      "Epoch: 5/50: 100%|██████████| 72/72 [00:00<00:00, 140.40it/s, train_loss=0.00544, valid_loss=0.00298]\n",
      "Epoch: 6/50: 100%|██████████| 72/72 [00:00<00:00, 151.61it/s, train_loss=0.00465, valid_loss=0.00281]\n",
      "Epoch: 7/50: 100%|██████████| 72/72 [00:00<00:00, 151.65it/s, train_loss=0.00494, valid_loss=0.00267]\n",
      "Epoch: 8/50: 100%|██████████| 72/72 [00:00<00:00, 135.95it/s, train_loss=0.00474, valid_loss=0.00279]\n",
      "Epoch: 9/50: 100%|██████████| 72/72 [00:00<00:00, 151.43it/s, train_loss=0.00413, valid_loss=0.00283]\n",
      "Epoch: 10/50: 100%|██████████| 72/72 [00:00<00:00, 139.93it/s, train_loss=0.00497, valid_loss=0.00256]\n",
      "Epoch: 11/50: 100%|██████████| 72/72 [00:00<00:00, 149.71it/s, train_loss=0.00462, valid_loss=0.0026] \n",
      "Epoch: 12/50: 100%|██████████| 72/72 [00:00<00:00, 147.83it/s, train_loss=0.00417, valid_loss=0.00279]\n",
      "Epoch: 13/50: 100%|██████████| 72/72 [00:00<00:00, 140.10it/s, train_loss=0.00423, valid_loss=0.00251]\n",
      "Epoch: 14/50: 100%|██████████| 72/72 [00:00<00:00, 145.98it/s, train_loss=0.00425, valid_loss=0.00259]\n",
      "Epoch: 15/50: 100%|██████████| 72/72 [00:00<00:00, 151.35it/s, train_loss=0.00441, valid_loss=0.0029] \n",
      "Epoch: 16/50: 100%|██████████| 72/72 [00:00<00:00, 139.21it/s, train_loss=0.00444, valid_loss=0.00288]\n",
      "Epoch: 17/50: 100%|██████████| 72/72 [00:00<00:00, 150.65it/s, train_loss=0.00396, valid_loss=0.00244]\n",
      "Epoch: 18/50: 100%|██████████| 72/72 [00:00<00:00, 140.01it/s, train_loss=0.00378, valid_loss=0.00236]\n",
      "Epoch: 19/50: 100%|██████████| 72/72 [00:00<00:00, 145.76it/s, train_loss=0.00428, valid_loss=0.00254]\n",
      "Epoch: 20/50: 100%|██████████| 72/72 [00:00<00:00, 152.25it/s, train_loss=0.00406, valid_loss=0.00221]\n",
      "Epoch: 21/50: 100%|██████████| 72/72 [00:00<00:00, 141.28it/s, train_loss=0.00468, valid_loss=0.00264]\n",
      "Epoch: 22/50: 100%|██████████| 72/72 [00:00<00:00, 152.20it/s, train_loss=0.00453, valid_loss=0.00243]\n",
      "Epoch: 23/50: 100%|██████████| 72/72 [00:00<00:00, 141.14it/s, train_loss=0.0041, valid_loss=0.00242] \n",
      "Epoch: 24/50: 100%|██████████| 72/72 [00:00<00:00, 143.46it/s, train_loss=0.00357, valid_loss=0.00252]\n",
      "Epoch: 25/50: 100%|██████████| 72/72 [00:00<00:00, 145.02it/s, train_loss=0.00389, valid_loss=0.00246]\n",
      "Epoch: 26/50: 100%|██████████| 72/72 [00:00<00:00, 134.81it/s, train_loss=0.00338, valid_loss=0.0022] \n",
      "Epoch: 27/50: 100%|██████████| 72/72 [00:00<00:00, 144.75it/s, train_loss=0.00381, valid_loss=0.0024] \n",
      "Epoch: 28/50: 100%|██████████| 72/72 [00:00<00:00, 146.59it/s, train_loss=0.00374, valid_loss=0.00267]\n",
      "Epoch: 29/50: 100%|██████████| 72/72 [00:00<00:00, 134.79it/s, train_loss=0.00427, valid_loss=0.00245]\n",
      "Epoch: 30/50: 100%|██████████| 72/72 [00:00<00:00, 138.86it/s, train_loss=0.00436, valid_loss=0.00249]\n",
      "Epoch: 31/50: 100%|██████████| 72/72 [00:00<00:00, 135.86it/s, train_loss=0.00534, valid_loss=0.00223]\n",
      "Epoch: 32/50: 100%|██████████| 72/72 [00:00<00:00, 144.35it/s, train_loss=0.00337, valid_loss=0.00268]\n",
      "Epoch: 33/50: 100%|██████████| 72/72 [00:00<00:00, 145.63it/s, train_loss=0.00422, valid_loss=0.00248]\n",
      "Epoch: 34/50: 100%|██████████| 72/72 [00:00<00:00, 132.85it/s, train_loss=0.00385, valid_loss=0.00229]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config: batch_size--128, lr--0.01, number_epoch--50, hidden_dim--35,drop_prob-0.1,weight_decay-1e-07\n",
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 29/29 [00:00<00:00, 123.01it/s, train_loss=0.0152, valid_loss=0.0254]\n",
      "Epoch: 2/50: 100%|██████████| 29/29 [00:00<00:00, 102.27it/s, train_loss=0.00773, valid_loss=0.00806]\n",
      "Epoch: 3/50: 100%|██████████| 29/29 [00:00<00:00, 87.61it/s, train_loss=0.00469, valid_loss=0.00601]\n",
      "Epoch: 4/50: 100%|██████████| 29/29 [00:00<00:00, 101.57it/s, train_loss=0.00453, valid_loss=0.00545]\n",
      "Epoch: 5/50: 100%|██████████| 29/29 [00:00<00:00, 134.67it/s, train_loss=0.00363, valid_loss=0.00486]\n",
      "Epoch: 6/50: 100%|██████████| 29/29 [00:00<00:00, 133.60it/s, train_loss=0.00396, valid_loss=0.00508]\n",
      "Epoch: 7/50: 100%|██████████| 29/29 [00:00<00:00, 134.85it/s, train_loss=0.00292, valid_loss=0.00529]\n",
      "Epoch: 8/50: 100%|██████████| 29/29 [00:00<00:00, 135.92it/s, train_loss=0.00353, valid_loss=0.00481]\n",
      "Epoch: 9/50: 100%|██████████| 29/29 [00:00<00:00, 135.02it/s, train_loss=0.00319, valid_loss=0.00439]\n",
      "Epoch: 10/50: 100%|██████████| 29/29 [00:00<00:00, 135.38it/s, train_loss=0.00277, valid_loss=0.00515]\n",
      "Epoch: 11/50: 100%|██████████| 29/29 [00:00<00:00, 133.33it/s, train_loss=0.0029, valid_loss=0.00446] \n",
      "Epoch: 12/50: 100%|██████████| 29/29 [00:00<00:00, 135.59it/s, train_loss=0.00239, valid_loss=0.00465]\n",
      "Epoch: 13/50: 100%|██████████| 29/29 [00:00<00:00, 134.68it/s, train_loss=0.00281, valid_loss=0.00456]\n",
      "Epoch: 14/50: 100%|██████████| 29/29 [00:00<00:00, 132.54it/s, train_loss=0.00219, valid_loss=0.00461]\n",
      "Epoch: 15/50: 100%|██████████| 29/29 [00:00<00:00, 125.76it/s, train_loss=0.0028, valid_loss=0.00461]\n",
      "Epoch: 16/50: 100%|██████████| 29/29 [00:00<00:00, 135.79it/s, train_loss=0.00214, valid_loss=0.00503]\n",
      "Epoch: 17/50: 100%|██████████| 29/29 [00:00<00:00, 134.42it/s, train_loss=0.0026, valid_loss=0.00445] \n",
      "Epoch: 18/50: 100%|██████████| 29/29 [00:00<00:00, 133.32it/s, train_loss=0.00247, valid_loss=0.0042] \n",
      "Epoch: 19/50: 100%|██████████| 29/29 [00:00<00:00, 134.06it/s, train_loss=0.00258, valid_loss=0.00449]\n",
      "Epoch: 20/50: 100%|██████████| 29/29 [00:00<00:00, 135.65it/s, train_loss=0.0024, valid_loss=0.00456] \n",
      "Epoch: 21/50: 100%|██████████| 29/29 [00:00<00:00, 132.66it/s, train_loss=0.00217, valid_loss=0.0043] \n",
      "Epoch: 22/50: 100%|██████████| 29/29 [00:00<00:00, 134.35it/s, train_loss=0.00221, valid_loss=0.00477]\n",
      "Epoch: 23/50: 100%|██████████| 29/29 [00:00<00:00, 134.05it/s, train_loss=0.00302, valid_loss=0.00451]\n",
      "Epoch: 24/50: 100%|██████████| 29/29 [00:00<00:00, 135.39it/s, train_loss=0.00249, valid_loss=0.00498]\n",
      "Epoch: 25/50: 100%|██████████| 29/29 [00:00<00:00, 135.27it/s, train_loss=0.00231, valid_loss=0.00557]\n",
      "Epoch: 26/50: 100%|██████████| 29/29 [00:00<00:00, 128.79it/s, train_loss=0.00253, valid_loss=0.00468]\n",
      "Epoch: 27/50: 100%|██████████| 29/29 [00:00<00:00, 134.75it/s, train_loss=0.00287, valid_loss=0.00514]\n",
      "Epoch: 28/50: 100%|██████████| 29/29 [00:00<00:00, 133.17it/s, train_loss=0.00251, valid_loss=0.00443]\n",
      "Epoch: 29/50: 100%|██████████| 29/29 [00:00<00:00, 124.66it/s, train_loss=0.00266, valid_loss=0.00442]\n",
      "Epoch: 30/50: 100%|██████████| 29/29 [00:00<00:00, 135.57it/s, train_loss=0.00203, valid_loss=0.00538]\n",
      "Epoch: 31/50: 100%|██████████| 29/29 [00:00<00:00, 136.33it/s, train_loss=0.00212, valid_loss=0.0049] \n",
      "Epoch: 32/50: 100%|██████████| 29/29 [00:00<00:00, 135.33it/s, train_loss=0.00229, valid_loss=0.00456]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 58/58 [00:00<00:00, 126.66it/s, train_loss=0.0114, valid_loss=0.0057] \n",
      "Epoch: 2/50: 100%|██████████| 58/58 [00:00<00:00, 92.49it/s, train_loss=0.00602, valid_loss=0.00408]\n",
      "Epoch: 3/50: 100%|██████████| 58/58 [00:00<00:00, 107.64it/s, train_loss=0.00641, valid_loss=0.00467]\n",
      "Epoch: 4/50: 100%|██████████| 58/58 [00:00<00:00, 104.21it/s, train_loss=0.00639, valid_loss=0.00614]\n",
      "Epoch: 5/50: 100%|██████████| 58/58 [00:00<00:00, 107.21it/s, train_loss=0.0047, valid_loss=0.00252] \n",
      "Epoch: 6/50: 100%|██████████| 58/58 [00:00<00:00, 106.37it/s, train_loss=0.0038, valid_loss=0.00327] \n",
      "Epoch: 7/50: 100%|██████████| 58/58 [00:00<00:00, 119.89it/s, train_loss=0.00469, valid_loss=0.00259]\n",
      "Epoch: 8/50: 100%|██████████| 58/58 [00:00<00:00, 112.63it/s, train_loss=0.00536, valid_loss=0.00325]\n",
      "Epoch: 9/50: 100%|██████████| 58/58 [00:00<00:00, 108.60it/s, train_loss=0.00579, valid_loss=0.00314]\n",
      "Epoch: 10/50: 100%|██████████| 58/58 [00:00<00:00, 104.76it/s, train_loss=0.00449, valid_loss=0.00194]\n",
      "Epoch: 11/50: 100%|██████████| 58/58 [00:00<00:00, 119.66it/s, train_loss=0.00374, valid_loss=0.00358]\n",
      "Epoch: 12/50: 100%|██████████| 58/58 [00:00<00:00, 102.54it/s, train_loss=0.00472, valid_loss=0.00532]\n",
      "Epoch: 13/50: 100%|██████████| 58/58 [00:00<00:00, 106.59it/s, train_loss=0.00483, valid_loss=0.00387]\n",
      "Epoch: 14/50: 100%|██████████| 58/58 [00:00<00:00, 113.98it/s, train_loss=0.00414, valid_loss=0.005]  \n",
      "Epoch: 15/50: 100%|██████████| 58/58 [00:00<00:00, 113.67it/s, train_loss=0.00575, valid_loss=0.00445]\n",
      "Epoch: 16/50: 100%|██████████| 58/58 [00:00<00:00, 108.51it/s, train_loss=0.00427, valid_loss=0.00362]\n",
      "Epoch: 17/50: 100%|██████████| 58/58 [00:00<00:00, 113.01it/s, train_loss=0.00495, valid_loss=0.00514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 87/87 [00:00<00:00, 125.52it/s, train_loss=0.00786, valid_loss=0.00637]\n",
      "Epoch: 2/50: 100%|██████████| 87/87 [00:00<00:00, 118.63it/s, train_loss=0.00546, valid_loss=0.00452]\n",
      "Epoch: 3/50: 100%|██████████| 87/87 [00:00<00:00, 108.47it/s, train_loss=0.00488, valid_loss=0.00412]\n",
      "Epoch: 4/50: 100%|██████████| 87/87 [00:00<00:00, 99.23it/s, train_loss=0.00406, valid_loss=0.00448] \n",
      "Epoch: 5/50: 100%|██████████| 87/87 [00:00<00:00, 110.19it/s, train_loss=0.00424, valid_loss=0.00434]\n",
      "Epoch: 6/50: 100%|██████████| 87/87 [00:00<00:00, 113.28it/s, train_loss=0.0043, valid_loss=0.00376] \n",
      "Epoch: 7/50: 100%|██████████| 87/87 [00:00<00:00, 104.01it/s, train_loss=0.00448, valid_loss=0.0035] \n",
      "Epoch: 8/50: 100%|██████████| 87/87 [00:00<00:00, 108.05it/s, train_loss=0.00435, valid_loss=0.00405]\n",
      "Epoch: 9/50: 100%|██████████| 87/87 [00:00<00:00, 119.47it/s, train_loss=0.00487, valid_loss=0.00397]\n",
      "Epoch: 10/50: 100%|██████████| 87/87 [00:00<00:00, 103.17it/s, train_loss=0.00416, valid_loss=0.00354]\n",
      "Epoch: 11/50: 100%|██████████| 87/87 [00:00<00:00, 106.63it/s, train_loss=0.00315, valid_loss=0.00317]\n",
      "Epoch: 12/50: 100%|██████████| 87/87 [00:00<00:00, 122.83it/s, train_loss=0.00416, valid_loss=0.00343]\n",
      "Epoch: 13/50: 100%|██████████| 87/87 [00:00<00:00, 151.64it/s, train_loss=0.00324, valid_loss=0.00399]\n",
      "Epoch: 14/50: 100%|██████████| 87/87 [00:00<00:00, 151.00it/s, train_loss=0.00377, valid_loss=0.00402]\n",
      "Epoch: 15/50: 100%|██████████| 87/87 [00:00<00:00, 152.35it/s, train_loss=0.00377, valid_loss=0.00363]\n",
      "Epoch: 16/50: 100%|██████████| 87/87 [00:00<00:00, 151.80it/s, train_loss=0.00399, valid_loss=0.00366]\n",
      "Epoch: 17/50: 100%|██████████| 87/87 [00:00<00:00, 150.95it/s, train_loss=0.00361, valid_loss=0.00333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 115/115 [00:01<00:00, 97.49it/s, train_loss=0.00802, valid_loss=0.0044] \n",
      "Epoch: 2/50: 100%|██████████| 115/115 [00:01<00:00, 109.71it/s, train_loss=0.00653, valid_loss=0.00459]\n",
      "Epoch: 3/50: 100%|██████████| 115/115 [00:01<00:00, 107.94it/s, train_loss=0.0052, valid_loss=0.00263] \n",
      "Epoch: 4/50: 100%|██████████| 115/115 [00:01<00:00, 103.69it/s, train_loss=0.00535, valid_loss=0.0024] \n",
      "Epoch: 5/50: 100%|██████████| 115/115 [00:01<00:00, 111.67it/s, train_loss=0.00444, valid_loss=0.00233]\n",
      "Epoch: 6/50: 100%|██████████| 115/115 [00:00<00:00, 124.84it/s, train_loss=0.00499, valid_loss=0.0025]\n",
      "Epoch: 7/50: 100%|██████████| 115/115 [00:00<00:00, 130.80it/s, train_loss=0.0047, valid_loss=0.00277] \n",
      "Epoch: 8/50: 100%|██████████| 115/115 [00:00<00:00, 130.57it/s, train_loss=0.00421, valid_loss=0.00319]\n",
      "Epoch: 9/50: 100%|██████████| 115/115 [00:00<00:00, 130.64it/s, train_loss=0.00326, valid_loss=0.00365]\n",
      "Epoch: 10/50: 100%|██████████| 115/115 [00:00<00:00, 128.06it/s, train_loss=0.00474, valid_loss=0.0034] \n",
      "Epoch: 11/50: 100%|██████████| 115/115 [00:00<00:00, 130.53it/s, train_loss=0.00343, valid_loss=0.00281]\n",
      "Epoch: 12/50: 100%|██████████| 115/115 [00:00<00:00, 130.58it/s, train_loss=0.00413, valid_loss=0.00233]\n",
      "Epoch: 13/50: 100%|██████████| 115/115 [00:00<00:00, 130.12it/s, train_loss=0.00408, valid_loss=0.00285]\n",
      "Epoch: 14/50: 100%|██████████| 115/115 [00:00<00:00, 130.43it/s, train_loss=0.00396, valid_loss=0.0025] \n",
      "Epoch: 15/50: 100%|██████████| 115/115 [00:00<00:00, 130.57it/s, train_loss=0.00472, valid_loss=0.0024] \n",
      "Epoch: 16/50: 100%|██████████| 115/115 [00:00<00:00, 130.76it/s, train_loss=0.00421, valid_loss=0.00398]\n",
      "Epoch: 17/50: 100%|██████████| 115/115 [00:00<00:00, 130.62it/s, train_loss=0.00367, valid_loss=0.00246]\n",
      "Epoch: 18/50: 100%|██████████| 115/115 [00:00<00:00, 129.97it/s, train_loss=0.00412, valid_loss=0.00242]\n",
      "Epoch: 19/50: 100%|██████████| 115/115 [00:00<00:00, 130.77it/s, train_loss=0.00415, valid_loss=0.00287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 144/144 [00:01<00:00, 122.50it/s, train_loss=0.00832, valid_loss=0.00378]\n",
      "Epoch: 2/50: 100%|██████████| 144/144 [00:01<00:00, 129.52it/s, train_loss=0.00494, valid_loss=0.00329]\n",
      "Epoch: 3/50: 100%|██████████| 144/144 [00:01<00:00, 129.88it/s, train_loss=0.00466, valid_loss=0.00261]\n",
      "Epoch: 4/50: 100%|██████████| 144/144 [00:01<00:00, 130.03it/s, train_loss=0.00566, valid_loss=0.00333]\n",
      "Epoch: 5/50: 100%|██████████| 144/144 [00:01<00:00, 130.32it/s, train_loss=0.00478, valid_loss=0.00249]\n",
      "Epoch: 6/50: 100%|██████████| 144/144 [00:01<00:00, 129.49it/s, train_loss=0.00396, valid_loss=0.00294]\n",
      "Epoch: 7/50: 100%|██████████| 144/144 [00:01<00:00, 130.30it/s, train_loss=0.00419, valid_loss=0.00239]\n",
      "Epoch: 8/50: 100%|██████████| 144/144 [00:01<00:00, 129.73it/s, train_loss=0.00406, valid_loss=0.00425]\n",
      "Epoch: 9/50: 100%|██████████| 144/144 [00:01<00:00, 129.92it/s, train_loss=0.00505, valid_loss=0.00289]\n",
      "Epoch: 10/50: 100%|██████████| 144/144 [00:01<00:00, 129.97it/s, train_loss=0.00405, valid_loss=0.00228]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config: batch_size--128, lr--0.005, number_epoch--50, hidden_dim--30,drop_prob-0.1,weight_decay-1e-07\n",
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 29/29 [00:00<00:00, 96.05it/s, train_loss=0.0179, valid_loss=0.0293]\n",
      "Epoch: 2/50: 100%|██████████| 29/29 [00:00<00:00, 117.35it/s, train_loss=0.0137, valid_loss=0.0244]\n",
      "Epoch: 3/50: 100%|██████████| 29/29 [00:00<00:00, 117.59it/s, train_loss=0.0101, valid_loss=0.0153]\n",
      "Epoch: 4/50: 100%|██████████| 29/29 [00:00<00:00, 120.06it/s, train_loss=0.00953, valid_loss=0.0129]\n",
      "Epoch: 5/50: 100%|██████████| 29/29 [00:00<00:00, 114.40it/s, train_loss=0.00897, valid_loss=0.0126]\n",
      "Epoch: 6/50: 100%|██████████| 29/29 [00:00<00:00, 114.63it/s, train_loss=0.00824, valid_loss=0.0107]\n",
      "Epoch: 7/50: 100%|██████████| 29/29 [00:00<00:00, 112.72it/s, train_loss=0.00456, valid_loss=0.00587]\n",
      "Epoch: 8/50: 100%|██████████| 29/29 [00:00<00:00, 118.39it/s, train_loss=0.00386, valid_loss=0.00597]\n",
      "Epoch: 9/50: 100%|██████████| 29/29 [00:00<00:00, 123.86it/s, train_loss=0.00412, valid_loss=0.00553]\n",
      "Epoch: 10/50: 100%|██████████| 29/29 [00:00<00:00, 115.32it/s, train_loss=0.00329, valid_loss=0.00609]\n",
      "Epoch: 11/50: 100%|██████████| 29/29 [00:00<00:00, 121.50it/s, train_loss=0.00335, valid_loss=0.00527]\n",
      "Epoch: 12/50: 100%|██████████| 29/29 [00:00<00:00, 112.39it/s, train_loss=0.00381, valid_loss=0.00518]\n",
      "Epoch: 13/50: 100%|██████████| 29/29 [00:00<00:00, 120.32it/s, train_loss=0.00349, valid_loss=0.00513]\n",
      "Epoch: 14/50: 100%|██████████| 29/29 [00:00<00:00, 118.45it/s, train_loss=0.00275, valid_loss=0.00546]\n",
      "Epoch: 15/50: 100%|██████████| 29/29 [00:00<00:00, 109.30it/s, train_loss=0.00323, valid_loss=0.00509]\n",
      "Epoch: 16/50: 100%|██████████| 29/29 [00:00<00:00, 118.74it/s, train_loss=0.00318, valid_loss=0.00516]\n",
      "Epoch: 17/50: 100%|██████████| 29/29 [00:00<00:00, 111.34it/s, train_loss=0.00277, valid_loss=0.00515]\n",
      "Epoch: 18/50: 100%|██████████| 29/29 [00:00<00:00, 125.00it/s, train_loss=0.00308, valid_loss=0.00529]\n",
      "Epoch: 19/50: 100%|██████████| 29/29 [00:00<00:00, 97.92it/s, train_loss=0.00324, valid_loss=0.00504]\n",
      "Epoch: 20/50: 100%|██████████| 29/29 [00:00<00:00, 110.21it/s, train_loss=0.00281, valid_loss=0.00549]\n",
      "Epoch: 21/50: 100%|██████████| 29/29 [00:00<00:00, 121.05it/s, train_loss=0.00302, valid_loss=0.00489]\n",
      "Epoch: 22/50: 100%|██████████| 29/29 [00:00<00:00, 121.20it/s, train_loss=0.00269, valid_loss=0.00558]\n",
      "Epoch: 23/50: 100%|██████████| 29/29 [00:00<00:00, 109.67it/s, train_loss=0.00235, valid_loss=0.00464]\n",
      "Epoch: 24/50: 100%|██████████| 29/29 [00:00<00:00, 138.75it/s, train_loss=0.00263, valid_loss=0.00507]\n",
      "Epoch: 25/50: 100%|██████████| 29/29 [00:00<00:00, 134.01it/s, train_loss=0.00254, valid_loss=0.00517]\n",
      "Epoch: 26/50: 100%|██████████| 29/29 [00:00<00:00, 103.23it/s, train_loss=0.00274, valid_loss=0.0051]\n",
      "Epoch: 27/50: 100%|██████████| 29/29 [00:00<00:00, 139.75it/s, train_loss=0.00263, valid_loss=0.00481]\n",
      "Epoch: 28/50: 100%|██████████| 29/29 [00:00<00:00, 137.59it/s, train_loss=0.00265, valid_loss=0.0051] \n",
      "Epoch: 29/50: 100%|██████████| 29/29 [00:00<00:00, 128.19it/s, train_loss=0.00292, valid_loss=0.00505]\n",
      "Epoch: 30/50: 100%|██████████| 29/29 [00:00<00:00, 142.59it/s, train_loss=0.00303, valid_loss=0.00487]\n",
      "Epoch: 31/50: 100%|██████████| 29/29 [00:00<00:00, 142.57it/s, train_loss=0.00245, valid_loss=0.00509]\n",
      "Epoch: 32/50: 100%|██████████| 29/29 [00:00<00:00, 142.42it/s, train_loss=0.00261, valid_loss=0.00503]\n",
      "Epoch: 33/50: 100%|██████████| 29/29 [00:00<00:00, 140.88it/s, train_loss=0.00228, valid_loss=0.00484]\n",
      "Epoch: 34/50: 100%|██████████| 29/29 [00:00<00:00, 142.80it/s, train_loss=0.00253, valid_loss=0.00525]\n",
      "Epoch: 35/50: 100%|██████████| 29/29 [00:00<00:00, 141.28it/s, train_loss=0.00252, valid_loss=0.00498]\n",
      "Epoch: 36/50: 100%|██████████| 29/29 [00:00<00:00, 141.95it/s, train_loss=0.00278, valid_loss=0.00486]\n",
      "Epoch: 37/50: 100%|██████████| 29/29 [00:00<00:00, 140.05it/s, train_loss=0.00268, valid_loss=0.00537]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 58/58 [00:00<00:00, 118.73it/s, train_loss=0.0248, valid_loss=0.0256]\n",
      "Epoch: 2/50: 100%|██████████| 58/58 [00:00<00:00, 141.91it/s, train_loss=0.00703, valid_loss=0.00378]\n",
      "Epoch: 3/50: 100%|██████████| 58/58 [00:00<00:00, 141.94it/s, train_loss=0.00665, valid_loss=0.00576]\n",
      "Epoch: 4/50: 100%|██████████| 58/58 [00:00<00:00, 142.30it/s, train_loss=0.00574, valid_loss=0.00291]\n",
      "Epoch: 5/50: 100%|██████████| 58/58 [00:00<00:00, 128.97it/s, train_loss=0.00425, valid_loss=0.00302]\n",
      "Epoch: 6/50: 100%|██████████| 58/58 [00:00<00:00, 141.09it/s, train_loss=0.00388, valid_loss=0.00645]\n",
      "Epoch: 7/50: 100%|██████████| 58/58 [00:00<00:00, 140.89it/s, train_loss=0.00476, valid_loss=0.00609]\n",
      "Epoch: 8/50: 100%|██████████| 58/58 [00:00<00:00, 139.67it/s, train_loss=0.00468, valid_loss=0.00202]\n",
      "Epoch: 9/50: 100%|██████████| 58/58 [00:00<00:00, 140.99it/s, train_loss=0.00467, valid_loss=0.00187]\n",
      "Epoch: 10/50: 100%|██████████| 58/58 [00:00<00:00, 141.71it/s, train_loss=0.00349, valid_loss=0.00245]\n",
      "Epoch: 11/50: 100%|██████████| 58/58 [00:00<00:00, 141.03it/s, train_loss=0.00453, valid_loss=0.00293]\n",
      "Epoch: 12/50: 100%|██████████| 58/58 [00:00<00:00, 141.20it/s, train_loss=0.00397, valid_loss=0.00353]\n",
      "Epoch: 13/50: 100%|██████████| 58/58 [00:00<00:00, 140.91it/s, train_loss=0.00415, valid_loss=0.00305]\n",
      "Epoch: 14/50: 100%|██████████| 58/58 [00:00<00:00, 135.19it/s, train_loss=0.00515, valid_loss=0.00188]\n",
      "Epoch: 15/50: 100%|██████████| 58/58 [00:00<00:00, 134.45it/s, train_loss=0.0051, valid_loss=0.00248] \n",
      "Epoch: 16/50: 100%|██████████| 58/58 [00:00<00:00, 142.41it/s, train_loss=0.00398, valid_loss=0.00275]\n",
      "Epoch: 17/50: 100%|██████████| 58/58 [00:00<00:00, 141.33it/s, train_loss=0.00358, valid_loss=0.0027] \n",
      "Epoch: 18/50: 100%|██████████| 58/58 [00:00<00:00, 141.87it/s, train_loss=0.00381, valid_loss=0.00361]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 87/87 [00:00<00:00, 131.27it/s, train_loss=0.00894, valid_loss=0.00708]\n",
      "Epoch: 2/50: 100%|██████████| 87/87 [00:00<00:00, 141.44it/s, train_loss=0.00653, valid_loss=0.00571]\n",
      "Epoch: 3/50: 100%|██████████| 87/87 [00:00<00:00, 141.76it/s, train_loss=0.00594, valid_loss=0.00419]\n",
      "Epoch: 4/50: 100%|██████████| 87/87 [00:00<00:00, 142.63it/s, train_loss=0.00538, valid_loss=0.00398]\n",
      "Epoch: 5/50: 100%|██████████| 87/87 [00:00<00:00, 142.13it/s, train_loss=0.00513, valid_loss=0.00368]\n",
      "Epoch: 6/50: 100%|██████████| 87/87 [00:00<00:00, 142.52it/s, train_loss=0.0044, valid_loss=0.00364] \n",
      "Epoch: 7/50: 100%|██████████| 87/87 [00:00<00:00, 140.46it/s, train_loss=0.00525, valid_loss=0.00423]\n",
      "Epoch: 8/50: 100%|██████████| 87/87 [00:00<00:00, 142.57it/s, train_loss=0.00359, valid_loss=0.00357]\n",
      "Epoch: 9/50: 100%|██████████| 87/87 [00:00<00:00, 137.50it/s, train_loss=0.00422, valid_loss=0.0042] \n",
      "Epoch: 10/50: 100%|██████████| 87/87 [00:00<00:00, 142.58it/s, train_loss=0.00373, valid_loss=0.00441]\n",
      "Epoch: 11/50: 100%|██████████| 87/87 [00:00<00:00, 142.67it/s, train_loss=0.00382, valid_loss=0.00405]\n",
      "Epoch: 12/50: 100%|██████████| 87/87 [00:00<00:00, 142.99it/s, train_loss=0.00373, valid_loss=0.00436]\n",
      "Epoch: 13/50: 100%|██████████| 87/87 [00:00<00:00, 137.59it/s, train_loss=0.00327, valid_loss=0.00451]\n",
      "Epoch: 14/50: 100%|██████████| 87/87 [00:00<00:00, 142.61it/s, train_loss=0.00389, valid_loss=0.00357]\n",
      "Epoch: 15/50: 100%|██████████| 87/87 [00:00<00:00, 137.99it/s, train_loss=0.00362, valid_loss=0.00372]\n",
      "Epoch: 16/50: 100%|██████████| 87/87 [00:00<00:00, 142.47it/s, train_loss=0.00363, valid_loss=0.00403]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 115/115 [00:00<00:00, 138.06it/s, train_loss=0.0089, valid_loss=0.00467] \n",
      "Epoch: 2/50: 100%|██████████| 115/115 [00:00<00:00, 145.94it/s, train_loss=0.0059, valid_loss=0.00285] \n",
      "Epoch: 3/50: 100%|██████████| 115/115 [00:00<00:00, 143.49it/s, train_loss=0.00577, valid_loss=0.00281]\n",
      "Epoch: 4/50: 100%|██████████| 115/115 [00:00<00:00, 146.44it/s, train_loss=0.00528, valid_loss=0.0022] \n",
      "Epoch: 5/50: 100%|██████████| 115/115 [00:00<00:00, 146.35it/s, train_loss=0.00498, valid_loss=0.00298]\n",
      "Epoch: 6/50: 100%|██████████| 115/115 [00:00<00:00, 146.19it/s, train_loss=0.00608, valid_loss=0.00303]\n",
      "Epoch: 7/50: 100%|██████████| 115/115 [00:00<00:00, 146.95it/s, train_loss=0.00501, valid_loss=0.00209]\n",
      "Epoch: 8/50: 100%|██████████| 115/115 [00:00<00:00, 146.44it/s, train_loss=0.0043, valid_loss=0.00183] \n",
      "Epoch: 9/50: 100%|██████████| 115/115 [00:00<00:00, 146.46it/s, train_loss=0.00407, valid_loss=0.00262]\n",
      "Epoch: 10/50: 100%|██████████| 115/115 [00:00<00:00, 142.93it/s, train_loss=0.00388, valid_loss=0.00193]\n",
      "Epoch: 11/50: 100%|██████████| 115/115 [00:00<00:00, 146.45it/s, train_loss=0.00443, valid_loss=0.00268]\n",
      "Epoch: 12/50: 100%|██████████| 115/115 [00:00<00:00, 146.79it/s, train_loss=0.00455, valid_loss=0.00191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 144/144 [00:01<00:00, 138.91it/s, train_loss=0.00731, valid_loss=0.00537]\n",
      "Epoch: 2/50: 100%|██████████| 144/144 [00:01<00:00, 143.44it/s, train_loss=0.00601, valid_loss=0.00331]\n",
      "Epoch: 3/50: 100%|██████████| 144/144 [00:00<00:00, 146.21it/s, train_loss=0.00616, valid_loss=0.00286]\n",
      "Epoch: 4/50: 100%|██████████| 144/144 [00:00<00:00, 147.04it/s, train_loss=0.00675, valid_loss=0.00275]\n",
      "Epoch: 5/50: 100%|██████████| 144/144 [00:00<00:00, 145.49it/s, train_loss=0.00452, valid_loss=0.00244]\n",
      "Epoch: 6/50: 100%|██████████| 144/144 [00:00<00:00, 146.77it/s, train_loss=0.00476, valid_loss=0.00254]\n",
      "Epoch: 7/50: 100%|██████████| 144/144 [00:00<00:00, 146.38it/s, train_loss=0.00452, valid_loss=0.00267]\n",
      "Epoch: 8/50: 100%|██████████| 144/144 [00:01<00:00, 142.42it/s, train_loss=0.00503, valid_loss=0.00324]\n",
      "Epoch: 9/50: 100%|██████████| 144/144 [00:00<00:00, 146.49it/s, train_loss=0.00501, valid_loss=0.0028] \n",
      "Epoch: 10/50: 100%|██████████| 144/144 [00:00<00:00, 146.08it/s, train_loss=0.00504, valid_loss=0.00306]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config: batch_size--512, lr--0.001, number_epoch--50, hidden_dim--30,drop_prob-0.1,weight_decay-1e-07\n",
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 8/8 [00:00<00:00, 82.41it/s, train_loss=0.0678, valid_loss=0.109]\n",
      "Epoch: 2/50: 100%|██████████| 8/8 [00:00<00:00, 88.91it/s, train_loss=0.0564, valid_loss=0.0899]\n",
      "Epoch: 3/50: 100%|██████████| 8/8 [00:00<00:00, 139.57it/s, train_loss=0.0491, valid_loss=0.0717]\n",
      "Epoch: 4/50: 100%|██████████| 8/8 [00:00<00:00, 129.77it/s, train_loss=0.0411, valid_loss=0.0616]\n",
      "Epoch: 5/50: 100%|██████████| 8/8 [00:00<00:00, 133.58it/s, train_loss=0.033, valid_loss=0.0479]\n",
      "Epoch: 6/50: 100%|██████████| 8/8 [00:00<00:00, 131.09it/s, train_loss=0.0249, valid_loss=0.0371]\n",
      "Epoch: 7/50: 100%|██████████| 8/8 [00:00<00:00, 131.90it/s, train_loss=0.0227, valid_loss=0.0338]\n",
      "Epoch: 8/50: 100%|██████████| 8/8 [00:00<00:00, 63.67it/s, train_loss=0.0214, valid_loss=0.0343]\n",
      "Epoch: 9/50: 100%|██████████| 8/8 [00:00<00:00, 128.77it/s, train_loss=0.0191, valid_loss=0.0306]\n",
      "Epoch: 10/50: 100%|██████████| 8/8 [00:00<00:00, 128.71it/s, train_loss=0.0157, valid_loss=0.0253]\n",
      "Epoch: 11/50: 100%|██████████| 8/8 [00:00<00:00, 104.24it/s, train_loss=0.0133, valid_loss=0.0224]\n",
      "Epoch: 12/50: 100%|██████████| 8/8 [00:00<00:00, 129.69it/s, train_loss=0.0117, valid_loss=0.0209]\n",
      "Epoch: 13/50: 100%|██████████| 8/8 [00:00<00:00, 129.52it/s, train_loss=0.0125, valid_loss=0.0207]\n",
      "Epoch: 14/50: 100%|██████████| 8/8 [00:00<00:00, 101.08it/s, train_loss=0.012, valid_loss=0.0201]\n",
      "Epoch: 15/50: 100%|██████████| 8/8 [00:00<00:00, 132.25it/s, train_loss=0.011, valid_loss=0.0196]\n",
      "Epoch: 16/50: 100%|██████████| 8/8 [00:00<00:00, 128.94it/s, train_loss=0.0112, valid_loss=0.019]\n",
      "Epoch: 17/50: 100%|██████████| 8/8 [00:00<00:00, 82.15it/s, train_loss=0.0102, valid_loss=0.0186]\n",
      "Epoch: 18/50: 100%|██████████| 8/8 [00:00<00:00, 127.12it/s, train_loss=0.0102, valid_loss=0.0179]\n",
      "Epoch: 19/50: 100%|██████████| 8/8 [00:00<00:00, 131.62it/s, train_loss=0.0104, valid_loss=0.017]\n",
      "Epoch: 20/50: 100%|██████████| 8/8 [00:00<00:00, 131.29it/s, train_loss=0.00941, valid_loss=0.0165]\n",
      "Epoch: 21/50: 100%|██████████| 8/8 [00:00<00:00, 127.89it/s, train_loss=0.00907, valid_loss=0.0157]\n",
      "Epoch: 22/50: 100%|██████████| 8/8 [00:00<00:00, 132.43it/s, train_loss=0.00883, valid_loss=0.0147]\n",
      "Epoch: 23/50: 100%|██████████| 8/8 [00:00<00:00, 131.10it/s, train_loss=0.0085, valid_loss=0.0143]\n",
      "Epoch: 24/50: 100%|██████████| 8/8 [00:00<00:00, 129.44it/s, train_loss=0.00813, valid_loss=0.0134]\n",
      "Epoch: 25/50: 100%|██████████| 8/8 [00:00<00:00, 130.45it/s, train_loss=0.0078, valid_loss=0.0127]\n",
      "Epoch: 26/50: 100%|██████████| 8/8 [00:00<00:00, 129.74it/s, train_loss=0.00774, valid_loss=0.0123]\n",
      "Epoch: 27/50: 100%|██████████| 8/8 [00:00<00:00, 129.44it/s, train_loss=0.00782, valid_loss=0.0113]\n",
      "Epoch: 28/50: 100%|██████████| 8/8 [00:00<00:00, 130.60it/s, train_loss=0.00739, valid_loss=0.0105]\n",
      "Epoch: 29/50: 100%|██████████| 8/8 [00:00<00:00, 130.88it/s, train_loss=0.00726, valid_loss=0.01]\n",
      "Epoch: 30/50: 100%|██████████| 8/8 [00:00<00:00, 129.52it/s, train_loss=0.00665, valid_loss=0.01]\n",
      "Epoch: 31/50: 100%|██████████| 8/8 [00:00<00:00, 85.02it/s, train_loss=0.00652, valid_loss=0.00898]\n",
      "Epoch: 32/50: 100%|██████████| 8/8 [00:00<00:00, 131.68it/s, train_loss=0.00675, valid_loss=0.00886]\n",
      "Epoch: 33/50: 100%|██████████| 8/8 [00:00<00:00, 132.55it/s, train_loss=0.00635, valid_loss=0.00858]\n",
      "Epoch: 34/50: 100%|██████████| 8/8 [00:00<00:00, 82.27it/s, train_loss=0.00621, valid_loss=0.00819]\n",
      "Epoch: 35/50: 100%|██████████| 8/8 [00:00<00:00, 128.91it/s, train_loss=0.00603, valid_loss=0.00794]\n",
      "Epoch: 36/50: 100%|██████████| 8/8 [00:00<00:00, 130.41it/s, train_loss=0.0063, valid_loss=0.0078]\n",
      "Epoch: 37/50: 100%|██████████| 8/8 [00:00<00:00, 132.99it/s, train_loss=0.00591, valid_loss=0.00781]\n",
      "Epoch: 38/50: 100%|██████████| 8/8 [00:00<00:00, 130.56it/s, train_loss=0.00586, valid_loss=0.00746]\n",
      "Epoch: 39/50: 100%|██████████| 8/8 [00:00<00:00, 129.56it/s, train_loss=0.00621, valid_loss=0.00731]\n",
      "Epoch: 40/50: 100%|██████████| 8/8 [00:00<00:00, 132.06it/s, train_loss=0.00615, valid_loss=0.00747]\n",
      "Epoch: 41/50: 100%|██████████| 8/8 [00:00<00:00, 131.72it/s, train_loss=0.00586, valid_loss=0.00727]\n",
      "Epoch: 42/50: 100%|██████████| 8/8 [00:00<00:00, 129.20it/s, train_loss=0.00597, valid_loss=0.0071]\n",
      "Epoch: 43/50: 100%|██████████| 8/8 [00:00<00:00, 128.14it/s, train_loss=0.00571, valid_loss=0.00707]\n",
      "Epoch: 44/50: 100%|██████████| 8/8 [00:00<00:00, 82.55it/s, train_loss=0.00584, valid_loss=0.00693]\n",
      "Epoch: 45/50: 100%|██████████| 8/8 [00:00<00:00, 128.44it/s, train_loss=0.00563, valid_loss=0.00682]\n",
      "Epoch: 46/50: 100%|██████████| 8/8 [00:00<00:00, 129.72it/s, train_loss=0.00571, valid_loss=0.00696]\n",
      "Epoch: 47/50: 100%|██████████| 8/8 [00:00<00:00, 131.16it/s, train_loss=0.00594, valid_loss=0.00663]\n",
      "Epoch: 48/50: 100%|██████████| 8/8 [00:00<00:00, 129.31it/s, train_loss=0.00536, valid_loss=0.0065]\n",
      "Epoch: 49/50: 100%|██████████| 8/8 [00:00<00:00, 129.17it/s, train_loss=0.00539, valid_loss=0.0065]\n",
      "Epoch: 50/50: 100%|██████████| 8/8 [00:00<00:00, 131.08it/s, train_loss=0.00536, valid_loss=0.00641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 15/15 [00:00<00:00, 88.90it/s, train_loss=0.0838, valid_loss=0.14]\n",
      "Epoch: 2/50: 100%|██████████| 15/15 [00:00<00:00, 103.16it/s, train_loss=0.0421, valid_loss=0.0504]\n",
      "Epoch: 3/50: 100%|██████████| 15/15 [00:00<00:00, 140.47it/s, train_loss=0.0268, valid_loss=0.0213]\n",
      "Epoch: 4/50: 100%|██████████| 15/15 [00:00<00:00, 124.22it/s, train_loss=0.0232, valid_loss=0.0218]\n",
      "Epoch: 5/50: 100%|██████████| 15/15 [00:00<00:00, 141.37it/s, train_loss=0.019, valid_loss=0.0145]\n",
      "Epoch: 6/50: 100%|██████████| 15/15 [00:00<00:00, 139.92it/s, train_loss=0.0165, valid_loss=0.0106]\n",
      "Epoch: 7/50: 100%|██████████| 15/15 [00:00<00:00, 114.28it/s, train_loss=0.0163, valid_loss=0.00981]\n",
      "Epoch: 8/50: 100%|██████████| 15/15 [00:00<00:00, 134.97it/s, train_loss=0.014, valid_loss=0.00955]\n",
      "Epoch: 9/50: 100%|██████████| 15/15 [00:00<00:00, 105.40it/s, train_loss=0.0134, valid_loss=0.00864]\n",
      "Epoch: 10/50: 100%|██████████| 15/15 [00:00<00:00, 140.54it/s, train_loss=0.0115, valid_loss=0.00773]\n",
      "Epoch: 11/50: 100%|██████████| 15/15 [00:00<00:00, 110.82it/s, train_loss=0.0109, valid_loss=0.0072]\n",
      "Epoch: 12/50: 100%|██████████| 15/15 [00:00<00:00, 121.84it/s, train_loss=0.00949, valid_loss=0.00668]\n",
      "Epoch: 13/50: 100%|██████████| 15/15 [00:00<00:00, 131.77it/s, train_loss=0.0089, valid_loss=0.00643]\n",
      "Epoch: 14/50: 100%|██████████| 15/15 [00:00<00:00, 125.90it/s, train_loss=0.00821, valid_loss=0.00569]\n",
      "Epoch: 15/50: 100%|██████████| 15/15 [00:00<00:00, 142.59it/s, train_loss=0.00838, valid_loss=0.00583]\n",
      "Epoch: 16/50: 100%|██████████| 15/15 [00:00<00:00, 125.32it/s, train_loss=0.00765, valid_loss=0.00492]\n",
      "Epoch: 17/50: 100%|██████████| 15/15 [00:00<00:00, 105.28it/s, train_loss=0.0076, valid_loss=0.00467]\n",
      "Epoch: 18/50: 100%|██████████| 15/15 [00:00<00:00, 141.94it/s, train_loss=0.00719, valid_loss=0.00523]\n",
      "Epoch: 19/50: 100%|██████████| 15/15 [00:00<00:00, 130.24it/s, train_loss=0.00781, valid_loss=0.00413]\n",
      "Epoch: 20/50: 100%|██████████| 15/15 [00:00<00:00, 136.03it/s, train_loss=0.00726, valid_loss=0.00517]\n",
      "Epoch: 21/50: 100%|██████████| 15/15 [00:00<00:00, 121.74it/s, train_loss=0.00715, valid_loss=0.00451]\n",
      "Epoch: 22/50: 100%|██████████| 15/15 [00:00<00:00, 105.88it/s, train_loss=0.00707, valid_loss=0.00396]\n",
      "Epoch: 23/50: 100%|██████████| 15/15 [00:00<00:00, 135.18it/s, train_loss=0.00722, valid_loss=0.00454]\n",
      "Epoch: 24/50: 100%|██████████| 15/15 [00:00<00:00, 90.85it/s, train_loss=0.0069, valid_loss=0.00427]\n",
      "Epoch: 25/50: 100%|██████████| 15/15 [00:00<00:00, 136.61it/s, train_loss=0.00702, valid_loss=0.00402]\n",
      "Epoch: 26/50: 100%|██████████| 15/15 [00:00<00:00, 123.60it/s, train_loss=0.00693, valid_loss=0.00408]\n",
      "Epoch: 27/50: 100%|██████████| 15/15 [00:00<00:00, 111.39it/s, train_loss=0.00702, valid_loss=0.00407]\n",
      "Epoch: 28/50: 100%|██████████| 15/15 [00:00<00:00, 125.94it/s, train_loss=0.00626, valid_loss=0.00398]\n",
      "Epoch: 29/50: 100%|██████████| 15/15 [00:00<00:00, 127.12it/s, train_loss=0.00649, valid_loss=0.00389]\n",
      "Epoch: 30/50: 100%|██████████| 15/15 [00:00<00:00, 138.38it/s, train_loss=0.00639, valid_loss=0.00343]\n",
      "Epoch: 31/50: 100%|██████████| 15/15 [00:00<00:00, 85.72it/s, train_loss=0.00688, valid_loss=0.00348]\n",
      "Epoch: 32/50: 100%|██████████| 15/15 [00:00<00:00, 142.95it/s, train_loss=0.00613, valid_loss=0.00316]\n",
      "Epoch: 33/50: 100%|██████████| 15/15 [00:00<00:00, 131.48it/s, train_loss=0.00579, valid_loss=0.00385]\n",
      "Epoch: 34/50: 100%|██████████| 15/15 [00:00<00:00, 119.20it/s, train_loss=0.00604, valid_loss=0.00333]\n",
      "Epoch: 35/50: 100%|██████████| 15/15 [00:00<00:00, 132.75it/s, train_loss=0.00625, valid_loss=0.0032]\n",
      "Epoch: 36/50: 100%|██████████| 15/15 [00:00<00:00, 143.89it/s, train_loss=0.00561, valid_loss=0.00301]\n",
      "Epoch: 37/50: 100%|██████████| 15/15 [00:00<00:00, 128.79it/s, train_loss=0.00608, valid_loss=0.00351]\n",
      "Epoch: 38/50: 100%|██████████| 15/15 [00:00<00:00, 94.97it/s, train_loss=0.00566, valid_loss=0.00352]\n",
      "Epoch: 39/50: 100%|██████████| 15/15 [00:00<00:00, 124.61it/s, train_loss=0.00544, valid_loss=0.00347]\n",
      "Epoch: 40/50: 100%|██████████| 15/15 [00:00<00:00, 135.02it/s, train_loss=0.00519, valid_loss=0.00272]\n",
      "Epoch: 41/50: 100%|██████████| 15/15 [00:00<00:00, 122.12it/s, train_loss=0.00569, valid_loss=0.00298]\n",
      "Epoch: 42/50: 100%|██████████| 15/15 [00:00<00:00, 138.71it/s, train_loss=0.00572, valid_loss=0.00332]\n",
      "Epoch: 43/50: 100%|██████████| 15/15 [00:00<00:00, 142.40it/s, train_loss=0.00577, valid_loss=0.00285]\n",
      "Epoch: 44/50: 100%|██████████| 15/15 [00:00<00:00, 114.73it/s, train_loss=0.00555, valid_loss=0.00294]\n",
      "Epoch: 45/50: 100%|██████████| 15/15 [00:00<00:00, 132.70it/s, train_loss=0.00543, valid_loss=0.0032]\n",
      "Epoch: 46/50: 100%|██████████| 15/15 [00:00<00:00, 95.57it/s, train_loss=0.00601, valid_loss=0.00289]\n",
      "Epoch: 47/50: 100%|██████████| 15/15 [00:00<00:00, 142.77it/s, train_loss=0.00545, valid_loss=0.00277]\n",
      "Epoch: 48/50: 100%|██████████| 15/15 [00:00<00:00, 142.08it/s, train_loss=0.00511, valid_loss=0.00321]\n",
      "Epoch: 49/50: 100%|██████████| 15/15 [00:00<00:00, 115.32it/s, train_loss=0.00593, valid_loss=0.00251]\n",
      "Epoch: 50/50: 100%|██████████| 15/15 [00:00<00:00, 141.35it/s, train_loss=0.00579, valid_loss=0.00258]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 22/22 [00:00<00:00, 80.67it/s, train_loss=0.0697, valid_loss=0.0842]\n",
      "Epoch: 2/50: 100%|██████████| 22/22 [00:00<00:00, 113.42it/s, train_loss=0.044, valid_loss=0.0484] \n",
      "Epoch: 3/50: 100%|██████████| 22/22 [00:00<00:00, 123.06it/s, train_loss=0.031, valid_loss=0.0362] \n",
      "Epoch: 4/50: 100%|██████████| 22/22 [00:00<00:00, 132.06it/s, train_loss=0.0288, valid_loss=0.0335]\n",
      "Epoch: 5/50: 100%|██████████| 22/22 [00:00<00:00, 131.91it/s, train_loss=0.0269, valid_loss=0.0302]\n",
      "Epoch: 6/50: 100%|██████████| 22/22 [00:00<00:00, 95.07it/s, train_loss=0.0253, valid_loss=0.0282]\n",
      "Epoch: 7/50: 100%|██████████| 22/22 [00:00<00:00, 119.30it/s, train_loss=0.0238, valid_loss=0.0251]\n",
      "Epoch: 8/50: 100%|██████████| 22/22 [00:00<00:00, 134.73it/s, train_loss=0.0221, valid_loss=0.0237]\n",
      "Epoch: 9/50: 100%|██████████| 22/22 [00:00<00:00, 123.21it/s, train_loss=0.0216, valid_loss=0.0223]\n",
      "Epoch: 10/50: 100%|██████████| 22/22 [00:00<00:00, 137.12it/s, train_loss=0.0212, valid_loss=0.0213]\n",
      "Epoch: 11/50: 100%|██████████| 22/22 [00:00<00:00, 106.97it/s, train_loss=0.0193, valid_loss=0.021]\n",
      "Epoch: 12/50: 100%|██████████| 22/22 [00:00<00:00, 135.20it/s, train_loss=0.0194, valid_loss=0.0206]\n",
      "Epoch: 13/50: 100%|██████████| 22/22 [00:00<00:00, 135.44it/s, train_loss=0.0191, valid_loss=0.0206]\n",
      "Epoch: 14/50: 100%|██████████| 22/22 [00:00<00:00, 135.49it/s, train_loss=0.0196, valid_loss=0.0204]\n",
      "Epoch: 15/50: 100%|██████████| 22/22 [00:00<00:00, 110.17it/s, train_loss=0.0195, valid_loss=0.0202]\n",
      "Epoch: 16/50: 100%|██████████| 22/22 [00:00<00:00, 135.28it/s, train_loss=0.0156, valid_loss=0.0155]\n",
      "Epoch: 17/50: 100%|██████████| 22/22 [00:00<00:00, 136.42it/s, train_loss=0.0132, valid_loss=0.0131]\n",
      "Epoch: 18/50: 100%|██████████| 22/22 [00:00<00:00, 135.54it/s, train_loss=0.0132, valid_loss=0.0128]\n",
      "Epoch: 19/50: 100%|██████████| 22/22 [00:00<00:00, 110.80it/s, train_loss=0.0126, valid_loss=0.0124]\n",
      "Epoch: 20/50: 100%|██████████| 22/22 [00:00<00:00, 135.02it/s, train_loss=0.0125, valid_loss=0.0123]\n",
      "Epoch: 21/50: 100%|██████████| 22/22 [00:00<00:00, 135.54it/s, train_loss=0.0131, valid_loss=0.0119]\n",
      "Epoch: 22/50: 100%|██████████| 22/22 [00:00<00:00, 135.91it/s, train_loss=0.012, valid_loss=0.0118] \n",
      "Epoch: 23/50: 100%|██████████| 22/22 [00:00<00:00, 136.41it/s, train_loss=0.0117, valid_loss=0.0117]\n",
      "Epoch: 24/50: 100%|██████████| 22/22 [00:00<00:00, 110.23it/s, train_loss=0.0118, valid_loss=0.0118]\n",
      "Epoch: 25/50: 100%|██████████| 22/22 [00:00<00:00, 136.23it/s, train_loss=0.0125, valid_loss=0.0117]\n",
      "Epoch: 26/50: 100%|██████████| 22/22 [00:00<00:00, 135.85it/s, train_loss=0.0121, valid_loss=0.0117]\n",
      "Epoch: 27/50: 100%|██████████| 22/22 [00:00<00:00, 136.45it/s, train_loss=0.0112, valid_loss=0.0115]\n",
      "Epoch: 28/50: 100%|██████████| 22/22 [00:00<00:00, 110.81it/s, train_loss=0.011, valid_loss=0.0115] \n",
      "Epoch: 29/50: 100%|██████████| 22/22 [00:00<00:00, 136.52it/s, train_loss=0.0118, valid_loss=0.0117]\n",
      "Epoch: 30/50: 100%|██████████| 22/22 [00:00<00:00, 134.53it/s, train_loss=0.012, valid_loss=0.0116]\n",
      "Epoch: 31/50: 100%|██████████| 22/22 [00:00<00:00, 135.88it/s, train_loss=0.0116, valid_loss=0.0115]\n",
      "Epoch: 32/50: 100%|██████████| 22/22 [00:00<00:00, 136.83it/s, train_loss=0.0113, valid_loss=0.0114]\n",
      "Epoch: 33/50: 100%|██████████| 22/22 [00:00<00:00, 110.31it/s, train_loss=0.011, valid_loss=0.0114]\n",
      "Epoch: 34/50: 100%|██████████| 22/22 [00:00<00:00, 135.92it/s, train_loss=0.0103, valid_loss=0.0113]\n",
      "Epoch: 35/50: 100%|██████████| 22/22 [00:00<00:00, 135.18it/s, train_loss=0.0119, valid_loss=0.0114]\n",
      "Epoch: 36/50: 100%|██████████| 22/22 [00:00<00:00, 134.41it/s, train_loss=0.012, valid_loss=0.0113] \n",
      "Epoch: 37/50: 100%|██████████| 22/22 [00:00<00:00, 110.41it/s, train_loss=0.0107, valid_loss=0.0115]\n",
      "Epoch: 38/50: 100%|██████████| 22/22 [00:00<00:00, 135.76it/s, train_loss=0.012, valid_loss=0.0114] \n",
      "Epoch: 39/50: 100%|██████████| 22/22 [00:00<00:00, 134.71it/s, train_loss=0.0108, valid_loss=0.0113]\n",
      "Epoch: 40/50: 100%|██████████| 22/22 [00:00<00:00, 122.53it/s, train_loss=0.0111, valid_loss=0.0113]\n",
      "Epoch: 41/50: 100%|██████████| 22/22 [00:00<00:00, 136.60it/s, train_loss=0.0112, valid_loss=0.0114]\n",
      "Epoch: 42/50: 100%|██████████| 22/22 [00:00<00:00, 106.38it/s, train_loss=0.0117, valid_loss=0.0113]\n",
      "Epoch: 43/50: 100%|██████████| 22/22 [00:00<00:00, 134.32it/s, train_loss=0.0108, valid_loss=0.0112]\n",
      "Epoch: 44/50: 100%|██████████| 22/22 [00:00<00:00, 134.61it/s, train_loss=0.0109, valid_loss=0.0113]\n",
      "Epoch: 45/50: 100%|██████████| 22/22 [00:00<00:00, 134.85it/s, train_loss=0.0111, valid_loss=0.0116]\n",
      "Epoch: 46/50: 100%|██████████| 22/22 [00:00<00:00, 135.96it/s, train_loss=0.0122, valid_loss=0.0112]\n",
      "Epoch: 47/50: 100%|██████████| 22/22 [00:00<00:00, 108.14it/s, train_loss=0.0115, valid_loss=0.0113]\n",
      "Epoch: 48/50: 100%|██████████| 22/22 [00:00<00:00, 134.25it/s, train_loss=0.0117, valid_loss=0.0111]\n",
      "Epoch: 49/50: 100%|██████████| 22/22 [00:00<00:00, 135.53it/s, train_loss=0.0105, valid_loss=0.0112]\n",
      "Epoch: 50/50: 100%|██████████| 22/22 [00:00<00:00, 135.36it/s, train_loss=0.011, valid_loss=0.0114] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 22/22 [00:00<00:00, 78.42it/s, train_loss=0.0603, valid_loss=0.0693]\n",
      "Epoch: 2/50: 100%|██████████| 22/22 [00:00<00:00, 123.57it/s, train_loss=0.0325, valid_loss=0.0368]\n",
      "Epoch: 3/50: 100%|██████████| 22/22 [00:00<00:00, 135.06it/s, train_loss=0.0211, valid_loss=0.0253]\n",
      "Epoch: 4/50: 100%|██████████| 22/22 [00:00<00:00, 135.74it/s, train_loss=0.0182, valid_loss=0.0216]\n",
      "Epoch: 5/50: 100%|██████████| 22/22 [00:00<00:00, 135.99it/s, train_loss=0.0155, valid_loss=0.0201]\n",
      "Epoch: 6/50: 100%|██████████| 22/22 [00:00<00:00, 109.76it/s, train_loss=0.0145, valid_loss=0.0177]\n",
      "Epoch: 7/50: 100%|██████████| 22/22 [00:00<00:00, 135.35it/s, train_loss=0.0134, valid_loss=0.0144]\n",
      "Epoch: 8/50: 100%|██████████| 22/22 [00:00<00:00, 135.67it/s, train_loss=0.0115, valid_loss=0.0108]\n",
      "Epoch: 9/50: 100%|██████████| 22/22 [00:00<00:00, 135.96it/s, train_loss=0.00966, valid_loss=0.00821]\n",
      "Epoch: 10/50: 100%|██████████| 22/22 [00:00<00:00, 110.26it/s, train_loss=0.00927, valid_loss=0.00735]\n",
      "Epoch: 11/50: 100%|██████████| 22/22 [00:00<00:00, 135.44it/s, train_loss=0.00831, valid_loss=0.00656]\n",
      "Epoch: 12/50: 100%|██████████| 22/22 [00:00<00:00, 135.56it/s, train_loss=0.00793, valid_loss=0.00606]\n",
      "Epoch: 13/50: 100%|██████████| 22/22 [00:00<00:00, 135.48it/s, train_loss=0.00791, valid_loss=0.006]  \n",
      "Epoch: 14/50: 100%|██████████| 22/22 [00:00<00:00, 107.96it/s, train_loss=0.00803, valid_loss=0.00559]\n",
      "Epoch: 15/50: 100%|██████████| 22/22 [00:00<00:00, 135.38it/s, train_loss=0.00744, valid_loss=0.00534]\n",
      "Epoch: 16/50: 100%|██████████| 22/22 [00:00<00:00, 135.22it/s, train_loss=0.00709, valid_loss=0.00529]\n",
      "Epoch: 17/50: 100%|██████████| 22/22 [00:00<00:00, 134.88it/s, train_loss=0.00644, valid_loss=0.00507]\n",
      "Epoch: 18/50: 100%|██████████| 22/22 [00:00<00:00, 136.23it/s, train_loss=0.00704, valid_loss=0.00496]\n",
      "Epoch: 19/50: 100%|██████████| 22/22 [00:00<00:00, 109.98it/s, train_loss=0.00665, valid_loss=0.00501]\n",
      "Epoch: 20/50: 100%|██████████| 22/22 [00:00<00:00, 134.97it/s, train_loss=0.0063, valid_loss=0.00489] \n",
      "Epoch: 21/50: 100%|██████████| 22/22 [00:00<00:00, 135.08it/s, train_loss=0.00638, valid_loss=0.00466]\n",
      "Epoch: 22/50: 100%|██████████| 22/22 [00:00<00:00, 135.40it/s, train_loss=0.00637, valid_loss=0.00467]\n",
      "Epoch: 23/50: 100%|██████████| 22/22 [00:00<00:00, 109.10it/s, train_loss=0.00632, valid_loss=0.00471]\n",
      "Epoch: 24/50: 100%|██████████| 22/22 [00:00<00:00, 134.70it/s, train_loss=0.00563, valid_loss=0.00444]\n",
      "Epoch: 25/50: 100%|██████████| 22/22 [00:00<00:00, 135.43it/s, train_loss=0.00576, valid_loss=0.0043] \n",
      "Epoch: 26/50: 100%|██████████| 22/22 [00:00<00:00, 135.13it/s, train_loss=0.00591, valid_loss=0.00437]\n",
      "Epoch: 27/50: 100%|██████████| 22/22 [00:00<00:00, 134.48it/s, train_loss=0.00624, valid_loss=0.00418]\n",
      "Epoch: 28/50: 100%|██████████| 22/22 [00:00<00:00, 109.13it/s, train_loss=0.00565, valid_loss=0.00411]\n",
      "Epoch: 29/50: 100%|██████████| 22/22 [00:00<00:00, 134.38it/s, train_loss=0.00571, valid_loss=0.004]  \n",
      "Epoch: 30/50: 100%|██████████| 22/22 [00:00<00:00, 135.57it/s, train_loss=0.00552, valid_loss=0.00404]\n",
      "Epoch: 31/50: 100%|██████████| 22/22 [00:00<00:00, 134.67it/s, train_loss=0.0058, valid_loss=0.004]   \n",
      "Epoch: 32/50: 100%|██████████| 22/22 [00:00<00:00, 110.30it/s, train_loss=0.00569, valid_loss=0.00389]\n",
      "Epoch: 33/50: 100%|██████████| 22/22 [00:00<00:00, 134.44it/s, train_loss=0.00554, valid_loss=0.0038] \n",
      "Epoch: 34/50: 100%|██████████| 22/22 [00:00<00:00, 131.82it/s, train_loss=0.00549, valid_loss=0.00374]\n",
      "Epoch: 35/50: 100%|██████████| 22/22 [00:00<00:00, 135.14it/s, train_loss=0.00544, valid_loss=0.00369]\n",
      "Epoch: 36/50: 100%|██████████| 22/22 [00:00<00:00, 135.32it/s, train_loss=0.00519, valid_loss=0.00357]\n",
      "Epoch: 37/50: 100%|██████████| 22/22 [00:00<00:00, 101.73it/s, train_loss=0.00511, valid_loss=0.00369]\n",
      "Epoch: 38/50: 100%|██████████| 22/22 [00:00<00:00, 134.25it/s, train_loss=0.00528, valid_loss=0.00354]\n",
      "Epoch: 39/50: 100%|██████████| 22/22 [00:00<00:00, 134.78it/s, train_loss=0.00489, valid_loss=0.00364]\n",
      "Epoch: 40/50: 100%|██████████| 22/22 [00:00<00:00, 124.40it/s, train_loss=0.00478, valid_loss=0.00354]\n",
      "Epoch: 41/50: 100%|██████████| 22/22 [00:00<00:00, 135.85it/s, train_loss=0.00505, valid_loss=0.00357]\n",
      "Epoch: 42/50: 100%|██████████| 22/22 [00:00<00:00, 110.50it/s, train_loss=0.00467, valid_loss=0.00362]\n",
      "Epoch: 43/50: 100%|██████████| 22/22 [00:00<00:00, 134.92it/s, train_loss=0.00519, valid_loss=0.00349]\n",
      "Epoch: 44/50: 100%|██████████| 22/22 [00:00<00:00, 135.30it/s, train_loss=0.00478, valid_loss=0.00348]\n",
      "Epoch: 45/50: 100%|██████████| 22/22 [00:00<00:00, 134.30it/s, train_loss=0.00459, valid_loss=0.00353]\n",
      "Epoch: 46/50: 100%|██████████| 22/22 [00:00<00:00, 109.85it/s, train_loss=0.0051, valid_loss=0.00347] \n",
      "Epoch: 47/50: 100%|██████████| 22/22 [00:00<00:00, 134.78it/s, train_loss=0.00525, valid_loss=0.00352]\n",
      "Epoch: 48/50: 100%|██████████| 22/22 [00:00<00:00, 120.84it/s, train_loss=0.0047, valid_loss=0.0035]  \n",
      "Epoch: 49/50: 100%|██████████| 22/22 [00:00<00:00, 134.96it/s, train_loss=0.00442, valid_loss=0.00353]\n",
      "Epoch: 50/50: 100%|██████████| 22/22 [00:00<00:00, 134.40it/s, train_loss=0.00494, valid_loss=0.00342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 29/29 [00:00<00:00, 93.91it/s, train_loss=0.0732, valid_loss=0.0771]\n",
      "Epoch: 2/50: 100%|██████████| 29/29 [00:00<00:00, 142.14it/s, train_loss=0.0368, valid_loss=0.0298]\n",
      "Epoch: 3/50: 100%|██████████| 29/29 [00:00<00:00, 141.13it/s, train_loss=0.0281, valid_loss=0.0212]\n",
      "Epoch: 4/50: 100%|██████████| 29/29 [00:00<00:00, 120.01it/s, train_loss=0.022, valid_loss=0.018]  \n",
      "Epoch: 5/50: 100%|██████████| 29/29 [00:00<00:00, 142.08it/s, train_loss=0.0195, valid_loss=0.0162]\n",
      "Epoch: 6/50: 100%|██████████| 29/29 [00:00<00:00, 120.10it/s, train_loss=0.0135, valid_loss=0.00928]\n",
      "Epoch: 7/50: 100%|██████████| 29/29 [00:00<00:00, 140.79it/s, train_loss=0.00982, valid_loss=0.00557]\n",
      "Epoch: 8/50: 100%|██████████| 29/29 [00:00<00:00, 128.79it/s, train_loss=0.00948, valid_loss=0.00547]\n",
      "Epoch: 9/50: 100%|██████████| 29/29 [00:00<00:00, 141.80it/s, train_loss=0.00794, valid_loss=0.00464]\n",
      "Epoch: 10/50: 100%|██████████| 29/29 [00:00<00:00, 141.50it/s, train_loss=0.00799, valid_loss=0.00437]\n",
      "Epoch: 11/50: 100%|██████████| 29/29 [00:00<00:00, 142.78it/s, train_loss=0.00771, valid_loss=0.00376]\n",
      "Epoch: 12/50: 100%|██████████| 29/29 [00:00<00:00, 119.48it/s, train_loss=0.00742, valid_loss=0.0037] \n",
      "Epoch: 13/50: 100%|██████████| 29/29 [00:00<00:00, 141.85it/s, train_loss=0.00679, valid_loss=0.00395]\n",
      "Epoch: 14/50: 100%|██████████| 29/29 [00:00<00:00, 141.70it/s, train_loss=0.00663, valid_loss=0.003]  \n",
      "Epoch: 15/50: 100%|██████████| 29/29 [00:00<00:00, 141.48it/s, train_loss=0.00661, valid_loss=0.00302]\n",
      "Epoch: 16/50: 100%|██████████| 29/29 [00:00<00:00, 141.09it/s, train_loss=0.00626, valid_loss=0.00276]\n",
      "Epoch: 17/50: 100%|██████████| 29/29 [00:00<00:00, 116.77it/s, train_loss=0.00586, valid_loss=0.00253]\n",
      "Epoch: 18/50: 100%|██████████| 29/29 [00:00<00:00, 141.15it/s, train_loss=0.00618, valid_loss=0.00251]\n",
      "Epoch: 19/50: 100%|██████████| 29/29 [00:00<00:00, 142.57it/s, train_loss=0.00605, valid_loss=0.00243]\n",
      "Epoch: 20/50: 100%|██████████| 29/29 [00:00<00:00, 141.89it/s, train_loss=0.00635, valid_loss=0.00229]\n",
      "Epoch: 21/50: 100%|██████████| 29/29 [00:00<00:00, 142.32it/s, train_loss=0.00548, valid_loss=0.00238]\n",
      "Epoch: 22/50: 100%|██████████| 29/29 [00:00<00:00, 120.01it/s, train_loss=0.00583, valid_loss=0.00236]\n",
      "Epoch: 23/50: 100%|██████████| 29/29 [00:00<00:00, 141.18it/s, train_loss=0.00556, valid_loss=0.00207]\n",
      "Epoch: 24/50: 100%|██████████| 29/29 [00:00<00:00, 141.83it/s, train_loss=0.00559, valid_loss=0.00206]\n",
      "Epoch: 25/50: 100%|██████████| 29/29 [00:00<00:00, 130.39it/s, train_loss=0.00536, valid_loss=0.00249]\n",
      "Epoch: 26/50: 100%|██████████| 29/29 [00:00<00:00, 142.61it/s, train_loss=0.00578, valid_loss=0.00202]\n",
      "Epoch: 27/50: 100%|██████████| 29/29 [00:00<00:00, 120.75it/s, train_loss=0.00566, valid_loss=0.00219]\n",
      "Epoch: 28/50: 100%|██████████| 29/29 [00:00<00:00, 142.81it/s, train_loss=0.00589, valid_loss=0.002]  \n",
      "Epoch: 29/50: 100%|██████████| 29/29 [00:00<00:00, 141.24it/s, train_loss=0.00565, valid_loss=0.0021] \n",
      "Epoch: 30/50: 100%|██████████| 29/29 [00:00<00:00, 143.54it/s, train_loss=0.00536, valid_loss=0.00203]\n",
      "Epoch: 31/50: 100%|██████████| 29/29 [00:00<00:00, 142.43it/s, train_loss=0.00565, valid_loss=0.00188]\n",
      "Epoch: 32/50: 100%|██████████| 29/29 [00:00<00:00, 119.68it/s, train_loss=0.00519, valid_loss=0.00188]\n",
      "Epoch: 33/50: 100%|██████████| 29/29 [00:00<00:00, 140.99it/s, train_loss=0.00495, valid_loss=0.00215]\n",
      "Epoch: 34/50: 100%|██████████| 29/29 [00:00<00:00, 141.67it/s, train_loss=0.00481, valid_loss=0.00182]\n",
      "Epoch: 35/50: 100%|██████████| 29/29 [00:00<00:00, 119.85it/s, train_loss=0.00458, valid_loss=0.00187]\n",
      "Epoch: 36/50: 100%|██████████| 29/29 [00:00<00:00, 141.83it/s, train_loss=0.00486, valid_loss=0.00188]\n",
      "Epoch: 37/50: 100%|██████████| 29/29 [00:00<00:00, 140.77it/s, train_loss=0.00506, valid_loss=0.00192]\n",
      "Epoch: 38/50: 100%|██████████| 29/29 [00:00<00:00, 120.07it/s, train_loss=0.00464, valid_loss=0.00176]\n",
      "Epoch: 39/50: 100%|██████████| 29/29 [00:00<00:00, 126.28it/s, train_loss=0.00531, valid_loss=0.00178]\n",
      "Epoch: 40/50: 100%|██████████| 29/29 [00:00<00:00, 120.07it/s, train_loss=0.00521, valid_loss=0.00175]\n",
      "Epoch: 41/50: 100%|██████████| 29/29 [00:00<00:00, 140.73it/s, train_loss=0.00478, valid_loss=0.00189]\n",
      "Epoch: 42/50: 100%|██████████| 29/29 [00:00<00:00, 141.77it/s, train_loss=0.00514, valid_loss=0.00193]\n",
      "Epoch: 43/50: 100%|██████████| 29/29 [00:00<00:00, 119.94it/s, train_loss=0.00542, valid_loss=0.00181]\n",
      "Epoch: 44/50: 100%|██████████| 29/29 [00:00<00:00, 141.27it/s, train_loss=0.00469, valid_loss=0.00182]\n",
      "Epoch: 45/50: 100%|██████████| 29/29 [00:00<00:00, 141.64it/s, train_loss=0.00459, valid_loss=0.00176]\n",
      "Epoch: 46/50: 100%|██████████| 29/29 [00:00<00:00, 143.48it/s, train_loss=0.00464, valid_loss=0.00187]\n",
      "Epoch: 47/50: 100%|██████████| 29/29 [00:00<00:00, 143.74it/s, train_loss=0.00449, valid_loss=0.00174]\n",
      "Epoch: 48/50: 100%|██████████| 29/29 [00:00<00:00, 120.32it/s, train_loss=0.00422, valid_loss=0.00181]\n",
      "Epoch: 49/50: 100%|██████████| 29/29 [00:00<00:00, 140.73it/s, train_loss=0.00463, valid_loss=0.00195]\n",
      "Epoch: 50/50: 100%|██████████| 29/29 [00:00<00:00, 139.08it/s, train_loss=0.00475, valid_loss=0.00192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 36/36 [00:00<00:00, 96.11it/s, train_loss=0.0559, valid_loss=0.0437]\n",
      "Epoch: 2/50: 100%|██████████| 36/36 [00:00<00:00, 136.60it/s, train_loss=0.0365, valid_loss=0.0276]\n",
      "Epoch: 3/50: 100%|██████████| 36/36 [00:00<00:00, 136.93it/s, train_loss=0.0275, valid_loss=0.0217]\n",
      "Epoch: 4/50: 100%|██████████| 36/36 [00:00<00:00, 137.20it/s, train_loss=0.0227, valid_loss=0.0171]\n",
      "Epoch: 5/50: 100%|██████████| 36/36 [00:00<00:00, 118.97it/s, train_loss=0.0181, valid_loss=0.0132]\n",
      "Epoch: 6/50: 100%|██████████| 36/36 [00:00<00:00, 137.34it/s, train_loss=0.0172, valid_loss=0.0116]\n",
      "Epoch: 7/50: 100%|██████████| 36/36 [00:00<00:00, 137.45it/s, train_loss=0.0157, valid_loss=0.011] \n",
      "Epoch: 8/50: 100%|██████████| 36/36 [00:00<00:00, 137.12it/s, train_loss=0.0152, valid_loss=0.0106]\n",
      "Epoch: 9/50: 100%|██████████| 36/36 [00:00<00:00, 119.59it/s, train_loss=0.0136, valid_loss=0.0104]\n",
      "Epoch: 10/50: 100%|██████████| 36/36 [00:00<00:00, 135.05it/s, train_loss=0.0135, valid_loss=0.00994]\n",
      "Epoch: 11/50: 100%|██████████| 36/36 [00:00<00:00, 128.73it/s, train_loss=0.0144, valid_loss=0.00967]\n",
      "Epoch: 12/50: 100%|██████████| 36/36 [00:00<00:00, 137.29it/s, train_loss=0.0135, valid_loss=0.0094] \n",
      "Epoch: 13/50: 100%|██████████| 36/36 [00:00<00:00, 118.78it/s, train_loss=0.0126, valid_loss=0.00913]\n",
      "Epoch: 14/50: 100%|██████████| 36/36 [00:00<00:00, 136.44it/s, train_loss=0.0134, valid_loss=0.00889]\n",
      "Epoch: 15/50: 100%|██████████| 36/36 [00:00<00:00, 136.81it/s, train_loss=0.0131, valid_loss=0.0089] \n",
      "Epoch: 16/50: 100%|██████████| 36/36 [00:00<00:00, 137.53it/s, train_loss=0.0139, valid_loss=0.00869]\n",
      "Epoch: 17/50: 100%|██████████| 36/36 [00:00<00:00, 119.31it/s, train_loss=0.0127, valid_loss=0.00876]\n",
      "Epoch: 18/50: 100%|██████████| 36/36 [00:00<00:00, 136.76it/s, train_loss=0.0126, valid_loss=0.00844]\n",
      "Epoch: 19/50: 100%|██████████| 36/36 [00:00<00:00, 136.65it/s, train_loss=0.0124, valid_loss=0.00848]\n",
      "Epoch: 20/50: 100%|██████████| 36/36 [00:00<00:00, 137.20it/s, train_loss=0.0118, valid_loss=0.00827]\n",
      "Epoch: 21/50: 100%|██████████| 36/36 [00:00<00:00, 119.07it/s, train_loss=0.0126, valid_loss=0.00826]\n",
      "Epoch: 22/50: 100%|██████████| 36/36 [00:00<00:00, 136.35it/s, train_loss=0.0125, valid_loss=0.00835]\n",
      "Epoch: 23/50: 100%|██████████| 36/36 [00:00<00:00, 118.82it/s, train_loss=0.0126, valid_loss=0.00829]\n",
      "Epoch: 24/50: 100%|██████████| 36/36 [00:00<00:00, 136.14it/s, train_loss=0.0129, valid_loss=0.00842]\n",
      "Epoch: 25/50: 100%|██████████| 36/36 [00:00<00:00, 120.01it/s, train_loss=0.0124, valid_loss=0.0079] \n",
      "Epoch: 26/50: 100%|██████████| 36/36 [00:00<00:00, 137.09it/s, train_loss=0.00609, valid_loss=0.00307]\n",
      "Epoch: 27/50: 100%|██████████| 36/36 [00:00<00:00, 119.94it/s, train_loss=0.00566, valid_loss=0.00282]\n",
      "Epoch: 28/50: 100%|██████████| 36/36 [00:00<00:00, 137.55it/s, train_loss=0.00521, valid_loss=0.00275]\n",
      "Epoch: 29/50: 100%|██████████| 36/36 [00:00<00:00, 136.66it/s, train_loss=0.00586, valid_loss=0.00261]\n",
      "Epoch: 30/50: 100%|██████████| 36/36 [00:00<00:00, 128.22it/s, train_loss=0.00557, valid_loss=0.00262]\n",
      "Epoch: 31/50: 100%|██████████| 36/36 [00:00<00:00, 113.72it/s, train_loss=0.00545, valid_loss=0.00257]\n",
      "Epoch: 32/50: 100%|██████████| 36/36 [00:00<00:00, 137.01it/s, train_loss=0.00501, valid_loss=0.00256]\n",
      "Epoch: 33/50: 100%|██████████| 36/36 [00:00<00:00, 136.15it/s, train_loss=0.0054, valid_loss=0.00253] \n",
      "Epoch: 34/50: 100%|██████████| 36/36 [00:00<00:00, 137.28it/s, train_loss=0.00486, valid_loss=0.00256]\n",
      "Epoch: 35/50: 100%|██████████| 36/36 [00:00<00:00, 119.47it/s, train_loss=0.00478, valid_loss=0.00251]\n",
      "Epoch: 36/50: 100%|██████████| 36/36 [00:00<00:00, 136.72it/s, train_loss=0.00492, valid_loss=0.00248]\n",
      "Epoch: 37/50: 100%|██████████| 36/36 [00:00<00:00, 112.75it/s, train_loss=0.00465, valid_loss=0.00243]\n",
      "Epoch: 38/50: 100%|██████████| 36/36 [00:00<00:00, 136.62it/s, train_loss=0.00434, valid_loss=0.00244]\n",
      "Epoch: 39/50: 100%|██████████| 36/36 [00:00<00:00, 136.72it/s, train_loss=0.00468, valid_loss=0.00237]\n",
      "Epoch: 40/50: 100%|██████████| 36/36 [00:00<00:00, 117.45it/s, train_loss=0.00471, valid_loss=0.00244]\n",
      "Epoch: 41/50: 100%|██████████| 36/36 [00:00<00:00, 135.93it/s, train_loss=0.00483, valid_loss=0.00237]\n",
      "Epoch: 42/50: 100%|██████████| 36/36 [00:00<00:00, 118.70it/s, train_loss=0.00478, valid_loss=0.0024] \n",
      "Epoch: 43/50: 100%|██████████| 36/36 [00:00<00:00, 136.04it/s, train_loss=0.00518, valid_loss=0.00233]\n",
      "Epoch: 44/50: 100%|██████████| 36/36 [00:00<00:00, 118.61it/s, train_loss=0.0047, valid_loss=0.0024]  \n",
      "Epoch: 45/50: 100%|██████████| 36/36 [00:00<00:00, 136.82it/s, train_loss=0.00463, valid_loss=0.00237]\n",
      "Epoch: 46/50: 100%|██████████| 36/36 [00:00<00:00, 119.57it/s, train_loss=0.00418, valid_loss=0.00232]\n",
      "Epoch: 47/50: 100%|██████████| 36/36 [00:00<00:00, 136.65it/s, train_loss=0.00484, valid_loss=0.00236]\n",
      "Epoch: 48/50: 100%|██████████| 36/36 [00:00<00:00, 119.65it/s, train_loss=0.00434, valid_loss=0.00234]\n",
      "Epoch: 49/50: 100%|██████████| 36/36 [00:00<00:00, 136.11it/s, train_loss=0.00459, valid_loss=0.0023] \n",
      "Epoch: 50/50: 100%|██████████| 36/36 [00:00<00:00, 119.88it/s, train_loss=0.00422, valid_loss=0.00234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config: batch_size--512, lr--0.005, number_epoch--50, hidden_dim--35,drop_prob-0.1,weight_decay-1e-07\n",
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 8/8 [00:00<00:00, 78.36it/s, train_loss=0.0574, valid_loss=0.0779]\n",
      "Epoch: 2/50: 100%|██████████| 8/8 [00:00<00:00, 84.51it/s, train_loss=0.0315, valid_loss=0.0485]\n",
      "Epoch: 3/50: 100%|██████████| 8/8 [00:00<00:00, 117.47it/s, train_loss=0.0202, valid_loss=0.0305]\n",
      "Epoch: 4/50: 100%|██████████| 8/8 [00:00<00:00, 131.26it/s, train_loss=0.017, valid_loss=0.029]\n",
      "Epoch: 5/50: 100%|██████████| 8/8 [00:00<00:00, 102.75it/s, train_loss=0.0154, valid_loss=0.0278]\n",
      "Epoch: 6/50: 100%|██████████| 8/8 [00:00<00:00, 128.70it/s, train_loss=0.0149, valid_loss=0.0281]\n",
      "Epoch: 7/50: 100%|██████████| 8/8 [00:00<00:00, 130.23it/s, train_loss=0.0142, valid_loss=0.0267]\n",
      "Epoch: 8/50: 100%|██████████| 8/8 [00:00<00:00, 129.17it/s, train_loss=0.0141, valid_loss=0.0258]\n",
      "Epoch: 9/50: 100%|██████████| 8/8 [00:00<00:00, 80.72it/s, train_loss=0.0127, valid_loss=0.0234]\n",
      "Epoch: 10/50: 100%|██████████| 8/8 [00:00<00:00, 86.12it/s, train_loss=0.0124, valid_loss=0.0211]\n",
      "Epoch: 11/50: 100%|██████████| 8/8 [00:00<00:00, 130.88it/s, train_loss=0.0119, valid_loss=0.0194]\n",
      "Epoch: 12/50: 100%|██████████| 8/8 [00:00<00:00, 80.52it/s, train_loss=0.012, valid_loss=0.0187]\n",
      "Epoch: 13/50: 100%|██████████| 8/8 [00:00<00:00, 113.62it/s, train_loss=0.0108, valid_loss=0.0178]\n",
      "Epoch: 14/50: 100%|██████████| 8/8 [00:00<00:00, 130.13it/s, train_loss=0.0105, valid_loss=0.0164]\n",
      "Epoch: 15/50: 100%|██████████| 8/8 [00:00<00:00, 100.69it/s, train_loss=0.0105, valid_loss=0.0154]\n",
      "Epoch: 16/50: 100%|██████████| 8/8 [00:00<00:00, 98.41it/s, train_loss=0.01, valid_loss=0.0151]\n",
      "Epoch: 17/50: 100%|██████████| 8/8 [00:00<00:00, 119.63it/s, train_loss=0.0099, valid_loss=0.014]\n",
      "Epoch: 18/50: 100%|██████████| 8/8 [00:00<00:00, 74.34it/s, train_loss=0.00955, valid_loss=0.0133]\n",
      "Epoch: 19/50: 100%|██████████| 8/8 [00:00<00:00, 127.56it/s, train_loss=0.00929, valid_loss=0.013]\n",
      "Epoch: 20/50: 100%|██████████| 8/8 [00:00<00:00, 105.07it/s, train_loss=0.0101, valid_loss=0.0129]\n",
      "Epoch: 21/50: 100%|██████████| 8/8 [00:00<00:00, 107.77it/s, train_loss=0.00837, valid_loss=0.0104]\n",
      "Epoch: 22/50: 100%|██████████| 8/8 [00:00<00:00, 128.16it/s, train_loss=0.00525, valid_loss=0.00755]\n",
      "Epoch: 23/50: 100%|██████████| 8/8 [00:00<00:00, 85.72it/s, train_loss=0.00549, valid_loss=0.00772]\n",
      "Epoch: 24/50: 100%|██████████| 8/8 [00:00<00:00, 126.93it/s, train_loss=0.00546, valid_loss=0.0072]\n",
      "Epoch: 25/50: 100%|██████████| 8/8 [00:00<00:00, 106.63it/s, train_loss=0.00525, valid_loss=0.00696]\n",
      "Epoch: 26/50: 100%|██████████| 8/8 [00:00<00:00, 102.87it/s, train_loss=0.00526, valid_loss=0.00664]\n",
      "Epoch: 27/50: 100%|██████████| 8/8 [00:00<00:00, 130.82it/s, train_loss=0.00512, valid_loss=0.00631]\n",
      "Epoch: 28/50: 100%|██████████| 8/8 [00:00<00:00, 132.01it/s, train_loss=0.00466, valid_loss=0.00622]\n",
      "Epoch: 29/50: 100%|██████████| 8/8 [00:00<00:00, 130.96it/s, train_loss=0.00512, valid_loss=0.00646]\n",
      "Epoch: 30/50: 100%|██████████| 8/8 [00:00<00:00, 130.13it/s, train_loss=0.00473, valid_loss=0.00592]\n",
      "Epoch: 31/50: 100%|██████████| 8/8 [00:00<00:00, 97.38it/s, train_loss=0.00455, valid_loss=0.00579]\n",
      "Epoch: 32/50: 100%|██████████| 8/8 [00:00<00:00, 127.65it/s, train_loss=0.00421, valid_loss=0.00577]\n",
      "Epoch: 33/50: 100%|██████████| 8/8 [00:00<00:00, 98.63it/s, train_loss=0.0041, valid_loss=0.00555]\n",
      "Epoch: 34/50: 100%|██████████| 8/8 [00:00<00:00, 119.53it/s, train_loss=0.00437, valid_loss=0.00554]\n",
      "Epoch: 35/50: 100%|██████████| 8/8 [00:00<00:00, 74.41it/s, train_loss=0.00408, valid_loss=0.00542]\n",
      "Epoch: 36/50: 100%|██████████| 8/8 [00:00<00:00, 119.14it/s, train_loss=0.00409, valid_loss=0.00547]\n",
      "Epoch: 37/50: 100%|██████████| 8/8 [00:00<00:00, 115.17it/s, train_loss=0.00373, valid_loss=0.00522]\n",
      "Epoch: 38/50: 100%|██████████| 8/8 [00:00<00:00, 120.73it/s, train_loss=0.00402, valid_loss=0.00523]\n",
      "Epoch: 39/50: 100%|██████████| 8/8 [00:00<00:00, 112.48it/s, train_loss=0.00432, valid_loss=0.00534]\n",
      "Epoch: 40/50: 100%|██████████| 8/8 [00:00<00:00, 129.17it/s, train_loss=0.00394, valid_loss=0.00539]\n",
      "Epoch: 41/50: 100%|██████████| 8/8 [00:00<00:00, 127.94it/s, train_loss=0.00366, valid_loss=0.0055]\n",
      "Epoch: 42/50: 100%|██████████| 8/8 [00:00<00:00, 128.15it/s, train_loss=0.00438, valid_loss=0.00531]\n",
      "Epoch: 43/50: 100%|██████████| 8/8 [00:00<00:00, 98.09it/s, train_loss=0.00364, valid_loss=0.00515]\n",
      "Epoch: 44/50: 100%|██████████| 8/8 [00:00<00:00, 127.99it/s, train_loss=0.00394, valid_loss=0.00516]\n",
      "Epoch: 45/50: 100%|██████████| 8/8 [00:00<00:00, 128.12it/s, train_loss=0.00392, valid_loss=0.00519]\n",
      "Epoch: 46/50: 100%|██████████| 8/8 [00:00<00:00, 119.43it/s, train_loss=0.00357, valid_loss=0.00523]\n",
      "Epoch: 47/50: 100%|██████████| 8/8 [00:00<00:00, 113.47it/s, train_loss=0.00382, valid_loss=0.00525]\n",
      "Epoch: 48/50: 100%|██████████| 8/8 [00:00<00:00, 129.68it/s, train_loss=0.00362, valid_loss=0.00514]\n",
      "Epoch: 49/50: 100%|██████████| 8/8 [00:00<00:00, 128.56it/s, train_loss=0.00359, valid_loss=0.00515]\n",
      "Epoch: 50/50: 100%|██████████| 8/8 [00:00<00:00, 127.80it/s, train_loss=0.00367, valid_loss=0.0052]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 15/15 [00:00<00:00, 73.74it/s, train_loss=0.0412, valid_loss=0.0455]\n",
      "Epoch: 2/50: 100%|██████████| 15/15 [00:00<00:00, 129.42it/s, train_loss=0.0199, valid_loss=0.0127]\n",
      "Epoch: 3/50: 100%|██████████| 15/15 [00:00<00:00, 133.01it/s, train_loss=0.0159, valid_loss=0.00874]\n",
      "Epoch: 4/50: 100%|██████████| 15/15 [00:00<00:00, 111.08it/s, train_loss=0.0105, valid_loss=0.00823]\n",
      "Epoch: 5/50: 100%|██████████| 15/15 [00:00<00:00, 135.06it/s, train_loss=0.0083, valid_loss=0.00732]\n",
      "Epoch: 6/50: 100%|██████████| 15/15 [00:00<00:00, 122.26it/s, train_loss=0.0078, valid_loss=0.00542]\n",
      "Epoch: 7/50: 100%|██████████| 15/15 [00:00<00:00, 142.38it/s, train_loss=0.0075, valid_loss=0.00562]\n",
      "Epoch: 8/50: 100%|██████████| 15/15 [00:00<00:00, 106.60it/s, train_loss=0.00657, valid_loss=0.00441]\n",
      "Epoch: 9/50: 100%|██████████| 15/15 [00:00<00:00, 125.74it/s, train_loss=0.00584, valid_loss=0.00438]\n",
      "Epoch: 10/50: 100%|██████████| 15/15 [00:00<00:00, 137.57it/s, train_loss=0.00655, valid_loss=0.00471]\n",
      "Epoch: 11/50: 100%|██████████| 15/15 [00:00<00:00, 109.79it/s, train_loss=0.00565, valid_loss=0.00496]\n",
      "Epoch: 12/50: 100%|██████████| 15/15 [00:00<00:00, 122.97it/s, train_loss=0.00534, valid_loss=0.00334]\n",
      "Epoch: 13/50: 100%|██████████| 15/15 [00:00<00:00, 120.25it/s, train_loss=0.00562, valid_loss=0.0042]\n",
      "Epoch: 14/50: 100%|██████████| 15/15 [00:00<00:00, 142.27it/s, train_loss=0.00471, valid_loss=0.00441]\n",
      "Epoch: 15/50: 100%|██████████| 15/15 [00:00<00:00, 106.48it/s, train_loss=0.00523, valid_loss=0.00399]\n",
      "Epoch: 16/50: 100%|██████████| 15/15 [00:00<00:00, 125.69it/s, train_loss=0.00499, valid_loss=0.00331]\n",
      "Epoch: 17/50: 100%|██████████| 15/15 [00:00<00:00, 141.01it/s, train_loss=0.00509, valid_loss=0.00371]\n",
      "Epoch: 18/50: 100%|██████████| 15/15 [00:00<00:00, 124.28it/s, train_loss=0.00516, valid_loss=0.0032]\n",
      "Epoch: 19/50: 100%|██████████| 15/15 [00:00<00:00, 139.94it/s, train_loss=0.0048, valid_loss=0.00278]\n",
      "Epoch: 20/50: 100%|██████████| 15/15 [00:00<00:00, 123.27it/s, train_loss=0.00469, valid_loss=0.00291]\n",
      "Epoch: 21/50: 100%|██████████| 15/15 [00:00<00:00, 140.80it/s, train_loss=0.00474, valid_loss=0.00355]\n",
      "Epoch: 22/50: 100%|██████████| 15/15 [00:00<00:00, 126.13it/s, train_loss=0.0044, valid_loss=0.00256]\n",
      "Epoch: 23/50: 100%|██████████| 15/15 [00:00<00:00, 91.20it/s, train_loss=0.00471, valid_loss=0.00239]\n",
      "Epoch: 24/50: 100%|██████████| 15/15 [00:00<00:00, 142.63it/s, train_loss=0.00454, valid_loss=0.00255]\n",
      "Epoch: 25/50: 100%|██████████| 15/15 [00:00<00:00, 129.94it/s, train_loss=0.00428, valid_loss=0.00248]\n",
      "Epoch: 26/50: 100%|██████████| 15/15 [00:00<00:00, 136.59it/s, train_loss=0.00439, valid_loss=0.00265]\n",
      "Epoch: 27/50: 100%|██████████| 15/15 [00:00<00:00, 130.22it/s, train_loss=0.0047, valid_loss=0.00288]\n",
      "Epoch: 28/50: 100%|██████████| 15/15 [00:00<00:00, 134.99it/s, train_loss=0.00405, valid_loss=0.00226]\n",
      "Epoch: 29/50: 100%|██████████| 15/15 [00:00<00:00, 142.49it/s, train_loss=0.00446, valid_loss=0.00323]\n",
      "Epoch: 30/50: 100%|██████████| 15/15 [00:00<00:00, 104.59it/s, train_loss=0.00405, valid_loss=0.00246]\n",
      "Epoch: 31/50: 100%|██████████| 15/15 [00:00<00:00, 141.28it/s, train_loss=0.00411, valid_loss=0.00232]\n",
      "Epoch: 32/50: 100%|██████████| 15/15 [00:00<00:00, 130.41it/s, train_loss=0.00378, valid_loss=0.00271]\n",
      "Epoch: 33/50: 100%|██████████| 15/15 [00:00<00:00, 126.08it/s, train_loss=0.00416, valid_loss=0.0027]\n",
      "Epoch: 34/50: 100%|██████████| 15/15 [00:00<00:00, 114.62it/s, train_loss=0.00382, valid_loss=0.00273]\n",
      "Epoch: 35/50: 100%|██████████| 15/15 [00:00<00:00, 142.69it/s, train_loss=0.0039, valid_loss=0.00282]\n",
      "Epoch: 36/50: 100%|██████████| 15/15 [00:00<00:00, 142.11it/s, train_loss=0.0043, valid_loss=0.00297]\n",
      "Epoch: 37/50: 100%|██████████| 15/15 [00:00<00:00, 96.96it/s, train_loss=0.00378, valid_loss=0.00311]\n",
      "Epoch: 38/50: 100%|██████████| 15/15 [00:00<00:00, 129.82it/s, train_loss=0.00434, valid_loss=0.00286]\n",
      "Epoch: 39/50: 100%|██████████| 15/15 [00:00<00:00, 135.02it/s, train_loss=0.00427, valid_loss=0.00277]\n",
      "Epoch: 40/50: 100%|██████████| 15/15 [00:00<00:00, 128.02it/s, train_loss=0.00394, valid_loss=0.00289]\n",
      "Epoch: 41/50: 100%|██████████| 15/15 [00:00<00:00, 121.21it/s, train_loss=0.00417, valid_loss=0.00302]\n",
      "Epoch: 42/50: 100%|██████████| 15/15 [00:00<00:00, 141.43it/s, train_loss=0.00346, valid_loss=0.00269]\n",
      "Epoch: 43/50: 100%|██████████| 15/15 [00:00<00:00, 142.71it/s, train_loss=0.00395, valid_loss=0.00336]\n",
      "Epoch: 44/50: 100%|██████████| 15/15 [00:00<00:00, 97.92it/s, train_loss=0.00393, valid_loss=0.00238]\n",
      "Epoch: 45/50: 100%|██████████| 15/15 [00:00<00:00, 114.97it/s, train_loss=0.00418, valid_loss=0.00287]\n",
      "Epoch: 46/50: 100%|██████████| 15/15 [00:00<00:00, 126.01it/s, train_loss=0.00441, valid_loss=0.00348]\n",
      "Epoch: 47/50: 100%|██████████| 15/15 [00:00<00:00, 118.79it/s, train_loss=0.00399, valid_loss=0.00262]\n",
      "Epoch: 48/50: 100%|██████████| 15/15 [00:00<00:00, 139.38it/s, train_loss=0.0041, valid_loss=0.00274]\n",
      "Epoch: 49/50: 100%|██████████| 15/15 [00:00<00:00, 121.33it/s, train_loss=0.0042, valid_loss=0.00292]\n",
      "Epoch: 50/50: 100%|██████████| 15/15 [00:00<00:00, 110.69it/s, train_loss=0.00353, valid_loss=0.00243]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 22/22 [00:00<00:00, 81.91it/s, train_loss=0.0286, valid_loss=0.033] \n",
      "Epoch: 2/50: 100%|██████████| 22/22 [00:00<00:00, 115.13it/s, train_loss=0.0216, valid_loss=0.0242]\n",
      "Epoch: 3/50: 100%|██████████| 22/22 [00:00<00:00, 131.97it/s, train_loss=0.0107, valid_loss=0.0118]\n",
      "Epoch: 4/50: 100%|██████████| 22/22 [00:00<00:00, 112.60it/s, train_loss=0.00892, valid_loss=0.0067]\n",
      "Epoch: 5/50: 100%|██████████| 22/22 [00:00<00:00, 120.96it/s, train_loss=0.0085, valid_loss=0.00616] \n",
      "Epoch: 6/50: 100%|██████████| 22/22 [00:00<00:00, 98.46it/s, train_loss=0.00685, valid_loss=0.00563]\n",
      "Epoch: 7/50: 100%|██████████| 22/22 [00:00<00:00, 116.41it/s, train_loss=0.00646, valid_loss=0.00521]\n",
      "Epoch: 8/50: 100%|██████████| 22/22 [00:00<00:00, 133.89it/s, train_loss=0.00664, valid_loss=0.00471]\n",
      "Epoch: 9/50: 100%|██████████| 22/22 [00:00<00:00, 122.21it/s, train_loss=0.00519, valid_loss=0.00433]\n",
      "Epoch: 10/50: 100%|██████████| 22/22 [00:00<00:00, 94.63it/s, train_loss=0.00557, valid_loss=0.00424]\n",
      "Epoch: 11/50: 100%|██████████| 22/22 [00:00<00:00, 124.73it/s, train_loss=0.00516, valid_loss=0.00437]\n",
      "Epoch: 12/50: 100%|██████████| 22/22 [00:00<00:00, 133.14it/s, train_loss=0.00515, valid_loss=0.00423]\n",
      "Epoch: 13/50: 100%|██████████| 22/22 [00:00<00:00, 132.65it/s, train_loss=0.00486, valid_loss=0.00395]\n",
      "Epoch: 14/50: 100%|██████████| 22/22 [00:00<00:00, 96.23it/s, train_loss=0.0047, valid_loss=0.00476]  \n",
      "Epoch: 15/50: 100%|██████████| 22/22 [00:00<00:00, 119.24it/s, train_loss=0.00443, valid_loss=0.00456]\n",
      "Epoch: 16/50: 100%|██████████| 22/22 [00:00<00:00, 120.79it/s, train_loss=0.00406, valid_loss=0.00396]\n",
      "Epoch: 17/50: 100%|██████████| 22/22 [00:00<00:00, 122.50it/s, train_loss=0.00454, valid_loss=0.00424]\n",
      "Epoch: 18/50: 100%|██████████| 22/22 [00:00<00:00, 134.53it/s, train_loss=0.0046, valid_loss=0.00422] \n",
      "Epoch: 19/50: 100%|██████████| 22/22 [00:00<00:00, 88.83it/s, train_loss=0.00412, valid_loss=0.00441]\n",
      "Epoch: 20/50: 100%|██████████| 22/22 [00:00<00:00, 111.60it/s, train_loss=0.00427, valid_loss=0.0041] \n",
      "Epoch: 21/50: 100%|██████████| 22/22 [00:00<00:00, 134.07it/s, train_loss=0.00398, valid_loss=0.00486]\n",
      "Epoch: 22/50: 100%|██████████| 22/22 [00:00<00:00, 122.02it/s, train_loss=0.00411, valid_loss=0.00501]\n",
      "Epoch: 23/50: 100%|██████████| 22/22 [00:00<00:00, 113.26it/s, train_loss=0.00421, valid_loss=0.00418]\n",
      "Epoch: 24/50: 100%|██████████| 22/22 [00:00<00:00, 98.76it/s, train_loss=0.00417, valid_loss=0.00424]\n",
      "Epoch: 25/50: 100%|██████████| 22/22 [00:00<00:00, 120.19it/s, train_loss=0.0037, valid_loss=0.00391] \n",
      "Epoch: 26/50: 100%|██████████| 22/22 [00:00<00:00, 132.12it/s, train_loss=0.0039, valid_loss=0.00447] \n",
      "Epoch: 27/50: 100%|██████████| 22/22 [00:00<00:00, 122.85it/s, train_loss=0.00354, valid_loss=0.00434]\n",
      "Epoch: 28/50: 100%|██████████| 22/22 [00:00<00:00, 102.67it/s, train_loss=0.00365, valid_loss=0.00419]\n",
      "Epoch: 29/50: 100%|██████████| 22/22 [00:00<00:00, 113.95it/s, train_loss=0.00401, valid_loss=0.00402]\n",
      "Epoch: 30/50: 100%|██████████| 22/22 [00:00<00:00, 132.69it/s, train_loss=0.00377, valid_loss=0.00465]\n",
      "Epoch: 31/50: 100%|██████████| 22/22 [00:00<00:00, 123.68it/s, train_loss=0.00385, valid_loss=0.00393]\n",
      "Epoch: 32/50: 100%|██████████| 22/22 [00:00<00:00, 109.22it/s, train_loss=0.00402, valid_loss=0.00431]\n",
      "Epoch: 33/50: 100%|██████████| 22/22 [00:00<00:00, 132.14it/s, train_loss=0.00392, valid_loss=0.00369]\n",
      "Epoch: 34/50: 100%|██████████| 22/22 [00:00<00:00, 132.14it/s, train_loss=0.00349, valid_loss=0.00406]\n",
      "Epoch: 35/50: 100%|██████████| 22/22 [00:00<00:00, 118.89it/s, train_loss=0.00367, valid_loss=0.00362]\n",
      "Epoch: 36/50: 100%|██████████| 22/22 [00:00<00:00, 115.88it/s, train_loss=0.00372, valid_loss=0.00406]\n",
      "Epoch: 37/50: 100%|██████████| 22/22 [00:00<00:00, 107.60it/s, train_loss=0.00384, valid_loss=0.00402]\n",
      "Epoch: 38/50: 100%|██████████| 22/22 [00:00<00:00, 104.07it/s, train_loss=0.00366, valid_loss=0.00387]\n",
      "Epoch: 39/50: 100%|██████████| 22/22 [00:00<00:00, 122.15it/s, train_loss=0.00359, valid_loss=0.00411]\n",
      "Epoch: 40/50: 100%|██████████| 22/22 [00:00<00:00, 133.19it/s, train_loss=0.00404, valid_loss=0.00442]\n",
      "Epoch: 41/50: 100%|██████████| 22/22 [00:00<00:00, 107.59it/s, train_loss=0.0035, valid_loss=0.0043]  \n",
      "Epoch: 42/50: 100%|██████████| 22/22 [00:00<00:00, 119.95it/s, train_loss=0.00372, valid_loss=0.00458]\n",
      "Epoch: 43/50: 100%|██████████| 22/22 [00:00<00:00, 122.80it/s, train_loss=0.00371, valid_loss=0.00415]\n",
      "Epoch: 44/50: 100%|██████████| 22/22 [00:00<00:00, 133.41it/s, train_loss=0.00364, valid_loss=0.00417]\n",
      "Epoch: 45/50: 100%|██████████| 22/22 [00:00<00:00, 96.22it/s, train_loss=0.00364, valid_loss=0.00463]\n",
      "Epoch: 46/50: 100%|██████████| 22/22 [00:00<00:00, 107.40it/s, train_loss=0.00334, valid_loss=0.00401]\n",
      "Epoch: 47/50: 100%|██████████| 22/22 [00:00<00:00, 133.30it/s, train_loss=0.00363, valid_loss=0.00447]\n",
      "Epoch: 48/50: 100%|██████████| 22/22 [00:00<00:00, 123.48it/s, train_loss=0.00371, valid_loss=0.00445]\n",
      "Epoch: 49/50: 100%|██████████| 22/22 [00:00<00:00, 113.74it/s, train_loss=0.00376, valid_loss=0.00461]\n",
      "Epoch: 50/50: 100%|██████████| 22/22 [00:00<00:00, 110.06it/s, train_loss=0.00353, valid_loss=0.00411]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 29/29 [00:00<00:00, 106.59it/s, train_loss=0.029, valid_loss=0.0222] \n",
      "Epoch: 2/50: 100%|██████████| 29/29 [00:00<00:00, 130.38it/s, train_loss=0.0182, valid_loss=0.0173]\n",
      "Epoch: 3/50: 100%|██████████| 29/29 [00:00<00:00, 111.01it/s, train_loss=0.0153, valid_loss=0.0139]\n",
      "Epoch: 4/50: 100%|██████████| 29/29 [00:00<00:00, 129.55it/s, train_loss=0.0151, valid_loss=0.0124]\n",
      "Epoch: 5/50: 100%|██████████| 29/29 [00:00<00:00, 126.32it/s, train_loss=0.0073, valid_loss=0.0039]  \n",
      "Epoch: 6/50: 100%|██████████| 29/29 [00:00<00:00, 137.99it/s, train_loss=0.0057, valid_loss=0.0032]  \n",
      "Epoch: 7/50: 100%|██████████| 29/29 [00:00<00:00, 134.36it/s, train_loss=0.00536, valid_loss=0.00241]\n",
      "Epoch: 8/50: 100%|██████████| 29/29 [00:00<00:00, 109.56it/s, train_loss=0.00548, valid_loss=0.00279]\n",
      "Epoch: 9/50: 100%|██████████| 29/29 [00:00<00:00, 121.53it/s, train_loss=0.00497, valid_loss=0.00201]\n",
      "Epoch: 10/50: 100%|██████████| 29/29 [00:00<00:00, 128.20it/s, train_loss=0.00508, valid_loss=0.00252]\n",
      "Epoch: 11/50: 100%|██████████| 29/29 [00:00<00:00, 118.26it/s, train_loss=0.00435, valid_loss=0.00251]\n",
      "Epoch: 12/50: 100%|██████████| 29/29 [00:00<00:00, 128.53it/s, train_loss=0.00491, valid_loss=0.00431]\n",
      "Epoch: 13/50: 100%|██████████| 29/29 [00:00<00:00, 131.56it/s, train_loss=0.00471, valid_loss=0.00213]\n",
      "Epoch: 14/50: 100%|██████████| 29/29 [00:00<00:00, 115.83it/s, train_loss=0.00424, valid_loss=0.00279]\n",
      "Epoch: 15/50: 100%|██████████| 29/29 [00:00<00:00, 132.24it/s, train_loss=0.0038, valid_loss=0.00199] \n",
      "Epoch: 16/50: 100%|██████████| 29/29 [00:00<00:00, 110.07it/s, train_loss=0.00382, valid_loss=0.00265]\n",
      "Epoch: 17/50: 100%|██████████| 29/29 [00:00<00:00, 122.14it/s, train_loss=0.00375, valid_loss=0.00259]\n",
      "Epoch: 18/50: 100%|██████████| 29/29 [00:00<00:00, 138.28it/s, train_loss=0.00356, valid_loss=0.00194]\n",
      "Epoch: 19/50: 100%|██████████| 29/29 [00:00<00:00, 121.33it/s, train_loss=0.00426, valid_loss=0.00234]\n",
      "Epoch: 20/50: 100%|██████████| 29/29 [00:00<00:00, 134.41it/s, train_loss=0.00411, valid_loss=0.00295]\n",
      "Epoch: 21/50: 100%|██████████| 29/29 [00:00<00:00, 136.27it/s, train_loss=0.00415, valid_loss=0.00241]\n",
      "Epoch: 22/50: 100%|██████████| 29/29 [00:00<00:00, 113.34it/s, train_loss=0.00404, valid_loss=0.00269]\n",
      "Epoch: 23/50: 100%|██████████| 29/29 [00:00<00:00, 135.96it/s, train_loss=0.00443, valid_loss=0.00298]\n",
      "Epoch: 24/50: 100%|██████████| 29/29 [00:00<00:00, 108.22it/s, train_loss=0.00362, valid_loss=0.00229]\n",
      "Epoch: 25/50: 100%|██████████| 29/29 [00:00<00:00, 111.35it/s, train_loss=0.00401, valid_loss=0.00291]\n",
      "Epoch: 26/50: 100%|██████████| 29/29 [00:00<00:00, 137.36it/s, train_loss=0.00389, valid_loss=0.00253]\n",
      "Epoch: 27/50: 100%|██████████| 29/29 [00:00<00:00, 138.75it/s, train_loss=0.00371, valid_loss=0.00208]\n",
      "Epoch: 28/50: 100%|██████████| 29/29 [00:00<00:00, 130.06it/s, train_loss=0.00344, valid_loss=0.00191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 36/36 [00:00<00:00, 94.99it/s, train_loss=0.0196, valid_loss=0.0161]\n",
      "Epoch: 2/50: 100%|██████████| 36/36 [00:00<00:00, 133.89it/s, train_loss=0.0105, valid_loss=0.00772]\n",
      "Epoch: 3/50: 100%|██████████| 36/36 [00:00<00:00, 111.03it/s, train_loss=0.0082, valid_loss=0.00563] \n",
      "Epoch: 4/50: 100%|██████████| 36/36 [00:00<00:00, 126.24it/s, train_loss=0.00838, valid_loss=0.00506]\n",
      "Epoch: 5/50: 100%|██████████| 36/36 [00:00<00:00, 127.39it/s, train_loss=0.00769, valid_loss=0.0043] \n",
      "Epoch: 6/50: 100%|██████████| 36/36 [00:00<00:00, 117.35it/s, train_loss=0.00678, valid_loss=0.00384]\n",
      "Epoch: 7/50: 100%|██████████| 36/36 [00:00<00:00, 134.46it/s, train_loss=0.00618, valid_loss=0.00348]\n",
      "Epoch: 8/50: 100%|██████████| 36/36 [00:00<00:00, 116.34it/s, train_loss=0.00617, valid_loss=0.00312]\n",
      "Epoch: 9/50: 100%|██████████| 36/36 [00:00<00:00, 125.13it/s, train_loss=0.00547, valid_loss=0.00281]\n",
      "Epoch: 10/50: 100%|██████████| 36/36 [00:00<00:00, 102.53it/s, train_loss=0.005, valid_loss=0.00272]  \n",
      "Epoch: 11/50: 100%|██████████| 36/36 [00:00<00:00, 133.24it/s, train_loss=0.00529, valid_loss=0.0027] \n",
      "Epoch: 12/50: 100%|██████████| 36/36 [00:00<00:00, 112.10it/s, train_loss=0.00501, valid_loss=0.00275]\n",
      "Epoch: 13/50: 100%|██████████| 36/36 [00:00<00:00, 133.28it/s, train_loss=0.00527, valid_loss=0.00247]\n",
      "Epoch: 14/50: 100%|██████████| 36/36 [00:00<00:00, 106.19it/s, train_loss=0.00456, valid_loss=0.00247]\n",
      "Epoch: 15/50: 100%|██████████| 36/36 [00:00<00:00, 128.17it/s, train_loss=0.00446, valid_loss=0.00269]\n",
      "Epoch: 16/50: 100%|██████████| 36/36 [00:00<00:00, 103.60it/s, train_loss=0.00531, valid_loss=0.00267]\n",
      "Epoch: 17/50: 100%|██████████| 36/36 [00:00<00:00, 121.36it/s, train_loss=0.00543, valid_loss=0.00243]\n",
      "Epoch: 18/50: 100%|██████████| 36/36 [00:00<00:00, 133.54it/s, train_loss=0.00435, valid_loss=0.00274]\n",
      "Epoch: 19/50: 100%|██████████| 36/36 [00:00<00:00, 127.05it/s, train_loss=0.00463, valid_loss=0.00255]\n",
      "Epoch: 20/50: 100%|██████████| 36/36 [00:00<00:00, 116.51it/s, train_loss=0.00488, valid_loss=0.00261]\n",
      "Epoch: 21/50: 100%|██████████| 36/36 [00:00<00:00, 127.16it/s, train_loss=0.00481, valid_loss=0.00261]\n",
      "Epoch: 22/50: 100%|██████████| 36/36 [00:00<00:00, 113.14it/s, train_loss=0.0048, valid_loss=0.00237] \n",
      "Epoch: 23/50: 100%|██████████| 36/36 [00:00<00:00, 128.69it/s, train_loss=0.00428, valid_loss=0.00263]\n",
      "Epoch: 24/50: 100%|██████████| 36/36 [00:00<00:00, 111.32it/s, train_loss=0.00488, valid_loss=0.00274]\n",
      "Epoch: 25/50: 100%|██████████| 36/36 [00:00<00:00, 129.41it/s, train_loss=0.00438, valid_loss=0.00249]\n",
      "Epoch: 26/50: 100%|██████████| 36/36 [00:00<00:00, 111.17it/s, train_loss=0.00436, valid_loss=0.00244]\n",
      "Epoch: 27/50: 100%|██████████| 36/36 [00:00<00:00, 127.90it/s, train_loss=0.00413, valid_loss=0.00266]\n",
      "Epoch: 28/50: 100%|██████████| 36/36 [00:00<00:00, 134.27it/s, train_loss=0.00433, valid_loss=0.00224]\n",
      "Epoch: 29/50: 100%|██████████| 36/36 [00:00<00:00, 117.84it/s, train_loss=0.00452, valid_loss=0.00252]\n",
      "Epoch: 30/50: 100%|██████████| 36/36 [00:00<00:00, 112.52it/s, train_loss=0.00392, valid_loss=0.0025] \n",
      "Epoch: 31/50: 100%|██████████| 36/36 [00:00<00:00, 134.35it/s, train_loss=0.00422, valid_loss=0.00246]\n",
      "Epoch: 32/50: 100%|██████████| 36/36 [00:00<00:00, 101.82it/s, train_loss=0.00442, valid_loss=0.00257]\n",
      "Epoch: 33/50: 100%|██████████| 36/36 [00:00<00:00, 133.99it/s, train_loss=0.00403, valid_loss=0.00245]\n",
      "Epoch: 34/50: 100%|██████████| 36/36 [00:00<00:00, 128.22it/s, train_loss=0.00341, valid_loss=0.00249]\n",
      "Epoch: 35/50: 100%|██████████| 36/36 [00:00<00:00, 112.08it/s, train_loss=0.00405, valid_loss=0.00239]\n",
      "Epoch: 36/50: 100%|██████████| 36/36 [00:00<00:00, 117.77it/s, train_loss=0.00377, valid_loss=0.00237]\n",
      "Epoch: 37/50: 100%|██████████| 36/36 [00:00<00:00, 123.84it/s, train_loss=0.0037, valid_loss=0.00231] \n",
      "Epoch: 38/50: 100%|██████████| 36/36 [00:00<00:00, 112.09it/s, train_loss=0.0037, valid_loss=0.00238] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config: batch_size--256, lr--0.01, number_epoch--50, hidden_dim--25,drop_prob-0.1,weight_decay-1e-07\n",
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 15/15 [00:00<00:00, 94.54it/s, train_loss=0.0299, valid_loss=0.0487]\n",
      "Epoch: 2/50: 100%|██████████| 15/15 [00:00<00:00, 143.72it/s, train_loss=0.0272, valid_loss=0.0445]\n",
      "Epoch: 3/50: 100%|██████████| 15/15 [00:00<00:00, 130.80it/s, train_loss=0.019, valid_loss=0.0338]\n",
      "Epoch: 4/50: 100%|██████████| 15/15 [00:00<00:00, 152.74it/s, train_loss=0.00903, valid_loss=0.0157]\n",
      "Epoch: 5/50: 100%|██████████| 15/15 [00:00<00:00, 155.98it/s, train_loss=0.00639, valid_loss=0.00931]\n",
      "Epoch: 6/50: 100%|██████████| 15/15 [00:00<00:00, 134.65it/s, train_loss=0.00593, valid_loss=0.0073]\n",
      "Epoch: 7/50: 100%|██████████| 15/15 [00:00<00:00, 110.22it/s, train_loss=0.00485, valid_loss=0.0075]\n",
      "Epoch: 8/50: 100%|██████████| 15/15 [00:00<00:00, 155.39it/s, train_loss=0.00552, valid_loss=0.00647]\n",
      "Epoch: 9/50: 100%|██████████| 15/15 [00:00<00:00, 133.60it/s, train_loss=0.0045, valid_loss=0.00612]\n",
      "Epoch: 10/50: 100%|██████████| 15/15 [00:00<00:00, 127.42it/s, train_loss=0.00451, valid_loss=0.00625]\n",
      "Epoch: 11/50: 100%|██████████| 15/15 [00:00<00:00, 154.27it/s, train_loss=0.00421, valid_loss=0.00566]\n",
      "Epoch: 12/50: 100%|██████████| 15/15 [00:00<00:00, 156.49it/s, train_loss=0.00393, valid_loss=0.00567]\n",
      "Epoch: 13/50: 100%|██████████| 15/15 [00:00<00:00, 106.35it/s, train_loss=0.00393, valid_loss=0.00551]\n",
      "Epoch: 14/50: 100%|██████████| 15/15 [00:00<00:00, 155.25it/s, train_loss=0.00403, valid_loss=0.0055]\n",
      "Epoch: 15/50: 100%|██████████| 15/15 [00:00<00:00, 129.90it/s, train_loss=0.00372, valid_loss=0.00528]\n",
      "Epoch: 16/50: 100%|██████████| 15/15 [00:00<00:00, 131.88it/s, train_loss=0.00335, valid_loss=0.00586]\n",
      "Epoch: 17/50: 100%|██████████| 15/15 [00:00<00:00, 128.06it/s, train_loss=0.00366, valid_loss=0.0053]\n",
      "Epoch: 18/50: 100%|██████████| 15/15 [00:00<00:00, 153.44it/s, train_loss=0.00391, valid_loss=0.0052]\n",
      "Epoch: 19/50: 100%|██████████| 15/15 [00:00<00:00, 135.25it/s, train_loss=0.00334, valid_loss=0.00517]\n",
      "Epoch: 20/50: 100%|██████████| 15/15 [00:00<00:00, 156.50it/s, train_loss=0.00382, valid_loss=0.00565]\n",
      "Epoch: 21/50: 100%|██████████| 15/15 [00:00<00:00, 156.14it/s, train_loss=0.00314, valid_loss=0.00573]\n",
      "Epoch: 22/50: 100%|██████████| 15/15 [00:00<00:00, 134.33it/s, train_loss=0.00344, valid_loss=0.00521]\n",
      "Epoch: 23/50: 100%|██████████| 15/15 [00:00<00:00, 129.33it/s, train_loss=0.00374, valid_loss=0.00523]\n",
      "Epoch: 24/50: 100%|██████████| 15/15 [00:00<00:00, 155.64it/s, train_loss=0.00338, valid_loss=0.00485]\n",
      "Epoch: 25/50: 100%|██████████| 15/15 [00:00<00:00, 154.71it/s, train_loss=0.00329, valid_loss=0.00489]\n",
      "Epoch: 26/50: 100%|██████████| 15/15 [00:00<00:00, 111.56it/s, train_loss=0.00358, valid_loss=0.0051]\n",
      "Epoch: 27/50: 100%|██████████| 15/15 [00:00<00:00, 123.34it/s, train_loss=0.00332, valid_loss=0.00495]\n",
      "Epoch: 28/50: 100%|██████████| 15/15 [00:00<00:00, 130.16it/s, train_loss=0.00368, valid_loss=0.00487]\n",
      "Epoch: 29/50: 100%|██████████| 15/15 [00:00<00:00, 156.23it/s, train_loss=0.00349, valid_loss=0.00479]\n",
      "Epoch: 30/50: 100%|██████████| 15/15 [00:00<00:00, 128.60it/s, train_loss=0.00321, valid_loss=0.0048]\n",
      "Epoch: 31/50: 100%|██████████| 15/15 [00:00<00:00, 155.16it/s, train_loss=0.0032, valid_loss=0.00488]\n",
      "Epoch: 32/50: 100%|██████████| 15/15 [00:00<00:00, 133.45it/s, train_loss=0.00316, valid_loss=0.00499]\n",
      "Epoch: 33/50: 100%|██████████| 15/15 [00:00<00:00, 128.65it/s, train_loss=0.00361, valid_loss=0.00475]\n",
      "Epoch: 34/50: 100%|██████████| 15/15 [00:00<00:00, 139.96it/s, train_loss=0.00331, valid_loss=0.00484]\n",
      "Epoch: 35/50: 100%|██████████| 15/15 [00:00<00:00, 128.51it/s, train_loss=0.00324, valid_loss=0.00503]\n",
      "Epoch: 36/50: 100%|██████████| 15/15 [00:00<00:00, 133.11it/s, train_loss=0.00309, valid_loss=0.00475]\n",
      "Epoch: 37/50: 100%|██████████| 15/15 [00:00<00:00, 139.09it/s, train_loss=0.0031, valid_loss=0.00477]\n",
      "Epoch: 38/50: 100%|██████████| 15/15 [00:00<00:00, 143.44it/s, train_loss=0.00328, valid_loss=0.00494]\n",
      "Epoch: 39/50: 100%|██████████| 15/15 [00:00<00:00, 94.28it/s, train_loss=0.0038, valid_loss=0.00478]\n",
      "Epoch: 40/50: 100%|██████████| 15/15 [00:00<00:00, 127.80it/s, train_loss=0.00302, valid_loss=0.00479]\n",
      "Epoch: 41/50: 100%|██████████| 15/15 [00:00<00:00, 142.23it/s, train_loss=0.00361, valid_loss=0.00493]\n",
      "Epoch: 42/50: 100%|██████████| 15/15 [00:00<00:00, 154.55it/s, train_loss=0.00305, valid_loss=0.0052]\n",
      "Epoch: 43/50: 100%|██████████| 15/15 [00:00<00:00, 156.90it/s, train_loss=0.00328, valid_loss=0.00456]\n",
      "Epoch: 44/50: 100%|██████████| 15/15 [00:00<00:00, 158.81it/s, train_loss=0.00311, valid_loss=0.0052]\n",
      "Epoch: 45/50: 100%|██████████| 15/15 [00:00<00:00, 155.12it/s, train_loss=0.00293, valid_loss=0.00463]\n",
      "Epoch: 46/50: 100%|██████████| 15/15 [00:00<00:00, 154.99it/s, train_loss=0.00329, valid_loss=0.0049]\n",
      "Epoch: 47/50: 100%|██████████| 15/15 [00:00<00:00, 156.65it/s, train_loss=0.00311, valid_loss=0.00476]\n",
      "Epoch: 48/50: 100%|██████████| 15/15 [00:00<00:00, 159.60it/s, train_loss=0.00328, valid_loss=0.00489]\n",
      "Epoch: 49/50: 100%|██████████| 15/15 [00:00<00:00, 155.96it/s, train_loss=0.00373, valid_loss=0.00474]\n",
      "Epoch: 50/50: 100%|██████████| 15/15 [00:00<00:00, 156.48it/s, train_loss=0.00344, valid_loss=0.00494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 29/29 [00:00<00:00, 98.61it/s, train_loss=0.0196, valid_loss=0.0125]\n",
      "Epoch: 2/50: 100%|██████████| 29/29 [00:00<00:00, 153.44it/s, train_loss=0.0117, valid_loss=0.00562]\n",
      "Epoch: 3/50: 100%|██████████| 29/29 [00:00<00:00, 151.40it/s, train_loss=0.00868, valid_loss=0.00808]\n",
      "Epoch: 4/50: 100%|██████████| 29/29 [00:00<00:00, 151.95it/s, train_loss=0.00782, valid_loss=0.00493]\n",
      "Epoch: 5/50: 100%|██████████| 29/29 [00:00<00:00, 152.42it/s, train_loss=0.00667, valid_loss=0.00462]\n",
      "Epoch: 6/50: 100%|██████████| 29/29 [00:00<00:00, 153.44it/s, train_loss=0.00667, valid_loss=0.00473]\n",
      "Epoch: 7/50: 100%|██████████| 29/29 [00:00<00:00, 153.01it/s, train_loss=0.00582, valid_loss=0.0036] \n",
      "Epoch: 8/50: 100%|██████████| 29/29 [00:00<00:00, 127.30it/s, train_loss=0.00584, valid_loss=0.00361]\n",
      "Epoch: 9/50: 100%|██████████| 29/29 [00:00<00:00, 152.46it/s, train_loss=0.00579, valid_loss=0.00318]\n",
      "Epoch: 10/50: 100%|██████████| 29/29 [00:00<00:00, 152.85it/s, train_loss=0.00493, valid_loss=0.0025] \n",
      "Epoch: 11/50: 100%|██████████| 29/29 [00:00<00:00, 153.34it/s, train_loss=0.0053, valid_loss=0.00343] \n",
      "Epoch: 12/50: 100%|██████████| 29/29 [00:00<00:00, 153.00it/s, train_loss=0.00576, valid_loss=0.00374]\n",
      "Epoch: 13/50: 100%|██████████| 29/29 [00:00<00:00, 152.66it/s, train_loss=0.00481, valid_loss=0.00257]\n",
      "Epoch: 14/50: 100%|██████████| 29/29 [00:00<00:00, 128.71it/s, train_loss=0.00484, valid_loss=0.0024] \n",
      "Epoch: 15/50: 100%|██████████| 29/29 [00:00<00:00, 152.01it/s, train_loss=0.005, valid_loss=0.00382]  \n",
      "Epoch: 16/50: 100%|██████████| 29/29 [00:00<00:00, 152.57it/s, train_loss=0.00509, valid_loss=0.00278]\n",
      "Epoch: 17/50: 100%|██████████| 29/29 [00:00<00:00, 151.99it/s, train_loss=0.00495, valid_loss=0.00334]\n",
      "Epoch: 18/50: 100%|██████████| 29/29 [00:00<00:00, 150.90it/s, train_loss=0.00508, valid_loss=0.00226]\n",
      "Epoch: 19/50: 100%|██████████| 29/29 [00:00<00:00, 152.46it/s, train_loss=0.00476, valid_loss=0.00266]\n",
      "Epoch: 20/50: 100%|██████████| 29/29 [00:00<00:00, 152.73it/s, train_loss=0.00472, valid_loss=0.00283]\n",
      "Epoch: 21/50: 100%|██████████| 29/29 [00:00<00:00, 127.46it/s, train_loss=0.00519, valid_loss=0.00294]\n",
      "Epoch: 22/50: 100%|██████████| 29/29 [00:00<00:00, 152.06it/s, train_loss=0.00489, valid_loss=0.00361]\n",
      "Epoch: 23/50: 100%|██████████| 29/29 [00:00<00:00, 152.50it/s, train_loss=0.00476, valid_loss=0.00289]\n",
      "Epoch: 24/50: 100%|██████████| 29/29 [00:00<00:00, 152.30it/s, train_loss=0.00482, valid_loss=0.00295]\n",
      "Epoch: 25/50: 100%|██████████| 29/29 [00:00<00:00, 150.39it/s, train_loss=0.00527, valid_loss=0.00408]\n",
      "Epoch: 26/50: 100%|██████████| 29/29 [00:00<00:00, 146.28it/s, train_loss=0.00513, valid_loss=0.00452]\n",
      "Epoch: 27/50: 100%|██████████| 29/29 [00:00<00:00, 145.81it/s, train_loss=0.00536, valid_loss=0.0033] \n",
      "Epoch: 28/50: 100%|██████████| 29/29 [00:00<00:00, 122.10it/s, train_loss=0.0048, valid_loss=0.00434] \n",
      "Epoch: 29/50: 100%|██████████| 29/29 [00:00<00:00, 145.10it/s, train_loss=0.00497, valid_loss=0.00435]\n",
      "Epoch: 30/50: 100%|██████████| 29/29 [00:00<00:00, 146.49it/s, train_loss=0.00458, valid_loss=0.00319]\n",
      "Epoch: 31/50: 100%|██████████| 29/29 [00:00<00:00, 144.87it/s, train_loss=0.00428, valid_loss=0.00301]\n",
      "Epoch: 32/50: 100%|██████████| 29/29 [00:00<00:00, 145.30it/s, train_loss=0.00394, valid_loss=0.00403]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 44/44 [00:00<00:00, 128.07it/s, train_loss=0.0207, valid_loss=0.0224]\n",
      "Epoch: 2/50: 100%|██████████| 44/44 [00:00<00:00, 134.80it/s, train_loss=0.00683, valid_loss=0.00623]\n",
      "Epoch: 3/50: 100%|██████████| 44/44 [00:00<00:00, 154.35it/s, train_loss=0.00763, valid_loss=0.00556]\n",
      "Epoch: 4/50: 100%|██████████| 44/44 [00:00<00:00, 153.97it/s, train_loss=0.00641, valid_loss=0.00434]\n",
      "Epoch: 5/50: 100%|██████████| 44/44 [00:00<00:00, 154.23it/s, train_loss=0.00557, valid_loss=0.00409]\n",
      "Epoch: 6/50: 100%|██████████| 44/44 [00:00<00:00, 136.87it/s, train_loss=0.00667, valid_loss=0.00419]\n",
      "Epoch: 7/50: 100%|██████████| 44/44 [00:00<00:00, 153.22it/s, train_loss=0.00536, valid_loss=0.00441]\n",
      "Epoch: 8/50: 100%|██████████| 44/44 [00:00<00:00, 147.46it/s, train_loss=0.00527, valid_loss=0.00394]\n",
      "Epoch: 9/50: 100%|██████████| 44/44 [00:00<00:00, 154.92it/s, train_loss=0.00479, valid_loss=0.00397]\n",
      "Epoch: 10/50: 100%|██████████| 44/44 [00:00<00:00, 136.81it/s, train_loss=0.00521, valid_loss=0.0038] \n",
      "Epoch: 11/50: 100%|██████████| 44/44 [00:00<00:00, 154.95it/s, train_loss=0.0047, valid_loss=0.00402] \n",
      "Epoch: 12/50: 100%|██████████| 44/44 [00:00<00:00, 153.54it/s, train_loss=0.00433, valid_loss=0.00375]\n",
      "Epoch: 13/50: 100%|██████████| 44/44 [00:00<00:00, 154.40it/s, train_loss=0.00437, valid_loss=0.00369]\n",
      "Epoch: 14/50: 100%|██████████| 44/44 [00:00<00:00, 154.01it/s, train_loss=0.00437, valid_loss=0.00387]\n",
      "Epoch: 15/50: 100%|██████████| 44/44 [00:00<00:00, 136.15it/s, train_loss=0.00464, valid_loss=0.00398]\n",
      "Epoch: 16/50: 100%|██████████| 44/44 [00:00<00:00, 154.21it/s, train_loss=0.0042, valid_loss=0.00434] \n",
      "Epoch: 17/50: 100%|██████████| 44/44 [00:00<00:00, 154.37it/s, train_loss=0.00395, valid_loss=0.00346]\n",
      "Epoch: 18/50: 100%|██████████| 44/44 [00:00<00:00, 145.45it/s, train_loss=0.00449, valid_loss=0.00429]\n",
      "Epoch: 19/50: 100%|██████████| 44/44 [00:00<00:00, 137.13it/s, train_loss=0.00426, valid_loss=0.00381]\n",
      "Epoch: 20/50: 100%|██████████| 44/44 [00:00<00:00, 153.76it/s, train_loss=0.0042, valid_loss=0.0037]  \n",
      "Epoch: 21/50: 100%|██████████| 44/44 [00:00<00:00, 153.25it/s, train_loss=0.00399, valid_loss=0.0041] \n",
      "Epoch: 22/50: 100%|██████████| 44/44 [00:00<00:00, 154.35it/s, train_loss=0.00408, valid_loss=0.00406]\n",
      "Epoch: 23/50: 100%|██████████| 44/44 [00:00<00:00, 154.17it/s, train_loss=0.00421, valid_loss=0.00365]\n",
      "Epoch: 24/50: 100%|██████████| 44/44 [00:00<00:00, 130.18it/s, train_loss=0.00355, valid_loss=0.00373]\n",
      "Epoch: 25/50: 100%|██████████| 44/44 [00:00<00:00, 153.41it/s, train_loss=0.00382, valid_loss=0.00403]\n",
      "Epoch: 26/50: 100%|██████████| 44/44 [00:00<00:00, 153.34it/s, train_loss=0.00365, valid_loss=0.00372]\n",
      "Epoch: 27/50: 100%|██████████| 44/44 [00:00<00:00, 153.83it/s, train_loss=0.00472, valid_loss=0.00452]\n",
      "Epoch: 28/50: 100%|██████████| 44/44 [00:00<00:00, 135.72it/s, train_loss=0.00414, valid_loss=0.00471]\n",
      "Epoch: 29/50: 100%|██████████| 44/44 [00:00<00:00, 154.33it/s, train_loss=0.00384, valid_loss=0.00402]\n",
      "Epoch: 30/50: 100%|██████████| 44/44 [00:00<00:00, 154.57it/s, train_loss=0.00445, valid_loss=0.00412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 58/58 [00:00<00:00, 132.94it/s, train_loss=0.0142, valid_loss=0.00801]\n",
      "Epoch: 2/50: 100%|██████████| 58/58 [00:00<00:00, 137.62it/s, train_loss=0.00844, valid_loss=0.0049] \n",
      "Epoch: 3/50: 100%|██████████| 58/58 [00:00<00:00, 152.08it/s, train_loss=0.00757, valid_loss=0.00376]\n",
      "Epoch: 4/50: 100%|██████████| 58/58 [00:00<00:00, 152.39it/s, train_loss=0.0067, valid_loss=0.00362] \n",
      "Epoch: 5/50: 100%|██████████| 58/58 [00:00<00:00, 138.63it/s, train_loss=0.00557, valid_loss=0.00384]\n",
      "Epoch: 6/50: 100%|██████████| 58/58 [00:00<00:00, 147.70it/s, train_loss=0.00634, valid_loss=0.00327]\n",
      "Epoch: 7/50: 100%|██████████| 58/58 [00:00<00:00, 145.60it/s, train_loss=0.00645, valid_loss=0.00302]\n",
      "Epoch: 8/50: 100%|██████████| 58/58 [00:00<00:00, 152.23it/s, train_loss=0.00664, valid_loss=0.00446]\n",
      "Epoch: 9/50: 100%|██████████| 58/58 [00:00<00:00, 138.06it/s, train_loss=0.007, valid_loss=0.00401]  \n",
      "Epoch: 10/50: 100%|██████████| 58/58 [00:00<00:00, 152.08it/s, train_loss=0.00554, valid_loss=0.00307]\n",
      "Epoch: 11/50: 100%|██████████| 58/58 [00:00<00:00, 151.46it/s, train_loss=0.00612, valid_loss=0.00324]\n",
      "Epoch: 12/50: 100%|██████████| 58/58 [00:00<00:00, 135.75it/s, train_loss=0.0074, valid_loss=0.00343] \n",
      "Epoch: 13/50: 100%|██████████| 58/58 [00:00<00:00, 152.34it/s, train_loss=0.00643, valid_loss=0.00296]\n",
      "Epoch: 14/50: 100%|██████████| 58/58 [00:00<00:00, 141.69it/s, train_loss=0.00592, valid_loss=0.0029] \n",
      "Epoch: 15/50: 100%|██████████| 58/58 [00:00<00:00, 130.95it/s, train_loss=0.00508, valid_loss=0.00276]\n",
      "Epoch: 16/50: 100%|██████████| 58/58 [00:00<00:00, 151.44it/s, train_loss=0.00685, valid_loss=0.00276]\n",
      "Epoch: 17/50: 100%|██████████| 58/58 [00:00<00:00, 151.16it/s, train_loss=0.00661, valid_loss=0.0027] \n",
      "Epoch: 18/50: 100%|██████████| 58/58 [00:00<00:00, 137.69it/s, train_loss=0.00602, valid_loss=0.00266]\n",
      "Epoch: 19/50: 100%|██████████| 58/58 [00:00<00:00, 152.41it/s, train_loss=0.00576, valid_loss=0.00307]\n",
      "Epoch: 20/50: 100%|██████████| 58/58 [00:00<00:00, 151.37it/s, train_loss=0.00619, valid_loss=0.00275]\n",
      "Epoch: 21/50: 100%|██████████| 58/58 [00:00<00:00, 151.35it/s, train_loss=0.00537, valid_loss=0.00363]\n",
      "Epoch: 22/50: 100%|██████████| 58/58 [00:00<00:00, 137.71it/s, train_loss=0.00513, valid_loss=0.00336]\n",
      "Epoch: 23/50: 100%|██████████| 58/58 [00:00<00:00, 147.63it/s, train_loss=0.00564, valid_loss=0.00338]\n",
      "Epoch: 24/50: 100%|██████████| 58/58 [00:00<00:00, 151.50it/s, train_loss=0.00559, valid_loss=0.00284]\n",
      "Epoch: 25/50: 100%|██████████| 58/58 [00:00<00:00, 132.28it/s, train_loss=0.0051, valid_loss=0.00239] \n",
      "Epoch: 26/50: 100%|██████████| 58/58 [00:00<00:00, 151.34it/s, train_loss=0.00512, valid_loss=0.00292]\n",
      "Epoch: 27/50: 100%|██████████| 58/58 [00:00<00:00, 151.44it/s, train_loss=0.00481, valid_loss=0.0031] \n",
      "Epoch: 28/50: 100%|██████████| 58/58 [00:00<00:00, 137.75it/s, train_loss=0.00545, valid_loss=0.00394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 72/72 [00:00<00:00, 136.46it/s, train_loss=0.0102, valid_loss=0.00767]\n",
      "Epoch: 2/50: 100%|██████████| 72/72 [00:00<00:00, 153.41it/s, train_loss=0.0064, valid_loss=0.00456] \n",
      "Epoch: 3/50: 100%|██████████| 72/72 [00:00<00:00, 140.85it/s, train_loss=0.00672, valid_loss=0.00358]\n",
      "Epoch: 4/50: 100%|██████████| 72/72 [00:00<00:00, 152.64it/s, train_loss=0.00621, valid_loss=0.00333]\n",
      "Epoch: 5/50: 100%|██████████| 72/72 [00:00<00:00, 150.69it/s, train_loss=0.00626, valid_loss=0.00323]\n",
      "Epoch: 6/50: 100%|██████████| 72/72 [00:00<00:00, 139.98it/s, train_loss=0.00552, valid_loss=0.0034] \n",
      "Epoch: 7/50: 100%|██████████| 72/72 [00:00<00:00, 150.64it/s, train_loss=0.0048, valid_loss=0.00311] \n",
      "Epoch: 8/50: 100%|██████████| 72/72 [00:00<00:00, 139.00it/s, train_loss=0.00492, valid_loss=0.003]  \n",
      "Epoch: 9/50: 100%|██████████| 72/72 [00:00<00:00, 150.90it/s, train_loss=0.0056, valid_loss=0.00317] \n",
      "Epoch: 10/50: 100%|██████████| 72/72 [00:00<00:00, 151.59it/s, train_loss=0.00576, valid_loss=0.00356]\n",
      "Epoch: 11/50: 100%|██████████| 72/72 [00:00<00:00, 138.74it/s, train_loss=0.00539, valid_loss=0.00309]\n",
      "Epoch: 12/50: 100%|██████████| 72/72 [00:00<00:00, 151.28it/s, train_loss=0.00537, valid_loss=0.00291]\n",
      "Epoch: 13/50: 100%|██████████| 72/72 [00:00<00:00, 146.18it/s, train_loss=0.00596, valid_loss=0.00257]\n",
      "Epoch: 14/50: 100%|██████████| 72/72 [00:00<00:00, 136.74it/s, train_loss=0.00494, valid_loss=0.00301]\n",
      "Epoch: 15/50: 100%|██████████| 72/72 [00:00<00:00, 152.01it/s, train_loss=0.00487, valid_loss=0.0031] \n",
      "Epoch: 16/50: 100%|██████████| 72/72 [00:00<00:00, 139.41it/s, train_loss=0.00472, valid_loss=0.00302]\n",
      "Epoch: 17/50: 100%|██████████| 72/72 [00:00<00:00, 144.12it/s, train_loss=0.00538, valid_loss=0.00324]\n",
      "Epoch: 18/50: 100%|██████████| 72/72 [00:00<00:00, 151.06it/s, train_loss=0.00442, valid_loss=0.00362]\n",
      "Epoch: 19/50: 100%|██████████| 72/72 [00:00<00:00, 139.76it/s, train_loss=0.00512, valid_loss=0.00288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config: batch_size--512, lr--0.005, number_epoch--50, hidden_dim--30,drop_prob-0.1,weight_decay-1e-07\n",
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 8/8 [00:00<00:00, 81.22it/s, train_loss=0.0529, valid_loss=0.0755]\n",
      "Epoch: 2/50: 100%|██████████| 8/8 [00:00<00:00, 89.14it/s, train_loss=0.0386, valid_loss=0.0603]\n",
      "Epoch: 3/50: 100%|██████████| 8/8 [00:00<00:00, 137.55it/s, train_loss=0.0285, valid_loss=0.0457]\n",
      "Epoch: 4/50: 100%|██████████| 8/8 [00:00<00:00, 127.64it/s, train_loss=0.028, valid_loss=0.0424]\n",
      "Epoch: 5/50: 100%|██████████| 8/8 [00:00<00:00, 130.18it/s, train_loss=0.0227, valid_loss=0.0365]\n",
      "Epoch: 6/50: 100%|██████████| 8/8 [00:00<00:00, 131.51it/s, train_loss=0.0225, valid_loss=0.0349]\n",
      "Epoch: 7/50: 100%|██████████| 8/8 [00:00<00:00, 80.18it/s, train_loss=0.0213, valid_loss=0.0325]\n",
      "Epoch: 8/50: 100%|██████████| 8/8 [00:00<00:00, 122.48it/s, train_loss=0.0193, valid_loss=0.0284]\n",
      "Epoch: 9/50: 100%|██████████| 8/8 [00:00<00:00, 126.06it/s, train_loss=0.0128, valid_loss=0.0193]\n",
      "Epoch: 10/50: 100%|██████████| 8/8 [00:00<00:00, 128.54it/s, train_loss=0.0116, valid_loss=0.018]\n",
      "Epoch: 11/50: 100%|██████████| 8/8 [00:00<00:00, 127.75it/s, train_loss=0.0106, valid_loss=0.0162]\n",
      "Epoch: 12/50: 100%|██████████| 8/8 [00:00<00:00, 129.53it/s, train_loss=0.00976, valid_loss=0.0146]\n",
      "Epoch: 13/50: 100%|██████████| 8/8 [00:00<00:00, 129.42it/s, train_loss=0.0098, valid_loss=0.0141]\n",
      "Epoch: 14/50: 100%|██████████| 8/8 [00:00<00:00, 131.37it/s, train_loss=0.00968, valid_loss=0.0132]\n",
      "Epoch: 15/50: 100%|██████████| 8/8 [00:00<00:00, 130.25it/s, train_loss=0.00926, valid_loss=0.0133]\n",
      "Epoch: 16/50: 100%|██████████| 8/8 [00:00<00:00, 127.63it/s, train_loss=0.00925, valid_loss=0.0125]\n",
      "Epoch: 17/50: 100%|██████████| 8/8 [00:00<00:00, 82.04it/s, train_loss=0.00895, valid_loss=0.0127]\n",
      "Epoch: 18/50: 100%|██████████| 8/8 [00:00<00:00, 128.32it/s, train_loss=0.00911, valid_loss=0.0124]\n",
      "Epoch: 19/50: 100%|██████████| 8/8 [00:00<00:00, 127.83it/s, train_loss=0.0095, valid_loss=0.0121]\n",
      "Epoch: 20/50: 100%|██████████| 8/8 [00:00<00:00, 129.41it/s, train_loss=0.00837, valid_loss=0.0123]\n",
      "Epoch: 21/50: 100%|██████████| 8/8 [00:00<00:00, 129.35it/s, train_loss=0.00876, valid_loss=0.0117]\n",
      "Epoch: 22/50: 100%|██████████| 8/8 [00:00<00:00, 129.02it/s, train_loss=0.00862, valid_loss=0.0117]\n",
      "Epoch: 23/50: 100%|██████████| 8/8 [00:00<00:00, 129.95it/s, train_loss=0.00872, valid_loss=0.0115]\n",
      "Epoch: 24/50: 100%|██████████| 8/8 [00:00<00:00, 126.60it/s, train_loss=0.00827, valid_loss=0.0116]\n",
      "Epoch: 25/50: 100%|██████████| 8/8 [00:00<00:00, 127.46it/s, train_loss=0.00851, valid_loss=0.0116]\n",
      "Epoch: 26/50: 100%|██████████| 8/8 [00:00<00:00, 81.15it/s, train_loss=0.00812, valid_loss=0.0113]\n",
      "Epoch: 27/50: 100%|██████████| 8/8 [00:00<00:00, 127.08it/s, train_loss=0.00826, valid_loss=0.0115]\n",
      "Epoch: 28/50: 100%|██████████| 8/8 [00:00<00:00, 128.74it/s, train_loss=0.00822, valid_loss=0.0113]\n",
      "Epoch: 29/50: 100%|██████████| 8/8 [00:00<00:00, 128.81it/s, train_loss=0.0081, valid_loss=0.0111]\n",
      "Epoch: 30/50: 100%|██████████| 8/8 [00:00<00:00, 128.09it/s, train_loss=0.00798, valid_loss=0.0113]\n",
      "Epoch: 31/50: 100%|██████████| 8/8 [00:00<00:00, 129.74it/s, train_loss=0.00801, valid_loss=0.011]\n",
      "Epoch: 32/50: 100%|██████████| 8/8 [00:00<00:00, 128.33it/s, train_loss=0.00793, valid_loss=0.011]\n",
      "Epoch: 33/50: 100%|██████████| 8/8 [00:00<00:00, 128.25it/s, train_loss=0.00798, valid_loss=0.011]\n",
      "Epoch: 34/50: 100%|██████████| 8/8 [00:00<00:00, 129.90it/s, train_loss=0.00801, valid_loss=0.0111]\n",
      "Epoch: 35/50: 100%|██████████| 8/8 [00:00<00:00, 81.85it/s, train_loss=0.00783, valid_loss=0.0108]\n",
      "Epoch: 36/50: 100%|██████████| 8/8 [00:00<00:00, 128.14it/s, train_loss=0.00803, valid_loss=0.0109]\n",
      "Epoch: 37/50: 100%|██████████| 8/8 [00:00<00:00, 130.60it/s, train_loss=0.00755, valid_loss=0.0108]\n",
      "Epoch: 38/50: 100%|██████████| 8/8 [00:00<00:00, 128.09it/s, train_loss=0.00769, valid_loss=0.011]\n",
      "Epoch: 39/50: 100%|██████████| 8/8 [00:00<00:00, 128.26it/s, train_loss=0.00731, valid_loss=0.0111]\n",
      "Epoch: 40/50: 100%|██████████| 8/8 [00:00<00:00, 131.19it/s, train_loss=0.00753, valid_loss=0.0106]\n",
      "Epoch: 41/50: 100%|██████████| 8/8 [00:00<00:00, 127.54it/s, train_loss=0.00713, valid_loss=0.0106]\n",
      "Epoch: 42/50: 100%|██████████| 8/8 [00:00<00:00, 129.60it/s, train_loss=0.00786, valid_loss=0.0109]\n",
      "Epoch: 43/50: 100%|██████████| 8/8 [00:00<00:00, 130.00it/s, train_loss=0.00723, valid_loss=0.0108]\n",
      "Epoch: 44/50: 100%|██████████| 8/8 [00:00<00:00, 128.65it/s, train_loss=0.00758, valid_loss=0.0107]\n",
      "Epoch: 45/50: 100%|██████████| 8/8 [00:00<00:00, 129.93it/s, train_loss=0.00783, valid_loss=0.0107]\n",
      "Epoch: 46/50: 100%|██████████| 8/8 [00:00<00:00, 125.65it/s, train_loss=0.00757, valid_loss=0.0109]\n",
      "Epoch: 47/50: 100%|██████████| 8/8 [00:00<00:00, 128.86it/s, train_loss=0.00753, valid_loss=0.0108]\n",
      "Epoch: 48/50: 100%|██████████| 8/8 [00:00<00:00, 129.45it/s, train_loss=0.00696, valid_loss=0.0111]\n",
      "Epoch: 49/50: 100%|██████████| 8/8 [00:00<00:00, 128.18it/s, train_loss=0.00754, valid_loss=0.0108]\n",
      "Epoch: 50/50: 100%|██████████| 8/8 [00:00<00:00, 130.74it/s, train_loss=0.00728, valid_loss=0.0108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 8/8 [00:00<00:00, 82.10it/s, train_loss=0.0428, valid_loss=0.0611]\n",
      "Epoch: 2/50: 100%|██████████| 8/8 [00:00<00:00, 61.46it/s, train_loss=0.0235, valid_loss=0.0357]\n",
      "Epoch: 3/50: 100%|██████████| 8/8 [00:00<00:00, 128.19it/s, train_loss=0.0172, valid_loss=0.0305]\n",
      "Epoch: 4/50: 100%|██████████| 8/8 [00:00<00:00, 127.34it/s, train_loss=0.0162, valid_loss=0.0289]\n",
      "Epoch: 5/50: 100%|██████████| 8/8 [00:00<00:00, 130.24it/s, train_loss=0.0137, valid_loss=0.0232]\n",
      "Epoch: 6/50: 100%|██████████| 8/8 [00:00<00:00, 126.06it/s, train_loss=0.0107, valid_loss=0.0215]\n",
      "Epoch: 7/50: 100%|██████████| 8/8 [00:00<00:00, 128.42it/s, train_loss=0.0103, valid_loss=0.0203]\n",
      "Epoch: 8/50: 100%|██████████| 8/8 [00:00<00:00, 127.54it/s, train_loss=0.00974, valid_loss=0.018]\n",
      "Epoch: 9/50: 100%|██████████| 8/8 [00:00<00:00, 127.25it/s, train_loss=0.00866, valid_loss=0.0152]\n",
      "Epoch: 10/50: 100%|██████████| 8/8 [00:00<00:00, 101.61it/s, train_loss=0.00749, valid_loss=0.0131]\n",
      "Epoch: 11/50: 100%|██████████| 8/8 [00:00<00:00, 82.30it/s, train_loss=0.0067, valid_loss=0.0103]\n",
      "Epoch: 12/50: 100%|██████████| 8/8 [00:00<00:00, 127.24it/s, train_loss=0.00598, valid_loss=0.00885]\n",
      "Epoch: 13/50: 100%|██████████| 8/8 [00:00<00:00, 126.47it/s, train_loss=0.00597, valid_loss=0.00763]\n",
      "Epoch: 14/50: 100%|██████████| 8/8 [00:00<00:00, 129.05it/s, train_loss=0.00544, valid_loss=0.00745]\n",
      "Epoch: 15/50: 100%|██████████| 8/8 [00:00<00:00, 127.65it/s, train_loss=0.00544, valid_loss=0.00688]\n",
      "Epoch: 16/50: 100%|██████████| 8/8 [00:00<00:00, 129.81it/s, train_loss=0.00506, valid_loss=0.00638]\n",
      "Epoch: 17/50: 100%|██████████| 8/8 [00:00<00:00, 125.95it/s, train_loss=0.00501, valid_loss=0.0065]\n",
      "Epoch: 18/50: 100%|██████████| 8/8 [00:00<00:00, 130.02it/s, train_loss=0.00506, valid_loss=0.00617]\n",
      "Epoch: 19/50: 100%|██████████| 8/8 [00:00<00:00, 127.01it/s, train_loss=0.00464, valid_loss=0.00601]\n",
      "Epoch: 20/50: 100%|██████████| 8/8 [00:00<00:00, 127.65it/s, train_loss=0.00466, valid_loss=0.00582]\n",
      "Epoch: 21/50: 100%|██████████| 8/8 [00:00<00:00, 82.27it/s, train_loss=0.00474, valid_loss=0.00566]\n",
      "Epoch: 22/50: 100%|██████████| 8/8 [00:00<00:00, 127.58it/s, train_loss=0.00438, valid_loss=0.00559]\n",
      "Epoch: 23/50: 100%|██████████| 8/8 [00:00<00:00, 126.86it/s, train_loss=0.0043, valid_loss=0.00568]\n",
      "Epoch: 24/50: 100%|██████████| 8/8 [00:00<00:00, 129.11it/s, train_loss=0.00433, valid_loss=0.00545]\n",
      "Epoch: 25/50: 100%|██████████| 8/8 [00:00<00:00, 128.47it/s, train_loss=0.00392, valid_loss=0.0054]\n",
      "Epoch: 26/50: 100%|██████████| 8/8 [00:00<00:00, 129.74it/s, train_loss=0.00389, valid_loss=0.00527]\n",
      "Epoch: 27/50: 100%|██████████| 8/8 [00:00<00:00, 126.03it/s, train_loss=0.0041, valid_loss=0.00532]\n",
      "Epoch: 28/50: 100%|██████████| 8/8 [00:00<00:00, 129.68it/s, train_loss=0.00418, valid_loss=0.00527]\n",
      "Epoch: 29/50: 100%|██████████| 8/8 [00:00<00:00, 101.32it/s, train_loss=0.0038, valid_loss=0.00504]\n",
      "Epoch: 30/50: 100%|██████████| 8/8 [00:00<00:00, 81.33it/s, train_loss=0.00363, valid_loss=0.00508]\n",
      "Epoch: 31/50: 100%|██████████| 8/8 [00:00<00:00, 126.19it/s, train_loss=0.00385, valid_loss=0.00502]\n",
      "Epoch: 32/50: 100%|██████████| 8/8 [00:00<00:00, 126.46it/s, train_loss=0.00358, valid_loss=0.00511]\n",
      "Epoch: 33/50: 100%|██████████| 8/8 [00:00<00:00, 126.89it/s, train_loss=0.00336, valid_loss=0.005]\n",
      "Epoch: 34/50: 100%|██████████| 8/8 [00:00<00:00, 129.24it/s, train_loss=0.00341, valid_loss=0.00517]\n",
      "Epoch: 35/50: 100%|██████████| 8/8 [00:00<00:00, 128.52it/s, train_loss=0.00355, valid_loss=0.00502]\n",
      "Epoch: 36/50: 100%|██████████| 8/8 [00:00<00:00, 126.48it/s, train_loss=0.00354, valid_loss=0.00479]\n",
      "Epoch: 37/50: 100%|██████████| 8/8 [00:00<00:00, 129.22it/s, train_loss=0.00331, valid_loss=0.00491]\n",
      "Epoch: 38/50: 100%|██████████| 8/8 [00:00<00:00, 129.61it/s, train_loss=0.00333, valid_loss=0.00482]\n",
      "Epoch: 39/50: 100%|██████████| 8/8 [00:00<00:00, 129.17it/s, train_loss=0.00301, valid_loss=0.00481]\n",
      "Epoch: 40/50: 100%|██████████| 8/8 [00:00<00:00, 126.34it/s, train_loss=0.00334, valid_loss=0.0047]\n",
      "Epoch: 41/50: 100%|██████████| 8/8 [00:00<00:00, 128.84it/s, train_loss=0.00326, valid_loss=0.00493]\n",
      "Epoch: 42/50: 100%|██████████| 8/8 [00:00<00:00, 127.57it/s, train_loss=0.00349, valid_loss=0.00478]\n",
      "Epoch: 43/50: 100%|██████████| 8/8 [00:00<00:00, 126.82it/s, train_loss=0.00305, valid_loss=0.00474]\n",
      "Epoch: 44/50: 100%|██████████| 8/8 [00:00<00:00, 128.97it/s, train_loss=0.00314, valid_loss=0.00497]\n",
      "Epoch: 45/50: 100%|██████████| 8/8 [00:00<00:00, 130.12it/s, train_loss=0.00347, valid_loss=0.00468]\n",
      "Epoch: 46/50: 100%|██████████| 8/8 [00:00<00:00, 129.90it/s, train_loss=0.00298, valid_loss=0.00466]\n",
      "Epoch: 47/50: 100%|██████████| 8/8 [00:00<00:00, 81.27it/s, train_loss=0.00333, valid_loss=0.00487]\n",
      "Epoch: 48/50: 100%|██████████| 8/8 [00:00<00:00, 125.65it/s, train_loss=0.00328, valid_loss=0.00482]\n",
      "Epoch: 49/50: 100%|██████████| 8/8 [00:00<00:00, 129.76it/s, train_loss=0.003, valid_loss=0.00488]\n",
      "Epoch: 50/50: 100%|██████████| 8/8 [00:00<00:00, 128.98it/s, train_loss=0.00303, valid_loss=0.00489]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 15/15 [00:00<00:00, 90.84it/s, train_loss=0.0375, valid_loss=0.0437]\n",
      "Epoch: 2/50: 100%|██████████| 15/15 [00:00<00:00, 142.52it/s, train_loss=0.019, valid_loss=0.0116]\n",
      "Epoch: 3/50: 100%|██████████| 15/15 [00:00<00:00, 142.93it/s, train_loss=0.0134, valid_loss=0.0102]\n",
      "Epoch: 4/50: 100%|██████████| 15/15 [00:00<00:00, 136.80it/s, train_loss=0.00921, valid_loss=0.0073]\n",
      "Epoch: 5/50: 100%|██████████| 15/15 [00:00<00:00, 124.98it/s, train_loss=0.00819, valid_loss=0.00822]\n",
      "Epoch: 6/50: 100%|██████████| 15/15 [00:00<00:00, 103.34it/s, train_loss=0.00664, valid_loss=0.00531]\n",
      "Epoch: 7/50: 100%|██████████| 15/15 [00:00<00:00, 140.78it/s, train_loss=0.00656, valid_loss=0.00364]\n",
      "Epoch: 8/50: 100%|██████████| 15/15 [00:00<00:00, 141.79it/s, train_loss=0.00638, valid_loss=0.00318]\n",
      "Epoch: 9/50: 100%|██████████| 15/15 [00:00<00:00, 141.63it/s, train_loss=0.00666, valid_loss=0.00365]\n",
      "Epoch: 10/50: 100%|██████████| 15/15 [00:00<00:00, 142.90it/s, train_loss=0.00575, valid_loss=0.00446]\n",
      "Epoch: 11/50: 100%|██████████| 15/15 [00:00<00:00, 141.78it/s, train_loss=0.00484, valid_loss=0.00352]\n",
      "Epoch: 12/50: 100%|██████████| 15/15 [00:00<00:00, 140.53it/s, train_loss=0.00509, valid_loss=0.00284]\n",
      "Epoch: 13/50: 100%|██████████| 15/15 [00:00<00:00, 142.57it/s, train_loss=0.00522, valid_loss=0.0025]\n",
      "Epoch: 14/50: 100%|██████████| 15/15 [00:00<00:00, 102.33it/s, train_loss=0.00496, valid_loss=0.00275]\n",
      "Epoch: 15/50: 100%|██████████| 15/15 [00:00<00:00, 137.47it/s, train_loss=0.00522, valid_loss=0.00275]\n",
      "Epoch: 16/50: 100%|██████████| 15/15 [00:00<00:00, 141.05it/s, train_loss=0.00484, valid_loss=0.00296]\n",
      "Epoch: 17/50: 100%|██████████| 15/15 [00:00<00:00, 136.84it/s, train_loss=0.00474, valid_loss=0.00227]\n",
      "Epoch: 18/50: 100%|██████████| 15/15 [00:00<00:00, 141.72it/s, train_loss=0.00466, valid_loss=0.00206]\n",
      "Epoch: 19/50: 100%|██████████| 15/15 [00:00<00:00, 142.32it/s, train_loss=0.0047, valid_loss=0.00208]\n",
      "Epoch: 20/50: 100%|██████████| 15/15 [00:00<00:00, 106.16it/s, train_loss=0.00478, valid_loss=0.00283]\n",
      "Epoch: 21/50: 100%|██████████| 15/15 [00:00<00:00, 141.91it/s, train_loss=0.00496, valid_loss=0.00225]\n",
      "Epoch: 22/50: 100%|██████████| 15/15 [00:00<00:00, 140.12it/s, train_loss=0.00415, valid_loss=0.00235]\n",
      "Epoch: 23/50: 100%|██████████| 15/15 [00:00<00:00, 141.29it/s, train_loss=0.00478, valid_loss=0.00241]\n",
      "Epoch: 24/50: 100%|██████████| 15/15 [00:00<00:00, 141.20it/s, train_loss=0.00423, valid_loss=0.00213]\n",
      "Epoch: 25/50: 100%|██████████| 15/15 [00:00<00:00, 141.55it/s, train_loss=0.00422, valid_loss=0.00255]\n",
      "Epoch: 26/50: 100%|██████████| 15/15 [00:00<00:00, 140.37it/s, train_loss=0.00479, valid_loss=0.00324]\n",
      "Epoch: 27/50: 100%|██████████| 15/15 [00:00<00:00, 140.63it/s, train_loss=0.00462, valid_loss=0.00183]\n",
      "Epoch: 28/50: 100%|██████████| 15/15 [00:00<00:00, 104.28it/s, train_loss=0.00488, valid_loss=0.00253]\n",
      "Epoch: 29/50: 100%|██████████| 15/15 [00:00<00:00, 142.46it/s, train_loss=0.00442, valid_loss=0.00227]\n",
      "Epoch: 30/50: 100%|██████████| 15/15 [00:00<00:00, 141.10it/s, train_loss=0.0043, valid_loss=0.0021]\n",
      "Epoch: 31/50: 100%|██████████| 15/15 [00:00<00:00, 141.73it/s, train_loss=0.0043, valid_loss=0.00227]\n",
      "Epoch: 32/50: 100%|██████████| 15/15 [00:00<00:00, 142.56it/s, train_loss=0.00475, valid_loss=0.00178]\n",
      "Epoch: 33/50: 100%|██████████| 15/15 [00:00<00:00, 141.03it/s, train_loss=0.00427, valid_loss=0.00289]\n",
      "Epoch: 34/50: 100%|██████████| 15/15 [00:00<00:00, 141.34it/s, train_loss=0.00432, valid_loss=0.00249]\n",
      "Epoch: 35/50: 100%|██████████| 15/15 [00:00<00:00, 105.14it/s, train_loss=0.00448, valid_loss=0.00216]\n",
      "Epoch: 36/50: 100%|██████████| 15/15 [00:00<00:00, 125.77it/s, train_loss=0.00381, valid_loss=0.00216]\n",
      "Epoch: 37/50: 100%|██████████| 15/15 [00:00<00:00, 141.62it/s, train_loss=0.00411, valid_loss=0.00242]\n",
      "Epoch: 38/50: 100%|██████████| 15/15 [00:00<00:00, 141.52it/s, train_loss=0.00359, valid_loss=0.00242]\n",
      "Epoch: 39/50: 100%|██████████| 15/15 [00:00<00:00, 141.75it/s, train_loss=0.00408, valid_loss=0.00249]\n",
      "Epoch: 40/50: 100%|██████████| 15/15 [00:00<00:00, 143.85it/s, train_loss=0.00406, valid_loss=0.00247]\n",
      "Epoch: 41/50: 100%|██████████| 15/15 [00:00<00:00, 140.91it/s, train_loss=0.00355, valid_loss=0.0027]\n",
      "Epoch: 42/50: 100%|██████████| 15/15 [00:00<00:00, 105.45it/s, train_loss=0.00406, valid_loss=0.00247]\n",
      "Epoch: 43/50: 100%|██████████| 15/15 [00:00<00:00, 124.96it/s, train_loss=0.00356, valid_loss=0.00315]\n",
      "Epoch: 44/50: 100%|██████████| 15/15 [00:00<00:00, 141.71it/s, train_loss=0.00407, valid_loss=0.00227]\n",
      "Epoch: 45/50: 100%|██████████| 15/15 [00:00<00:00, 140.61it/s, train_loss=0.00414, valid_loss=0.0023]\n",
      "Epoch: 46/50: 100%|██████████| 15/15 [00:00<00:00, 140.90it/s, train_loss=0.004, valid_loss=0.00249]\n",
      "Epoch: 47/50: 100%|██████████| 15/15 [00:00<00:00, 143.11it/s, train_loss=0.00407, valid_loss=0.0028]\n",
      "Epoch: 48/50: 100%|██████████| 15/15 [00:00<00:00, 141.62it/s, train_loss=0.00411, valid_loss=0.00197]\n",
      "Epoch: 49/50: 100%|██████████| 15/15 [00:00<00:00, 104.78it/s, train_loss=0.00414, valid_loss=0.00293]\n",
      "Epoch: 50/50: 100%|██████████| 15/15 [00:00<00:00, 142.67it/s, train_loss=0.00406, valid_loss=0.00264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 22/22 [00:00<00:00, 97.23it/s, train_loss=0.0413, valid_loss=0.0493]\n",
      "Epoch: 2/50: 100%|██████████| 22/22 [00:00<00:00, 134.77it/s, train_loss=0.0291, valid_loss=0.0366]\n",
      "Epoch: 3/50: 100%|██████████| 22/22 [00:00<00:00, 134.01it/s, train_loss=0.0248, valid_loss=0.0312]\n",
      "Epoch: 4/50: 100%|██████████| 22/22 [00:00<00:00, 106.90it/s, train_loss=0.0221, valid_loss=0.0243]\n",
      "Epoch: 5/50: 100%|██████████| 22/22 [00:00<00:00, 132.75it/s, train_loss=0.0205, valid_loss=0.0209]\n",
      "Epoch: 6/50: 100%|██████████| 22/22 [00:00<00:00, 133.45it/s, train_loss=0.0141, valid_loss=0.0139]\n",
      "Epoch: 7/50: 100%|██████████| 22/22 [00:00<00:00, 134.39it/s, train_loss=0.0139, valid_loss=0.0128]\n",
      "Epoch: 8/50: 100%|██████████| 22/22 [00:00<00:00, 107.70it/s, train_loss=0.0129, valid_loss=0.0121]\n",
      "Epoch: 9/50: 100%|██████████| 22/22 [00:00<00:00, 121.64it/s, train_loss=0.0118, valid_loss=0.0119]\n",
      "Epoch: 10/50: 100%|██████████| 22/22 [00:00<00:00, 134.32it/s, train_loss=0.012, valid_loss=0.0117] \n",
      "Epoch: 11/50: 100%|██████████| 22/22 [00:00<00:00, 133.82it/s, train_loss=0.0129, valid_loss=0.0116]\n",
      "Epoch: 12/50: 100%|██████████| 22/22 [00:00<00:00, 109.41it/s, train_loss=0.0111, valid_loss=0.0115]\n",
      "Epoch: 13/50: 100%|██████████| 22/22 [00:00<00:00, 133.14it/s, train_loss=0.0124, valid_loss=0.0116]\n",
      "Epoch: 14/50: 100%|██████████| 22/22 [00:00<00:00, 133.46it/s, train_loss=0.0119, valid_loss=0.0122]\n",
      "Epoch: 15/50: 100%|██████████| 22/22 [00:00<00:00, 133.88it/s, train_loss=0.0113, valid_loss=0.0116]\n",
      "Epoch: 16/50: 100%|██████████| 22/22 [00:00<00:00, 133.59it/s, train_loss=0.0113, valid_loss=0.0121]\n",
      "Epoch: 17/50: 100%|██████████| 22/22 [00:00<00:00, 107.59it/s, train_loss=0.0113, valid_loss=0.0115]\n",
      "Epoch: 18/50: 100%|██████████| 22/22 [00:00<00:00, 133.21it/s, train_loss=0.0111, valid_loss=0.0117]\n",
      "Epoch: 19/50: 100%|██████████| 22/22 [00:00<00:00, 132.42it/s, train_loss=0.0108, valid_loss=0.0117]\n",
      "Epoch: 20/50: 100%|██████████| 22/22 [00:00<00:00, 132.14it/s, train_loss=0.011, valid_loss=0.0115] \n",
      "Epoch: 21/50: 100%|██████████| 22/22 [00:00<00:00, 108.32it/s, train_loss=0.0117, valid_loss=0.0115]\n",
      "Epoch: 22/50: 100%|██████████| 22/22 [00:00<00:00, 123.07it/s, train_loss=0.0109, valid_loss=0.0112]\n",
      "Epoch: 23/50: 100%|██████████| 22/22 [00:00<00:00, 133.96it/s, train_loss=0.01, valid_loss=0.0113]  \n",
      "Epoch: 24/50: 100%|██████████| 22/22 [00:00<00:00, 133.99it/s, train_loss=0.0107, valid_loss=0.0114]\n",
      "Epoch: 25/50: 100%|██████████| 22/22 [00:00<00:00, 131.11it/s, train_loss=0.0107, valid_loss=0.0112]\n",
      "Epoch: 26/50: 100%|██████████| 22/22 [00:00<00:00, 108.78it/s, train_loss=0.0114, valid_loss=0.0114]\n",
      "Epoch: 27/50: 100%|██████████| 22/22 [00:00<00:00, 131.91it/s, train_loss=0.0108, valid_loss=0.0112]\n",
      "Epoch: 28/50: 100%|██████████| 22/22 [00:00<00:00, 134.99it/s, train_loss=0.0103, valid_loss=0.0114]\n",
      "Epoch: 29/50: 100%|██████████| 22/22 [00:00<00:00, 132.47it/s, train_loss=0.0112, valid_loss=0.0113]\n",
      "Epoch: 30/50: 100%|██████████| 22/22 [00:00<00:00, 109.44it/s, train_loss=0.0106, valid_loss=0.0116]\n",
      "Epoch: 31/50: 100%|██████████| 22/22 [00:00<00:00, 132.41it/s, train_loss=0.0103, valid_loss=0.0112]\n",
      "Epoch: 32/50: 100%|██████████| 22/22 [00:00<00:00, 132.18it/s, train_loss=0.0108, valid_loss=0.0111]\n",
      "Epoch: 33/50: 100%|██████████| 22/22 [00:00<00:00, 132.60it/s, train_loss=0.0102, valid_loss=0.0115]\n",
      "Epoch: 34/50: 100%|██████████| 22/22 [00:00<00:00, 133.87it/s, train_loss=0.0107, valid_loss=0.0115]\n",
      "Epoch: 35/50: 100%|██████████| 22/22 [00:00<00:00, 106.28it/s, train_loss=0.0101, valid_loss=0.0115]\n",
      "Epoch: 36/50: 100%|██████████| 22/22 [00:00<00:00, 131.66it/s, train_loss=0.01, valid_loss=0.0116]  \n",
      "Epoch: 37/50: 100%|██████████| 22/22 [00:00<00:00, 133.47it/s, train_loss=0.01, valid_loss=0.0114]  \n",
      "Epoch: 38/50: 100%|██████████| 22/22 [00:00<00:00, 134.52it/s, train_loss=0.0103, valid_loss=0.0114]\n",
      "Epoch: 39/50: 100%|██████████| 22/22 [00:00<00:00, 133.48it/s, train_loss=0.0107, valid_loss=0.0113]\n",
      "Epoch: 40/50: 100%|██████████| 22/22 [00:00<00:00, 108.52it/s, train_loss=0.00985, valid_loss=0.0112]\n",
      "Epoch: 41/50: 100%|██████████| 22/22 [00:00<00:00, 132.93it/s, train_loss=0.00972, valid_loss=0.0113]\n",
      "Epoch: 42/50: 100%|██████████| 22/22 [00:00<00:00, 134.59it/s, train_loss=0.0102, valid_loss=0.0111]\n",
      "Epoch: 43/50: 100%|██████████| 22/22 [00:00<00:00, 133.67it/s, train_loss=0.0102, valid_loss=0.0121] \n",
      "Epoch: 44/50: 100%|██████████| 22/22 [00:00<00:00, 109.48it/s, train_loss=0.0101, valid_loss=0.0118]\n",
      "Epoch: 45/50: 100%|██████████| 22/22 [00:00<00:00, 133.70it/s, train_loss=0.0102, valid_loss=0.0111]\n",
      "Epoch: 46/50: 100%|██████████| 22/22 [00:00<00:00, 133.41it/s, train_loss=0.0107, valid_loss=0.0113] \n",
      "Epoch: 47/50: 100%|██████████| 22/22 [00:00<00:00, 134.69it/s, train_loss=0.0102, valid_loss=0.011]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 22/22 [00:00<00:00, 96.75it/s, train_loss=0.0346, valid_loss=0.0382] \n",
      "Epoch: 2/50: 100%|██████████| 22/22 [00:00<00:00, 106.50it/s, train_loss=0.0229, valid_loss=0.0275]\n",
      "Epoch: 3/50: 100%|██████████| 22/22 [00:00<00:00, 133.14it/s, train_loss=0.0178, valid_loss=0.0218]\n",
      "Epoch: 4/50: 100%|██████████| 22/22 [00:00<00:00, 132.69it/s, train_loss=0.0155, valid_loss=0.0151]\n",
      "Epoch: 5/50: 100%|██████████| 22/22 [00:00<00:00, 134.38it/s, train_loss=0.0146, valid_loss=0.0136]\n",
      "Epoch: 6/50: 100%|██████████| 22/22 [00:00<00:00, 132.65it/s, train_loss=0.0129, valid_loss=0.0133]\n",
      "Epoch: 7/50: 100%|██████████| 22/22 [00:00<00:00, 108.42it/s, train_loss=0.0128, valid_loss=0.0125]\n",
      "Epoch: 8/50: 100%|██████████| 22/22 [00:00<00:00, 132.11it/s, train_loss=0.0126, valid_loss=0.0121]\n",
      "Epoch: 9/50: 100%|██████████| 22/22 [00:00<00:00, 132.72it/s, train_loss=0.0119, valid_loss=0.0123]\n",
      "Epoch: 10/50: 100%|██████████| 22/22 [00:00<00:00, 134.35it/s, train_loss=0.0111, valid_loss=0.0121]\n",
      "Epoch: 11/50: 100%|██████████| 22/22 [00:00<00:00, 108.72it/s, train_loss=0.0113, valid_loss=0.0127]\n",
      "Epoch: 12/50: 100%|██████████| 22/22 [00:00<00:00, 133.05it/s, train_loss=0.00624, valid_loss=0.00531]\n",
      "Epoch: 13/50: 100%|██████████| 22/22 [00:00<00:00, 132.47it/s, train_loss=0.00484, valid_loss=0.00486]\n",
      "Epoch: 14/50: 100%|██████████| 22/22 [00:00<00:00, 133.86it/s, train_loss=0.00481, valid_loss=0.00401]\n",
      "Epoch: 15/50: 100%|██████████| 22/22 [00:00<00:00, 109.09it/s, train_loss=0.00443, valid_loss=0.00455]\n",
      "Epoch: 16/50: 100%|██████████| 22/22 [00:00<00:00, 132.52it/s, train_loss=0.00459, valid_loss=0.00438]\n",
      "Epoch: 17/50: 100%|██████████| 22/22 [00:00<00:00, 133.15it/s, train_loss=0.00495, valid_loss=0.00361]\n",
      "Epoch: 18/50: 100%|██████████| 22/22 [00:00<00:00, 134.12it/s, train_loss=0.00444, valid_loss=0.00414]\n",
      "Epoch: 19/50: 100%|██████████| 22/22 [00:00<00:00, 133.93it/s, train_loss=0.00491, valid_loss=0.00413]\n",
      "Epoch: 20/50: 100%|██████████| 22/22 [00:00<00:00, 107.63it/s, train_loss=0.00465, valid_loss=0.00422]\n",
      "Epoch: 21/50: 100%|██████████| 22/22 [00:00<00:00, 132.11it/s, train_loss=0.00406, valid_loss=0.00432]\n",
      "Epoch: 22/50: 100%|██████████| 22/22 [00:00<00:00, 132.89it/s, train_loss=0.00408, valid_loss=0.00496]\n",
      "Epoch: 23/50: 100%|██████████| 22/22 [00:00<00:00, 134.54it/s, train_loss=0.00428, valid_loss=0.00428]\n",
      "Epoch: 24/50: 100%|██████████| 22/22 [00:00<00:00, 109.19it/s, train_loss=0.00432, valid_loss=0.00433]\n",
      "Epoch: 25/50: 100%|██████████| 22/22 [00:00<00:00, 130.28it/s, train_loss=0.0043, valid_loss=0.00442] \n",
      "Epoch: 26/50: 100%|██████████| 22/22 [00:00<00:00, 132.53it/s, train_loss=0.00437, valid_loss=0.00421]\n",
      "Epoch: 27/50: 100%|██████████| 22/22 [00:00<00:00, 131.78it/s, train_loss=0.00462, valid_loss=0.00448]\n",
      "Epoch: 28/50: 100%|██████████| 22/22 [00:00<00:00, 133.85it/s, train_loss=0.00408, valid_loss=0.00412]\n",
      "Epoch: 29/50: 100%|██████████| 22/22 [00:00<00:00, 107.44it/s, train_loss=0.00411, valid_loss=0.00445]\n",
      "Epoch: 30/50: 100%|██████████| 22/22 [00:00<00:00, 132.01it/s, train_loss=0.00393, valid_loss=0.00437]\n",
      "Epoch: 31/50: 100%|██████████| 22/22 [00:00<00:00, 133.94it/s, train_loss=0.00391, valid_loss=0.00433]\n",
      "Epoch: 32/50: 100%|██████████| 22/22 [00:00<00:00, 132.43it/s, train_loss=0.00458, valid_loss=0.00399]\n",
      "Epoch: 33/50: 100%|██████████| 22/22 [00:00<00:00, 109.08it/s, train_loss=0.00442, valid_loss=0.00448]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 29/29 [00:00<00:00, 106.71it/s, train_loss=0.0423, valid_loss=0.0404]\n",
      "Epoch: 2/50: 100%|██████████| 29/29 [00:00<00:00, 116.75it/s, train_loss=0.0232, valid_loss=0.0194]\n",
      "Epoch: 3/50: 100%|██████████| 29/29 [00:00<00:00, 116.12it/s, train_loss=0.00991, valid_loss=0.00749]\n",
      "Epoch: 4/50: 100%|██████████| 29/29 [00:00<00:00, 140.38it/s, train_loss=0.00713, valid_loss=0.00521]\n",
      "Epoch: 5/50: 100%|██████████| 29/29 [00:00<00:00, 141.03it/s, train_loss=0.00615, valid_loss=0.00357]\n",
      "Epoch: 6/50: 100%|██████████| 29/29 [00:00<00:00, 119.41it/s, train_loss=0.00623, valid_loss=0.00499]\n",
      "Epoch: 7/50: 100%|██████████| 29/29 [00:00<00:00, 140.91it/s, train_loss=0.00514, valid_loss=0.00379]\n",
      "Epoch: 8/50: 100%|██████████| 29/29 [00:00<00:00, 141.97it/s, train_loss=0.00493, valid_loss=0.00294]\n",
      "Epoch: 9/50: 100%|██████████| 29/29 [00:00<00:00, 142.99it/s, train_loss=0.0053, valid_loss=0.00368] \n",
      "Epoch: 10/50: 100%|██████████| 29/29 [00:00<00:00, 141.93it/s, train_loss=0.00469, valid_loss=0.0032] \n",
      "Epoch: 11/50: 100%|██████████| 29/29 [00:00<00:00, 118.79it/s, train_loss=0.00498, valid_loss=0.00345]\n",
      "Epoch: 12/50: 100%|██████████| 29/29 [00:00<00:00, 129.46it/s, train_loss=0.00452, valid_loss=0.00342]\n",
      "Epoch: 13/50: 100%|██████████| 29/29 [00:00<00:00, 139.37it/s, train_loss=0.00528, valid_loss=0.00351]\n",
      "Epoch: 14/50: 100%|██████████| 29/29 [00:00<00:00, 129.15it/s, train_loss=0.00461, valid_loss=0.00449]\n",
      "Epoch: 15/50: 100%|██████████| 29/29 [00:00<00:00, 142.33it/s, train_loss=0.00437, valid_loss=0.00387]\n",
      "Epoch: 16/50: 100%|██████████| 29/29 [00:00<00:00, 119.12it/s, train_loss=0.00479, valid_loss=0.00391]\n",
      "Epoch: 17/50: 100%|██████████| 29/29 [00:00<00:00, 140.90it/s, train_loss=0.00427, valid_loss=0.0031] \n",
      "Epoch: 18/50: 100%|██████████| 29/29 [00:00<00:00, 141.25it/s, train_loss=0.00488, valid_loss=0.00382]\n",
      "Epoch: 19/50: 100%|██████████| 29/29 [00:00<00:00, 140.99it/s, train_loss=0.00433, valid_loss=0.0034] \n",
      "Epoch: 20/50: 100%|██████████| 29/29 [00:00<00:00, 131.91it/s, train_loss=0.00421, valid_loss=0.00326]\n",
      "Epoch: 21/50: 100%|██████████| 29/29 [00:00<00:00, 119.93it/s, train_loss=0.0044, valid_loss=0.00328] \n",
      "Epoch: 22/50: 100%|██████████| 29/29 [00:00<00:00, 141.03it/s, train_loss=0.00476, valid_loss=0.00313]\n",
      "Epoch: 23/50: 100%|██████████| 29/29 [00:00<00:00, 141.06it/s, train_loss=0.00455, valid_loss=0.00257]\n",
      "Epoch: 24/50: 100%|██████████| 29/29 [00:00<00:00, 141.12it/s, train_loss=0.00441, valid_loss=0.00292]\n",
      "Epoch: 25/50: 100%|██████████| 29/29 [00:00<00:00, 140.89it/s, train_loss=0.00431, valid_loss=0.00302]\n",
      "Epoch: 26/50: 100%|██████████| 29/29 [00:00<00:00, 116.56it/s, train_loss=0.00381, valid_loss=0.00297]\n",
      "Epoch: 27/50: 100%|██████████| 29/29 [00:00<00:00, 140.10it/s, train_loss=0.00427, valid_loss=0.00286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 36/36 [00:00<00:00, 110.32it/s, train_loss=0.0375, valid_loss=0.033] \n",
      "Epoch: 2/50: 100%|██████████| 36/36 [00:00<00:00, 127.54it/s, train_loss=0.0191, valid_loss=0.0163]\n",
      "Epoch: 3/50: 100%|██████████| 36/36 [00:00<00:00, 116.62it/s, train_loss=0.00923, valid_loss=0.00734]\n",
      "Epoch: 4/50: 100%|██████████| 36/36 [00:00<00:00, 136.99it/s, train_loss=0.00826, valid_loss=0.00593]\n",
      "Epoch: 5/50: 100%|██████████| 36/36 [00:00<00:00, 136.95it/s, train_loss=0.00828, valid_loss=0.00518]\n",
      "Epoch: 6/50: 100%|██████████| 36/36 [00:00<00:00, 128.01it/s, train_loss=0.00736, valid_loss=0.00454]\n",
      "Epoch: 7/50: 100%|██████████| 36/36 [00:00<00:00, 119.28it/s, train_loss=0.00657, valid_loss=0.00411]\n",
      "Epoch: 8/50: 100%|██████████| 36/36 [00:00<00:00, 137.64it/s, train_loss=0.00605, valid_loss=0.00369]\n",
      "Epoch: 9/50: 100%|██████████| 36/36 [00:00<00:00, 124.23it/s, train_loss=0.00519, valid_loss=0.00352]\n",
      "Epoch: 10/50: 100%|██████████| 36/36 [00:00<00:00, 135.98it/s, train_loss=0.00557, valid_loss=0.00323]\n",
      "Epoch: 11/50: 100%|██████████| 36/36 [00:00<00:00, 111.27it/s, train_loss=0.00493, valid_loss=0.00312]\n",
      "Epoch: 12/50: 100%|██████████| 36/36 [00:00<00:00, 134.62it/s, train_loss=0.00516, valid_loss=0.00297]\n",
      "Epoch: 13/50: 100%|██████████| 36/36 [00:00<00:00, 118.15it/s, train_loss=0.00472, valid_loss=0.00356]\n",
      "Epoch: 14/50: 100%|██████████| 36/36 [00:00<00:00, 135.21it/s, train_loss=0.00496, valid_loss=0.00349]\n",
      "Epoch: 15/50: 100%|██████████| 36/36 [00:00<00:00, 118.51it/s, train_loss=0.0051, valid_loss=0.00305] \n",
      "Epoch: 16/50: 100%|██████████| 36/36 [00:00<00:00, 134.37it/s, train_loss=0.00504, valid_loss=0.00332]\n",
      "Epoch: 17/50: 100%|██████████| 36/36 [00:00<00:00, 118.36it/s, train_loss=0.00529, valid_loss=0.00293]\n",
      "Epoch: 18/50: 100%|██████████| 36/36 [00:00<00:00, 134.13it/s, train_loss=0.00454, valid_loss=0.00309]\n",
      "Epoch: 19/50: 100%|██████████| 36/36 [00:00<00:00, 129.16it/s, train_loss=0.00452, valid_loss=0.0036] \n",
      "Epoch: 20/50: 100%|██████████| 36/36 [00:00<00:00, 117.59it/s, train_loss=0.00453, valid_loss=0.00318]\n",
      "Epoch: 21/50: 100%|██████████| 36/36 [00:00<00:00, 134.17it/s, train_loss=0.00472, valid_loss=0.00328]\n",
      "Epoch: 22/50: 100%|██████████| 36/36 [00:00<00:00, 117.68it/s, train_loss=0.00439, valid_loss=0.00295]\n",
      "Epoch: 23/50: 100%|██████████| 36/36 [00:00<00:00, 134.58it/s, train_loss=0.00438, valid_loss=0.00306]\n",
      "Epoch: 24/50: 100%|██████████| 36/36 [00:00<00:00, 117.80it/s, train_loss=0.00498, valid_loss=0.0029] \n",
      "Epoch: 25/50: 100%|██████████| 36/36 [00:00<00:00, 127.26it/s, train_loss=0.00402, valid_loss=0.00277]\n",
      "Epoch: 26/50: 100%|██████████| 36/36 [00:00<00:00, 118.56it/s, train_loss=0.00403, valid_loss=0.00314]\n",
      "Epoch: 27/50: 100%|██████████| 36/36 [00:00<00:00, 134.48it/s, train_loss=0.00448, valid_loss=0.00274]\n",
      "Epoch: 28/50: 100%|██████████| 36/36 [00:00<00:00, 118.01it/s, train_loss=0.00433, valid_loss=0.00279]\n",
      "Epoch: 29/50: 100%|██████████| 36/36 [00:00<00:00, 134.86it/s, train_loss=0.00431, valid_loss=0.00293]\n",
      "Epoch: 30/50: 100%|██████████| 36/36 [00:00<00:00, 135.66it/s, train_loss=0.00458, valid_loss=0.00289]\n",
      "Epoch: 31/50: 100%|██████████| 36/36 [00:00<00:00, 135.53it/s, train_loss=0.00413, valid_loss=0.00284]\n",
      "Epoch: 32/50: 100%|██████████| 36/36 [00:00<00:00, 116.19it/s, train_loss=0.00409, valid_loss=0.00275]\n",
      "Epoch: 33/50: 100%|██████████| 36/36 [00:00<00:00, 135.26it/s, train_loss=0.00446, valid_loss=0.00286]\n",
      "Epoch: 34/50: 100%|██████████| 36/36 [00:00<00:00, 117.92it/s, train_loss=0.00461, valid_loss=0.00333]\n",
      "Epoch: 35/50: 100%|██████████| 36/36 [00:00<00:00, 135.19it/s, train_loss=0.00493, valid_loss=0.00277]\n",
      "Epoch: 36/50: 100%|██████████| 36/36 [00:00<00:00, 135.30it/s, train_loss=0.00421, valid_loss=0.00262]\n",
      "Epoch: 37/50: 100%|██████████| 36/36 [00:00<00:00, 136.01it/s, train_loss=0.00465, valid_loss=0.00284]\n",
      "Epoch: 38/50: 100%|██████████| 36/36 [00:00<00:00, 118.18it/s, train_loss=0.00441, valid_loss=0.00287]\n",
      "Epoch: 39/50: 100%|██████████| 36/36 [00:00<00:00, 135.23it/s, train_loss=0.00412, valid_loss=0.00279]\n",
      "Epoch: 40/50: 100%|██████████| 36/36 [00:00<00:00, 135.35it/s, train_loss=0.00483, valid_loss=0.00272]\n",
      "Epoch: 41/50: 100%|██████████| 36/36 [00:00<00:00, 135.31it/s, train_loss=0.00455, valid_loss=0.00269]\n",
      "Epoch: 42/50: 100%|██████████| 36/36 [00:00<00:00, 118.19it/s, train_loss=0.00427, valid_loss=0.00273]\n",
      "Epoch: 43/50: 100%|██████████| 36/36 [00:00<00:00, 132.83it/s, train_loss=0.00393, valid_loss=0.00293]\n",
      "Epoch: 44/50: 100%|██████████| 36/36 [00:00<00:00, 127.86it/s, train_loss=0.00415, valid_loss=0.00309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config: batch_size--512, lr--0.01, number_epoch--50, hidden_dim--35,drop_prob-0.1,weight_decay-1e-07\n",
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 8/8 [00:00<00:00, 78.85it/s, train_loss=0.0433, valid_loss=0.061]\n",
      "Epoch: 2/50: 100%|██████████| 8/8 [00:00<00:00, 89.95it/s, train_loss=0.0221, valid_loss=0.0376]\n",
      "Epoch: 3/50: 100%|██████████| 8/8 [00:00<00:00, 128.74it/s, train_loss=0.0199, valid_loss=0.0334]\n",
      "Epoch: 4/50: 100%|██████████| 8/8 [00:00<00:00, 127.04it/s, train_loss=0.0184, valid_loss=0.0325]\n",
      "Epoch: 5/50: 100%|██████████| 8/8 [00:00<00:00, 63.33it/s, train_loss=0.0163, valid_loss=0.0281]\n",
      "Epoch: 6/50: 100%|██████████| 8/8 [00:00<00:00, 97.42it/s, train_loss=0.0116, valid_loss=0.0194]\n",
      "Epoch: 7/50: 100%|██████████| 8/8 [00:00<00:00, 116.90it/s, train_loss=0.00811, valid_loss=0.015]\n",
      "Epoch: 8/50: 100%|██████████| 8/8 [00:00<00:00, 111.87it/s, train_loss=0.0071, valid_loss=0.013]\n",
      "Epoch: 9/50: 100%|██████████| 8/8 [00:00<00:00, 127.93it/s, train_loss=0.00672, valid_loss=0.00992]\n",
      "Epoch: 10/50: 100%|██████████| 8/8 [00:00<00:00, 128.05it/s, train_loss=0.00566, valid_loss=0.00838]\n",
      "Epoch: 11/50: 100%|██████████| 8/8 [00:00<00:00, 105.26it/s, train_loss=0.00546, valid_loss=0.00737]\n",
      "Epoch: 12/50: 100%|██████████| 8/8 [00:00<00:00, 123.92it/s, train_loss=0.00524, valid_loss=0.00667]\n",
      "Epoch: 13/50: 100%|██████████| 8/8 [00:00<00:00, 130.90it/s, train_loss=0.00489, valid_loss=0.00627]\n",
      "Epoch: 14/50: 100%|██████████| 8/8 [00:00<00:00, 81.18it/s, train_loss=0.00503, valid_loss=0.00603]\n",
      "Epoch: 15/50: 100%|██████████| 8/8 [00:00<00:00, 128.04it/s, train_loss=0.00472, valid_loss=0.00601]\n",
      "Epoch: 16/50: 100%|██████████| 8/8 [00:00<00:00, 130.15it/s, train_loss=0.0046, valid_loss=0.00578]\n",
      "Epoch: 17/50: 100%|██████████| 8/8 [00:00<00:00, 124.91it/s, train_loss=0.00416, valid_loss=0.00554]\n",
      "Epoch: 18/50: 100%|██████████| 8/8 [00:00<00:00, 129.51it/s, train_loss=0.00413, valid_loss=0.00542]\n",
      "Epoch: 19/50: 100%|██████████| 8/8 [00:00<00:00, 127.12it/s, train_loss=0.00425, valid_loss=0.00561]\n",
      "Epoch: 20/50: 100%|██████████| 8/8 [00:00<00:00, 103.89it/s, train_loss=0.00418, valid_loss=0.00547]\n",
      "Epoch: 21/50: 100%|██████████| 8/8 [00:00<00:00, 108.09it/s, train_loss=0.00394, valid_loss=0.00547]\n",
      "Epoch: 22/50: 100%|██████████| 8/8 [00:00<00:00, 107.92it/s, train_loss=0.00397, valid_loss=0.00524]\n",
      "Epoch: 23/50: 100%|██████████| 8/8 [00:00<00:00, 80.75it/s, train_loss=0.00389, valid_loss=0.00587]\n",
      "Epoch: 24/50: 100%|██████████| 8/8 [00:00<00:00, 124.98it/s, train_loss=0.00371, valid_loss=0.00498]\n",
      "Epoch: 25/50: 100%|██████████| 8/8 [00:00<00:00, 129.31it/s, train_loss=0.00341, valid_loss=0.00551]\n",
      "Epoch: 26/50: 100%|██████████| 8/8 [00:00<00:00, 126.46it/s, train_loss=0.00355, valid_loss=0.00491]\n",
      "Epoch: 27/50: 100%|██████████| 8/8 [00:00<00:00, 109.14it/s, train_loss=0.00357, valid_loss=0.00516]\n",
      "Epoch: 28/50: 100%|██████████| 8/8 [00:00<00:00, 128.18it/s, train_loss=0.0034, valid_loss=0.00524]\n",
      "Epoch: 29/50: 100%|██████████| 8/8 [00:00<00:00, 129.38it/s, train_loss=0.0037, valid_loss=0.0049]\n",
      "Epoch: 30/50: 100%|██████████| 8/8 [00:00<00:00, 128.42it/s, train_loss=0.00336, valid_loss=0.00489]\n",
      "Epoch: 31/50: 100%|██████████| 8/8 [00:00<00:00, 98.95it/s, train_loss=0.0033, valid_loss=0.00489]\n",
      "Epoch: 32/50: 100%|██████████| 8/8 [00:00<00:00, 71.64it/s, train_loss=0.00332, valid_loss=0.00527]\n",
      "Epoch: 33/50: 100%|██████████| 8/8 [00:00<00:00, 98.15it/s, train_loss=0.00331, valid_loss=0.00506]\n",
      "Epoch: 34/50: 100%|██████████| 8/8 [00:00<00:00, 130.55it/s, train_loss=0.00344, valid_loss=0.00503]\n",
      "Epoch: 35/50: 100%|██████████| 8/8 [00:00<00:00, 93.36it/s, train_loss=0.00315, valid_loss=0.00476]\n",
      "Epoch: 36/50: 100%|██████████| 8/8 [00:00<00:00, 104.96it/s, train_loss=0.00324, valid_loss=0.00516]\n",
      "Epoch: 37/50: 100%|██████████| 8/8 [00:00<00:00, 99.38it/s, train_loss=0.00311, valid_loss=0.00475]\n",
      "Epoch: 38/50: 100%|██████████| 8/8 [00:00<00:00, 128.27it/s, train_loss=0.0032, valid_loss=0.00515]\n",
      "Epoch: 39/50: 100%|██████████| 8/8 [00:00<00:00, 129.17it/s, train_loss=0.00317, valid_loss=0.00485]\n",
      "Epoch: 40/50: 100%|██████████| 8/8 [00:00<00:00, 126.77it/s, train_loss=0.00278, valid_loss=0.00548]\n",
      "Epoch: 41/50: 100%|██████████| 8/8 [00:00<00:00, 97.44it/s, train_loss=0.00331, valid_loss=0.00502]\n",
      "Epoch: 42/50: 100%|██████████| 8/8 [00:00<00:00, 125.87it/s, train_loss=0.00292, valid_loss=0.00495]\n",
      "Epoch: 43/50: 100%|██████████| 8/8 [00:00<00:00, 128.68it/s, train_loss=0.00317, valid_loss=0.00503]\n",
      "Epoch: 44/50: 100%|██████████| 8/8 [00:00<00:00, 128.14it/s, train_loss=0.00287, valid_loss=0.00505]\n",
      "Epoch: 45/50: 100%|██████████| 8/8 [00:00<00:00, 85.33it/s, train_loss=0.00334, valid_loss=0.00495]\n",
      "Epoch: 46/50: 100%|██████████| 8/8 [00:00<00:00, 103.67it/s, train_loss=0.00291, valid_loss=0.00496]\n",
      "Epoch: 47/50: 100%|██████████| 8/8 [00:00<00:00, 127.83it/s, train_loss=0.00312, valid_loss=0.0053]\n",
      "Epoch: 48/50: 100%|██████████| 8/8 [00:00<00:00, 127.83it/s, train_loss=0.00296, valid_loss=0.00489]\n",
      "Epoch: 49/50: 100%|██████████| 8/8 [00:00<00:00, 80.99it/s, train_loss=0.00287, valid_loss=0.00489]\n",
      "Epoch: 50/50: 100%|██████████| 8/8 [00:00<00:00, 103.20it/s, train_loss=0.00292, valid_loss=0.00543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 15/15 [00:00<00:00, 87.66it/s, train_loss=0.0444, valid_loss=0.0462]\n",
      "Epoch: 2/50: 100%|██████████| 15/15 [00:00<00:00, 142.84it/s, train_loss=0.0243, valid_loss=0.0296]\n",
      "Epoch: 3/50: 100%|██████████| 15/15 [00:00<00:00, 122.41it/s, train_loss=0.0119, valid_loss=0.00981]\n",
      "Epoch: 4/50: 100%|██████████| 15/15 [00:00<00:00, 141.01it/s, train_loss=0.00746, valid_loss=0.00482]\n",
      "Epoch: 5/50: 100%|██████████| 15/15 [00:00<00:00, 141.54it/s, train_loss=0.00672, valid_loss=0.00713]\n",
      "Epoch: 6/50: 100%|██████████| 15/15 [00:00<00:00, 130.24it/s, train_loss=0.00578, valid_loss=0.00427]\n",
      "Epoch: 7/50: 100%|██████████| 15/15 [00:00<00:00, 100.69it/s, train_loss=0.00613, valid_loss=0.00257]\n",
      "Epoch: 8/50: 100%|██████████| 15/15 [00:00<00:00, 140.38it/s, train_loss=0.00533, valid_loss=0.00511]\n",
      "Epoch: 9/50: 100%|██████████| 15/15 [00:00<00:00, 125.78it/s, train_loss=0.00526, valid_loss=0.00241]\n",
      "Epoch: 10/50: 100%|██████████| 15/15 [00:00<00:00, 135.47it/s, train_loss=0.00507, valid_loss=0.00414]\n",
      "Epoch: 11/50: 100%|██████████| 15/15 [00:00<00:00, 138.71it/s, train_loss=0.00481, valid_loss=0.00234]\n",
      "Epoch: 12/50: 100%|██████████| 15/15 [00:00<00:00, 140.80it/s, train_loss=0.00484, valid_loss=0.00255]\n",
      "Epoch: 13/50: 100%|██████████| 15/15 [00:00<00:00, 78.47it/s, train_loss=0.00515, valid_loss=0.00282]\n",
      "Epoch: 14/50: 100%|██████████| 15/15 [00:00<00:00, 139.42it/s, train_loss=0.00494, valid_loss=0.00222]\n",
      "Epoch: 15/50: 100%|██████████| 15/15 [00:00<00:00, 128.06it/s, train_loss=0.00558, valid_loss=0.00355]\n",
      "Epoch: 16/50: 100%|██████████| 15/15 [00:00<00:00, 129.08it/s, train_loss=0.00436, valid_loss=0.00211]\n",
      "Epoch: 17/50: 100%|██████████| 15/15 [00:00<00:00, 101.30it/s, train_loss=0.0044, valid_loss=0.00191]\n",
      "Epoch: 18/50: 100%|██████████| 15/15 [00:00<00:00, 136.12it/s, train_loss=0.00428, valid_loss=0.00306]\n",
      "Epoch: 19/50: 100%|██████████| 15/15 [00:00<00:00, 120.35it/s, train_loss=0.0049, valid_loss=0.00194]\n",
      "Epoch: 20/50: 100%|██████████| 15/15 [00:00<00:00, 138.54it/s, train_loss=0.00487, valid_loss=0.00214]\n",
      "Epoch: 21/50: 100%|██████████| 15/15 [00:00<00:00, 103.58it/s, train_loss=0.00401, valid_loss=0.00205]\n",
      "Epoch: 22/50: 100%|██████████| 15/15 [00:00<00:00, 108.04it/s, train_loss=0.00415, valid_loss=0.00213]\n",
      "Epoch: 23/50: 100%|██████████| 15/15 [00:00<00:00, 98.29it/s, train_loss=0.0047, valid_loss=0.00259]\n",
      "Epoch: 24/50: 100%|██████████| 15/15 [00:00<00:00, 138.34it/s, train_loss=0.0047, valid_loss=0.0024]\n",
      "Epoch: 25/50: 100%|██████████| 15/15 [00:00<00:00, 141.58it/s, train_loss=0.0046, valid_loss=0.00233]\n",
      "Epoch: 26/50: 100%|██████████| 15/15 [00:00<00:00, 140.24it/s, train_loss=0.00541, valid_loss=0.00183]\n",
      "Epoch: 27/50: 100%|██████████| 15/15 [00:00<00:00, 124.88it/s, train_loss=0.00464, valid_loss=0.00186]\n",
      "Epoch: 28/50: 100%|██████████| 15/15 [00:00<00:00, 104.50it/s, train_loss=0.00449, valid_loss=0.00212]\n",
      "Epoch: 29/50: 100%|██████████| 15/15 [00:00<00:00, 140.49it/s, train_loss=0.00423, valid_loss=0.00179]\n",
      "Epoch: 30/50: 100%|██████████| 15/15 [00:00<00:00, 141.01it/s, train_loss=0.00457, valid_loss=0.00181]\n",
      "Epoch: 31/50: 100%|██████████| 15/15 [00:00<00:00, 109.28it/s, train_loss=0.00394, valid_loss=0.00168]\n",
      "Epoch: 32/50: 100%|██████████| 15/15 [00:00<00:00, 140.33it/s, train_loss=0.00459, valid_loss=0.00254]\n",
      "Epoch: 33/50: 100%|██████████| 15/15 [00:00<00:00, 139.55it/s, train_loss=0.00444, valid_loss=0.00208]\n",
      "Epoch: 34/50: 100%|██████████| 15/15 [00:00<00:00, 142.47it/s, train_loss=0.00379, valid_loss=0.00169]\n",
      "Epoch: 35/50: 100%|██████████| 15/15 [00:00<00:00, 105.26it/s, train_loss=0.0044, valid_loss=0.00216]\n",
      "Epoch: 36/50: 100%|██████████| 15/15 [00:00<00:00, 137.11it/s, train_loss=0.00468, valid_loss=0.00183]\n",
      "Epoch: 37/50: 100%|██████████| 15/15 [00:00<00:00, 135.82it/s, train_loss=0.00447, valid_loss=0.00168]\n",
      "Epoch: 38/50: 100%|██████████| 15/15 [00:00<00:00, 110.41it/s, train_loss=0.00382, valid_loss=0.00237]\n",
      "Epoch: 39/50: 100%|██████████| 15/15 [00:00<00:00, 141.73it/s, train_loss=0.00439, valid_loss=0.00177]\n",
      "Epoch: 40/50: 100%|██████████| 15/15 [00:00<00:00, 124.88it/s, train_loss=0.00414, valid_loss=0.00217]\n",
      "Epoch: 41/50: 100%|██████████| 15/15 [00:00<00:00, 135.60it/s, train_loss=0.00392, valid_loss=0.00192]\n",
      "Epoch: 42/50: 100%|██████████| 15/15 [00:00<00:00, 93.62it/s, train_loss=0.00434, valid_loss=0.00183]\n",
      "Epoch: 43/50: 100%|██████████| 15/15 [00:00<00:00, 118.92it/s, train_loss=0.00418, valid_loss=0.00229]\n",
      "Epoch: 44/50: 100%|██████████| 15/15 [00:00<00:00, 111.62it/s, train_loss=0.00411, valid_loss=0.00182]\n",
      "Epoch: 45/50: 100%|██████████| 15/15 [00:00<00:00, 112.26it/s, train_loss=0.00471, valid_loss=0.00244]\n",
      "Epoch: 46/50: 100%|██████████| 15/15 [00:00<00:00, 128.59it/s, train_loss=0.00391, valid_loss=0.0019]\n",
      "Epoch: 47/50: 100%|██████████| 15/15 [00:00<00:00, 135.78it/s, train_loss=0.00396, valid_loss=0.00197]\n",
      "Epoch: 48/50: 100%|██████████| 15/15 [00:00<00:00, 129.91it/s, train_loss=0.00426, valid_loss=0.00293]\n",
      "Epoch: 49/50: 100%|██████████| 15/15 [00:00<00:00, 78.78it/s, train_loss=0.00432, valid_loss=0.0019] \n",
      "Epoch: 50/50: 100%|██████████| 15/15 [00:00<00:00, 123.31it/s, train_loss=0.00414, valid_loss=0.00301]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 22/22 [00:00<00:00, 92.70it/s, train_loss=0.0221, valid_loss=0.0278]\n",
      "Epoch: 2/50: 100%|██████████| 22/22 [00:00<00:00, 122.70it/s, train_loss=0.0103, valid_loss=0.0107]\n",
      "Epoch: 3/50: 100%|██████████| 22/22 [00:00<00:00, 122.16it/s, train_loss=0.00777, valid_loss=0.00646]\n",
      "Epoch: 4/50: 100%|██████████| 22/22 [00:00<00:00, 104.34it/s, train_loss=0.0067, valid_loss=0.00715]\n",
      "Epoch: 5/50: 100%|██████████| 22/22 [00:00<00:00, 121.59it/s, train_loss=0.00735, valid_loss=0.00512]\n",
      "Epoch: 6/50: 100%|██████████| 22/22 [00:00<00:00, 110.98it/s, train_loss=0.00619, valid_loss=0.0049] \n",
      "Epoch: 7/50: 100%|██████████| 22/22 [00:00<00:00, 123.48it/s, train_loss=0.00536, valid_loss=0.00435]\n",
      "Epoch: 8/50: 100%|██████████| 22/22 [00:00<00:00, 106.95it/s, train_loss=0.00525, valid_loss=0.00432]\n",
      "Epoch: 9/50: 100%|██████████| 22/22 [00:00<00:00, 129.70it/s, train_loss=0.00558, valid_loss=0.00392]\n",
      "Epoch: 10/50: 100%|██████████| 22/22 [00:00<00:00, 104.32it/s, train_loss=0.00489, valid_loss=0.00459]\n",
      "Epoch: 11/50: 100%|██████████| 22/22 [00:00<00:00, 131.19it/s, train_loss=0.00475, valid_loss=0.00382]\n",
      "Epoch: 12/50: 100%|██████████| 22/22 [00:00<00:00, 130.95it/s, train_loss=0.00504, valid_loss=0.00394]\n",
      "Epoch: 13/50: 100%|██████████| 22/22 [00:00<00:00, 106.61it/s, train_loss=0.00507, valid_loss=0.00371]\n",
      "Epoch: 14/50: 100%|██████████| 22/22 [00:00<00:00, 117.87it/s, train_loss=0.0047, valid_loss=0.00384] \n",
      "Epoch: 15/50: 100%|██████████| 22/22 [00:00<00:00, 122.69it/s, train_loss=0.00504, valid_loss=0.00382]\n",
      "Epoch: 16/50: 100%|██████████| 22/22 [00:00<00:00, 128.87it/s, train_loss=0.00497, valid_loss=0.00376]\n",
      "Epoch: 17/50: 100%|██████████| 22/22 [00:00<00:00, 96.08it/s, train_loss=0.00463, valid_loss=0.00359] \n",
      "Epoch: 18/50: 100%|██████████| 22/22 [00:00<00:00, 122.15it/s, train_loss=0.00542, valid_loss=0.00393]\n",
      "Epoch: 19/50: 100%|██████████| 22/22 [00:00<00:00, 131.94it/s, train_loss=0.0046, valid_loss=0.0041]  \n",
      "Epoch: 20/50: 100%|██████████| 22/22 [00:00<00:00, 132.16it/s, train_loss=0.00448, valid_loss=0.00416]\n",
      "Epoch: 21/50: 100%|██████████| 22/22 [00:00<00:00, 131.75it/s, train_loss=0.0044, valid_loss=0.00447] \n",
      "Epoch: 22/50: 100%|██████████| 22/22 [00:00<00:00, 105.55it/s, train_loss=0.0047, valid_loss=0.00349]\n",
      "Epoch: 23/50: 100%|██████████| 22/22 [00:00<00:00, 120.75it/s, train_loss=0.0043, valid_loss=0.00392] \n",
      "Epoch: 24/50: 100%|██████████| 22/22 [00:00<00:00, 131.80it/s, train_loss=0.00427, valid_loss=0.0041] \n",
      "Epoch: 25/50: 100%|██████████| 22/22 [00:00<00:00, 120.69it/s, train_loss=0.00431, valid_loss=0.00391]\n",
      "Epoch: 26/50: 100%|██████████| 22/22 [00:00<00:00, 106.77it/s, train_loss=0.00443, valid_loss=0.00448]\n",
      "Epoch: 27/50: 100%|██████████| 22/22 [00:00<00:00, 98.48it/s, train_loss=0.0044, valid_loss=0.0043]  \n",
      "Epoch: 28/50: 100%|██████████| 22/22 [00:00<00:00, 131.03it/s, train_loss=0.00463, valid_loss=0.00395]\n",
      "Epoch: 29/50: 100%|██████████| 22/22 [00:00<00:00, 114.17it/s, train_loss=0.00409, valid_loss=0.00384]\n",
      "Epoch: 30/50: 100%|██████████| 22/22 [00:00<00:00, 121.09it/s, train_loss=0.00483, valid_loss=0.00377]\n",
      "Epoch: 31/50: 100%|██████████| 22/22 [00:00<00:00, 96.02it/s, train_loss=0.00437, valid_loss=0.00448] \n",
      "Epoch: 32/50: 100%|██████████| 22/22 [00:00<00:00, 120.44it/s, train_loss=0.00396, valid_loss=0.00392]\n",
      "Epoch: 33/50: 100%|██████████| 22/22 [00:00<00:00, 119.08it/s, train_loss=0.00439, valid_loss=0.00394]\n",
      "Epoch: 34/50: 100%|██████████| 22/22 [00:00<00:00, 130.48it/s, train_loss=0.00413, valid_loss=0.00385]\n",
      "Epoch: 35/50: 100%|██████████| 22/22 [00:00<00:00, 101.38it/s, train_loss=0.00406, valid_loss=0.00401]\n",
      "Epoch: 36/50: 100%|██████████| 22/22 [00:00<00:00, 119.35it/s, train_loss=0.00393, valid_loss=0.00392]\n",
      "Epoch: 37/50: 100%|██████████| 22/22 [00:00<00:00, 110.09it/s, train_loss=0.00397, valid_loss=0.00452]\n",
      "Epoch: 38/50: 100%|██████████| 22/22 [00:00<00:00, 133.91it/s, train_loss=0.00426, valid_loss=0.0041] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 29/29 [00:00<00:00, 105.27it/s, train_loss=0.0254, valid_loss=0.0227]\n",
      "Epoch: 2/50: 100%|██████████| 29/29 [00:00<00:00, 103.36it/s, train_loss=0.0118, valid_loss=0.0069] \n",
      "Epoch: 3/50: 100%|██████████| 29/29 [00:00<00:00, 132.85it/s, train_loss=0.0078, valid_loss=0.00647] \n",
      "Epoch: 4/50: 100%|██████████| 29/29 [00:00<00:00, 126.76it/s, train_loss=0.0071, valid_loss=0.00505] \n",
      "Epoch: 5/50: 100%|██████████| 29/29 [00:00<00:00, 129.11it/s, train_loss=0.00598, valid_loss=0.00607]\n",
      "Epoch: 6/50: 100%|██████████| 29/29 [00:00<00:00, 121.03it/s, train_loss=0.00633, valid_loss=0.0042] \n",
      "Epoch: 7/50: 100%|██████████| 29/29 [00:00<00:00, 116.97it/s, train_loss=0.00563, valid_loss=0.00478]\n",
      "Epoch: 8/50: 100%|██████████| 29/29 [00:00<00:00, 123.18it/s, train_loss=0.00575, valid_loss=0.0037] \n",
      "Epoch: 9/50: 100%|██████████| 29/29 [00:00<00:00, 126.87it/s, train_loss=0.00563, valid_loss=0.00404]\n",
      "Epoch: 10/50: 100%|██████████| 29/29 [00:00<00:00, 108.52it/s, train_loss=0.00495, valid_loss=0.0041]\n",
      "Epoch: 11/50: 100%|██████████| 29/29 [00:00<00:00, 128.99it/s, train_loss=0.00542, valid_loss=0.00316]\n",
      "Epoch: 12/50: 100%|██████████| 29/29 [00:00<00:00, 131.73it/s, train_loss=0.00511, valid_loss=0.00487]\n",
      "Epoch: 13/50: 100%|██████████| 29/29 [00:00<00:00, 97.70it/s, train_loss=0.00459, valid_loss=0.00459]\n",
      "Epoch: 14/50: 100%|██████████| 29/29 [00:00<00:00, 124.93it/s, train_loss=0.00489, valid_loss=0.00336]\n",
      "Epoch: 15/50: 100%|██████████| 29/29 [00:00<00:00, 104.12it/s, train_loss=0.00501, valid_loss=0.00395]\n",
      "Epoch: 16/50: 100%|██████████| 29/29 [00:00<00:00, 137.11it/s, train_loss=0.00428, valid_loss=0.00261]\n",
      "Epoch: 17/50: 100%|██████████| 29/29 [00:00<00:00, 125.68it/s, train_loss=0.0045, valid_loss=0.00361] \n",
      "Epoch: 18/50: 100%|██████████| 29/29 [00:00<00:00, 128.70it/s, train_loss=0.00462, valid_loss=0.00315]\n",
      "Epoch: 19/50: 100%|██████████| 29/29 [00:00<00:00, 111.83it/s, train_loss=0.00435, valid_loss=0.00482]\n",
      "Epoch: 20/50: 100%|██████████| 29/29 [00:00<00:00, 138.57it/s, train_loss=0.0041, valid_loss=0.00395] \n",
      "Epoch: 21/50: 100%|██████████| 29/29 [00:00<00:00, 108.88it/s, train_loss=0.00425, valid_loss=0.00405]\n",
      "Epoch: 22/50: 100%|██████████| 29/29 [00:00<00:00, 113.70it/s, train_loss=0.00425, valid_loss=0.00339]\n",
      "Epoch: 23/50: 100%|██████████| 29/29 [00:00<00:00, 124.12it/s, train_loss=0.00378, valid_loss=0.00292]\n",
      "Epoch: 24/50: 100%|██████████| 29/29 [00:00<00:00, 118.51it/s, train_loss=0.00477, valid_loss=0.00314]\n",
      "Epoch: 25/50: 100%|██████████| 29/29 [00:00<00:00, 115.89it/s, train_loss=0.00409, valid_loss=0.00315]\n",
      "Epoch: 26/50: 100%|██████████| 29/29 [00:00<00:00, 102.41it/s, train_loss=0.00386, valid_loss=0.00379]\n",
      "Epoch: 27/50: 100%|██████████| 29/29 [00:00<00:00, 137.83it/s, train_loss=0.0039, valid_loss=0.00361] \n",
      "Epoch: 28/50: 100%|██████████| 29/29 [00:00<00:00, 120.94it/s, train_loss=0.00431, valid_loss=0.00269]\n",
      "Epoch: 29/50: 100%|██████████| 29/29 [00:00<00:00, 131.97it/s, train_loss=0.00428, valid_loss=0.00374]\n",
      "Epoch: 30/50: 100%|██████████| 29/29 [00:00<00:00, 125.33it/s, train_loss=0.0042, valid_loss=0.00421]\n",
      "Epoch: 31/50: 100%|██████████| 29/29 [00:00<00:00, 115.86it/s, train_loss=0.00401, valid_loss=0.00275]\n",
      "Epoch: 32/50: 100%|██████████| 29/29 [00:00<00:00, 127.31it/s, train_loss=0.00385, valid_loss=0.00344]\n",
      "Epoch: 33/50: 100%|██████████| 29/29 [00:00<00:00, 129.01it/s, train_loss=0.0042, valid_loss=0.00342] \n",
      "Epoch: 34/50: 100%|██████████| 29/29 [00:00<00:00, 110.29it/s, train_loss=0.00429, valid_loss=0.00266]\n",
      "Epoch: 35/50: 100%|██████████| 29/29 [00:00<00:00, 114.13it/s, train_loss=0.00418, valid_loss=0.00424]\n",
      "Epoch: 36/50: 100%|██████████| 29/29 [00:00<00:00, 104.44it/s, train_loss=0.00449, valid_loss=0.00305]\n",
      "Epoch: 37/50: 100%|██████████| 29/29 [00:00<00:00, 114.24it/s, train_loss=0.00374, valid_loss=0.00227]\n",
      "Epoch: 38/50: 100%|██████████| 29/29 [00:00<00:00, 126.47it/s, train_loss=0.00374, valid_loss=0.00335]\n",
      "Epoch: 39/50: 100%|██████████| 29/29 [00:00<00:00, 111.39it/s, train_loss=0.00399, valid_loss=0.00286]\n",
      "Epoch: 40/50: 100%|██████████| 29/29 [00:00<00:00, 137.94it/s, train_loss=0.00405, valid_loss=0.00296]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 36/36 [00:00<00:00, 102.04it/s, train_loss=0.0142, valid_loss=0.0119]\n",
      "Epoch: 2/50: 100%|██████████| 36/36 [00:00<00:00, 101.39it/s, train_loss=0.00881, valid_loss=0.00523]\n",
      "Epoch: 3/50: 100%|██████████| 36/36 [00:00<00:00, 114.51it/s, train_loss=0.00719, valid_loss=0.00406]\n",
      "Epoch: 4/50: 100%|██████████| 36/36 [00:00<00:00, 109.25it/s, train_loss=0.00638, valid_loss=0.0036] \n",
      "Epoch: 5/50: 100%|██████████| 36/36 [00:00<00:00, 119.58it/s, train_loss=0.00638, valid_loss=0.00332]\n",
      "Epoch: 6/50: 100%|██████████| 36/36 [00:00<00:00, 106.65it/s, train_loss=0.0057, valid_loss=0.0031]  \n",
      "Epoch: 7/50: 100%|██████████| 36/36 [00:00<00:00, 124.64it/s, train_loss=0.006, valid_loss=0.00287]  \n",
      "Epoch: 8/50: 100%|██████████| 36/36 [00:00<00:00, 111.95it/s, train_loss=0.00553, valid_loss=0.00319]\n",
      "Epoch: 9/50: 100%|██████████| 36/36 [00:00<00:00, 104.63it/s, train_loss=0.0052, valid_loss=0.00279] \n",
      "Epoch: 10/50: 100%|██████████| 36/36 [00:00<00:00, 133.04it/s, train_loss=0.00501, valid_loss=0.00265]\n",
      "Epoch: 11/50: 100%|██████████| 36/36 [00:00<00:00, 133.98it/s, train_loss=0.00488, valid_loss=0.00257]\n",
      "Epoch: 12/50: 100%|██████████| 36/36 [00:00<00:00, 98.42it/s, train_loss=0.00429, valid_loss=0.00258] \n",
      "Epoch: 13/50: 100%|██████████| 36/36 [00:00<00:00, 119.99it/s, train_loss=0.00428, valid_loss=0.00252]\n",
      "Epoch: 14/50: 100%|██████████| 36/36 [00:00<00:00, 119.12it/s, train_loss=0.00404, valid_loss=0.0027] \n",
      "Epoch: 15/50: 100%|██████████| 36/36 [00:00<00:00, 120.75it/s, train_loss=0.00428, valid_loss=0.00237]\n",
      "Epoch: 16/50: 100%|██████████| 36/36 [00:00<00:00, 115.55it/s, train_loss=0.00417, valid_loss=0.00239]\n",
      "Epoch: 17/50: 100%|██████████| 36/36 [00:00<00:00, 125.24it/s, train_loss=0.00436, valid_loss=0.00238]\n",
      "Epoch: 18/50: 100%|██████████| 36/36 [00:00<00:00, 113.72it/s, train_loss=0.00428, valid_loss=0.00245]\n",
      "Epoch: 19/50: 100%|██████████| 36/36 [00:00<00:00, 132.46it/s, train_loss=0.00432, valid_loss=0.00249]\n",
      "Epoch: 20/50: 100%|██████████| 36/36 [00:00<00:00, 125.71it/s, train_loss=0.00415, valid_loss=0.00248]\n",
      "Epoch: 21/50: 100%|██████████| 36/36 [00:00<00:00, 126.26it/s, train_loss=0.0043, valid_loss=0.00227] \n",
      "Epoch: 22/50: 100%|██████████| 36/36 [00:00<00:00, 108.34it/s, train_loss=0.00406, valid_loss=0.00261]\n",
      "Epoch: 23/50: 100%|██████████| 36/36 [00:00<00:00, 113.43it/s, train_loss=0.00435, valid_loss=0.00291]\n",
      "Epoch: 24/50: 100%|██████████| 36/36 [00:00<00:00, 104.03it/s, train_loss=0.00385, valid_loss=0.00227]\n",
      "Epoch: 25/50: 100%|██████████| 36/36 [00:00<00:00, 126.60it/s, train_loss=0.00403, valid_loss=0.00259]\n",
      "Epoch: 26/50: 100%|██████████| 36/36 [00:00<00:00, 126.18it/s, train_loss=0.00395, valid_loss=0.00264]\n",
      "Epoch: 27/50: 100%|██████████| 36/36 [00:00<00:00, 105.27it/s, train_loss=0.00406, valid_loss=0.00236]\n",
      "Epoch: 28/50: 100%|██████████| 36/36 [00:00<00:00, 114.23it/s, train_loss=0.00375, valid_loss=0.00225]\n",
      "Epoch: 29/50: 100%|██████████| 36/36 [00:00<00:00, 115.79it/s, train_loss=0.0039, valid_loss=0.00229] \n",
      "Epoch: 30/50: 100%|██████████| 36/36 [00:00<00:00, 121.66it/s, train_loss=0.00402, valid_loss=0.00238]\n",
      "Epoch: 31/50: 100%|██████████| 36/36 [00:00<00:00, 124.87it/s, train_loss=0.00363, valid_loss=0.00258]\n",
      "Epoch: 32/50: 100%|██████████| 36/36 [00:00<00:00, 106.70it/s, train_loss=0.00355, valid_loss=0.00244]\n",
      "Epoch: 33/50: 100%|██████████| 36/36 [00:00<00:00, 110.32it/s, train_loss=0.00404, valid_loss=0.00228]\n",
      "Epoch: 34/50: 100%|██████████| 36/36 [00:00<00:00, 124.33it/s, train_loss=0.00426, valid_loss=0.00258]\n",
      "Epoch: 35/50: 100%|██████████| 36/36 [00:00<00:00, 122.92it/s, train_loss=0.00414, valid_loss=0.00239]\n",
      "Epoch: 36/50: 100%|██████████| 36/36 [00:00<00:00, 110.56it/s, train_loss=0.00384, valid_loss=0.00249]\n",
      "Epoch: 37/50: 100%|██████████| 36/36 [00:00<00:00, 126.80it/s, train_loss=0.00362, valid_loss=0.00262]\n",
      "Epoch: 38/50: 100%|██████████| 36/36 [00:00<00:00, 119.53it/s, train_loss=0.00392, valid_loss=0.00235]\n",
      "Epoch: 39/50: 100%|██████████| 36/36 [00:00<00:00, 121.25it/s, train_loss=0.00371, valid_loss=0.00245]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config: batch_size--512, lr--0.001, number_epoch--50, hidden_dim--35,drop_prob-0.1,weight_decay-1e-07\n",
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 8/8 [00:00<00:00, 50.17it/s, train_loss=0.08, valid_loss=0.119]  \n",
      "Epoch: 2/50: 100%|██████████| 8/8 [00:00<00:00, 119.36it/s, train_loss=0.0679, valid_loss=0.0966]\n",
      "Epoch: 3/50: 100%|██████████| 8/8 [00:00<00:00, 128.24it/s, train_loss=0.0554, valid_loss=0.0834]\n",
      "Epoch: 4/50: 100%|██████████| 8/8 [00:00<00:00, 126.79it/s, train_loss=0.0484, valid_loss=0.0751]\n",
      "Epoch: 5/50: 100%|██████████| 8/8 [00:00<00:00, 127.96it/s, train_loss=0.0446, valid_loss=0.0675]\n",
      "Epoch: 6/50: 100%|██████████| 8/8 [00:00<00:00, 117.14it/s, train_loss=0.038, valid_loss=0.0587]\n",
      "Epoch: 7/50: 100%|██████████| 8/8 [00:00<00:00, 102.17it/s, train_loss=0.0341, valid_loss=0.0517]\n",
      "Epoch: 8/50: 100%|██████████| 8/8 [00:00<00:00, 102.95it/s, train_loss=0.0309, valid_loss=0.0467]\n",
      "Epoch: 9/50: 100%|██████████| 8/8 [00:00<00:00, 105.21it/s, train_loss=0.028, valid_loss=0.044]\n",
      "Epoch: 10/50: 100%|██████████| 8/8 [00:00<00:00, 72.53it/s, train_loss=0.0276, valid_loss=0.0417]\n",
      "Epoch: 11/50: 100%|██████████| 8/8 [00:00<00:00, 125.29it/s, train_loss=0.0225, valid_loss=0.0379]\n",
      "Epoch: 12/50: 100%|██████████| 8/8 [00:00<00:00, 128.20it/s, train_loss=0.021, valid_loss=0.0323]\n",
      "Epoch: 13/50: 100%|██████████| 8/8 [00:00<00:00, 127.57it/s, train_loss=0.0189, valid_loss=0.0305]\n",
      "Epoch: 14/50: 100%|██████████| 8/8 [00:00<00:00, 128.69it/s, train_loss=0.0186, valid_loss=0.0302]\n",
      "Epoch: 15/50: 100%|██████████| 8/8 [00:00<00:00, 129.00it/s, train_loss=0.0182, valid_loss=0.0289]\n",
      "Epoch: 16/50: 100%|██████████| 8/8 [00:00<00:00, 127.67it/s, train_loss=0.0177, valid_loss=0.0282]\n",
      "Epoch: 17/50: 100%|██████████| 8/8 [00:00<00:00, 127.54it/s, train_loss=0.0172, valid_loss=0.0277]\n",
      "Epoch: 18/50: 100%|██████████| 8/8 [00:00<00:00, 92.70it/s, train_loss=0.0173, valid_loss=0.026]\n",
      "Epoch: 19/50: 100%|██████████| 8/8 [00:00<00:00, 78.12it/s, train_loss=0.0165, valid_loss=0.0259]\n",
      "Epoch: 20/50: 100%|██████████| 8/8 [00:00<00:00, 105.19it/s, train_loss=0.0161, valid_loss=0.0248]\n",
      "Epoch: 21/50: 100%|██████████| 8/8 [00:00<00:00, 112.83it/s, train_loss=0.0162, valid_loss=0.0238]\n",
      "Epoch: 22/50: 100%|██████████| 8/8 [00:00<00:00, 129.31it/s, train_loss=0.0157, valid_loss=0.023]\n",
      "Epoch: 23/50: 100%|██████████| 8/8 [00:00<00:00, 130.27it/s, train_loss=0.0149, valid_loss=0.0223]\n",
      "Epoch: 24/50: 100%|██████████| 8/8 [00:00<00:00, 125.45it/s, train_loss=0.0152, valid_loss=0.0222]\n",
      "Epoch: 25/50: 100%|██████████| 8/8 [00:00<00:00, 130.67it/s, train_loss=0.015, valid_loss=0.0215]\n",
      "Epoch: 26/50: 100%|██████████| 8/8 [00:00<00:00, 127.48it/s, train_loss=0.0147, valid_loss=0.0207]\n",
      "Epoch: 27/50: 100%|██████████| 8/8 [00:00<00:00, 129.11it/s, train_loss=0.0144, valid_loss=0.0208]\n",
      "Epoch: 28/50: 100%|██████████| 8/8 [00:00<00:00, 127.25it/s, train_loss=0.0149, valid_loss=0.0202]\n",
      "Epoch: 29/50: 100%|██████████| 8/8 [00:00<00:00, 106.46it/s, train_loss=0.0145, valid_loss=0.02]\n",
      "Epoch: 30/50: 100%|██████████| 8/8 [00:00<00:00, 108.25it/s, train_loss=0.0138, valid_loss=0.0198]\n",
      "Epoch: 31/50: 100%|██████████| 8/8 [00:00<00:00, 128.66it/s, train_loss=0.0138, valid_loss=0.0195]\n",
      "Epoch: 32/50: 100%|██████████| 8/8 [00:00<00:00, 103.40it/s, train_loss=0.0136, valid_loss=0.0192]\n",
      "Epoch: 33/50: 100%|██████████| 8/8 [00:00<00:00, 129.53it/s, train_loss=0.0133, valid_loss=0.019]\n",
      "Epoch: 34/50: 100%|██████████| 8/8 [00:00<00:00, 129.80it/s, train_loss=0.0141, valid_loss=0.0193]\n",
      "Epoch: 35/50: 100%|██████████| 8/8 [00:00<00:00, 128.17it/s, train_loss=0.0133, valid_loss=0.0189]\n",
      "Epoch: 36/50: 100%|██████████| 8/8 [00:00<00:00, 82.99it/s, train_loss=0.0134, valid_loss=0.0185]\n",
      "Epoch: 37/50: 100%|██████████| 8/8 [00:00<00:00, 96.49it/s, train_loss=0.0138, valid_loss=0.0186]\n",
      "Epoch: 38/50: 100%|██████████| 8/8 [00:00<00:00, 127.71it/s, train_loss=0.0135, valid_loss=0.0185]\n",
      "Epoch: 39/50: 100%|██████████| 8/8 [00:00<00:00, 97.59it/s, train_loss=0.0133, valid_loss=0.0185]\n",
      "Epoch: 40/50: 100%|██████████| 8/8 [00:00<00:00, 119.75it/s, train_loss=0.0134, valid_loss=0.0185]\n",
      "Epoch: 41/50: 100%|██████████| 8/8 [00:00<00:00, 111.53it/s, train_loss=0.0135, valid_loss=0.0184]\n",
      "Epoch: 42/50: 100%|██████████| 8/8 [00:00<00:00, 104.86it/s, train_loss=0.0135, valid_loss=0.0181]\n",
      "Epoch: 43/50: 100%|██████████| 8/8 [00:00<00:00, 129.27it/s, train_loss=0.0137, valid_loss=0.0184]\n",
      "Epoch: 44/50: 100%|██████████| 8/8 [00:00<00:00, 97.80it/s, train_loss=0.0132, valid_loss=0.0182]\n",
      "Epoch: 45/50: 100%|██████████| 8/8 [00:00<00:00, 127.55it/s, train_loss=0.0131, valid_loss=0.018]\n",
      "Epoch: 46/50: 100%|██████████| 8/8 [00:00<00:00, 131.23it/s, train_loss=0.0124, valid_loss=0.0183]\n",
      "Epoch: 47/50: 100%|██████████| 8/8 [00:00<00:00, 117.81it/s, train_loss=0.0133, valid_loss=0.018]\n",
      "Epoch: 48/50: 100%|██████████| 8/8 [00:00<00:00, 114.46it/s, train_loss=0.0128, valid_loss=0.0179]\n",
      "Epoch: 49/50: 100%|██████████| 8/8 [00:00<00:00, 128.73it/s, train_loss=0.0126, valid_loss=0.0179]\n",
      "Epoch: 50/50: 100%|██████████| 8/8 [00:00<00:00, 99.31it/s, train_loss=0.0127, valid_loss=0.0179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 8/8 [00:00<00:00, 74.96it/s, train_loss=0.076, valid_loss=0.117]\n",
      "Epoch: 2/50: 100%|██████████| 8/8 [00:00<00:00, 88.06it/s, train_loss=0.0674, valid_loss=0.101]\n",
      "Epoch: 3/50: 100%|██████████| 8/8 [00:00<00:00, 84.48it/s, train_loss=0.0614, valid_loss=0.0895]\n",
      "Epoch: 4/50: 100%|██████████| 8/8 [00:00<00:00, 57.25it/s, train_loss=0.0564, valid_loss=0.083]\n",
      "Epoch: 5/50: 100%|██████████| 8/8 [00:00<00:00, 82.79it/s, train_loss=0.0486, valid_loss=0.0722]\n",
      "Epoch: 6/50: 100%|██████████| 8/8 [00:00<00:00, 90.63it/s, train_loss=0.0415, valid_loss=0.0614]\n",
      "Epoch: 7/50: 100%|██████████| 8/8 [00:00<00:00, 124.75it/s, train_loss=0.0376, valid_loss=0.0564]\n",
      "Epoch: 8/50: 100%|██████████| 8/8 [00:00<00:00, 123.40it/s, train_loss=0.0327, valid_loss=0.0502]\n",
      "Epoch: 9/50: 100%|██████████| 8/8 [00:00<00:00, 99.00it/s, train_loss=0.031, valid_loss=0.0483]\n",
      "Epoch: 10/50: 100%|██████████| 8/8 [00:00<00:00, 96.97it/s, train_loss=0.0283, valid_loss=0.0447]\n",
      "Epoch: 11/50: 100%|██████████| 8/8 [00:00<00:00, 97.85it/s, train_loss=0.0285, valid_loss=0.0426]\n",
      "Epoch: 12/50: 100%|██████████| 8/8 [00:00<00:00, 125.40it/s, train_loss=0.0272, valid_loss=0.0422]\n",
      "Epoch: 13/50: 100%|██████████| 8/8 [00:00<00:00, 120.26it/s, train_loss=0.0273, valid_loss=0.0418]\n",
      "Epoch: 14/50: 100%|██████████| 8/8 [00:00<00:00, 91.22it/s, train_loss=0.0265, valid_loss=0.0409]\n",
      "Epoch: 15/50: 100%|██████████| 8/8 [00:00<00:00, 109.06it/s, train_loss=0.0255, valid_loss=0.0398]\n",
      "Epoch: 16/50: 100%|██████████| 8/8 [00:00<00:00, 86.58it/s, train_loss=0.0241, valid_loss=0.0374]\n",
      "Epoch: 17/50: 100%|██████████| 8/8 [00:00<00:00, 88.87it/s, train_loss=0.023, valid_loss=0.0343]\n",
      "Epoch: 18/50: 100%|██████████| 8/8 [00:00<00:00, 101.28it/s, train_loss=0.0206, valid_loss=0.033]\n",
      "Epoch: 19/50: 100%|██████████| 8/8 [00:00<00:00, 93.22it/s, train_loss=0.0209, valid_loss=0.0325]\n",
      "Epoch: 20/50: 100%|██████████| 8/8 [00:00<00:00, 122.31it/s, train_loss=0.0212, valid_loss=0.0315]\n",
      "Epoch: 21/50: 100%|██████████| 8/8 [00:00<00:00, 57.45it/s, train_loss=0.0206, valid_loss=0.0311]\n",
      "Epoch: 22/50: 100%|██████████| 8/8 [00:00<00:00, 116.44it/s, train_loss=0.0195, valid_loss=0.0302]\n",
      "Epoch: 23/50: 100%|██████████| 8/8 [00:00<00:00, 102.30it/s, train_loss=0.0196, valid_loss=0.0293]\n",
      "Epoch: 24/50: 100%|██████████| 8/8 [00:00<00:00, 99.19it/s, train_loss=0.0195, valid_loss=0.0286]\n",
      "Epoch: 25/50: 100%|██████████| 8/8 [00:00<00:00, 97.91it/s, train_loss=0.0192, valid_loss=0.0284]\n",
      "Epoch: 26/50: 100%|██████████| 8/8 [00:00<00:00, 97.77it/s, train_loss=0.019, valid_loss=0.0278]\n",
      "Epoch: 27/50: 100%|██████████| 8/8 [00:00<00:00, 96.33it/s, train_loss=0.0187, valid_loss=0.0275]\n",
      "Epoch: 28/50: 100%|██████████| 8/8 [00:00<00:00, 93.22it/s, train_loss=0.0186, valid_loss=0.0272]\n",
      "Epoch: 29/50: 100%|██████████| 8/8 [00:00<00:00, 85.94it/s, train_loss=0.0183, valid_loss=0.0264]\n",
      "Epoch: 30/50: 100%|██████████| 8/8 [00:00<00:00, 86.58it/s, train_loss=0.0176, valid_loss=0.0263]\n",
      "Epoch: 31/50: 100%|██████████| 8/8 [00:00<00:00, 124.29it/s, train_loss=0.0182, valid_loss=0.026]\n",
      "Epoch: 32/50: 100%|██████████| 8/8 [00:00<00:00, 124.85it/s, train_loss=0.0182, valid_loss=0.0257]\n",
      "Epoch: 33/50: 100%|██████████| 8/8 [00:00<00:00, 96.22it/s, train_loss=0.0185, valid_loss=0.0241]\n",
      "Epoch: 34/50: 100%|██████████| 8/8 [00:00<00:00, 89.71it/s, train_loss=0.0154, valid_loss=0.022]\n",
      "Epoch: 35/50: 100%|██████████| 8/8 [00:00<00:00, 81.28it/s, train_loss=0.0152, valid_loss=0.0204]\n",
      "Epoch: 36/50: 100%|██████████| 8/8 [00:00<00:00, 96.63it/s, train_loss=0.0142, valid_loss=0.0198]\n",
      "Epoch: 37/50: 100%|██████████| 8/8 [00:00<00:00, 95.58it/s, train_loss=0.0143, valid_loss=0.0195]\n",
      "Epoch: 38/50: 100%|██████████| 8/8 [00:00<00:00, 75.90it/s, train_loss=0.0141, valid_loss=0.0196]\n",
      "Epoch: 39/50: 100%|██████████| 8/8 [00:00<00:00, 119.78it/s, train_loss=0.0138, valid_loss=0.0191]\n",
      "Epoch: 40/50: 100%|██████████| 8/8 [00:00<00:00, 99.60it/s, train_loss=0.0134, valid_loss=0.0189]\n",
      "Epoch: 41/50: 100%|██████████| 8/8 [00:00<00:00, 97.27it/s, train_loss=0.0137, valid_loss=0.019]\n",
      "Epoch: 42/50: 100%|██████████| 8/8 [00:00<00:00, 78.19it/s, train_loss=0.0133, valid_loss=0.0188]\n",
      "Epoch: 43/50: 100%|██████████| 8/8 [00:00<00:00, 97.76it/s, train_loss=0.013, valid_loss=0.0189]\n",
      "Epoch: 44/50: 100%|██████████| 8/8 [00:00<00:00, 124.80it/s, train_loss=0.0134, valid_loss=0.0186]\n",
      "Epoch: 45/50: 100%|██████████| 8/8 [00:00<00:00, 94.04it/s, train_loss=0.0136, valid_loss=0.0186]\n",
      "Epoch: 46/50: 100%|██████████| 8/8 [00:00<00:00, 91.15it/s, train_loss=0.0135, valid_loss=0.0183]\n",
      "Epoch: 47/50: 100%|██████████| 8/8 [00:00<00:00, 124.12it/s, train_loss=0.0133, valid_loss=0.0186]\n",
      "Epoch: 48/50: 100%|██████████| 8/8 [00:00<00:00, 96.89it/s, train_loss=0.0133, valid_loss=0.0186]\n",
      "Epoch: 49/50: 100%|██████████| 8/8 [00:00<00:00, 125.71it/s, train_loss=0.0135, valid_loss=0.0182]\n",
      "Epoch: 50/50: 100%|██████████| 8/8 [00:00<00:00, 76.55it/s, train_loss=0.0129, valid_loss=0.0182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 8/8 [00:00<00:00, 74.68it/s, train_loss=0.0768, valid_loss=0.119]\n",
      "Epoch: 2/50: 100%|██████████| 8/8 [00:00<00:00, 88.30it/s, train_loss=0.0672, valid_loss=0.102]\n",
      "Epoch: 3/50: 100%|██████████| 8/8 [00:00<00:00, 95.68it/s, train_loss=0.055, valid_loss=0.0821]\n",
      "Epoch: 4/50: 100%|██████████| 8/8 [00:00<00:00, 93.81it/s, train_loss=0.0492, valid_loss=0.0702]\n",
      "Epoch: 5/50: 100%|██████████| 8/8 [00:00<00:00, 107.23it/s, train_loss=0.0407, valid_loss=0.0618]\n",
      "Epoch: 6/50: 100%|██████████| 8/8 [00:00<00:00, 78.79it/s, train_loss=0.035, valid_loss=0.0532]\n",
      "Epoch: 7/50: 100%|██████████| 8/8 [00:00<00:00, 119.11it/s, train_loss=0.032, valid_loss=0.0503]\n",
      "Epoch: 8/50: 100%|██████████| 8/8 [00:00<00:00, 97.41it/s, train_loss=0.0317, valid_loss=0.0504]\n",
      "Epoch: 9/50: 100%|██████████| 8/8 [00:00<00:00, 80.10it/s, train_loss=0.0313, valid_loss=0.0492]\n",
      "Epoch: 10/50: 100%|██████████| 8/8 [00:00<00:00, 116.72it/s, train_loss=0.0303, valid_loss=0.0483]\n",
      "Epoch: 11/50: 100%|██████████| 8/8 [00:00<00:00, 90.51it/s, train_loss=0.0288, valid_loss=0.0448]\n",
      "Epoch: 12/50: 100%|██████████| 8/8 [00:00<00:00, 84.28it/s, train_loss=0.0267, valid_loss=0.043]\n",
      "Epoch: 13/50: 100%|██████████| 8/8 [00:00<00:00, 98.30it/s, train_loss=0.0264, valid_loss=0.0423]\n",
      "Epoch: 14/50: 100%|██████████| 8/8 [00:00<00:00, 98.93it/s, train_loss=0.0265, valid_loss=0.0423]\n",
      "Epoch: 15/50: 100%|██████████| 8/8 [00:00<00:00, 70.60it/s, train_loss=0.0249, valid_loss=0.0408]\n",
      "Epoch: 16/50: 100%|██████████| 8/8 [00:00<00:00, 124.02it/s, train_loss=0.0243, valid_loss=0.0377]\n",
      "Epoch: 17/50: 100%|██████████| 8/8 [00:00<00:00, 99.65it/s, train_loss=0.0223, valid_loss=0.0363]\n",
      "Epoch: 18/50: 100%|██████████| 8/8 [00:00<00:00, 101.02it/s, train_loss=0.0217, valid_loss=0.0363]\n",
      "Epoch: 19/50: 100%|██████████| 8/8 [00:00<00:00, 96.44it/s, train_loss=0.0222, valid_loss=0.0354]\n",
      "Epoch: 20/50: 100%|██████████| 8/8 [00:00<00:00, 98.61it/s, train_loss=0.021, valid_loss=0.0349]\n",
      "Epoch: 21/50: 100%|██████████| 8/8 [00:00<00:00, 100.02it/s, train_loss=0.0209, valid_loss=0.0342]\n",
      "Epoch: 22/50: 100%|██████████| 8/8 [00:00<00:00, 126.37it/s, train_loss=0.0199, valid_loss=0.0318]\n",
      "Epoch: 23/50: 100%|██████████| 8/8 [00:00<00:00, 98.65it/s, train_loss=0.017, valid_loss=0.0283]\n",
      "Epoch: 24/50: 100%|██████████| 8/8 [00:00<00:00, 69.65it/s, train_loss=0.0146, valid_loss=0.0237]\n",
      "Epoch: 25/50: 100%|██████████| 8/8 [00:00<00:00, 96.71it/s, train_loss=0.0132, valid_loss=0.0217]\n",
      "Epoch: 26/50: 100%|██████████| 8/8 [00:00<00:00, 77.61it/s, train_loss=0.012, valid_loss=0.0207]\n",
      "Epoch: 27/50: 100%|██████████| 8/8 [00:00<00:00, 95.69it/s, train_loss=0.012, valid_loss=0.0194]\n",
      "Epoch: 28/50: 100%|██████████| 8/8 [00:00<00:00, 99.87it/s, train_loss=0.012, valid_loss=0.0188]\n",
      "Epoch: 29/50: 100%|██████████| 8/8 [00:00<00:00, 97.56it/s, train_loss=0.0117, valid_loss=0.0185]\n",
      "Epoch: 30/50: 100%|██████████| 8/8 [00:00<00:00, 95.81it/s, train_loss=0.0117, valid_loss=0.0177]\n",
      "Epoch: 31/50: 100%|██████████| 8/8 [00:00<00:00, 80.68it/s, train_loss=0.0107, valid_loss=0.0173]\n",
      "Epoch: 32/50: 100%|██████████| 8/8 [00:00<00:00, 99.74it/s, train_loss=0.011, valid_loss=0.0163]\n",
      "Epoch: 33/50: 100%|██████████| 8/8 [00:00<00:00, 68.15it/s, train_loss=0.0109, valid_loss=0.0162]\n",
      "Epoch: 34/50: 100%|██████████| 8/8 [00:00<00:00, 95.38it/s, train_loss=0.0111, valid_loss=0.0161]\n",
      "Epoch: 35/50: 100%|██████████| 8/8 [00:00<00:00, 100.11it/s, train_loss=0.0104, valid_loss=0.0153]\n",
      "Epoch: 36/50: 100%|██████████| 8/8 [00:00<00:00, 98.53it/s, train_loss=0.0105, valid_loss=0.0152]\n",
      "Epoch: 37/50: 100%|██████████| 8/8 [00:00<00:00, 123.52it/s, train_loss=0.0102, valid_loss=0.0146]\n",
      "Epoch: 38/50: 100%|██████████| 8/8 [00:00<00:00, 99.51it/s, train_loss=0.00997, valid_loss=0.0144]\n",
      "Epoch: 39/50: 100%|██████████| 8/8 [00:00<00:00, 99.10it/s, train_loss=0.0101, valid_loss=0.014]\n",
      "Epoch: 40/50: 100%|██████████| 8/8 [00:00<00:00, 100.53it/s, train_loss=0.0104, valid_loss=0.0139]\n",
      "Epoch: 41/50: 100%|██████████| 8/8 [00:00<00:00, 122.98it/s, train_loss=0.0103, valid_loss=0.0138]\n",
      "Epoch: 42/50: 100%|██████████| 8/8 [00:00<00:00, 126.40it/s, train_loss=0.00942, valid_loss=0.0134]\n",
      "Epoch: 43/50: 100%|██████████| 8/8 [00:00<00:00, 67.85it/s, train_loss=0.00948, valid_loss=0.0133]\n",
      "Epoch: 44/50: 100%|██████████| 8/8 [00:00<00:00, 119.95it/s, train_loss=0.00968, valid_loss=0.0133]\n",
      "Epoch: 45/50: 100%|██████████| 8/8 [00:00<00:00, 100.03it/s, train_loss=0.00951, valid_loss=0.013]\n",
      "Epoch: 46/50: 100%|██████████| 8/8 [00:00<00:00, 99.55it/s, train_loss=0.00949, valid_loss=0.0129]\n",
      "Epoch: 47/50: 100%|██████████| 8/8 [00:00<00:00, 123.54it/s, train_loss=0.00944, valid_loss=0.0129]\n",
      "Epoch: 48/50: 100%|██████████| 8/8 [00:00<00:00, 99.94it/s, train_loss=0.00951, valid_loss=0.0128]\n",
      "Epoch: 49/50: 100%|██████████| 8/8 [00:00<00:00, 95.66it/s, train_loss=0.00982, valid_loss=0.0125]\n",
      "Epoch: 50/50: 100%|██████████| 8/8 [00:00<00:00, 97.36it/s, train_loss=0.00905, valid_loss=0.0127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 8/8 [00:00<00:00, 77.35it/s, train_loss=0.0649, valid_loss=0.098]\n",
      "Epoch: 2/50: 100%|██████████| 8/8 [00:00<00:00, 57.62it/s, train_loss=0.0355, valid_loss=0.0543]\n",
      "Epoch: 3/50: 100%|██████████| 8/8 [00:00<00:00, 98.18it/s, train_loss=0.0251, valid_loss=0.0353]\n",
      "Epoch: 4/50: 100%|██████████| 8/8 [00:00<00:00, 101.89it/s, train_loss=0.02, valid_loss=0.0313]\n",
      "Epoch: 5/50: 100%|██████████| 8/8 [00:00<00:00, 101.83it/s, train_loss=0.0181, valid_loss=0.0293]\n",
      "Epoch: 6/50: 100%|██████████| 8/8 [00:00<00:00, 101.76it/s, train_loss=0.0141, valid_loss=0.0234]\n",
      "Epoch: 7/50: 100%|██████████| 8/8 [00:00<00:00, 126.37it/s, train_loss=0.0128, valid_loss=0.0217]\n",
      "Epoch: 8/50: 100%|██████████| 8/8 [00:00<00:00, 125.44it/s, train_loss=0.0121, valid_loss=0.0217]\n",
      "Epoch: 9/50: 100%|██████████| 8/8 [00:00<00:00, 99.79it/s, train_loss=0.0119, valid_loss=0.0202]\n",
      "Epoch: 10/50: 100%|██████████| 8/8 [00:00<00:00, 124.56it/s, train_loss=0.011, valid_loss=0.0197]\n",
      "Epoch: 11/50: 100%|██████████| 8/8 [00:00<00:00, 72.09it/s, train_loss=0.0106, valid_loss=0.019]\n",
      "Epoch: 12/50: 100%|██████████| 8/8 [00:00<00:00, 97.27it/s, train_loss=0.0103, valid_loss=0.0181]\n",
      "Epoch: 13/50: 100%|██████████| 8/8 [00:00<00:00, 105.07it/s, train_loss=0.0101, valid_loss=0.0172]\n",
      "Epoch: 14/50: 100%|██████████| 8/8 [00:00<00:00, 125.97it/s, train_loss=0.00987, valid_loss=0.0163]\n",
      "Epoch: 15/50: 100%|██████████| 8/8 [00:00<00:00, 128.12it/s, train_loss=0.00965, valid_loss=0.0155]\n",
      "Epoch: 16/50: 100%|██████████| 8/8 [00:00<00:00, 97.18it/s, train_loss=0.00874, valid_loss=0.0145]\n",
      "Epoch: 17/50: 100%|██████████| 8/8 [00:00<00:00, 102.09it/s, train_loss=0.00837, valid_loss=0.0135]\n",
      "Epoch: 18/50: 100%|██████████| 8/8 [00:00<00:00, 102.36it/s, train_loss=0.00761, valid_loss=0.0127]\n",
      "Epoch: 19/50: 100%|██████████| 8/8 [00:00<00:00, 97.83it/s, train_loss=0.0078, valid_loss=0.0119]\n",
      "Epoch: 20/50: 100%|██████████| 8/8 [00:00<00:00, 127.15it/s, train_loss=0.00722, valid_loss=0.011]\n",
      "Epoch: 21/50: 100%|██████████| 8/8 [00:00<00:00, 98.66it/s, train_loss=0.0069, valid_loss=0.0106]\n",
      "Epoch: 22/50: 100%|██████████| 8/8 [00:00<00:00, 99.92it/s, train_loss=0.0068, valid_loss=0.00983]\n",
      "Epoch: 23/50: 100%|██████████| 8/8 [00:00<00:00, 127.79it/s, train_loss=0.00642, valid_loss=0.0092]\n",
      "Epoch: 24/50: 100%|██████████| 8/8 [00:00<00:00, 99.60it/s, train_loss=0.00629, valid_loss=0.00893]\n",
      "Epoch: 25/50: 100%|██████████| 8/8 [00:00<00:00, 124.11it/s, train_loss=0.00606, valid_loss=0.00835]\n",
      "Epoch: 26/50: 100%|██████████| 8/8 [00:00<00:00, 124.16it/s, train_loss=0.00585, valid_loss=0.00811]\n",
      "Epoch: 27/50: 100%|██████████| 8/8 [00:00<00:00, 83.01it/s, train_loss=0.00607, valid_loss=0.00779]\n",
      "Epoch: 28/50: 100%|██████████| 8/8 [00:00<00:00, 71.30it/s, train_loss=0.00589, valid_loss=0.00742]\n",
      "Epoch: 29/50: 100%|██████████| 8/8 [00:00<00:00, 125.25it/s, train_loss=0.00552, valid_loss=0.00753]\n",
      "Epoch: 30/50: 100%|██████████| 8/8 [00:00<00:00, 101.36it/s, train_loss=0.00522, valid_loss=0.00714]\n",
      "Epoch: 31/50: 100%|██████████| 8/8 [00:00<00:00, 128.37it/s, train_loss=0.00512, valid_loss=0.007]\n",
      "Epoch: 32/50: 100%|██████████| 8/8 [00:00<00:00, 126.65it/s, train_loss=0.00501, valid_loss=0.007]\n",
      "Epoch: 33/50: 100%|██████████| 8/8 [00:00<00:00, 128.84it/s, train_loss=0.00521, valid_loss=0.00682]\n",
      "Epoch: 34/50: 100%|██████████| 8/8 [00:00<00:00, 120.88it/s, train_loss=0.00536, valid_loss=0.00675]\n",
      "Epoch: 35/50: 100%|██████████| 8/8 [00:00<00:00, 98.01it/s, train_loss=0.0049, valid_loss=0.00658]\n",
      "Epoch: 36/50: 100%|██████████| 8/8 [00:00<00:00, 99.63it/s, train_loss=0.00482, valid_loss=0.00648]\n",
      "Epoch: 37/50: 100%|██████████| 8/8 [00:00<00:00, 70.12it/s, train_loss=0.00508, valid_loss=0.00649]\n",
      "Epoch: 38/50: 100%|██████████| 8/8 [00:00<00:00, 124.67it/s, train_loss=0.00512, valid_loss=0.00636]\n",
      "Epoch: 39/50: 100%|██████████| 8/8 [00:00<00:00, 102.89it/s, train_loss=0.00474, valid_loss=0.00638]\n",
      "Epoch: 40/50: 100%|██████████| 8/8 [00:00<00:00, 101.71it/s, train_loss=0.00469, valid_loss=0.00632]\n",
      "Epoch: 41/50: 100%|██████████| 8/8 [00:00<00:00, 126.55it/s, train_loss=0.00471, valid_loss=0.00621]\n",
      "Epoch: 42/50: 100%|██████████| 8/8 [00:00<00:00, 124.60it/s, train_loss=0.00463, valid_loss=0.00613]\n",
      "Epoch: 43/50: 100%|██████████| 8/8 [00:00<00:00, 98.33it/s, train_loss=0.00468, valid_loss=0.00603]\n",
      "Epoch: 44/50: 100%|██████████| 8/8 [00:00<00:00, 99.15it/s, train_loss=0.00451, valid_loss=0.00606]\n",
      "Epoch: 45/50: 100%|██████████| 8/8 [00:00<00:00, 124.58it/s, train_loss=0.00484, valid_loss=0.0059]\n",
      "Epoch: 46/50: 100%|██████████| 8/8 [00:00<00:00, 124.78it/s, train_loss=0.00475, valid_loss=0.00608]\n",
      "Epoch: 47/50: 100%|██████████| 8/8 [00:00<00:00, 82.93it/s, train_loss=0.00432, valid_loss=0.00587]\n",
      "Epoch: 48/50: 100%|██████████| 8/8 [00:00<00:00, 101.84it/s, train_loss=0.00461, valid_loss=0.00573]\n",
      "Epoch: 49/50: 100%|██████████| 8/8 [00:00<00:00, 126.53it/s, train_loss=0.00418, valid_loss=0.00574]\n",
      "Epoch: 50/50: 100%|██████████| 8/8 [00:00<00:00, 124.66it/s, train_loss=0.00405, valid_loss=0.00567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 15/15 [00:00<00:00, 86.56it/s, train_loss=0.0868, valid_loss=0.15]\n",
      "Epoch: 2/50: 100%|██████████| 15/15 [00:00<00:00, 149.93it/s, train_loss=0.0601, valid_loss=0.08]\n",
      "Epoch: 3/50: 100%|██████████| 15/15 [00:00<00:00, 144.53it/s, train_loss=0.0535, valid_loss=0.0735]\n",
      "Epoch: 4/50: 100%|██████████| 15/15 [00:00<00:00, 144.64it/s, train_loss=0.0495, valid_loss=0.0686]\n",
      "Epoch: 5/50: 100%|██████████| 15/15 [00:00<00:00, 104.65it/s, train_loss=0.0328, valid_loss=0.0388]\n",
      "Epoch: 6/50: 100%|██████████| 15/15 [00:00<00:00, 144.47it/s, train_loss=0.0259, valid_loss=0.0271]\n",
      "Epoch: 7/50: 100%|██████████| 15/15 [00:00<00:00, 142.82it/s, train_loss=0.0233, valid_loss=0.0257]\n",
      "Epoch: 8/50: 100%|██████████| 15/15 [00:00<00:00, 143.10it/s, train_loss=0.0223, valid_loss=0.0249]\n",
      "Epoch: 9/50: 100%|██████████| 15/15 [00:00<00:00, 144.50it/s, train_loss=0.0218, valid_loss=0.0246]\n",
      "Epoch: 10/50: 100%|██████████| 15/15 [00:00<00:00, 143.66it/s, train_loss=0.0185, valid_loss=0.0212]\n",
      "Epoch: 11/50: 100%|██████████| 15/15 [00:00<00:00, 146.56it/s, train_loss=0.015, valid_loss=0.0153]\n",
      "Epoch: 12/50: 100%|██████████| 15/15 [00:00<00:00, 106.75it/s, train_loss=0.0143, valid_loss=0.0153]\n",
      "Epoch: 13/50: 100%|██████████| 15/15 [00:00<00:00, 144.22it/s, train_loss=0.0137, valid_loss=0.0145]\n",
      "Epoch: 14/50: 100%|██████████| 15/15 [00:00<00:00, 144.44it/s, train_loss=0.0133, valid_loss=0.0147]\n",
      "Epoch: 15/50: 100%|██████████| 15/15 [00:00<00:00, 144.30it/s, train_loss=0.0122, valid_loss=0.0144]\n",
      "Epoch: 16/50: 100%|██████████| 15/15 [00:00<00:00, 142.74it/s, train_loss=0.0126, valid_loss=0.0142]\n",
      "Epoch: 17/50: 100%|██████████| 15/15 [00:00<00:00, 125.56it/s, train_loss=0.0124, valid_loss=0.0141]\n",
      "Epoch: 18/50: 100%|██████████| 15/15 [00:00<00:00, 145.29it/s, train_loss=0.0127, valid_loss=0.0137]\n",
      "Epoch: 19/50: 100%|██████████| 15/15 [00:00<00:00, 107.45it/s, train_loss=0.0115, valid_loss=0.0137]\n",
      "Epoch: 20/50: 100%|██████████| 15/15 [00:00<00:00, 144.66it/s, train_loss=0.0117, valid_loss=0.0132]\n",
      "Epoch: 21/50: 100%|██████████| 15/15 [00:00<00:00, 124.49it/s, train_loss=0.0113, valid_loss=0.0134]\n",
      "Epoch: 22/50: 100%|██████████| 15/15 [00:00<00:00, 143.46it/s, train_loss=0.0105, valid_loss=0.0132]\n",
      "Epoch: 23/50: 100%|██████████| 15/15 [00:00<00:00, 145.69it/s, train_loss=0.0111, valid_loss=0.013]\n",
      "Epoch: 24/50: 100%|██████████| 15/15 [00:00<00:00, 144.32it/s, train_loss=0.0105, valid_loss=0.0129]\n",
      "Epoch: 25/50: 100%|██████████| 15/15 [00:00<00:00, 145.70it/s, train_loss=0.0112, valid_loss=0.0128]\n",
      "Epoch: 26/50: 100%|██████████| 15/15 [00:00<00:00, 107.65it/s, train_loss=0.0113, valid_loss=0.0129]\n",
      "Epoch: 27/50: 100%|██████████| 15/15 [00:00<00:00, 142.83it/s, train_loss=0.0111, valid_loss=0.0124]\n",
      "Epoch: 28/50: 100%|██████████| 15/15 [00:00<00:00, 143.97it/s, train_loss=0.0104, valid_loss=0.0131]\n",
      "Epoch: 29/50: 100%|██████████| 15/15 [00:00<00:00, 143.89it/s, train_loss=0.0109, valid_loss=0.0122]\n",
      "Epoch: 30/50: 100%|██████████| 15/15 [00:00<00:00, 143.21it/s, train_loss=0.0113, valid_loss=0.013]\n",
      "Epoch: 31/50: 100%|██████████| 15/15 [00:00<00:00, 145.80it/s, train_loss=0.0104, valid_loss=0.0133]\n",
      "Epoch: 32/50: 100%|██████████| 15/15 [00:00<00:00, 144.69it/s, train_loss=0.0102, valid_loss=0.0125]\n",
      "Epoch: 33/50: 100%|██████████| 15/15 [00:00<00:00, 108.23it/s, train_loss=0.0113, valid_loss=0.0128]\n",
      "Epoch: 34/50: 100%|██████████| 15/15 [00:00<00:00, 144.77it/s, train_loss=0.0102, valid_loss=0.0122]\n",
      "Epoch: 35/50: 100%|██████████| 15/15 [00:00<00:00, 143.73it/s, train_loss=0.0108, valid_loss=0.0122]\n",
      "Epoch: 36/50: 100%|██████████| 15/15 [00:00<00:00, 145.81it/s, train_loss=0.0111, valid_loss=0.0119]\n",
      "Epoch: 37/50: 100%|██████████| 15/15 [00:00<00:00, 143.42it/s, train_loss=0.00822, valid_loss=0.00734]\n",
      "Epoch: 38/50: 100%|██████████| 15/15 [00:00<00:00, 145.31it/s, train_loss=0.00588, valid_loss=0.00424]\n",
      "Epoch: 39/50: 100%|██████████| 15/15 [00:00<00:00, 142.86it/s, train_loss=0.00587, valid_loss=0.00412]\n",
      "Epoch: 40/50: 100%|██████████| 15/15 [00:00<00:00, 143.36it/s, train_loss=0.0049, valid_loss=0.00299]\n",
      "Epoch: 41/50: 100%|██████████| 15/15 [00:00<00:00, 108.23it/s, train_loss=0.00524, valid_loss=0.00332]\n",
      "Epoch: 42/50: 100%|██████████| 15/15 [00:00<00:00, 146.19it/s, train_loss=0.00537, valid_loss=0.00277]\n",
      "Epoch: 43/50: 100%|██████████| 15/15 [00:00<00:00, 142.57it/s, train_loss=0.00523, valid_loss=0.00331]\n",
      "Epoch: 44/50: 100%|██████████| 15/15 [00:00<00:00, 146.66it/s, train_loss=0.0053, valid_loss=0.00351]\n",
      "Epoch: 45/50: 100%|██████████| 15/15 [00:00<00:00, 142.10it/s, train_loss=0.00491, valid_loss=0.00275]\n",
      "Epoch: 46/50: 100%|██████████| 15/15 [00:00<00:00, 124.17it/s, train_loss=0.00568, valid_loss=0.00295]\n",
      "Epoch: 47/50: 100%|██████████| 15/15 [00:00<00:00, 145.23it/s, train_loss=0.00485, valid_loss=0.00309]\n",
      "Epoch: 48/50: 100%|██████████| 15/15 [00:00<00:00, 108.14it/s, train_loss=0.0052, valid_loss=0.00287]\n",
      "Epoch: 49/50: 100%|██████████| 15/15 [00:00<00:00, 146.53it/s, train_loss=0.0054, valid_loss=0.00257]\n",
      "Epoch: 50/50: 100%|██████████| 15/15 [00:00<00:00, 143.63it/s, train_loss=0.00554, valid_loss=0.00307]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 22/22 [00:00<00:00, 96.92it/s, train_loss=0.0612, valid_loss=0.0677] \n",
      "Epoch: 2/50: 100%|██████████| 22/22 [00:00<00:00, 136.79it/s, train_loss=0.0369, valid_loss=0.0419]\n",
      "Epoch: 3/50: 100%|██████████| 22/22 [00:00<00:00, 137.17it/s, train_loss=0.0274, valid_loss=0.0306]\n",
      "Epoch: 4/50: 100%|██████████| 22/22 [00:00<00:00, 108.74it/s, train_loss=0.0221, valid_loss=0.0268]\n",
      "Epoch: 5/50: 100%|██████████| 22/22 [00:00<00:00, 135.66it/s, train_loss=0.0215, valid_loss=0.0235]\n",
      "Epoch: 6/50: 100%|██████████| 22/22 [00:00<00:00, 134.74it/s, train_loss=0.0183, valid_loss=0.0215]\n",
      "Epoch: 7/50: 100%|██████████| 22/22 [00:00<00:00, 135.91it/s, train_loss=0.0187, valid_loss=0.0192]\n",
      "Epoch: 8/50: 100%|██████████| 22/22 [00:00<00:00, 111.11it/s, train_loss=0.0172, valid_loss=0.0178]\n",
      "Epoch: 9/50: 100%|██████████| 22/22 [00:00<00:00, 133.94it/s, train_loss=0.0165, valid_loss=0.0167]\n",
      "Epoch: 10/50: 100%|██████████| 22/22 [00:00<00:00, 134.75it/s, train_loss=0.0155, valid_loss=0.0151]\n",
      "Epoch: 11/50: 100%|██████████| 22/22 [00:00<00:00, 136.44it/s, train_loss=0.0147, valid_loss=0.014] \n",
      "Epoch: 12/50: 100%|██████████| 22/22 [00:00<00:00, 111.89it/s, train_loss=0.0145, valid_loss=0.0136]\n",
      "Epoch: 13/50: 100%|██████████| 22/22 [00:00<00:00, 134.98it/s, train_loss=0.0135, valid_loss=0.013] \n",
      "Epoch: 14/50: 100%|██████████| 22/22 [00:00<00:00, 135.84it/s, train_loss=0.0134, valid_loss=0.013] \n",
      "Epoch: 15/50: 100%|██████████| 22/22 [00:00<00:00, 135.25it/s, train_loss=0.0135, valid_loss=0.0125]\n",
      "Epoch: 16/50: 100%|██████████| 22/22 [00:00<00:00, 135.45it/s, train_loss=0.0133, valid_loss=0.0125]\n",
      "Epoch: 17/50: 100%|██████████| 22/22 [00:00<00:00, 111.62it/s, train_loss=0.0126, valid_loss=0.0123]\n",
      "Epoch: 18/50: 100%|██████████| 22/22 [00:00<00:00, 135.32it/s, train_loss=0.0121, valid_loss=0.0123]\n",
      "Epoch: 19/50: 100%|██████████| 22/22 [00:00<00:00, 136.23it/s, train_loss=0.0124, valid_loss=0.0124]\n",
      "Epoch: 20/50: 100%|██████████| 22/22 [00:00<00:00, 134.93it/s, train_loss=0.0125, valid_loss=0.012] \n",
      "Epoch: 21/50: 100%|██████████| 22/22 [00:00<00:00, 135.90it/s, train_loss=0.0114, valid_loss=0.0119]\n",
      "Epoch: 22/50: 100%|██████████| 22/22 [00:00<00:00, 111.20it/s, train_loss=0.0115, valid_loss=0.0119]\n",
      "Epoch: 23/50: 100%|██████████| 22/22 [00:00<00:00, 136.25it/s, train_loss=0.0129, valid_loss=0.0118]\n",
      "Epoch: 24/50: 100%|██████████| 22/22 [00:00<00:00, 136.00it/s, train_loss=0.0127, valid_loss=0.0117]\n",
      "Epoch: 25/50: 100%|██████████| 22/22 [00:00<00:00, 118.61it/s, train_loss=0.0114, valid_loss=0.0118]\n",
      "Epoch: 26/50: 100%|██████████| 22/22 [00:00<00:00, 111.94it/s, train_loss=0.012, valid_loss=0.0115] \n",
      "Epoch: 27/50: 100%|██████████| 22/22 [00:00<00:00, 134.92it/s, train_loss=0.0113, valid_loss=0.0115]\n",
      "Epoch: 28/50: 100%|██████████| 22/22 [00:00<00:00, 135.31it/s, train_loss=0.0116, valid_loss=0.0114]\n",
      "Epoch: 29/50: 100%|██████████| 22/22 [00:00<00:00, 135.46it/s, train_loss=0.00843, valid_loss=0.00794]\n",
      "Epoch: 30/50: 100%|██████████| 22/22 [00:00<00:00, 135.62it/s, train_loss=0.00546, valid_loss=0.00453]\n",
      "Epoch: 31/50: 100%|██████████| 22/22 [00:00<00:00, 111.66it/s, train_loss=0.00506, valid_loss=0.00437]\n",
      "Epoch: 32/50: 100%|██████████| 22/22 [00:00<00:00, 135.03it/s, train_loss=0.00487, valid_loss=0.00399]\n",
      "Epoch: 33/50: 100%|██████████| 22/22 [00:00<00:00, 135.91it/s, train_loss=0.00472, valid_loss=0.004]  \n",
      "Epoch: 34/50: 100%|██████████| 22/22 [00:00<00:00, 134.80it/s, train_loss=0.00537, valid_loss=0.00385]\n",
      "Epoch: 35/50: 100%|██████████| 22/22 [00:00<00:00, 135.76it/s, train_loss=0.00505, valid_loss=0.00393]\n",
      "Epoch: 36/50: 100%|██████████| 22/22 [00:00<00:00, 110.74it/s, train_loss=0.00433, valid_loss=0.00378]\n",
      "Epoch: 37/50: 100%|██████████| 22/22 [00:00<00:00, 136.23it/s, train_loss=0.00459, valid_loss=0.00369]\n",
      "Epoch: 38/50: 100%|██████████| 22/22 [00:00<00:00, 136.16it/s, train_loss=0.00446, valid_loss=0.00365]\n",
      "Epoch: 39/50: 100%|██████████| 22/22 [00:00<00:00, 135.30it/s, train_loss=0.00419, valid_loss=0.00364]\n",
      "Epoch: 40/50: 100%|██████████| 22/22 [00:00<00:00, 110.16it/s, train_loss=0.00484, valid_loss=0.00357]\n",
      "Epoch: 41/50: 100%|██████████| 22/22 [00:00<00:00, 135.48it/s, train_loss=0.00431, valid_loss=0.00355]\n",
      "Epoch: 42/50: 100%|██████████| 22/22 [00:00<00:00, 135.87it/s, train_loss=0.00418, valid_loss=0.00345]\n",
      "Epoch: 43/50: 100%|██████████| 22/22 [00:00<00:00, 136.57it/s, train_loss=0.00429, valid_loss=0.00363]\n",
      "Epoch: 44/50: 100%|██████████| 22/22 [00:00<00:00, 135.33it/s, train_loss=0.00467, valid_loss=0.00344]\n",
      "Epoch: 45/50: 100%|██████████| 22/22 [00:00<00:00, 110.09it/s, train_loss=0.00498, valid_loss=0.00362]\n",
      "Epoch: 46/50: 100%|██████████| 22/22 [00:00<00:00, 135.37it/s, train_loss=0.00424, valid_loss=0.0035] \n",
      "Epoch: 47/50: 100%|██████████| 22/22 [00:00<00:00, 135.67it/s, train_loss=0.00427, valid_loss=0.00345]\n",
      "Epoch: 48/50: 100%|██████████| 22/22 [00:00<00:00, 135.82it/s, train_loss=0.00443, valid_loss=0.00342]\n",
      "Epoch: 49/50: 100%|██████████| 22/22 [00:00<00:00, 110.04it/s, train_loss=0.00436, valid_loss=0.00338]\n",
      "Epoch: 50/50: 100%|██████████| 22/22 [00:00<00:00, 135.01it/s, train_loss=0.00432, valid_loss=0.00349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 29/29 [00:00<00:00, 109.09it/s, train_loss=0.0649, valid_loss=0.0647]\n",
      "Epoch: 2/50: 100%|██████████| 29/29 [00:00<00:00, 141.77it/s, train_loss=0.0252, valid_loss=0.0154]\n",
      "Epoch: 3/50: 100%|██████████| 29/29 [00:00<00:00, 142.42it/s, train_loss=0.0171, valid_loss=0.0107]\n",
      "Epoch: 4/50: 100%|██████████| 29/29 [00:00<00:00, 118.69it/s, train_loss=0.016, valid_loss=0.00909] \n",
      "Epoch: 5/50: 100%|██████████| 29/29 [00:00<00:00, 140.68it/s, train_loss=0.0119, valid_loss=0.00658]\n",
      "Epoch: 6/50: 100%|██████████| 29/29 [00:00<00:00, 140.03it/s, train_loss=0.0102, valid_loss=0.00541]\n",
      "Epoch: 7/50: 100%|██████████| 29/29 [00:00<00:00, 119.23it/s, train_loss=0.00927, valid_loss=0.00536]\n",
      "Epoch: 8/50: 100%|██████████| 29/29 [00:00<00:00, 141.04it/s, train_loss=0.00869, valid_loss=0.00551]\n",
      "Epoch: 9/50: 100%|██████████| 29/29 [00:00<00:00, 140.65it/s, train_loss=0.00784, valid_loss=0.00453]\n",
      "Epoch: 10/50: 100%|██████████| 29/29 [00:00<00:00, 118.82it/s, train_loss=0.00814, valid_loss=0.00469]\n",
      "Epoch: 11/50: 100%|██████████| 29/29 [00:00<00:00, 141.64it/s, train_loss=0.00743, valid_loss=0.00402]\n",
      "Epoch: 12/50: 100%|██████████| 29/29 [00:00<00:00, 140.91it/s, train_loss=0.00706, valid_loss=0.00371]\n",
      "Epoch: 13/50: 100%|██████████| 29/29 [00:00<00:00, 142.66it/s, train_loss=0.00712, valid_loss=0.0031] \n",
      "Epoch: 14/50: 100%|██████████| 29/29 [00:00<00:00, 142.54it/s, train_loss=0.00569, valid_loss=0.00308]\n",
      "Epoch: 15/50: 100%|██████████| 29/29 [00:00<00:00, 119.25it/s, train_loss=0.00682, valid_loss=0.0026]\n",
      "Epoch: 16/50: 100%|██████████| 29/29 [00:00<00:00, 142.01it/s, train_loss=0.00665, valid_loss=0.00309]\n",
      "Epoch: 17/50: 100%|██████████| 29/29 [00:00<00:00, 141.33it/s, train_loss=0.00625, valid_loss=0.00253]\n",
      "Epoch: 18/50: 100%|██████████| 29/29 [00:00<00:00, 143.15it/s, train_loss=0.00607, valid_loss=0.00256]\n",
      "Epoch: 19/50: 100%|██████████| 29/29 [00:00<00:00, 143.26it/s, train_loss=0.00647, valid_loss=0.00209]\n",
      "Epoch: 20/50: 100%|██████████| 29/29 [00:00<00:00, 119.44it/s, train_loss=0.00618, valid_loss=0.00219]\n",
      "Epoch: 21/50: 100%|██████████| 29/29 [00:00<00:00, 141.41it/s, train_loss=0.00605, valid_loss=0.00214]\n",
      "Epoch: 22/50: 100%|██████████| 29/29 [00:00<00:00, 132.84it/s, train_loss=0.00648, valid_loss=0.00223]\n",
      "Epoch: 23/50: 100%|██████████| 29/29 [00:00<00:00, 132.34it/s, train_loss=0.00597, valid_loss=0.0021] \n",
      "Epoch: 24/50: 100%|██████████| 29/29 [00:00<00:00, 143.47it/s, train_loss=0.00521, valid_loss=0.00223]\n",
      "Epoch: 25/50: 100%|██████████| 29/29 [00:00<00:00, 120.46it/s, train_loss=0.00558, valid_loss=0.0024] \n",
      "Epoch: 26/50: 100%|██████████| 29/29 [00:00<00:00, 141.82it/s, train_loss=0.00534, valid_loss=0.00195]\n",
      "Epoch: 27/50: 100%|██████████| 29/29 [00:00<00:00, 140.77it/s, train_loss=0.00562, valid_loss=0.00193]\n",
      "Epoch: 28/50: 100%|██████████| 29/29 [00:00<00:00, 142.02it/s, train_loss=0.00558, valid_loss=0.00186]\n",
      "Epoch: 29/50: 100%|██████████| 29/29 [00:00<00:00, 142.79it/s, train_loss=0.00529, valid_loss=0.00193]\n",
      "Epoch: 30/50: 100%|██████████| 29/29 [00:00<00:00, 120.83it/s, train_loss=0.00583, valid_loss=0.00228]\n",
      "Epoch: 31/50: 100%|██████████| 29/29 [00:00<00:00, 141.77it/s, train_loss=0.00572, valid_loss=0.00193]\n",
      "Epoch: 32/50: 100%|██████████| 29/29 [00:00<00:00, 141.60it/s, train_loss=0.00531, valid_loss=0.00198]\n",
      "Epoch: 33/50: 100%|██████████| 29/29 [00:00<00:00, 119.41it/s, train_loss=0.00513, valid_loss=0.00192]\n",
      "Epoch: 34/50: 100%|██████████| 29/29 [00:00<00:00, 139.03it/s, train_loss=0.00551, valid_loss=0.00184]\n",
      "Epoch: 35/50: 100%|██████████| 29/29 [00:00<00:00, 141.35it/s, train_loss=0.00528, valid_loss=0.00204]\n",
      "Epoch: 36/50: 100%|██████████| 29/29 [00:00<00:00, 110.61it/s, train_loss=0.00531, valid_loss=0.00201]\n",
      "Epoch: 37/50: 100%|██████████| 29/29 [00:00<00:00, 141.84it/s, train_loss=0.00557, valid_loss=0.00206]\n",
      "Epoch: 38/50: 100%|██████████| 29/29 [00:00<00:00, 120.27it/s, train_loss=0.00556, valid_loss=0.0019] \n",
      "Epoch: 39/50: 100%|██████████| 29/29 [00:00<00:00, 140.84it/s, train_loss=0.00511, valid_loss=0.00201]\n",
      "Epoch: 40/50: 100%|██████████| 29/29 [00:00<00:00, 130.53it/s, train_loss=0.00515, valid_loss=0.00206]\n",
      "Epoch: 41/50: 100%|██████████| 29/29 [00:00<00:00, 130.35it/s, train_loss=0.00541, valid_loss=0.00192]\n",
      "Epoch: 42/50: 100%|██████████| 29/29 [00:00<00:00, 141.76it/s, train_loss=0.00541, valid_loss=0.00214]\n",
      "Epoch: 43/50: 100%|██████████| 29/29 [00:00<00:00, 143.74it/s, train_loss=0.00524, valid_loss=0.00191]\n",
      "Epoch: 44/50: 100%|██████████| 29/29 [00:00<00:00, 117.43it/s, train_loss=0.00489, valid_loss=0.00203]\n",
      "Epoch: 45/50: 100%|██████████| 29/29 [00:00<00:00, 142.11it/s, train_loss=0.0053, valid_loss=0.00204] \n",
      "Epoch: 46/50: 100%|██████████| 29/29 [00:00<00:00, 141.52it/s, train_loss=0.0049, valid_loss=0.00186] \n",
      "Epoch: 47/50: 100%|██████████| 29/29 [00:00<00:00, 142.48it/s, train_loss=0.005, valid_loss=0.00194]  \n",
      "Epoch: 48/50: 100%|██████████| 29/29 [00:00<00:00, 142.68it/s, train_loss=0.00502, valid_loss=0.00177]\n",
      "Epoch: 49/50: 100%|██████████| 29/29 [00:00<00:00, 119.41it/s, train_loss=0.00535, valid_loss=0.00217]\n",
      "Epoch: 50/50: 100%|██████████| 29/29 [00:00<00:00, 141.93it/s, train_loss=0.00499, valid_loss=0.0019] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 36/36 [00:00<00:00, 109.15it/s, train_loss=0.0343, valid_loss=0.0261]\n",
      "Epoch: 2/50: 100%|██████████| 36/36 [00:00<00:00, 136.47it/s, train_loss=0.0207, valid_loss=0.0166]\n",
      "Epoch: 3/50: 100%|██████████| 36/36 [00:00<00:00, 116.82it/s, train_loss=0.0154, valid_loss=0.0131]\n",
      "Epoch: 4/50: 100%|██████████| 36/36 [00:00<00:00, 136.16it/s, train_loss=0.0125, valid_loss=0.0091] \n",
      "Epoch: 5/50: 100%|██████████| 36/36 [00:00<00:00, 137.22it/s, train_loss=0.01, valid_loss=0.00701]  \n",
      "Epoch: 6/50: 100%|██████████| 36/36 [00:00<00:00, 137.65it/s, train_loss=0.0096, valid_loss=0.00581] \n",
      "Epoch: 7/50: 100%|██████████| 36/36 [00:00<00:00, 111.84it/s, train_loss=0.00841, valid_loss=0.00515]\n",
      "Epoch: 8/50: 100%|██████████| 36/36 [00:00<00:00, 136.61it/s, train_loss=0.00788, valid_loss=0.00452]\n",
      "Epoch: 9/50: 100%|██████████| 36/36 [00:00<00:00, 136.47it/s, train_loss=0.00715, valid_loss=0.0039] \n",
      "Epoch: 10/50: 100%|██████████| 36/36 [00:00<00:00, 136.79it/s, train_loss=0.00701, valid_loss=0.00341]\n",
      "Epoch: 11/50: 100%|██████████| 36/36 [00:00<00:00, 114.68it/s, train_loss=0.00605, valid_loss=0.00309]\n",
      "Epoch: 12/50: 100%|██████████| 36/36 [00:00<00:00, 135.99it/s, train_loss=0.00629, valid_loss=0.00297]\n",
      "Epoch: 13/50: 100%|██████████| 36/36 [00:00<00:00, 136.22it/s, train_loss=0.00609, valid_loss=0.00275]\n",
      "Epoch: 14/50: 100%|██████████| 36/36 [00:00<00:00, 128.85it/s, train_loss=0.0061, valid_loss=0.00267] \n",
      "Epoch: 15/50: 100%|██████████| 36/36 [00:00<00:00, 119.33it/s, train_loss=0.00578, valid_loss=0.00264]\n",
      "Epoch: 16/50: 100%|██████████| 36/36 [00:00<00:00, 135.77it/s, train_loss=0.00568, valid_loss=0.00259]\n",
      "Epoch: 17/50: 100%|██████████| 36/36 [00:00<00:00, 136.44it/s, train_loss=0.00565, valid_loss=0.00258]\n",
      "Epoch: 18/50: 100%|██████████| 36/36 [00:00<00:00, 127.61it/s, train_loss=0.00527, valid_loss=0.00244]\n",
      "Epoch: 19/50: 100%|██████████| 36/36 [00:00<00:00, 119.23it/s, train_loss=0.00507, valid_loss=0.00248]\n",
      "Epoch: 20/50: 100%|██████████| 36/36 [00:00<00:00, 135.73it/s, train_loss=0.00558, valid_loss=0.00241]\n",
      "Epoch: 21/50: 100%|██████████| 36/36 [00:00<00:00, 127.81it/s, train_loss=0.00517, valid_loss=0.00241]\n",
      "Epoch: 22/50: 100%|██████████| 36/36 [00:00<00:00, 136.17it/s, train_loss=0.00563, valid_loss=0.00249]\n",
      "Epoch: 23/50: 100%|██████████| 36/36 [00:00<00:00, 118.62it/s, train_loss=0.00534, valid_loss=0.00241]\n",
      "Epoch: 24/50: 100%|██████████| 36/36 [00:00<00:00, 135.23it/s, train_loss=0.00484, valid_loss=0.0025] \n",
      "Epoch: 25/50: 100%|██████████| 36/36 [00:00<00:00, 133.40it/s, train_loss=0.00528, valid_loss=0.00235]\n",
      "Epoch: 26/50: 100%|██████████| 36/36 [00:00<00:00, 136.35it/s, train_loss=0.00505, valid_loss=0.00235]\n",
      "Epoch: 27/50: 100%|██████████| 36/36 [00:00<00:00, 118.30it/s, train_loss=0.00437, valid_loss=0.00242]\n",
      "Epoch: 28/50: 100%|██████████| 36/36 [00:00<00:00, 136.18it/s, train_loss=0.0044, valid_loss=0.00237] \n",
      "Epoch: 29/50: 100%|██████████| 36/36 [00:00<00:00, 134.71it/s, train_loss=0.00477, valid_loss=0.00247]\n",
      "Epoch: 30/50: 100%|██████████| 36/36 [00:00<00:00, 126.27it/s, train_loss=0.00446, valid_loss=0.00235]\n",
      "Epoch: 31/50: 100%|██████████| 36/36 [00:00<00:00, 117.75it/s, train_loss=0.00463, valid_loss=0.00242]\n",
      "Epoch: 32/50: 100%|██████████| 36/36 [00:00<00:00, 136.28it/s, train_loss=0.00421, valid_loss=0.00237]\n",
      "Epoch: 33/50: 100%|██████████| 36/36 [00:00<00:00, 135.79it/s, train_loss=0.00457, valid_loss=0.00235]\n",
      "Epoch: 34/50: 100%|██████████| 36/36 [00:00<00:00, 136.59it/s, train_loss=0.00494, valid_loss=0.00234]\n",
      "Epoch: 35/50: 100%|██████████| 36/36 [00:00<00:00, 119.38it/s, train_loss=0.00472, valid_loss=0.00229]\n",
      "Epoch: 36/50: 100%|██████████| 36/36 [00:00<00:00, 135.61it/s, train_loss=0.00474, valid_loss=0.00227]\n",
      "Epoch: 37/50: 100%|██████████| 36/36 [00:00<00:00, 136.45it/s, train_loss=0.0044, valid_loss=0.00227] \n",
      "Epoch: 38/50: 100%|██████████| 36/36 [00:00<00:00, 136.43it/s, train_loss=0.00487, valid_loss=0.00228]\n",
      "Epoch: 39/50: 100%|██████████| 36/36 [00:00<00:00, 118.50it/s, train_loss=0.00438, valid_loss=0.00243]\n",
      "Epoch: 40/50: 100%|██████████| 36/36 [00:00<00:00, 134.51it/s, train_loss=0.00405, valid_loss=0.00239]\n",
      "Epoch: 41/50: 100%|██████████| 36/36 [00:00<00:00, 136.54it/s, train_loss=0.00415, valid_loss=0.00232]\n",
      "Epoch: 42/50: 100%|██████████| 36/36 [00:00<00:00, 135.73it/s, train_loss=0.00426, valid_loss=0.00231]\n",
      "Epoch: 43/50: 100%|██████████| 36/36 [00:00<00:00, 116.03it/s, train_loss=0.00416, valid_loss=0.00233]\n",
      "Epoch: 44/50: 100%|██████████| 36/36 [00:00<00:00, 136.86it/s, train_loss=0.00441, valid_loss=0.00237]\n",
      "Epoch: 45/50: 100%|██████████| 36/36 [00:00<00:00, 135.54it/s, train_loss=0.00419, valid_loss=0.0024] \n",
      "Epoch: 46/50: 100%|██████████| 36/36 [00:00<00:00, 135.97it/s, train_loss=0.00423, valid_loss=0.00233]\n",
      "Epoch: 47/50: 100%|██████████| 36/36 [00:00<00:00, 114.20it/s, train_loss=0.00405, valid_loss=0.00224]\n",
      "Epoch: 48/50: 100%|██████████| 36/36 [00:00<00:00, 135.81it/s, train_loss=0.0042, valid_loss=0.00227] \n",
      "Epoch: 49/50: 100%|██████████| 36/36 [00:00<00:00, 136.02it/s, train_loss=0.00446, valid_loss=0.00232]\n",
      "Epoch: 50/50: 100%|██████████| 36/36 [00:00<00:00, 136.33it/s, train_loss=0.00461, valid_loss=0.00226]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config: batch_size--256, lr--0.005, number_epoch--50, hidden_dim--30,drop_prob-0.1,weight_decay-1e-07\n",
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 15/15 [00:00<00:00, 100.41it/s, train_loss=0.0337, valid_loss=0.05]\n",
      "Epoch: 2/50: 100%|██████████| 15/15 [00:00<00:00, 134.73it/s, train_loss=0.0224, valid_loss=0.0328]\n",
      "Epoch: 3/50: 100%|██████████| 15/15 [00:00<00:00, 101.86it/s, train_loss=0.014, valid_loss=0.0235]\n",
      "Epoch: 4/50: 100%|██████████| 15/15 [00:00<00:00, 129.93it/s, train_loss=0.0116, valid_loss=0.019]\n",
      "Epoch: 5/50: 100%|██████████| 15/15 [00:00<00:00, 127.80it/s, train_loss=0.0103, valid_loss=0.0157]\n",
      "Epoch: 6/50: 100%|██████████| 15/15 [00:00<00:00, 153.95it/s, train_loss=0.00629, valid_loss=0.00814]\n",
      "Epoch: 7/50: 100%|██████████| 15/15 [00:00<00:00, 134.65it/s, train_loss=0.0055, valid_loss=0.00739]\n",
      "Epoch: 8/50: 100%|██████████| 15/15 [00:00<00:00, 129.45it/s, train_loss=0.00454, valid_loss=0.00606]\n",
      "Epoch: 9/50: 100%|██████████| 15/15 [00:00<00:00, 122.60it/s, train_loss=0.0041, valid_loss=0.00521]\n",
      "Epoch: 10/50: 100%|██████████| 15/15 [00:00<00:00, 128.24it/s, train_loss=0.00366, valid_loss=0.00492]\n",
      "Epoch: 11/50: 100%|██████████| 15/15 [00:00<00:00, 127.22it/s, train_loss=0.00385, valid_loss=0.00463]\n",
      "Epoch: 12/50: 100%|██████████| 15/15 [00:00<00:00, 129.00it/s, train_loss=0.0034, valid_loss=0.00465]\n",
      "Epoch: 13/50: 100%|██████████| 15/15 [00:00<00:00, 128.54it/s, train_loss=0.00379, valid_loss=0.00469]\n",
      "Epoch: 14/50: 100%|██████████| 15/15 [00:00<00:00, 133.76it/s, train_loss=0.00336, valid_loss=0.00452]\n",
      "Epoch: 15/50: 100%|██████████| 15/15 [00:00<00:00, 156.62it/s, train_loss=0.00322, valid_loss=0.00454]\n",
      "Epoch: 16/50: 100%|██████████| 15/15 [00:00<00:00, 155.94it/s, train_loss=0.00307, valid_loss=0.00458]\n",
      "Epoch: 17/50: 100%|██████████| 15/15 [00:00<00:00, 113.39it/s, train_loss=0.00313, valid_loss=0.00453]\n",
      "Epoch: 18/50: 100%|██████████| 15/15 [00:00<00:00, 153.64it/s, train_loss=0.0034, valid_loss=0.00483]\n",
      "Epoch: 19/50: 100%|██████████| 15/15 [00:00<00:00, 136.00it/s, train_loss=0.00316, valid_loss=0.00477]\n",
      "Epoch: 20/50: 100%|██████████| 15/15 [00:00<00:00, 130.22it/s, train_loss=0.00307, valid_loss=0.00439]\n",
      "Epoch: 21/50: 100%|██████████| 15/15 [00:00<00:00, 154.94it/s, train_loss=0.00314, valid_loss=0.00454]\n",
      "Epoch: 22/50: 100%|██████████| 15/15 [00:00<00:00, 134.62it/s, train_loss=0.00296, valid_loss=0.00439]\n",
      "Epoch: 23/50: 100%|██████████| 15/15 [00:00<00:00, 155.93it/s, train_loss=0.00283, valid_loss=0.00443]\n",
      "Epoch: 24/50: 100%|██████████| 15/15 [00:00<00:00, 156.72it/s, train_loss=0.00274, valid_loss=0.0045]\n",
      "Epoch: 25/50: 100%|██████████| 15/15 [00:00<00:00, 132.66it/s, train_loss=0.00285, valid_loss=0.00464]\n",
      "Epoch: 26/50: 100%|██████████| 15/15 [00:00<00:00, 115.76it/s, train_loss=0.0033, valid_loss=0.00443]\n",
      "Epoch: 27/50: 100%|██████████| 15/15 [00:00<00:00, 128.89it/s, train_loss=0.00348, valid_loss=0.00437]\n",
      "Epoch: 28/50: 100%|██████████| 15/15 [00:00<00:00, 154.35it/s, train_loss=0.00293, valid_loss=0.00442]\n",
      "Epoch: 29/50: 100%|██████████| 15/15 [00:00<00:00, 156.06it/s, train_loss=0.00289, valid_loss=0.00436]\n",
      "Epoch: 30/50: 100%|██████████| 15/15 [00:00<00:00, 104.83it/s, train_loss=0.00286, valid_loss=0.00424]\n",
      "Epoch: 31/50: 100%|██████████| 15/15 [00:00<00:00, 125.97it/s, train_loss=0.00271, valid_loss=0.00449]\n",
      "Epoch: 32/50: 100%|██████████| 15/15 [00:00<00:00, 128.68it/s, train_loss=0.00287, valid_loss=0.00432]\n",
      "Epoch: 33/50: 100%|██████████| 15/15 [00:00<00:00, 157.11it/s, train_loss=0.00263, valid_loss=0.00442]\n",
      "Epoch: 34/50: 100%|██████████| 15/15 [00:00<00:00, 133.34it/s, train_loss=0.00296, valid_loss=0.00434]\n",
      "Epoch: 35/50: 100%|██████████| 15/15 [00:00<00:00, 128.06it/s, train_loss=0.00281, valid_loss=0.00438]\n",
      "Epoch: 36/50: 100%|██████████| 15/15 [00:00<00:00, 154.75it/s, train_loss=0.00322, valid_loss=0.00447]\n",
      "Epoch: 37/50: 100%|██████████| 15/15 [00:00<00:00, 116.63it/s, train_loss=0.00277, valid_loss=0.00443]\n",
      "Epoch: 38/50: 100%|██████████| 15/15 [00:00<00:00, 138.26it/s, train_loss=0.00283, valid_loss=0.00445]\n",
      "Epoch: 39/50: 100%|██████████| 15/15 [00:00<00:00, 155.66it/s, train_loss=0.00267, valid_loss=0.00442]\n",
      "Epoch: 40/50: 100%|██████████| 15/15 [00:00<00:00, 134.18it/s, train_loss=0.00265, valid_loss=0.00429]\n",
      "Epoch: 41/50: 100%|██████████| 15/15 [00:00<00:00, 156.95it/s, train_loss=0.00293, valid_loss=0.0046]\n",
      "Epoch: 42/50: 100%|██████████| 15/15 [00:00<00:00, 115.12it/s, train_loss=0.00298, valid_loss=0.00422]\n",
      "Epoch: 43/50: 100%|██████████| 15/15 [00:00<00:00, 114.55it/s, train_loss=0.0026, valid_loss=0.00462]\n",
      "Epoch: 44/50: 100%|██████████| 15/15 [00:00<00:00, 157.81it/s, train_loss=0.00263, valid_loss=0.0043]\n",
      "Epoch: 45/50: 100%|██████████| 15/15 [00:00<00:00, 156.95it/s, train_loss=0.0028, valid_loss=0.00461]\n",
      "Epoch: 46/50: 100%|██████████| 15/15 [00:00<00:00, 132.37it/s, train_loss=0.00302, valid_loss=0.0046]\n",
      "Epoch: 47/50: 100%|██████████| 15/15 [00:00<00:00, 157.62it/s, train_loss=0.00277, valid_loss=0.0043]\n",
      "Epoch: 48/50: 100%|██████████| 15/15 [00:00<00:00, 115.42it/s, train_loss=0.00266, valid_loss=0.00438]\n",
      "Epoch: 49/50: 100%|██████████| 15/15 [00:00<00:00, 157.37it/s, train_loss=0.00259, valid_loss=0.00448]\n",
      "Epoch: 50/50: 100%|██████████| 15/15 [00:00<00:00, 132.94it/s, train_loss=0.00268, valid_loss=0.00439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 29/29 [00:00<00:00, 110.55it/s, train_loss=0.0228, valid_loss=0.0214]\n",
      "Epoch: 2/50: 100%|██████████| 29/29 [00:00<00:00, 122.10it/s, train_loss=0.0112, valid_loss=0.00854]\n",
      "Epoch: 3/50: 100%|██████████| 29/29 [00:00<00:00, 117.62it/s, train_loss=0.00731, valid_loss=0.00641]\n",
      "Epoch: 4/50: 100%|██████████| 29/29 [00:00<00:00, 124.32it/s, train_loss=0.00648, valid_loss=0.00353]\n",
      "Epoch: 5/50: 100%|██████████| 29/29 [00:00<00:00, 143.70it/s, train_loss=0.00557, valid_loss=0.00303]\n",
      "Epoch: 6/50: 100%|██████████| 29/29 [00:00<00:00, 151.61it/s, train_loss=0.00552, valid_loss=0.00517]\n",
      "Epoch: 7/50: 100%|██████████| 29/29 [00:00<00:00, 133.35it/s, train_loss=0.00552, valid_loss=0.00252]\n",
      "Epoch: 8/50: 100%|██████████| 29/29 [00:00<00:00, 131.85it/s, train_loss=0.00513, valid_loss=0.00196]\n",
      "Epoch: 9/50: 100%|██████████| 29/29 [00:00<00:00, 139.63it/s, train_loss=0.00536, valid_loss=0.00306]\n",
      "Epoch: 10/50: 100%|██████████| 29/29 [00:00<00:00, 105.50it/s, train_loss=0.00548, valid_loss=0.0023]\n",
      "Epoch: 11/50: 100%|██████████| 29/29 [00:00<00:00, 147.54it/s, train_loss=0.00624, valid_loss=0.00257]\n",
      "Epoch: 12/50: 100%|██████████| 29/29 [00:00<00:00, 130.33it/s, train_loss=0.00477, valid_loss=0.00241]\n",
      "Epoch: 13/50: 100%|██████████| 29/29 [00:00<00:00, 136.61it/s, train_loss=0.00419, valid_loss=0.00239]\n",
      "Epoch: 14/50: 100%|██████████| 29/29 [00:00<00:00, 124.12it/s, train_loss=0.00455, valid_loss=0.00239]\n",
      "Epoch: 15/50: 100%|██████████| 29/29 [00:00<00:00, 147.22it/s, train_loss=0.00507, valid_loss=0.00275]\n",
      "Epoch: 16/50: 100%|██████████| 29/29 [00:00<00:00, 107.50it/s, train_loss=0.00457, valid_loss=0.00247]\n",
      "Epoch: 17/50: 100%|██████████| 29/29 [00:00<00:00, 128.46it/s, train_loss=0.00502, valid_loss=0.00388]\n",
      "Epoch: 18/50: 100%|██████████| 29/29 [00:00<00:00, 129.24it/s, train_loss=0.00448, valid_loss=0.00193]\n",
      "Epoch: 19/50: 100%|██████████| 29/29 [00:00<00:00, 129.29it/s, train_loss=0.00486, valid_loss=0.00208]\n",
      "Epoch: 20/50: 100%|██████████| 29/29 [00:00<00:00, 151.08it/s, train_loss=0.00354, valid_loss=0.00204]\n",
      "Epoch: 21/50: 100%|██████████| 29/29 [00:00<00:00, 150.08it/s, train_loss=0.00352, valid_loss=0.00182]\n",
      "Epoch: 22/50: 100%|██████████| 29/29 [00:00<00:00, 140.72it/s, train_loss=0.00474, valid_loss=0.00193]\n",
      "Epoch: 23/50: 100%|██████████| 29/29 [00:00<00:00, 116.15it/s, train_loss=0.00409, valid_loss=0.00205]\n",
      "Epoch: 24/50: 100%|██████████| 29/29 [00:00<00:00, 124.35it/s, train_loss=0.00448, valid_loss=0.00365]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 44/44 [00:00<00:00, 125.33it/s, train_loss=0.0157, valid_loss=0.0218]\n",
      "Epoch: 2/50: 100%|██████████| 44/44 [00:00<00:00, 145.83it/s, train_loss=0.0109, valid_loss=0.012] \n",
      "Epoch: 3/50: 100%|██████████| 44/44 [00:00<00:00, 149.63it/s, train_loss=0.00827, valid_loss=0.00631]\n",
      "Epoch: 4/50: 100%|██████████| 44/44 [00:00<00:00, 122.38it/s, train_loss=0.00624, valid_loss=0.0054] \n",
      "Epoch: 5/50: 100%|██████████| 44/44 [00:00<00:00, 133.17it/s, train_loss=0.00614, valid_loss=0.00462]\n",
      "Epoch: 6/50: 100%|██████████| 44/44 [00:00<00:00, 136.40it/s, train_loss=0.00574, valid_loss=0.00421]\n",
      "Epoch: 7/50: 100%|██████████| 44/44 [00:00<00:00, 139.14it/s, train_loss=0.00519, valid_loss=0.00402]\n",
      "Epoch: 8/50: 100%|██████████| 44/44 [00:00<00:00, 118.92it/s, train_loss=0.00479, valid_loss=0.00449]\n",
      "Epoch: 9/50: 100%|██████████| 44/44 [00:00<00:00, 133.77it/s, train_loss=0.00508, valid_loss=0.00379]\n",
      "Epoch: 10/50: 100%|██████████| 44/44 [00:00<00:00, 144.35it/s, train_loss=0.00457, valid_loss=0.00395]\n",
      "Epoch: 11/50: 100%|██████████| 44/44 [00:00<00:00, 144.12it/s, train_loss=0.00456, valid_loss=0.00388]\n",
      "Epoch: 12/50: 100%|██████████| 44/44 [00:00<00:00, 132.00it/s, train_loss=0.00444, valid_loss=0.00373]\n",
      "Epoch: 13/50: 100%|██████████| 44/44 [00:00<00:00, 129.44it/s, train_loss=0.00457, valid_loss=0.00365]\n",
      "Epoch: 14/50: 100%|██████████| 44/44 [00:00<00:00, 153.47it/s, train_loss=0.00479, valid_loss=0.00371]\n",
      "Epoch: 15/50: 100%|██████████| 44/44 [00:00<00:00, 144.53it/s, train_loss=0.00413, valid_loss=0.00399]\n",
      "Epoch: 16/50: 100%|██████████| 44/44 [00:00<00:00, 153.52it/s, train_loss=0.00376, valid_loss=0.00379]\n",
      "Epoch: 17/50: 100%|██████████| 44/44 [00:00<00:00, 136.37it/s, train_loss=0.0044, valid_loss=0.00363] \n",
      "Epoch: 18/50: 100%|██████████| 44/44 [00:00<00:00, 152.88it/s, train_loss=0.00455, valid_loss=0.00396]\n",
      "Epoch: 19/50: 100%|██████████| 44/44 [00:00<00:00, 153.51it/s, train_loss=0.0046, valid_loss=0.00354] \n",
      "Epoch: 20/50: 100%|██████████| 44/44 [00:00<00:00, 153.42it/s, train_loss=0.00366, valid_loss=0.0036] \n",
      "Epoch: 21/50: 100%|██████████| 44/44 [00:00<00:00, 135.39it/s, train_loss=0.00358, valid_loss=0.00351]\n",
      "Epoch: 22/50: 100%|██████████| 44/44 [00:00<00:00, 153.00it/s, train_loss=0.00383, valid_loss=0.00368]\n",
      "Epoch: 23/50: 100%|██████████| 44/44 [00:00<00:00, 153.48it/s, train_loss=0.0035, valid_loss=0.00369] \n",
      "Epoch: 24/50: 100%|██████████| 44/44 [00:00<00:00, 153.36it/s, train_loss=0.00389, valid_loss=0.00346]\n",
      "Epoch: 25/50: 100%|██████████| 44/44 [00:00<00:00, 152.50it/s, train_loss=0.0038, valid_loss=0.00345] \n",
      "Epoch: 26/50: 100%|██████████| 44/44 [00:00<00:00, 136.69it/s, train_loss=0.00391, valid_loss=0.00347]\n",
      "Epoch: 27/50: 100%|██████████| 44/44 [00:00<00:00, 153.79it/s, train_loss=0.00416, valid_loss=0.00371]\n",
      "Epoch: 28/50: 100%|██████████| 44/44 [00:00<00:00, 152.67it/s, train_loss=0.0041, valid_loss=0.00353] \n",
      "Epoch: 29/50: 100%|██████████| 44/44 [00:00<00:00, 152.58it/s, train_loss=0.00402, valid_loss=0.00367]\n",
      "Epoch: 30/50: 100%|██████████| 44/44 [00:00<00:00, 136.00it/s, train_loss=0.00387, valid_loss=0.00357]\n",
      "Epoch: 31/50: 100%|██████████| 44/44 [00:00<00:00, 153.01it/s, train_loss=0.00396, valid_loss=0.00367]\n",
      "Epoch: 32/50: 100%|██████████| 44/44 [00:00<00:00, 153.30it/s, train_loss=0.00402, valid_loss=0.00341]\n",
      "Epoch: 33/50: 100%|██████████| 44/44 [00:00<00:00, 153.07it/s, train_loss=0.00393, valid_loss=0.00354]\n",
      "Epoch: 34/50: 100%|██████████| 44/44 [00:00<00:00, 144.47it/s, train_loss=0.00342, valid_loss=0.00342]\n",
      "Epoch: 35/50: 100%|██████████| 44/44 [00:00<00:00, 135.08it/s, train_loss=0.00393, valid_loss=0.0038] \n",
      "Epoch: 36/50: 100%|██████████| 44/44 [00:00<00:00, 152.98it/s, train_loss=0.00342, valid_loss=0.00397]\n",
      "Epoch: 37/50: 100%|██████████| 44/44 [00:00<00:00, 152.42it/s, train_loss=0.00405, valid_loss=0.00385]\n",
      "Epoch: 38/50: 100%|██████████| 44/44 [00:00<00:00, 153.28it/s, train_loss=0.00433, valid_loss=0.00372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 58/58 [00:00<00:00, 121.84it/s, train_loss=0.0351, valid_loss=0.0384]\n",
      "Epoch: 2/50: 100%|██████████| 58/58 [00:00<00:00, 152.20it/s, train_loss=0.0139, valid_loss=0.0136]\n",
      "Epoch: 3/50: 100%|██████████| 58/58 [00:00<00:00, 153.48it/s, train_loss=0.0126, valid_loss=0.00958]\n",
      "Epoch: 4/50: 100%|██████████| 58/58 [00:00<00:00, 138.39it/s, train_loss=0.00574, valid_loss=0.00342]\n",
      "Epoch: 5/50: 100%|██████████| 58/58 [00:00<00:00, 153.06it/s, train_loss=0.0049, valid_loss=0.00218] \n",
      "Epoch: 6/50: 100%|██████████| 58/58 [00:00<00:00, 153.12it/s, train_loss=0.00515, valid_loss=0.00212]\n",
      "Epoch: 7/50: 100%|██████████| 58/58 [00:00<00:00, 151.91it/s, train_loss=0.00581, valid_loss=0.00206]\n",
      "Epoch: 8/50: 100%|██████████| 58/58 [00:00<00:00, 137.75it/s, train_loss=0.00459, valid_loss=0.0021] \n",
      "Epoch: 9/50: 100%|██████████| 58/58 [00:00<00:00, 150.92it/s, train_loss=0.00404, valid_loss=0.00246]\n",
      "Epoch: 10/50: 100%|██████████| 58/58 [00:00<00:00, 153.11it/s, train_loss=0.00435, valid_loss=0.00175]\n",
      "Epoch: 11/50: 100%|██████████| 58/58 [00:00<00:00, 138.85it/s, train_loss=0.0045, valid_loss=0.00192] \n",
      "Epoch: 12/50: 100%|██████████| 58/58 [00:00<00:00, 152.08it/s, train_loss=0.00438, valid_loss=0.00224]\n",
      "Epoch: 13/50: 100%|██████████| 58/58 [00:00<00:00, 153.20it/s, train_loss=0.0039, valid_loss=0.0033]  \n",
      "Epoch: 14/50: 100%|██████████| 58/58 [00:00<00:00, 139.43it/s, train_loss=0.0042, valid_loss=0.00258] \n",
      "Epoch: 15/50: 100%|██████████| 58/58 [00:00<00:00, 153.05it/s, train_loss=0.0042, valid_loss=0.00238] \n",
      "Epoch: 16/50: 100%|██████████| 58/58 [00:00<00:00, 152.94it/s, train_loss=0.00337, valid_loss=0.0025] \n",
      "Epoch: 17/50: 100%|██████████| 58/58 [00:00<00:00, 152.73it/s, train_loss=0.00405, valid_loss=0.00262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 72/72 [00:00<00:00, 112.86it/s, train_loss=0.0266, valid_loss=0.0204]\n",
      "Epoch: 2/50: 100%|██████████| 72/72 [00:00<00:00, 133.29it/s, train_loss=0.0077, valid_loss=0.00556]\n",
      "Epoch: 3/50: 100%|██████████| 72/72 [00:00<00:00, 131.60it/s, train_loss=0.00607, valid_loss=0.00309]\n",
      "Epoch: 4/50: 100%|██████████| 72/72 [00:00<00:00, 136.48it/s, train_loss=0.00583, valid_loss=0.00279]\n",
      "Epoch: 5/50: 100%|██████████| 72/72 [00:00<00:00, 129.78it/s, train_loss=0.00552, valid_loss=0.00291]\n",
      "Epoch: 6/50: 100%|██████████| 72/72 [00:00<00:00, 123.38it/s, train_loss=0.00537, valid_loss=0.00254]\n",
      "Epoch: 7/50: 100%|██████████| 72/72 [00:00<00:00, 128.46it/s, train_loss=0.0051, valid_loss=0.00258] \n",
      "Epoch: 8/50: 100%|██████████| 72/72 [00:00<00:00, 124.25it/s, train_loss=0.00502, valid_loss=0.00264]\n",
      "Epoch: 9/50: 100%|██████████| 72/72 [00:00<00:00, 128.87it/s, train_loss=0.00497, valid_loss=0.00254]\n",
      "Epoch: 10/50: 100%|██████████| 72/72 [00:00<00:00, 136.94it/s, train_loss=0.00418, valid_loss=0.00254]\n",
      "Epoch: 11/50: 100%|██████████| 72/72 [00:00<00:00, 127.09it/s, train_loss=0.00437, valid_loss=0.00242]\n",
      "Epoch: 12/50: 100%|██████████| 72/72 [00:00<00:00, 145.54it/s, train_loss=0.00443, valid_loss=0.00232]\n",
      "Epoch: 13/50: 100%|██████████| 72/72 [00:00<00:00, 131.05it/s, train_loss=0.00461, valid_loss=0.00245]\n",
      "Epoch: 14/50: 100%|██████████| 72/72 [00:00<00:00, 130.49it/s, train_loss=0.00448, valid_loss=0.00239]\n",
      "Epoch: 15/50: 100%|██████████| 72/72 [00:00<00:00, 133.63it/s, train_loss=0.00396, valid_loss=0.00274]\n",
      "Epoch: 16/50: 100%|██████████| 72/72 [00:00<00:00, 126.39it/s, train_loss=0.00404, valid_loss=0.00227]\n",
      "Epoch: 17/50: 100%|██████████| 72/72 [00:00<00:00, 126.07it/s, train_loss=0.00417, valid_loss=0.00266]\n",
      "Epoch: 18/50: 100%|██████████| 72/72 [00:00<00:00, 140.64it/s, train_loss=0.00409, valid_loss=0.00246]\n",
      "Epoch: 19/50: 100%|██████████| 72/72 [00:00<00:00, 127.34it/s, train_loss=0.00384, valid_loss=0.00248]\n",
      "Epoch: 20/50: 100%|██████████| 72/72 [00:00<00:00, 134.87it/s, train_loss=0.0041, valid_loss=0.00278] \n",
      "Epoch: 21/50: 100%|██████████| 72/72 [00:00<00:00, 137.31it/s, train_loss=0.00382, valid_loss=0.00241]\n",
      "Epoch: 22/50: 100%|██████████| 72/72 [00:00<00:00, 126.76it/s, train_loss=0.00487, valid_loss=0.00254]\n",
      "Epoch: 23/50: 100%|██████████| 72/72 [00:00<00:00, 137.00it/s, train_loss=0.00414, valid_loss=0.00252]\n",
      "Epoch: 24/50: 100%|██████████| 72/72 [00:00<00:00, 124.07it/s, train_loss=0.00372, valid_loss=0.00259]\n",
      "Epoch: 25/50: 100%|██████████| 72/72 [00:00<00:00, 138.02it/s, train_loss=0.00388, valid_loss=0.0024] \n",
      "Epoch: 26/50: 100%|██████████| 72/72 [00:00<00:00, 139.86it/s, train_loss=0.00338, valid_loss=0.00229]\n",
      "Epoch: 27/50: 100%|██████████| 72/72 [00:00<00:00, 130.71it/s, train_loss=0.00341, valid_loss=0.00252]\n",
      "Epoch: 28/50: 100%|██████████| 72/72 [00:00<00:00, 127.44it/s, train_loss=0.00361, valid_loss=0.00251]\n",
      "Epoch: 29/50: 100%|██████████| 72/72 [00:00<00:00, 132.64it/s, train_loss=0.00345, valid_loss=0.00245]\n",
      "Epoch: 30/50: 100%|██████████| 72/72 [00:00<00:00, 124.63it/s, train_loss=0.00322, valid_loss=0.00257]\n",
      "Epoch: 31/50: 100%|██████████| 72/72 [00:00<00:00, 142.42it/s, train_loss=0.00388, valid_loss=0.00244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config: batch_size--256, lr--0.005, number_epoch--50, hidden_dim--25,drop_prob-0.1,weight_decay-1e-07\n",
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 15/15 [00:00<00:00, 93.11it/s, train_loss=0.0321, valid_loss=0.0432]\n",
      "Epoch: 2/50: 100%|██████████| 15/15 [00:00<00:00, 147.66it/s, train_loss=0.0196, valid_loss=0.0306]\n",
      "Epoch: 3/50: 100%|██████████| 15/15 [00:00<00:00, 153.46it/s, train_loss=0.0151, valid_loss=0.0264]\n",
      "Epoch: 4/50: 100%|██████████| 15/15 [00:00<00:00, 84.12it/s, train_loss=0.0125, valid_loss=0.0214]\n",
      "Epoch: 5/50: 100%|██████████| 15/15 [00:00<00:00, 131.71it/s, train_loss=0.0115, valid_loss=0.02]\n",
      "Epoch: 6/50: 100%|██████████| 15/15 [00:00<00:00, 154.80it/s, train_loss=0.0109, valid_loss=0.0161]\n",
      "Epoch: 7/50: 100%|██████████| 15/15 [00:00<00:00, 126.35it/s, train_loss=0.00906, valid_loss=0.0138]\n",
      "Epoch: 8/50: 100%|██████████| 15/15 [00:00<00:00, 154.59it/s, train_loss=0.00923, valid_loss=0.013]\n",
      "Epoch: 9/50: 100%|██████████| 15/15 [00:00<00:00, 128.61it/s, train_loss=0.00814, valid_loss=0.0128]\n",
      "Epoch: 10/50: 100%|██████████| 15/15 [00:00<00:00, 154.12it/s, train_loss=0.00878, valid_loss=0.012]\n",
      "Epoch: 11/50: 100%|██████████| 15/15 [00:00<00:00, 114.41it/s, train_loss=0.00773, valid_loss=0.0118]\n",
      "Epoch: 12/50: 100%|██████████| 15/15 [00:00<00:00, 128.43it/s, train_loss=0.00762, valid_loss=0.0122]\n",
      "Epoch: 13/50: 100%|██████████| 15/15 [00:00<00:00, 154.41it/s, train_loss=0.00803, valid_loss=0.0118]\n",
      "Epoch: 14/50: 100%|██████████| 15/15 [00:00<00:00, 151.33it/s, train_loss=0.00804, valid_loss=0.0115]\n",
      "Epoch: 15/50: 100%|██████████| 15/15 [00:00<00:00, 115.71it/s, train_loss=0.00779, valid_loss=0.0118]\n",
      "Epoch: 16/50: 100%|██████████| 15/15 [00:00<00:00, 155.31it/s, train_loss=0.00808, valid_loss=0.0112]\n",
      "Epoch: 17/50: 100%|██████████| 15/15 [00:00<00:00, 110.78it/s, train_loss=0.00756, valid_loss=0.0115]\n",
      "Epoch: 18/50: 100%|██████████| 15/15 [00:00<00:00, 132.20it/s, train_loss=0.00817, valid_loss=0.0116]\n",
      "Epoch: 19/50: 100%|██████████| 15/15 [00:00<00:00, 155.00it/s, train_loss=0.00754, valid_loss=0.0116]\n",
      "Epoch: 20/50: 100%|██████████| 15/15 [00:00<00:00, 153.32it/s, train_loss=0.00784, valid_loss=0.0115]\n",
      "Epoch: 21/50: 100%|██████████| 15/15 [00:00<00:00, 114.98it/s, train_loss=0.00765, valid_loss=0.0112]\n",
      "Epoch: 22/50: 100%|██████████| 15/15 [00:00<00:00, 128.25it/s, train_loss=0.00762, valid_loss=0.0112]\n",
      "Epoch: 23/50: 100%|██████████| 15/15 [00:00<00:00, 153.95it/s, train_loss=0.00735, valid_loss=0.0113]\n",
      "Epoch: 24/50: 100%|██████████| 15/15 [00:00<00:00, 155.94it/s, train_loss=0.00744, valid_loss=0.0116]\n",
      "Epoch: 25/50: 100%|██████████| 15/15 [00:00<00:00, 132.02it/s, train_loss=0.00762, valid_loss=0.0114]\n",
      "Epoch: 26/50: 100%|██████████| 15/15 [00:00<00:00, 117.82it/s, train_loss=0.00741, valid_loss=0.0114]\n",
      "Epoch: 27/50: 100%|██████████| 15/15 [00:00<00:00, 131.80it/s, train_loss=0.00803, valid_loss=0.0112]\n",
      "Epoch: 28/50: 100%|██████████| 15/15 [00:00<00:00, 153.80it/s, train_loss=0.00728, valid_loss=0.0114]\n",
      "Epoch: 29/50: 100%|██████████| 15/15 [00:00<00:00, 152.88it/s, train_loss=0.0071, valid_loss=0.0111]\n",
      "Epoch: 30/50: 100%|██████████| 15/15 [00:00<00:00, 101.88it/s, train_loss=0.00757, valid_loss=0.0111]\n",
      "Epoch: 31/50: 100%|██████████| 15/15 [00:00<00:00, 132.91it/s, train_loss=0.00675, valid_loss=0.0111]\n",
      "Epoch: 32/50: 100%|██████████| 15/15 [00:00<00:00, 156.21it/s, train_loss=0.00758, valid_loss=0.011]\n",
      "Epoch: 33/50: 100%|██████████| 15/15 [00:00<00:00, 115.44it/s, train_loss=0.00697, valid_loss=0.0113]\n",
      "Epoch: 34/50: 100%|██████████| 15/15 [00:00<00:00, 128.55it/s, train_loss=0.00685, valid_loss=0.0111]\n",
      "Epoch: 35/50: 100%|██████████| 15/15 [00:00<00:00, 128.75it/s, train_loss=0.00727, valid_loss=0.0111]\n",
      "Epoch: 36/50: 100%|██████████| 15/15 [00:00<00:00, 153.13it/s, train_loss=0.007, valid_loss=0.0109]\n",
      "Epoch: 37/50: 100%|██████████| 15/15 [00:00<00:00, 154.88it/s, train_loss=0.00721, valid_loss=0.0112]\n",
      "Epoch: 38/50: 100%|██████████| 15/15 [00:00<00:00, 145.45it/s, train_loss=0.00709, valid_loss=0.011]\n",
      "Epoch: 39/50: 100%|██████████| 15/15 [00:00<00:00, 119.89it/s, train_loss=0.00729, valid_loss=0.0111]\n",
      "Epoch: 40/50: 100%|██████████| 15/15 [00:00<00:00, 107.80it/s, train_loss=0.00727, valid_loss=0.0108]\n",
      "Epoch: 41/50: 100%|██████████| 15/15 [00:00<00:00, 139.88it/s, train_loss=0.00678, valid_loss=0.0109]\n",
      "Epoch: 42/50: 100%|██████████| 15/15 [00:00<00:00, 155.16it/s, train_loss=0.00677, valid_loss=0.011]\n",
      "Epoch: 43/50: 100%|██████████| 15/15 [00:00<00:00, 86.99it/s, train_loss=0.00742, valid_loss=0.0109]\n",
      "Epoch: 44/50: 100%|██████████| 15/15 [00:00<00:00, 154.47it/s, train_loss=0.00657, valid_loss=0.011]\n",
      "Epoch: 45/50: 100%|██████████| 15/15 [00:00<00:00, 127.66it/s, train_loss=0.00665, valid_loss=0.011]\n",
      "Epoch: 46/50: 100%|██████████| 15/15 [00:00<00:00, 155.31it/s, train_loss=0.00705, valid_loss=0.0114]\n",
      "Epoch: 47/50: 100%|██████████| 15/15 [00:00<00:00, 155.48it/s, train_loss=0.00697, valid_loss=0.0111]\n",
      "Epoch: 48/50: 100%|██████████| 15/15 [00:00<00:00, 153.03it/s, train_loss=0.00711, valid_loss=0.0111]\n",
      "Epoch: 49/50: 100%|██████████| 15/15 [00:00<00:00, 155.52it/s, train_loss=0.00702, valid_loss=0.0113]\n",
      "Epoch: 50/50: 100%|██████████| 15/15 [00:00<00:00, 154.05it/s, train_loss=0.00704, valid_loss=0.0113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 15/15 [00:00<00:00, 102.50it/s, train_loss=0.0436, valid_loss=0.0596]\n",
      "Epoch: 2/50: 100%|██████████| 15/15 [00:00<00:00, 128.25it/s, train_loss=0.033, valid_loss=0.0491]\n",
      "Epoch: 3/50: 100%|██████████| 15/15 [00:00<00:00, 155.04it/s, train_loss=0.0241, valid_loss=0.0375]\n",
      "Epoch: 4/50: 100%|██████████| 15/15 [00:00<00:00, 157.02it/s, train_loss=0.0207, valid_loss=0.0342]\n",
      "Epoch: 5/50: 100%|██████████| 15/15 [00:00<00:00, 158.16it/s, train_loss=0.0165, valid_loss=0.0234]\n",
      "Epoch: 6/50: 100%|██████████| 15/15 [00:00<00:00, 110.36it/s, train_loss=0.0145, valid_loss=0.0203]\n",
      "Epoch: 7/50: 100%|██████████| 15/15 [00:00<00:00, 153.79it/s, train_loss=0.0139, valid_loss=0.0191]\n",
      "Epoch: 8/50: 100%|██████████| 15/15 [00:00<00:00, 128.72it/s, train_loss=0.0139, valid_loss=0.0185]\n",
      "Epoch: 9/50: 100%|██████████| 15/15 [00:00<00:00, 156.94it/s, train_loss=0.0135, valid_loss=0.0184]\n",
      "Epoch: 10/50: 100%|██████████| 15/15 [00:00<00:00, 157.48it/s, train_loss=0.0121, valid_loss=0.0164]\n",
      "Epoch: 11/50: 100%|██████████| 15/15 [00:00<00:00, 154.23it/s, train_loss=0.00909, valid_loss=0.0128]\n",
      "Epoch: 12/50: 100%|██████████| 15/15 [00:00<00:00, 155.75it/s, train_loss=0.00863, valid_loss=0.0122]\n",
      "Epoch: 13/50: 100%|██████████| 15/15 [00:00<00:00, 157.41it/s, train_loss=0.00762, valid_loss=0.0115]\n",
      "Epoch: 14/50: 100%|██████████| 15/15 [00:00<00:00, 155.67it/s, train_loss=0.00794, valid_loss=0.0113]\n",
      "Epoch: 15/50: 100%|██████████| 15/15 [00:00<00:00, 154.14it/s, train_loss=0.00762, valid_loss=0.0115]\n",
      "Epoch: 16/50: 100%|██████████| 15/15 [00:00<00:00, 153.58it/s, train_loss=0.00787, valid_loss=0.0113]\n",
      "Epoch: 17/50: 100%|██████████| 15/15 [00:00<00:00, 155.96it/s, train_loss=0.00746, valid_loss=0.0112]\n",
      "Epoch: 18/50: 100%|██████████| 15/15 [00:00<00:00, 157.11it/s, train_loss=0.00763, valid_loss=0.0111]\n",
      "Epoch: 19/50: 100%|██████████| 15/15 [00:00<00:00, 157.64it/s, train_loss=0.00753, valid_loss=0.0113]\n",
      "Epoch: 20/50: 100%|██████████| 15/15 [00:00<00:00, 112.58it/s, train_loss=0.00718, valid_loss=0.0111]\n",
      "Epoch: 21/50: 100%|██████████| 15/15 [00:00<00:00, 156.31it/s, train_loss=0.00719, valid_loss=0.0113]\n",
      "Epoch: 22/50: 100%|██████████| 15/15 [00:00<00:00, 155.77it/s, train_loss=0.00737, valid_loss=0.011]\n",
      "Epoch: 23/50: 100%|██████████| 15/15 [00:00<00:00, 155.58it/s, train_loss=0.00765, valid_loss=0.0112]\n",
      "Epoch: 24/50: 100%|██████████| 15/15 [00:00<00:00, 156.63it/s, train_loss=0.00744, valid_loss=0.011]\n",
      "Epoch: 25/50: 100%|██████████| 15/15 [00:00<00:00, 146.14it/s, train_loss=0.00731, valid_loss=0.0111]\n",
      "Epoch: 26/50: 100%|██████████| 15/15 [00:00<00:00, 135.64it/s, train_loss=0.00763, valid_loss=0.0111]\n",
      "Epoch: 27/50: 100%|██████████| 15/15 [00:00<00:00, 155.38it/s, train_loss=0.00703, valid_loss=0.0109]\n",
      "Epoch: 28/50: 100%|██████████| 15/15 [00:00<00:00, 155.71it/s, train_loss=0.00729, valid_loss=0.0112]\n",
      "Epoch: 29/50: 100%|██████████| 15/15 [00:00<00:00, 156.39it/s, train_loss=0.00758, valid_loss=0.0109]\n",
      "Epoch: 30/50: 100%|██████████| 15/15 [00:00<00:00, 157.03it/s, train_loss=0.0074, valid_loss=0.011]\n",
      "Epoch: 31/50: 100%|██████████| 15/15 [00:00<00:00, 154.76it/s, train_loss=0.00736, valid_loss=0.0115]\n",
      "Epoch: 32/50: 100%|██████████| 15/15 [00:00<00:00, 155.25it/s, train_loss=0.00774, valid_loss=0.0112]\n",
      "Epoch: 33/50: 100%|██████████| 15/15 [00:00<00:00, 112.35it/s, train_loss=0.00746, valid_loss=0.0111]\n",
      "Epoch: 34/50: 100%|██████████| 15/15 [00:00<00:00, 145.29it/s, train_loss=0.00725, valid_loss=0.0109]\n",
      "Epoch: 35/50: 100%|██████████| 15/15 [00:00<00:00, 138.22it/s, train_loss=0.00681, valid_loss=0.0109]\n",
      "Epoch: 36/50: 100%|██████████| 15/15 [00:00<00:00, 128.98it/s, train_loss=0.0072, valid_loss=0.0108]\n",
      "Epoch: 37/50: 100%|██████████| 15/15 [00:00<00:00, 155.52it/s, train_loss=0.00704, valid_loss=0.011]\n",
      "Epoch: 38/50: 100%|██████████| 15/15 [00:00<00:00, 156.92it/s, train_loss=0.00686, valid_loss=0.0112]\n",
      "Epoch: 39/50: 100%|██████████| 15/15 [00:00<00:00, 154.90it/s, train_loss=0.00735, valid_loss=0.0109]\n",
      "Epoch: 40/50: 100%|██████████| 15/15 [00:00<00:00, 154.70it/s, train_loss=0.00717, valid_loss=0.011]\n",
      "Epoch: 41/50: 100%|██████████| 15/15 [00:00<00:00, 155.91it/s, train_loss=0.00697, valid_loss=0.0109]\n",
      "Epoch: 42/50: 100%|██████████| 15/15 [00:00<00:00, 155.61it/s, train_loss=0.00723, valid_loss=0.0108]\n",
      "Epoch: 43/50: 100%|██████████| 15/15 [00:00<00:00, 155.59it/s, train_loss=0.00712, valid_loss=0.011]\n",
      "Epoch: 44/50: 100%|██████████| 15/15 [00:00<00:00, 154.74it/s, train_loss=0.00724, valid_loss=0.0109]\n",
      "Epoch: 45/50: 100%|██████████| 15/15 [00:00<00:00, 156.16it/s, train_loss=0.00737, valid_loss=0.011]\n",
      "Epoch: 46/50: 100%|██████████| 15/15 [00:00<00:00, 104.24it/s, train_loss=0.00668, valid_loss=0.0109]\n",
      "Epoch: 47/50: 100%|██████████| 15/15 [00:00<00:00, 154.91it/s, train_loss=0.00689, valid_loss=0.011]\n",
      "Epoch: 48/50: 100%|██████████| 15/15 [00:00<00:00, 155.32it/s, train_loss=0.00662, valid_loss=0.0111]\n",
      "Epoch: 49/50: 100%|██████████| 15/15 [00:00<00:00, 155.01it/s, train_loss=0.00673, valid_loss=0.0108]\n",
      "Epoch: 50/50: 100%|██████████| 15/15 [00:00<00:00, 155.57it/s, train_loss=0.00642, valid_loss=0.0111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 15/15 [00:00<00:00, 101.47it/s, train_loss=0.0316, valid_loss=0.05]\n",
      "Epoch: 2/50: 100%|██████████| 15/15 [00:00<00:00, 146.38it/s, train_loss=0.0235, valid_loss=0.0374]\n",
      "Epoch: 3/50: 100%|██████████| 15/15 [00:00<00:00, 155.04it/s, train_loss=0.0199, valid_loss=0.032]\n",
      "Epoch: 4/50: 100%|██████████| 15/15 [00:00<00:00, 156.49it/s, train_loss=0.018, valid_loss=0.0293]\n",
      "Epoch: 5/50: 100%|██████████| 15/15 [00:00<00:00, 157.87it/s, train_loss=0.016, valid_loss=0.0254]\n",
      "Epoch: 6/50: 100%|██████████| 15/15 [00:00<00:00, 155.61it/s, train_loss=0.0136, valid_loss=0.0183]\n",
      "Epoch: 7/50: 100%|██████████| 15/15 [00:00<00:00, 153.85it/s, train_loss=0.0113, valid_loss=0.015]\n",
      "Epoch: 8/50: 100%|██████████| 15/15 [00:00<00:00, 153.77it/s, train_loss=0.0101, valid_loss=0.0136]\n",
      "Epoch: 9/50: 100%|██████████| 15/15 [00:00<00:00, 109.21it/s, train_loss=0.00975, valid_loss=0.013]\n",
      "Epoch: 10/50: 100%|██████████| 15/15 [00:00<00:00, 157.44it/s, train_loss=0.00971, valid_loss=0.0125]\n",
      "Epoch: 11/50: 100%|██████████| 15/15 [00:00<00:00, 155.35it/s, train_loss=0.00934, valid_loss=0.0123]\n",
      "Epoch: 12/50: 100%|██████████| 15/15 [00:00<00:00, 128.62it/s, train_loss=0.0087, valid_loss=0.0121]\n",
      "Epoch: 13/50: 100%|██████████| 15/15 [00:00<00:00, 155.22it/s, train_loss=0.00878, valid_loss=0.0117]\n",
      "Epoch: 14/50: 100%|██████████| 15/15 [00:00<00:00, 158.23it/s, train_loss=0.00831, valid_loss=0.0113]\n",
      "Epoch: 15/50: 100%|██████████| 15/15 [00:00<00:00, 156.83it/s, train_loss=0.00804, valid_loss=0.0108]\n",
      "Epoch: 16/50: 100%|██████████| 15/15 [00:00<00:00, 150.92it/s, train_loss=0.00414, valid_loss=0.00547]\n",
      "Epoch: 17/50: 100%|██████████| 15/15 [00:00<00:00, 154.69it/s, train_loss=0.00427, valid_loss=0.0054]\n",
      "Epoch: 18/50: 100%|██████████| 15/15 [00:00<00:00, 156.28it/s, train_loss=0.00398, valid_loss=0.00482]\n",
      "Epoch: 19/50: 100%|██████████| 15/15 [00:00<00:00, 158.59it/s, train_loss=0.00337, valid_loss=0.00462]\n",
      "Epoch: 20/50: 100%|██████████| 15/15 [00:00<00:00, 157.87it/s, train_loss=0.00331, valid_loss=0.00534]\n",
      "Epoch: 21/50: 100%|██████████| 15/15 [00:00<00:00, 156.00it/s, train_loss=0.00371, valid_loss=0.00434]\n",
      "Epoch: 22/50: 100%|██████████| 15/15 [00:00<00:00, 113.78it/s, train_loss=0.00316, valid_loss=0.0045]\n",
      "Epoch: 23/50: 100%|██████████| 15/15 [00:00<00:00, 154.43it/s, train_loss=0.00335, valid_loss=0.00443]\n",
      "Epoch: 24/50: 100%|██████████| 15/15 [00:00<00:00, 155.52it/s, train_loss=0.00323, valid_loss=0.00446]\n",
      "Epoch: 25/50: 100%|██████████| 15/15 [00:00<00:00, 156.23it/s, train_loss=0.0033, valid_loss=0.00457]\n",
      "Epoch: 26/50: 100%|██████████| 15/15 [00:00<00:00, 158.78it/s, train_loss=0.00316, valid_loss=0.00443]\n",
      "Epoch: 27/50: 100%|██████████| 15/15 [00:00<00:00, 156.15it/s, train_loss=0.00354, valid_loss=0.00465]\n",
      "Epoch: 28/50: 100%|██████████| 15/15 [00:00<00:00, 154.77it/s, train_loss=0.00295, valid_loss=0.00448]\n",
      "Epoch: 29/50: 100%|██████████| 15/15 [00:00<00:00, 157.93it/s, train_loss=0.00287, valid_loss=0.00441]\n",
      "Epoch: 30/50: 100%|██████████| 15/15 [00:00<00:00, 157.51it/s, train_loss=0.00259, valid_loss=0.00453]\n",
      "Epoch: 31/50: 100%|██████████| 15/15 [00:00<00:00, 156.19it/s, train_loss=0.00292, valid_loss=0.0043]\n",
      "Epoch: 32/50: 100%|██████████| 15/15 [00:00<00:00, 157.82it/s, train_loss=0.00316, valid_loss=0.00451]\n",
      "Epoch: 33/50: 100%|██████████| 15/15 [00:00<00:00, 157.79it/s, train_loss=0.00296, valid_loss=0.00435]\n",
      "Epoch: 34/50: 100%|██████████| 15/15 [00:00<00:00, 157.73it/s, train_loss=0.00337, valid_loss=0.00464]\n",
      "Epoch: 35/50: 100%|██████████| 15/15 [00:00<00:00, 114.78it/s, train_loss=0.00281, valid_loss=0.00454]\n",
      "Epoch: 36/50: 100%|██████████| 15/15 [00:00<00:00, 153.91it/s, train_loss=0.00291, valid_loss=0.0046]\n",
      "Epoch: 37/50: 100%|██████████| 15/15 [00:00<00:00, 157.56it/s, train_loss=0.00245, valid_loss=0.00483]\n",
      "Epoch: 38/50: 100%|██████████| 15/15 [00:00<00:00, 158.25it/s, train_loss=0.00293, valid_loss=0.00452]\n",
      "Epoch: 39/50: 100%|██████████| 15/15 [00:00<00:00, 124.11it/s, train_loss=0.00267, valid_loss=0.00445]\n",
      "Epoch: 40/50: 100%|██████████| 15/15 [00:00<00:00, 156.56it/s, train_loss=0.00256, valid_loss=0.00441]\n",
      "Epoch: 41/50: 100%|██████████| 15/15 [00:00<00:00, 155.90it/s, train_loss=0.00305, valid_loss=0.00462]\n",
      "Epoch: 42/50: 100%|██████████| 15/15 [00:00<00:00, 157.75it/s, train_loss=0.00272, valid_loss=0.00461]\n",
      "Epoch: 43/50: 100%|██████████| 15/15 [00:00<00:00, 158.53it/s, train_loss=0.00313, valid_loss=0.00444]\n",
      "Epoch: 44/50: 100%|██████████| 15/15 [00:00<00:00, 156.01it/s, train_loss=0.00293, valid_loss=0.00441]\n",
      "Epoch: 45/50: 100%|██████████| 15/15 [00:00<00:00, 156.98it/s, train_loss=0.00311, valid_loss=0.00438]\n",
      "Epoch: 46/50: 100%|██████████| 15/15 [00:00<00:00, 158.56it/s, train_loss=0.00286, valid_loss=0.00494]\n",
      "Epoch: 47/50: 100%|██████████| 15/15 [00:00<00:00, 156.69it/s, train_loss=0.00273, valid_loss=0.00453]\n",
      "Epoch: 48/50: 100%|██████████| 15/15 [00:00<00:00, 114.25it/s, train_loss=0.00253, valid_loss=0.00474]\n",
      "Epoch: 49/50: 100%|██████████| 15/15 [00:00<00:00, 154.50it/s, train_loss=0.0026, valid_loss=0.00475]\n",
      "Epoch: 50/50: 100%|██████████| 15/15 [00:00<00:00, 155.84it/s, train_loss=0.00273, valid_loss=0.00484]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 29/29 [00:00<00:00, 112.43it/s, train_loss=0.0204, valid_loss=0.0206]\n",
      "Epoch: 2/50: 100%|██████████| 29/29 [00:00<00:00, 144.80it/s, train_loss=0.0098, valid_loss=0.00598]\n",
      "Epoch: 3/50: 100%|██████████| 29/29 [00:00<00:00, 125.65it/s, train_loss=0.00687, valid_loss=0.00488]\n",
      "Epoch: 4/50: 100%|██████████| 29/29 [00:00<00:00, 127.88it/s, train_loss=0.00588, valid_loss=0.00282]\n",
      "Epoch: 5/50: 100%|██████████| 29/29 [00:00<00:00, 130.51it/s, train_loss=0.00571, valid_loss=0.00469]\n",
      "Epoch: 6/50: 100%|██████████| 29/29 [00:00<00:00, 123.64it/s, train_loss=0.00523, valid_loss=0.00358]\n",
      "Epoch: 7/50: 100%|██████████| 29/29 [00:00<00:00, 134.21it/s, train_loss=0.00425, valid_loss=0.00379]\n",
      "Epoch: 8/50: 100%|██████████| 29/29 [00:00<00:00, 127.18it/s, train_loss=0.00469, valid_loss=0.00211]\n",
      "Epoch: 9/50: 100%|██████████| 29/29 [00:00<00:00, 139.33it/s, train_loss=0.00526, valid_loss=0.00243]\n",
      "Epoch: 10/50: 100%|██████████| 29/29 [00:00<00:00, 130.37it/s, train_loss=0.00462, valid_loss=0.00212]\n",
      "Epoch: 11/50: 100%|██████████| 29/29 [00:00<00:00, 145.57it/s, train_loss=0.00428, valid_loss=0.00246]\n",
      "Epoch: 12/50: 100%|██████████| 29/29 [00:00<00:00, 114.33it/s, train_loss=0.00436, valid_loss=0.00213]\n",
      "Epoch: 13/50: 100%|██████████| 29/29 [00:00<00:00, 128.65it/s, train_loss=0.00535, valid_loss=0.00264]\n",
      "Epoch: 14/50: 100%|██████████| 29/29 [00:00<00:00, 138.27it/s, train_loss=0.00485, valid_loss=0.00215]\n",
      "Epoch: 15/50: 100%|██████████| 29/29 [00:00<00:00, 152.21it/s, train_loss=0.00423, valid_loss=0.00304]\n",
      "Epoch: 16/50: 100%|██████████| 29/29 [00:00<00:00, 138.95it/s, train_loss=0.00474, valid_loss=0.0032] \n",
      "Epoch: 17/50: 100%|██████████| 29/29 [00:00<00:00, 117.00it/s, train_loss=0.00469, valid_loss=0.00208]\n",
      "Epoch: 18/50: 100%|██████████| 29/29 [00:00<00:00, 125.19it/s, train_loss=0.00415, valid_loss=0.00231]\n",
      "Epoch: 19/50: 100%|██████████| 29/29 [00:00<00:00, 103.39it/s, train_loss=0.00411, valid_loss=0.00235]\n",
      "Epoch: 20/50: 100%|██████████| 29/29 [00:00<00:00, 128.17it/s, train_loss=0.00414, valid_loss=0.00314]\n",
      "Epoch: 21/50: 100%|██████████| 29/29 [00:00<00:00, 137.36it/s, train_loss=0.00406, valid_loss=0.00261]\n",
      "Epoch: 22/50: 100%|██████████| 29/29 [00:00<00:00, 112.26it/s, train_loss=0.00432, valid_loss=0.00294]\n",
      "Epoch: 23/50: 100%|██████████| 29/29 [00:00<00:00, 149.14it/s, train_loss=0.00455, valid_loss=0.00214]\n",
      "Epoch: 24/50: 100%|██████████| 29/29 [00:00<00:00, 135.47it/s, train_loss=0.0041, valid_loss=0.00306] \n",
      "Epoch: 25/50: 100%|██████████| 29/29 [00:00<00:00, 127.94it/s, train_loss=0.00361, valid_loss=0.00246]\n",
      "Epoch: 26/50: 100%|██████████| 29/29 [00:00<00:00, 107.02it/s, train_loss=0.00336, valid_loss=0.00231]\n",
      "Epoch: 27/50: 100%|██████████| 29/29 [00:00<00:00, 132.38it/s, train_loss=0.00444, valid_loss=0.00225]\n",
      "Epoch: 28/50: 100%|██████████| 29/29 [00:00<00:00, 127.09it/s, train_loss=0.00395, valid_loss=0.00286]\n",
      "Epoch: 29/50: 100%|██████████| 29/29 [00:00<00:00, 123.94it/s, train_loss=0.00348, valid_loss=0.002] \n",
      "Epoch: 30/50: 100%|██████████| 29/29 [00:00<00:00, 147.27it/s, train_loss=0.00386, valid_loss=0.00228]\n",
      "Epoch: 31/50: 100%|██████████| 29/29 [00:00<00:00, 126.03it/s, train_loss=0.00375, valid_loss=0.00275]\n",
      "Epoch: 32/50: 100%|██████████| 29/29 [00:00<00:00, 110.03it/s, train_loss=0.0038, valid_loss=0.00286] \n",
      "Epoch: 33/50: 100%|██████████| 29/29 [00:00<00:00, 139.88it/s, train_loss=0.0042, valid_loss=0.0025]  \n",
      "Epoch: 34/50: 100%|██████████| 29/29 [00:00<00:00, 135.49it/s, train_loss=0.00416, valid_loss=0.00309]\n",
      "Epoch: 35/50: 100%|██████████| 29/29 [00:00<00:00, 149.78it/s, train_loss=0.00399, valid_loss=0.00253]\n",
      "Epoch: 36/50: 100%|██████████| 29/29 [00:00<00:00, 127.18it/s, train_loss=0.00383, valid_loss=0.00215]\n",
      "Epoch: 37/50: 100%|██████████| 29/29 [00:00<00:00, 121.74it/s, train_loss=0.00358, valid_loss=0.00308]\n",
      "Epoch: 38/50: 100%|██████████| 29/29 [00:00<00:00, 127.06it/s, train_loss=0.00415, valid_loss=0.00264]\n",
      "Epoch: 39/50: 100%|██████████| 29/29 [00:00<00:00, 114.83it/s, train_loss=0.00367, valid_loss=0.00275]\n",
      "Epoch: 40/50: 100%|██████████| 29/29 [00:00<00:00, 120.14it/s, train_loss=0.00373, valid_loss=0.0027]\n",
      "Epoch: 41/50: 100%|██████████| 29/29 [00:00<00:00, 135.52it/s, train_loss=0.00364, valid_loss=0.00193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 44/44 [00:00<00:00, 118.71it/s, train_loss=0.0222, valid_loss=0.0272]\n",
      "Epoch: 2/50: 100%|██████████| 44/44 [00:00<00:00, 145.36it/s, train_loss=0.016, valid_loss=0.0157] \n",
      "Epoch: 3/50: 100%|██████████| 44/44 [00:00<00:00, 129.11it/s, train_loss=0.00758, valid_loss=0.00573]\n",
      "Epoch: 4/50: 100%|██████████| 44/44 [00:00<00:00, 144.60it/s, train_loss=0.00687, valid_loss=0.00462]\n",
      "Epoch: 5/50: 100%|██████████| 44/44 [00:00<00:00, 136.85it/s, train_loss=0.00543, valid_loss=0.00451]\n",
      "Epoch: 6/50: 100%|██████████| 44/44 [00:00<00:00, 144.75it/s, train_loss=0.00541, valid_loss=0.00409]\n",
      "Epoch: 7/50: 100%|██████████| 44/44 [00:00<00:00, 125.49it/s, train_loss=0.00553, valid_loss=0.00383]\n",
      "Epoch: 8/50: 100%|██████████| 44/44 [00:00<00:00, 137.23it/s, train_loss=0.00528, valid_loss=0.00373]\n",
      "Epoch: 9/50: 100%|██████████| 44/44 [00:00<00:00, 136.55it/s, train_loss=0.00459, valid_loss=0.00373]\n",
      "Epoch: 10/50: 100%|██████████| 44/44 [00:00<00:00, 144.93it/s, train_loss=0.00524, valid_loss=0.00432]\n",
      "Epoch: 11/50: 100%|██████████| 44/44 [00:00<00:00, 132.28it/s, train_loss=0.00513, valid_loss=0.00369]\n",
      "Epoch: 12/50: 100%|██████████| 44/44 [00:00<00:00, 116.72it/s, train_loss=0.00461, valid_loss=0.00369]\n",
      "Epoch: 13/50: 100%|██████████| 44/44 [00:00<00:00, 144.75it/s, train_loss=0.00453, valid_loss=0.00359]\n",
      "Epoch: 14/50: 100%|██████████| 44/44 [00:00<00:00, 130.12it/s, train_loss=0.00479, valid_loss=0.00381]\n",
      "Epoch: 15/50: 100%|██████████| 44/44 [00:00<00:00, 144.42it/s, train_loss=0.00471, valid_loss=0.00361]\n",
      "Epoch: 16/50: 100%|██████████| 44/44 [00:00<00:00, 122.37it/s, train_loss=0.00431, valid_loss=0.00387]\n",
      "Epoch: 17/50: 100%|██████████| 44/44 [00:00<00:00, 144.64it/s, train_loss=0.00457, valid_loss=0.00388]\n",
      "Epoch: 18/50: 100%|██████████| 44/44 [00:00<00:00, 114.84it/s, train_loss=0.00495, valid_loss=0.00378]\n",
      "Epoch: 19/50: 100%|██████████| 44/44 [00:00<00:00, 120.06it/s, train_loss=0.00473, valid_loss=0.00406]\n",
      "Epoch: 20/50: 100%|██████████| 44/44 [00:00<00:00, 135.41it/s, train_loss=0.00432, valid_loss=0.00371]\n",
      "Epoch: 21/50: 100%|██████████| 44/44 [00:00<00:00, 120.75it/s, train_loss=0.00456, valid_loss=0.00351]\n",
      "Epoch: 22/50: 100%|██████████| 44/44 [00:00<00:00, 133.36it/s, train_loss=0.00415, valid_loss=0.00349]\n",
      "Epoch: 23/50: 100%|██████████| 44/44 [00:00<00:00, 135.22it/s, train_loss=0.00387, valid_loss=0.00343]\n",
      "Epoch: 24/50: 100%|██████████| 44/44 [00:00<00:00, 131.61it/s, train_loss=0.00441, valid_loss=0.00362]\n",
      "Epoch: 25/50: 100%|██████████| 44/44 [00:00<00:00, 127.50it/s, train_loss=0.00494, valid_loss=0.00345]\n",
      "Epoch: 26/50: 100%|██████████| 44/44 [00:00<00:00, 137.26it/s, train_loss=0.00418, valid_loss=0.00369]\n",
      "Epoch: 27/50: 100%|██████████| 44/44 [00:00<00:00, 138.55it/s, train_loss=0.00395, valid_loss=0.00344]\n",
      "Epoch: 28/50: 100%|██████████| 44/44 [00:00<00:00, 130.68it/s, train_loss=0.00425, valid_loss=0.00338]\n",
      "Epoch: 29/50: 100%|██████████| 44/44 [00:00<00:00, 146.09it/s, train_loss=0.00484, valid_loss=0.00345]\n",
      "Epoch: 30/50: 100%|██████████| 44/44 [00:00<00:00, 115.21it/s, train_loss=0.00416, valid_loss=0.00404]\n",
      "Epoch: 31/50: 100%|██████████| 44/44 [00:00<00:00, 136.97it/s, train_loss=0.00434, valid_loss=0.00337]\n",
      "Epoch: 32/50: 100%|██████████| 44/44 [00:00<00:00, 129.67it/s, train_loss=0.00316, valid_loss=0.00345]\n",
      "Epoch: 33/50: 100%|██████████| 44/44 [00:00<00:00, 124.86it/s, train_loss=0.00391, valid_loss=0.00345]\n",
      "Epoch: 34/50: 100%|██████████| 44/44 [00:00<00:00, 130.52it/s, train_loss=0.00315, valid_loss=0.00384]\n",
      "Epoch: 35/50: 100%|██████████| 44/44 [00:00<00:00, 115.57it/s, train_loss=0.00378, valid_loss=0.00383]\n",
      "Epoch: 36/50: 100%|██████████| 44/44 [00:00<00:00, 122.74it/s, train_loss=0.00365, valid_loss=0.00384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 58/58 [00:00<00:00, 114.80it/s, train_loss=0.0161, valid_loss=0.0116]\n",
      "Epoch: 2/50: 100%|██████████| 58/58 [00:00<00:00, 123.36it/s, train_loss=0.0109, valid_loss=0.00577] \n",
      "Epoch: 3/50: 100%|██████████| 58/58 [00:00<00:00, 137.84it/s, train_loss=0.00756, valid_loss=0.00523]\n",
      "Epoch: 4/50: 100%|██████████| 58/58 [00:00<00:00, 143.54it/s, train_loss=0.00672, valid_loss=0.00495]\n",
      "Epoch: 5/50: 100%|██████████| 58/58 [00:00<00:00, 120.43it/s, train_loss=0.00712, valid_loss=0.00358]\n",
      "Epoch: 6/50: 100%|██████████| 58/58 [00:00<00:00, 141.84it/s, train_loss=0.00557, valid_loss=0.00313]\n",
      "Epoch: 7/50: 100%|██████████| 58/58 [00:00<00:00, 140.47it/s, train_loss=0.00604, valid_loss=0.00452]\n",
      "Epoch: 8/50: 100%|██████████| 58/58 [00:00<00:00, 133.64it/s, train_loss=0.00515, valid_loss=0.00355]\n",
      "Epoch: 9/50: 100%|██████████| 58/58 [00:00<00:00, 123.14it/s, train_loss=0.00494, valid_loss=0.00385]\n",
      "Epoch: 10/50: 100%|██████████| 58/58 [00:00<00:00, 131.67it/s, train_loss=0.00484, valid_loss=0.00451]\n",
      "Epoch: 11/50: 100%|██████████| 58/58 [00:00<00:00, 129.51it/s, train_loss=0.00514, valid_loss=0.00415]\n",
      "Epoch: 12/50: 100%|██████████| 58/58 [00:00<00:00, 112.01it/s, train_loss=0.00507, valid_loss=0.00366]\n",
      "Epoch: 13/50: 100%|██████████| 58/58 [00:00<00:00, 128.22it/s, train_loss=0.00546, valid_loss=0.00314]\n",
      "Epoch: 14/50: 100%|██████████| 58/58 [00:00<00:00, 138.74it/s, train_loss=0.00466, valid_loss=0.00302]\n",
      "Epoch: 15/50: 100%|██████████| 58/58 [00:00<00:00, 126.43it/s, train_loss=0.00447, valid_loss=0.00301]\n",
      "Epoch: 16/50: 100%|██████████| 58/58 [00:00<00:00, 126.16it/s, train_loss=0.00468, valid_loss=0.00408]\n",
      "Epoch: 17/50: 100%|██████████| 58/58 [00:00<00:00, 139.72it/s, train_loss=0.00446, valid_loss=0.00392]\n",
      "Epoch: 18/50: 100%|██████████| 58/58 [00:00<00:00, 119.27it/s, train_loss=0.00465, valid_loss=0.00348]\n",
      "Epoch: 19/50: 100%|██████████| 58/58 [00:00<00:00, 137.97it/s, train_loss=0.00488, valid_loss=0.00309]\n",
      "Epoch: 20/50: 100%|██████████| 58/58 [00:00<00:00, 144.21it/s, train_loss=0.0045, valid_loss=0.00345] \n",
      "Epoch: 21/50: 100%|██████████| 58/58 [00:00<00:00, 143.95it/s, train_loss=0.00488, valid_loss=0.00345]\n",
      "Epoch: 22/50: 100%|██████████| 58/58 [00:00<00:00, 109.96it/s, train_loss=0.00496, valid_loss=0.00446]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation dataset 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50: 100%|██████████| 72/72 [00:00<00:00, 122.35it/s, train_loss=0.0105, valid_loss=0.00686]\n",
      "Epoch: 2/50: 100%|██████████| 72/72 [00:00<00:00, 137.76it/s, train_loss=0.0079, valid_loss=0.00447] \n",
      "Epoch: 3/50: 100%|██████████| 72/72 [00:00<00:00, 113.00it/s, train_loss=0.00727, valid_loss=0.00379]\n",
      "Epoch: 4/50: 100%|██████████| 72/72 [00:00<00:00, 133.79it/s, train_loss=0.00558, valid_loss=0.00335]\n",
      "Epoch: 5/50: 100%|██████████| 72/72 [00:00<00:00, 126.33it/s, train_loss=0.00521, valid_loss=0.00261]\n",
      "Epoch: 6/50: 100%|██████████| 72/72 [00:00<00:00, 129.71it/s, train_loss=0.00521, valid_loss=0.00252]\n",
      "Epoch: 7/50: 100%|██████████| 72/72 [00:00<00:00, 129.87it/s, train_loss=0.00521, valid_loss=0.00309]\n",
      "Epoch: 8/50: 100%|██████████| 72/72 [00:00<00:00, 124.69it/s, train_loss=0.00461, valid_loss=0.00239]\n",
      "Epoch: 9/50: 100%|██████████| 72/72 [00:00<00:00, 139.55it/s, train_loss=0.00464, valid_loss=0.00267]\n",
      "Epoch: 10/50: 100%|██████████| 72/72 [00:00<00:00, 126.71it/s, train_loss=0.00414, valid_loss=0.00258]\n",
      "Epoch: 11/50: 100%|██████████| 72/72 [00:00<00:00, 123.72it/s, train_loss=0.00368, valid_loss=0.00261]\n",
      "Epoch: 12/50: 100%|██████████| 72/72 [00:00<00:00, 133.33it/s, train_loss=0.00454, valid_loss=0.00228]\n",
      "Epoch: 13/50: 100%|██████████| 72/72 [00:00<00:00, 121.32it/s, train_loss=0.00441, valid_loss=0.00248]\n",
      "Epoch: 14/50: 100%|██████████| 72/72 [00:00<00:00, 131.31it/s, train_loss=0.00358, valid_loss=0.00268]\n",
      "Epoch: 15/50: 100%|██████████| 72/72 [00:00<00:00, 138.58it/s, train_loss=0.0035, valid_loss=0.00239] \n",
      "Epoch: 16/50: 100%|██████████| 72/72 [00:00<00:00, 125.00it/s, train_loss=0.00351, valid_loss=0.00244]\n",
      "Epoch: 17/50: 100%|██████████| 72/72 [00:00<00:00, 135.04it/s, train_loss=0.00429, valid_loss=0.00249]\n",
      "Epoch: 18/50: 100%|██████████| 72/72 [00:00<00:00, 120.83it/s, train_loss=0.0039, valid_loss=0.00272] \n",
      "Epoch: 19/50: 100%|██████████| 72/72 [00:00<00:00, 120.39it/s, train_loss=0.00355, valid_loss=0.00286]\n",
      "Epoch: 20/50: 100%|██████████| 72/72 [00:00<00:00, 131.03it/s, train_loss=0.00415, valid_loss=0.00277]\n",
      "Epoch: 21/50: 100%|██████████| 72/72 [00:00<00:00, 129.40it/s, train_loss=0.0037, valid_loss=0.00248] \n",
      "Epoch: 22/50: 100%|██████████| 72/72 [00:00<00:00, 133.71it/s, train_loss=0.00386, valid_loss=0.00257]\n"
     ]
    }
   ],
   "source": [
    "records = run_model_hpo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2eacf83",
   "metadata": {},
   "source": [
    "## find the best hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2837c31a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T11:41:56.516895Z",
     "start_time": "2021-12-28T11:41:56.481798Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>number_epoch</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>drop_prob</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>valid_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>0.005</td>\n",
       "      <td>50</td>\n",
       "      <td>35</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.002603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>256</td>\n",
       "      <td>0.005</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.002615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>35</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.002667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.002679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>128</td>\n",
       "      <td>0.010</td>\n",
       "      <td>50</td>\n",
       "      <td>35</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.002695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>256</td>\n",
       "      <td>0.010</td>\n",
       "      <td>50</td>\n",
       "      <td>35</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.002718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>128</td>\n",
       "      <td>0.005</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.002790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>0.005</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.002811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>512</td>\n",
       "      <td>0.010</td>\n",
       "      <td>50</td>\n",
       "      <td>35</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.002822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>512</td>\n",
       "      <td>0.010</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.002827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>256</td>\n",
       "      <td>0.005</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.002834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>128</td>\n",
       "      <td>0.010</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.002900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>512</td>\n",
       "      <td>0.005</td>\n",
       "      <td>50</td>\n",
       "      <td>35</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.002924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>512</td>\n",
       "      <td>0.005</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.002936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>256</td>\n",
       "      <td>0.010</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.003023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>512</td>\n",
       "      <td>0.005</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.003037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>512</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>35</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.003098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>512</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.003258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.003729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>512</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.004364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    batch_size     lr  number_epoch  hidden_dim  drop_prob  weight_decay  \\\n",
       "3          128  0.005            50          35        0.1  1.000000e-07   \n",
       "18         256  0.005            50          30        0.1  1.000000e-07   \n",
       "7          256  0.001            50          35        0.1  1.000000e-07   \n",
       "6          256  0.001            50          30        0.1  1.000000e-07   \n",
       "10         128  0.010            50          35        0.1  1.000000e-07   \n",
       "9          256  0.010            50          35        0.1  1.000000e-07   \n",
       "11         128  0.005            50          30        0.1  1.000000e-07   \n",
       "0          128  0.005            50          25        0.1  1.000000e-07   \n",
       "16         512  0.010            50          35        0.1  1.000000e-07   \n",
       "4          512  0.010            50          30        0.1  1.000000e-07   \n",
       "19         256  0.005            50          25        0.1  1.000000e-07   \n",
       "8          128  0.010            50          25        0.1  1.000000e-07   \n",
       "13         512  0.005            50          35        0.1  1.000000e-07   \n",
       "15         512  0.005            50          30        0.1  1.000000e-07   \n",
       "14         256  0.010            50          25        0.1  1.000000e-07   \n",
       "1          512  0.005            50          25        0.1  1.000000e-07   \n",
       "17         512  0.001            50          35        0.1  1.000000e-07   \n",
       "12         512  0.001            50          30        0.1  1.000000e-07   \n",
       "2          128  0.001            50          25        0.1  1.000000e-07   \n",
       "5          512  0.001            50          25        0.1  1.000000e-07   \n",
       "\n",
       "    valid_loss  \n",
       "3     0.002603  \n",
       "18    0.002615  \n",
       "7     0.002667  \n",
       "6     0.002679  \n",
       "10    0.002695  \n",
       "9     0.002718  \n",
       "11    0.002790  \n",
       "0     0.002811  \n",
       "16    0.002822  \n",
       "4     0.002827  \n",
       "19    0.002834  \n",
       "8     0.002900  \n",
       "13    0.002924  \n",
       "15    0.002936  \n",
       "14    0.003023  \n",
       "1     0.003037  \n",
       "17    0.003098  \n",
       "12    0.003258  \n",
       "2     0.003729  \n",
       "5     0.004364  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = pd.DataFrame(records).sort_values(by='valid_loss')\n",
    "records.to_csv('./records/fnn_records_without_features.csv', mode='a', index=False, header=False)\n",
    "records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d46b2df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T03:14:37.931135Z",
     "start_time": "2021-12-22T03:14:37.875320Z"
    }
   },
   "source": [
    "## retrain a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd5f4169",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T12:18:10.241320Z",
     "start_time": "2021-12-26T12:18:10.220954Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train_model(train_x, train_y, valid_x, valid_y, input_size, output_size,\n",
    "                mse_thresh, batch_size, lr, number_epoch, hidden_dim,\n",
    "                drop_prob, weight_decay):\n",
    "    while (1):\n",
    "        model_fnn = FNN(input_size, output_size, hidden_dim, drop_prob)\n",
    "        model_fnn.to(device=device)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model_fnn.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.98)\n",
    "        valid_loss_min = np.Inf\n",
    "        train_dataset = TensorDataset(torch.FloatTensor(train_x),\n",
    "                                      torch.FloatTensor(train_y))\n",
    "        valid_dataset = TensorDataset(torch.FloatTensor(valid_x),\n",
    "                                      torch.FloatTensor(valid_y))\n",
    "        train_loader = DataLoader(dataset=train_dataset,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=True,\n",
    "                                  drop_last=False)\n",
    "        valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=True,\n",
    "                                  drop_last=False)\n",
    "        num_without_imp = 0\n",
    "        train_loss_list = []\n",
    "        valid_loss_list = []\n",
    "        # training process\n",
    "        for epoch in range(1, number_epoch + 1):\n",
    "            loop = tqdm(enumerate(train_loader),\n",
    "                        total=len(train_loader),\n",
    "                        leave=True)\n",
    "            for i, (inputs, labels) in loop:\n",
    "                inputs = inputs.to(device=device)\n",
    "                labels = labels.to(device=device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model_fnn(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if i % 5 == 0:\n",
    "                    num_without_imp = num_without_imp + 1\n",
    "                    valid_losses = list()\n",
    "                    model_fnn.eval()\n",
    "                    for inp, lab in valid_loader:\n",
    "                        inp = inp.to(device)\n",
    "                        lab = lab.to(device)\n",
    "                        out = model_fnn(inp)\n",
    "                        valid_loss = criterion(out, lab)\n",
    "                        valid_losses.append(valid_loss.item())\n",
    "\n",
    "                    model_fnn.train()\n",
    "                    loop.set_description(\"Epoch: {}/{}\".format(\n",
    "                        epoch, number_epoch))\n",
    "                    loop.set_postfix(train_loss=loss.item(),\n",
    "                                     valid_loss=np.mean(valid_losses))\n",
    "                    train_loss_list.append(loss.item())\n",
    "                    valid_loss_list.append(np.mean(valid_losses))\n",
    "                    if np.mean(valid_losses) < valid_loss_min:\n",
    "                        num_without_imp = 0\n",
    "                        torch.save(model_fnn.state_dict(),\n",
    "                                   './model/fnn_without_features_state_dict.pt')\n",
    "                        valid_loss_min = np.mean(valid_losses)\n",
    "            scheduler.step()\n",
    "        if valid_loss_min < mse_thresh:\n",
    "            break\n",
    "    return model_fnn, train_loss_list, valid_loss_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89895001",
   "metadata": {},
   "source": [
    "## test the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e65d50d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T12:18:08.962940Z",
     "start_time": "2021-12-26T12:18:08.949997Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_model(model, test_x, test_y, scaler_y, batch_size):\n",
    "    test_dataset = TensorDataset(torch.FloatTensor(test_x),\n",
    "                                 torch.FloatTensor(test_y))\n",
    "    test_loader = DataLoader(dataset=test_dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=False,\n",
    "                             drop_last=False)\n",
    "    model.load_state_dict(torch.load('./model/fnn_without_features_state_dict.pt'))\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, label in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            label = label.to(device)\n",
    "            outputs = model(inputs)\n",
    "            y_pred += outputs.cpu().numpy().flatten().tolist()\n",
    "            y_true += label.cpu().numpy().flatten().tolist()\n",
    "    y_pred = np.array(y_pred).reshape(-1, 1)\n",
    "    y_true = np.array(y_true).reshape(-1, 1)\n",
    "#     pdb.set_trace()\n",
    "    load_pred = scaler_y.inverse_transform(y_pred)\n",
    "    load_true = scaler_y.inverse_transform(y_true)\n",
    "    MAPE = np.mean(np.abs(load_true - load_pred) / load_true)\n",
    "    MAE = np.mean(np.abs(load_true - load_pred))\n",
    "    RMSE = np.sqrt(np.mean(np.square(load_true - load_pred)))\n",
    "    return MAPE, MAE, RMSE, load_pred, load_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf3839c",
   "metadata": {},
   "source": [
    "## run model retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7be95055",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-27T05:58:56.702562Z",
     "start_time": "2021-12-27T05:58:56.692608Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_model_retraining(seq_len=seq_len,\n",
    "                         target_len=target_len,\n",
    "                         feature_num=feature_num,\n",
    "                         mse_thresh=mse_thresh):\n",
    "    train_data = data[:int(0.8 * len(data))]\n",
    "    train_data, scaler, scaler_y = normalization(train_data)\n",
    "    train_x, train_y = Series_To_Supervise(train_data, seq_len, target_len)\n",
    "    #     ind = select_feature(train_x, train_y, feature_num=feature_num)\n",
    "    train_x = train_x.reshape(train_x.shape[0], -1)\n",
    "    valid_x = train_x[int(0.8 * len(train_x)):]\n",
    "    valid_y = train_y[int(0.8 * len(train_y)):]\n",
    "    train_x = train_x[:int(0.8 * len(train_x))]\n",
    "    train_y = train_y[:int(0.8 * len(train_y))]\n",
    "    input_size = train_x.shape[1]\n",
    "    output_size = target_len\n",
    "\n",
    "    #     hyper-parameters define\n",
    "    batch_size = 128\n",
    "    lr = 0.001\n",
    "    number_epoch = 100\n",
    "    hidden_dim = 30\n",
    "    drop_prob = 0\n",
    "    weight_decay = 0\n",
    "    mse_thresh = 0.01\n",
    "\n",
    "    model, train_loss_list, valid_loss_list = train_model(\n",
    "        train_x, train_y, valid_x, valid_y, input_size, output_size,\n",
    "        mse_thresh, batch_size, lr, number_epoch, hidden_dim, drop_prob, weight_decay)\n",
    "    # plot training process\n",
    "    plt.plot(train_loss_list, 'm', label='train_loss')\n",
    "    plt.plot(valid_loss_list, 'g', label='valid_loss')\n",
    "    plt.grid('both')\n",
    "    plt.legend()\n",
    "    # test\n",
    "    test_data = data[int(0.8 * len(data)):]\n",
    "    test_data = scaler.transform(test_data)\n",
    "    test_x, test_y = Series_To_Supervise(test_data, seq_len, target_len)\n",
    "    test_x = test_x.reshape(test_x.shape[0], -1)\n",
    "    MAPE, MAE, RMSE, load_pred, load_true = test_model(model, test_x, test_y,\n",
    "                                                       scaler_y, batch_size)\n",
    "    return MAPE, MAE, RMSE, load_pred, load_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6e3eac55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-27T06:04:53.864396Z",
     "start_time": "2021-12-27T05:58:58.912230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised Data: Shape of x: (25232, 72, 1), Shape of y: (25232, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100: 100%|██████████| 158/158 [00:02<00:00, 75.03it/s, train_loss=0.0418, valid_loss=0.0453]\n",
      "Epoch: 2/100: 100%|██████████| 158/158 [00:01<00:00, 82.33it/s, train_loss=0.0377, valid_loss=0.0374]\n",
      "Epoch: 3/100: 100%|██████████| 158/158 [00:01<00:00, 82.70it/s, train_loss=0.0325, valid_loss=0.032] \n",
      "Epoch: 4/100: 100%|██████████| 158/158 [00:01<00:00, 82.31it/s, train_loss=0.0258, valid_loss=0.0313]\n",
      "Epoch: 5/100: 100%|██████████| 158/158 [00:01<00:00, 82.18it/s, train_loss=0.0237, valid_loss=0.0247]\n",
      "Epoch: 6/100: 100%|██████████| 158/158 [00:01<00:00, 82.18it/s, train_loss=0.0244, valid_loss=0.0238]\n",
      "Epoch: 7/100: 100%|██████████| 158/158 [00:01<00:00, 82.55it/s, train_loss=0.0238, valid_loss=0.0238]\n",
      "Epoch: 8/100: 100%|██████████| 158/158 [00:01<00:00, 83.18it/s, train_loss=0.0237, valid_loss=0.0237]\n",
      "Epoch: 9/100: 100%|██████████| 158/158 [00:01<00:00, 83.77it/s, train_loss=0.0215, valid_loss=0.0238]\n",
      "Epoch: 10/100: 100%|██████████| 158/158 [00:01<00:00, 85.24it/s, train_loss=0.0202, valid_loss=0.0237]\n",
      "Epoch: 11/100: 100%|██████████| 158/158 [00:01<00:00, 85.16it/s, train_loss=0.0218, valid_loss=0.0237]\n",
      "Epoch: 12/100: 100%|██████████| 158/158 [00:01<00:00, 82.85it/s, train_loss=0.0218, valid_loss=0.0237]\n",
      "Epoch: 13/100: 100%|██████████| 158/158 [00:01<00:00, 79.28it/s, train_loss=0.023, valid_loss=0.0236] \n",
      "Epoch: 14/100: 100%|██████████| 158/158 [00:01<00:00, 79.48it/s, train_loss=0.0247, valid_loss=0.0236]\n",
      "Epoch: 15/100: 100%|██████████| 158/158 [00:01<00:00, 79.91it/s, train_loss=0.0227, valid_loss=0.0236]\n",
      "Epoch: 16/100: 100%|██████████| 158/158 [00:01<00:00, 79.35it/s, train_loss=0.0242, valid_loss=0.0236]\n",
      "Epoch: 17/100: 100%|██████████| 158/158 [00:02<00:00, 78.92it/s, train_loss=0.0215, valid_loss=0.0236]\n",
      "Epoch: 18/100: 100%|██████████| 158/158 [00:01<00:00, 79.40it/s, train_loss=0.0212, valid_loss=0.0236]\n",
      "Epoch: 19/100: 100%|██████████| 158/158 [00:01<00:00, 79.66it/s, train_loss=0.0232, valid_loss=0.0235]\n",
      "Epoch: 20/100: 100%|██████████| 158/158 [00:01<00:00, 79.16it/s, train_loss=0.0234, valid_loss=0.0237]\n",
      "Epoch: 21/100: 100%|██████████| 158/158 [00:01<00:00, 79.40it/s, train_loss=0.0216, valid_loss=0.0236]\n",
      "Epoch: 22/100: 100%|██████████| 158/158 [00:02<00:00, 78.62it/s, train_loss=0.0214, valid_loss=0.0235]\n",
      "Epoch: 23/100: 100%|██████████| 158/158 [00:01<00:00, 80.26it/s, train_loss=0.0214, valid_loss=0.0236]\n",
      "Epoch: 24/100: 100%|██████████| 158/158 [00:01<00:00, 79.16it/s, train_loss=0.0231, valid_loss=0.0235]\n",
      "Epoch: 25/100: 100%|██████████| 158/158 [00:01<00:00, 79.51it/s, train_loss=0.025, valid_loss=0.0235] \n",
      "Epoch: 26/100: 100%|██████████| 158/158 [00:01<00:00, 80.19it/s, train_loss=0.0263, valid_loss=0.0235]\n",
      "Epoch: 27/100: 100%|██████████| 158/158 [00:01<00:00, 79.60it/s, train_loss=0.0232, valid_loss=0.0235]\n",
      "Epoch: 28/100: 100%|██████████| 158/158 [00:01<00:00, 79.85it/s, train_loss=0.0237, valid_loss=0.0235]\n",
      "Epoch: 29/100: 100%|██████████| 158/158 [00:01<00:00, 79.59it/s, train_loss=0.0235, valid_loss=0.0235]\n",
      "Epoch: 30/100: 100%|██████████| 158/158 [00:01<00:00, 79.22it/s, train_loss=0.0227, valid_loss=0.0235]\n",
      "Epoch: 31/100: 100%|██████████| 158/158 [00:01<00:00, 79.96it/s, train_loss=0.0253, valid_loss=0.0235]\n",
      "Epoch: 32/100: 100%|██████████| 158/158 [00:01<00:00, 80.25it/s, train_loss=0.0236, valid_loss=0.0234]\n",
      "Epoch: 33/100: 100%|██████████| 158/158 [00:01<00:00, 80.19it/s, train_loss=0.0213, valid_loss=0.0235]\n",
      "Epoch: 34/100: 100%|██████████| 158/158 [00:01<00:00, 79.99it/s, train_loss=0.0229, valid_loss=0.0235]\n",
      "Epoch: 35/100: 100%|██████████| 158/158 [00:01<00:00, 80.49it/s, train_loss=0.0225, valid_loss=0.0234]\n",
      "Epoch: 36/100: 100%|██████████| 158/158 [00:01<00:00, 80.29it/s, train_loss=0.0236, valid_loss=0.0234]\n",
      "Epoch: 37/100: 100%|██████████| 158/158 [00:01<00:00, 80.21it/s, train_loss=0.0203, valid_loss=0.0234]\n",
      "Epoch: 38/100: 100%|██████████| 158/158 [00:01<00:00, 80.83it/s, train_loss=0.0246, valid_loss=0.0234]\n",
      "Epoch: 39/100: 100%|██████████| 158/158 [00:01<00:00, 80.10it/s, train_loss=0.0222, valid_loss=0.0234]\n",
      "Epoch: 40/100: 100%|██████████| 158/158 [00:01<00:00, 80.70it/s, train_loss=0.0255, valid_loss=0.0234]\n",
      "Epoch: 41/100: 100%|██████████| 158/158 [00:01<00:00, 80.15it/s, train_loss=0.0233, valid_loss=0.0235]\n",
      "Epoch: 42/100: 100%|██████████| 158/158 [00:01<00:00, 80.61it/s, train_loss=0.0252, valid_loss=0.0234]\n",
      "Epoch: 43/100: 100%|██████████| 158/158 [00:01<00:00, 80.87it/s, train_loss=0.0231, valid_loss=0.0234]\n",
      "Epoch: 44/100: 100%|██████████| 158/158 [00:01<00:00, 80.18it/s, train_loss=0.0213, valid_loss=0.0234]\n",
      "Epoch: 45/100: 100%|██████████| 158/158 [00:01<00:00, 80.36it/s, train_loss=0.021, valid_loss=0.0234] \n",
      "Epoch: 46/100: 100%|██████████| 158/158 [00:01<00:00, 83.07it/s, train_loss=0.0213, valid_loss=0.0234]\n",
      "Epoch: 47/100: 100%|██████████| 158/158 [00:01<00:00, 84.05it/s, train_loss=0.0209, valid_loss=0.0234]\n",
      "Epoch: 48/100: 100%|██████████| 158/158 [00:01<00:00, 83.56it/s, train_loss=0.0241, valid_loss=0.0234]\n",
      "Epoch: 49/100: 100%|██████████| 158/158 [00:01<00:00, 88.44it/s, train_loss=0.0224, valid_loss=0.0234]\n",
      "Epoch: 50/100: 100%|██████████| 158/158 [00:01<00:00, 91.55it/s, train_loss=0.0201, valid_loss=0.0234]\n",
      "Epoch: 51/100: 100%|██████████| 158/158 [00:01<00:00, 92.48it/s, train_loss=0.0231, valid_loss=0.0234] \n",
      "Epoch: 52/100: 100%|██████████| 158/158 [00:01<00:00, 91.67it/s, train_loss=0.0239, valid_loss=0.0234]\n",
      "Epoch: 53/100: 100%|██████████| 158/158 [00:01<00:00, 93.72it/s, train_loss=0.0236, valid_loss=0.0234]\n",
      "Epoch: 54/100: 100%|██████████| 158/158 [00:01<00:00, 95.14it/s, train_loss=0.0214, valid_loss=0.0234]\n",
      "Epoch: 55/100: 100%|██████████| 158/158 [00:01<00:00, 94.82it/s, train_loss=0.0212, valid_loss=0.0235]\n",
      "Epoch: 56/100: 100%|██████████| 158/158 [00:01<00:00, 92.68it/s, train_loss=0.0225, valid_loss=0.0235]\n",
      "Epoch: 57/100: 100%|██████████| 158/158 [00:01<00:00, 95.29it/s, train_loss=0.0227, valid_loss=0.0234] \n",
      "Epoch: 58/100: 100%|██████████| 158/158 [00:01<00:00, 95.56it/s, train_loss=0.022, valid_loss=0.0234] \n",
      "Epoch: 59/100: 100%|██████████| 158/158 [00:01<00:00, 95.45it/s, train_loss=0.0237, valid_loss=0.0234]\n",
      "Epoch: 60/100: 100%|██████████| 158/158 [00:01<00:00, 95.01it/s, train_loss=0.0203, valid_loss=0.0233]\n",
      "Epoch: 61/100: 100%|██████████| 158/158 [00:01<00:00, 95.22it/s, train_loss=0.0202, valid_loss=0.0234]\n",
      "Epoch: 62/100: 100%|██████████| 158/158 [00:01<00:00, 110.54it/s, train_loss=0.0229, valid_loss=0.0234]\n",
      "Epoch: 63/100: 100%|██████████| 158/158 [00:01<00:00, 91.50it/s, train_loss=0.021, valid_loss=0.0234] \n",
      "Epoch: 64/100: 100%|██████████| 158/158 [00:01<00:00, 90.98it/s, train_loss=0.0236, valid_loss=0.0233]\n",
      "Epoch: 65/100: 100%|██████████| 158/158 [00:01<00:00, 90.95it/s, train_loss=0.0221, valid_loss=0.0233]\n",
      "Epoch: 66/100: 100%|██████████| 158/158 [00:01<00:00, 92.54it/s, train_loss=0.0215, valid_loss=0.0233] \n",
      "Epoch: 67/100: 100%|██████████| 158/158 [00:01<00:00, 92.60it/s, train_loss=0.0256, valid_loss=0.0234]\n",
      "Epoch: 68/100: 100%|██████████| 158/158 [00:01<00:00, 90.95it/s, train_loss=0.0222, valid_loss=0.0234]\n",
      "Epoch: 69/100: 100%|██████████| 158/158 [00:01<00:00, 91.22it/s, train_loss=0.0227, valid_loss=0.0234]\n",
      "Epoch: 70/100: 100%|██████████| 158/158 [00:01<00:00, 90.55it/s, train_loss=0.0216, valid_loss=0.0233]\n",
      "Epoch: 71/100: 100%|██████████| 158/158 [00:01<00:00, 94.57it/s, train_loss=0.0238, valid_loss=0.0233]\n",
      "Epoch: 72/100: 100%|██████████| 158/158 [00:01<00:00, 94.46it/s, train_loss=0.0255, valid_loss=0.0233]\n",
      "Epoch: 73/100: 100%|██████████| 158/158 [00:01<00:00, 94.03it/s, train_loss=0.0242, valid_loss=0.0233]\n",
      "Epoch: 74/100: 100%|██████████| 158/158 [00:01<00:00, 94.82it/s, train_loss=0.022, valid_loss=0.0234] \n",
      "Epoch: 75/100: 100%|██████████| 158/158 [00:01<00:00, 94.92it/s, train_loss=0.0219, valid_loss=0.0234]\n",
      "Epoch: 76/100: 100%|██████████| 158/158 [00:01<00:00, 94.08it/s, train_loss=0.0226, valid_loss=0.0233]\n",
      "Epoch: 77/100: 100%|██████████| 158/158 [00:01<00:00, 94.52it/s, train_loss=0.0224, valid_loss=0.0233]\n",
      "Epoch: 78/100: 100%|██████████| 158/158 [00:01<00:00, 94.12it/s, train_loss=0.0217, valid_loss=0.0234]\n",
      "Epoch: 79/100: 100%|██████████| 158/158 [00:01<00:00, 96.33it/s, train_loss=0.0238, valid_loss=0.0234] \n",
      "Epoch: 80/100: 100%|██████████| 158/158 [00:01<00:00, 93.89it/s, train_loss=0.0222, valid_loss=0.0234]\n",
      "Epoch: 81/100: 100%|██████████| 158/158 [00:01<00:00, 94.78it/s, train_loss=0.0223, valid_loss=0.0233]\n",
      "Epoch: 82/100: 100%|██████████| 158/158 [00:01<00:00, 94.71it/s, train_loss=0.0186, valid_loss=0.0233]\n",
      "Epoch: 83/100: 100%|██████████| 158/158 [00:01<00:00, 94.53it/s, train_loss=0.0258, valid_loss=0.0233]\n",
      "Epoch: 84/100: 100%|██████████| 158/158 [00:01<00:00, 95.48it/s, train_loss=0.0234, valid_loss=0.0234]\n",
      "Epoch: 85/100: 100%|██████████| 158/158 [00:01<00:00, 97.75it/s, train_loss=0.0228, valid_loss=0.0233] \n",
      "Epoch: 86/100: 100%|██████████| 158/158 [00:01<00:00, 94.34it/s, train_loss=0.0208, valid_loss=0.0233]\n",
      "Epoch: 87/100: 100%|██████████| 158/158 [00:01<00:00, 94.28it/s, train_loss=0.0238, valid_loss=0.0233]\n",
      "Epoch: 88/100: 100%|██████████| 158/158 [00:01<00:00, 94.72it/s, train_loss=0.0205, valid_loss=0.0233]\n",
      "Epoch: 89/100: 100%|██████████| 158/158 [00:01<00:00, 94.83it/s, train_loss=0.0234, valid_loss=0.0233]\n",
      "Epoch: 90/100: 100%|██████████| 158/158 [00:01<00:00, 94.31it/s, train_loss=0.0227, valid_loss=0.0233]\n",
      "Epoch: 91/100: 100%|██████████| 158/158 [00:01<00:00, 94.72it/s, train_loss=0.0235, valid_loss=0.0234]\n",
      "Epoch: 92/100: 100%|██████████| 158/158 [00:01<00:00, 94.51it/s, train_loss=0.0229, valid_loss=0.0234]\n",
      "Epoch: 93/100: 100%|██████████| 158/158 [00:01<00:00, 96.46it/s, train_loss=0.0228, valid_loss=0.0233]\n",
      "Epoch: 94/100: 100%|██████████| 158/158 [00:01<00:00, 94.24it/s, train_loss=0.0212, valid_loss=0.0233]\n",
      "Epoch: 95/100: 100%|██████████| 158/158 [00:01<00:00, 94.29it/s, train_loss=0.0249, valid_loss=0.0233]\n",
      "Epoch: 96/100: 100%|██████████| 158/158 [00:01<00:00, 94.18it/s, train_loss=0.0216, valid_loss=0.0233]\n",
      "Epoch: 97/100: 100%|██████████| 158/158 [00:01<00:00, 95.11it/s, train_loss=0.0205, valid_loss=0.0233]\n",
      "Epoch: 98/100: 100%|██████████| 158/158 [00:01<00:00, 94.14it/s, train_loss=0.0226, valid_loss=0.0233]\n",
      "Epoch: 99/100: 100%|██████████| 158/158 [00:01<00:00, 94.90it/s, train_loss=0.0255, valid_loss=0.0233]\n",
      "Epoch: 100/100: 100%|██████████| 158/158 [00:01<00:00, 94.33it/s, train_loss=0.0211, valid_loss=0.0233]\n",
      "Epoch: 1/100: 100%|██████████| 158/158 [00:01<00:00, 87.69it/s, train_loss=0.0288, valid_loss=0.0307]\n",
      "Epoch: 2/100: 100%|██████████| 158/158 [00:01<00:00, 91.62it/s, train_loss=0.0219, valid_loss=0.0248]\n",
      "Epoch: 3/100: 100%|██████████| 158/158 [00:01<00:00, 90.68it/s, train_loss=0.00868, valid_loss=0.0103]\n",
      "Epoch: 4/100: 100%|██████████| 158/158 [00:01<00:00, 90.42it/s, train_loss=0.00871, valid_loss=0.00991]\n",
      "Epoch: 5/100: 100%|██████████| 158/158 [00:01<00:00, 91.18it/s, train_loss=0.0082, valid_loss=0.00968] \n",
      "Epoch: 6/100: 100%|██████████| 158/158 [00:01<00:00, 91.01it/s, train_loss=0.00903, valid_loss=0.00967]\n",
      "Epoch: 7/100: 100%|██████████| 158/158 [00:01<00:00, 90.94it/s, train_loss=0.00859, valid_loss=0.00964]\n",
      "Epoch: 8/100: 100%|██████████| 158/158 [00:01<00:00, 91.41it/s, train_loss=0.00826, valid_loss=0.00962]\n",
      "Epoch: 9/100: 100%|██████████| 158/158 [00:01<00:00, 91.41it/s, train_loss=0.00983, valid_loss=0.0096] \n",
      "Epoch: 10/100: 100%|██████████| 158/158 [00:01<00:00, 90.87it/s, train_loss=0.0081, valid_loss=0.00957] \n",
      "Epoch: 11/100: 100%|██████████| 158/158 [00:01<00:00, 92.74it/s, train_loss=0.00896, valid_loss=0.00959]\n",
      "Epoch: 12/100: 100%|██████████| 158/158 [00:01<00:00, 91.31it/s, train_loss=0.00818, valid_loss=0.00951]\n",
      "Epoch: 13/100: 100%|██████████| 158/158 [00:01<00:00, 90.75it/s, train_loss=0.00803, valid_loss=0.00947]\n",
      "Epoch: 14/100: 100%|██████████| 158/158 [00:01<00:00, 91.24it/s, train_loss=0.00764, valid_loss=0.00958]\n",
      "Epoch: 15/100: 100%|██████████| 158/158 [00:01<00:00, 90.86it/s, train_loss=0.00905, valid_loss=0.00946]\n",
      "Epoch: 16/100: 100%|██████████| 158/158 [00:01<00:00, 90.85it/s, train_loss=0.00976, valid_loss=0.00946]\n",
      "Epoch: 17/100: 100%|██████████| 158/158 [00:01<00:00, 90.87it/s, train_loss=0.00886, valid_loss=0.00943]\n",
      "Epoch: 18/100: 100%|██████████| 158/158 [00:01<00:00, 91.10it/s, train_loss=0.00941, valid_loss=0.00943]\n",
      "Epoch: 19/100: 100%|██████████| 158/158 [00:01<00:00, 91.07it/s, train_loss=0.00829, valid_loss=0.00952]\n",
      "Epoch: 20/100: 100%|██████████| 158/158 [00:01<00:00, 92.48it/s, train_loss=0.00844, valid_loss=0.00942]\n",
      "Epoch: 21/100: 100%|██████████| 158/158 [00:01<00:00, 91.20it/s, train_loss=0.00975, valid_loss=0.0094] \n",
      "Epoch: 22/100: 100%|██████████| 158/158 [00:01<00:00, 91.19it/s, train_loss=0.00966, valid_loss=0.00941]\n",
      "Epoch: 23/100: 100%|██████████| 158/158 [00:01<00:00, 90.97it/s, train_loss=0.00872, valid_loss=0.0094] \n",
      "Epoch: 24/100: 100%|██████████| 158/158 [00:01<00:00, 91.46it/s, train_loss=0.00779, valid_loss=0.00939]\n",
      "Epoch: 25/100: 100%|██████████| 158/158 [00:01<00:00, 91.24it/s, train_loss=0.00801, valid_loss=0.00945]\n",
      "Epoch: 26/100: 100%|██████████| 158/158 [00:01<00:00, 90.94it/s, train_loss=0.00932, valid_loss=0.00937]\n",
      "Epoch: 27/100: 100%|██████████| 158/158 [00:01<00:00, 91.13it/s, train_loss=0.00861, valid_loss=0.00934]\n",
      "Epoch: 28/100: 100%|██████████| 158/158 [00:01<00:00, 91.01it/s, train_loss=0.0081, valid_loss=0.00938] \n",
      "Epoch: 29/100: 100%|██████████| 158/158 [00:01<00:00, 92.38it/s, train_loss=0.00857, valid_loss=0.0094] \n",
      "Epoch: 30/100: 100%|██████████| 158/158 [00:01<00:00, 96.87it/s, train_loss=0.00839, valid_loss=0.00933] \n",
      "Epoch: 31/100: 100%|██████████| 158/158 [00:01<00:00, 90.40it/s, train_loss=0.00833, valid_loss=0.00935]\n",
      "Epoch: 32/100: 100%|██████████| 158/158 [00:01<00:00, 90.70it/s, train_loss=0.00801, valid_loss=0.00932]\n",
      "Epoch: 33/100: 100%|██████████| 158/158 [00:01<00:00, 91.97it/s, train_loss=0.00881, valid_loss=0.0094] \n",
      "Epoch: 34/100: 100%|██████████| 158/158 [00:01<00:00, 92.08it/s, train_loss=0.00901, valid_loss=0.00934] \n",
      "Epoch: 35/100: 100%|██████████| 158/158 [00:01<00:00, 91.20it/s, train_loss=0.00976, valid_loss=0.00932]\n",
      "Epoch: 36/100: 100%|██████████| 158/158 [00:01<00:00, 90.65it/s, train_loss=0.00772, valid_loss=0.00936]\n",
      "Epoch: 37/100: 100%|██████████| 158/158 [00:01<00:00, 90.92it/s, train_loss=0.00826, valid_loss=0.0093] \n",
      "Epoch: 38/100: 100%|██████████| 158/158 [00:01<00:00, 91.72it/s, train_loss=0.00893, valid_loss=0.00931]\n",
      "Epoch: 39/100: 100%|██████████| 158/158 [00:01<00:00, 90.97it/s, train_loss=0.00881, valid_loss=0.00929]\n",
      "Epoch: 40/100: 100%|██████████| 158/158 [00:01<00:00, 90.81it/s, train_loss=0.00799, valid_loss=0.0093] \n",
      "Epoch: 41/100: 100%|██████████| 158/158 [00:01<00:00, 92.59it/s, train_loss=0.00954, valid_loss=0.00931]\n",
      "Epoch: 42/100: 100%|██████████| 158/158 [00:01<00:00, 92.67it/s, train_loss=0.00911, valid_loss=0.00928]\n",
      "Epoch: 43/100: 100%|██████████| 158/158 [00:01<00:00, 91.32it/s, train_loss=0.00832, valid_loss=0.00934]\n",
      "Epoch: 44/100: 100%|██████████| 158/158 [00:01<00:00, 92.20it/s, train_loss=0.00815, valid_loss=0.00928]\n",
      "Epoch: 45/100: 100%|██████████| 158/158 [00:01<00:00, 91.36it/s, train_loss=0.00883, valid_loss=0.00928]\n",
      "Epoch: 46/100: 100%|██████████| 158/158 [00:01<00:00, 91.98it/s, train_loss=0.00827, valid_loss=0.00928]\n",
      "Epoch: 47/100: 100%|██████████| 158/158 [00:01<00:00, 92.60it/s, train_loss=0.00796, valid_loss=0.00939]\n",
      "Epoch: 48/100: 100%|██████████| 158/158 [00:01<00:00, 90.89it/s, train_loss=0.00726, valid_loss=0.00927]\n",
      "Epoch: 49/100: 100%|██████████| 158/158 [00:01<00:00, 91.68it/s, train_loss=0.00849, valid_loss=0.00929]\n",
      "Epoch: 50/100: 100%|██████████| 158/158 [00:01<00:00, 90.48it/s, train_loss=0.00816, valid_loss=0.00927]\n",
      "Epoch: 51/100: 100%|██████████| 158/158 [00:01<00:00, 91.07it/s, train_loss=0.00809, valid_loss=0.00932]\n",
      "Epoch: 52/100: 100%|██████████| 158/158 [00:01<00:00, 92.19it/s, train_loss=0.00781, valid_loss=0.00927] \n",
      "Epoch: 53/100: 100%|██████████| 158/158 [00:01<00:00, 90.66it/s, train_loss=0.0094, valid_loss=0.00926] \n",
      "Epoch: 54/100: 100%|██████████| 158/158 [00:01<00:00, 92.04it/s, train_loss=0.00841, valid_loss=0.00927]\n",
      "Epoch: 55/100: 100%|██████████| 158/158 [00:01<00:00, 91.15it/s, train_loss=0.00871, valid_loss=0.00927]\n",
      "Epoch: 56/100: 100%|██████████| 158/158 [00:01<00:00, 91.54it/s, train_loss=0.00888, valid_loss=0.00936]\n",
      "Epoch: 57/100: 100%|██████████| 158/158 [00:01<00:00, 92.30it/s, train_loss=0.00926, valid_loss=0.00926]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 58/100: 100%|██████████| 158/158 [00:01<00:00, 91.10it/s, train_loss=0.00919, valid_loss=0.00928]\n",
      "Epoch: 59/100: 100%|██████████| 158/158 [00:01<00:00, 90.90it/s, train_loss=0.00913, valid_loss=0.00926]\n",
      "Epoch: 60/100: 100%|██████████| 158/158 [00:01<00:00, 91.06it/s, train_loss=0.00859, valid_loss=0.00927]\n",
      "Epoch: 61/100: 100%|██████████| 158/158 [00:01<00:00, 91.22it/s, train_loss=0.00876, valid_loss=0.00928]\n",
      "Epoch: 62/100: 100%|██████████| 158/158 [00:01<00:00, 91.92it/s, train_loss=0.00852, valid_loss=0.00926] \n",
      "Epoch: 63/100: 100%|██████████| 158/158 [00:01<00:00, 91.10it/s, train_loss=0.00767, valid_loss=0.0093] \n",
      "Epoch: 64/100: 100%|██████████| 158/158 [00:01<00:00, 90.96it/s, train_loss=0.00904, valid_loss=0.00927]\n",
      "Epoch: 65/100: 100%|██████████| 158/158 [00:01<00:00, 91.46it/s, train_loss=0.00916, valid_loss=0.00923]\n",
      "Epoch: 66/100: 100%|██████████| 158/158 [00:01<00:00, 91.99it/s, train_loss=0.0085, valid_loss=0.00923] \n",
      "Epoch: 67/100: 100%|██████████| 158/158 [00:01<00:00, 91.62it/s, train_loss=0.00806, valid_loss=0.0093] \n",
      "Epoch: 68/100: 100%|██████████| 158/158 [00:01<00:00, 90.87it/s, train_loss=0.00967, valid_loss=0.00924]\n",
      "Epoch: 69/100: 100%|██████████| 158/158 [00:01<00:00, 91.10it/s, train_loss=0.00801, valid_loss=0.00927]\n",
      "Epoch: 70/100: 100%|██████████| 158/158 [00:01<00:00, 91.84it/s, train_loss=0.00822, valid_loss=0.00927] \n",
      "Epoch: 71/100: 100%|██████████| 158/158 [00:01<00:00, 91.65it/s, train_loss=0.00792, valid_loss=0.00928]\n",
      "Epoch: 72/100: 100%|██████████| 158/158 [00:01<00:00, 91.29it/s, train_loss=0.00839, valid_loss=0.00929]\n",
      "Epoch: 73/100: 100%|██████████| 158/158 [00:01<00:00, 91.20it/s, train_loss=0.00837, valid_loss=0.00926]\n",
      "Epoch: 74/100: 100%|██████████| 158/158 [00:01<00:00, 91.55it/s, train_loss=0.00769, valid_loss=0.00929]\n",
      "Epoch: 75/100: 100%|██████████| 158/158 [00:01<00:00, 91.18it/s, train_loss=0.00913, valid_loss=0.00925]\n",
      "Epoch: 76/100: 100%|██████████| 158/158 [00:01<00:00, 90.56it/s, train_loss=0.00808, valid_loss=0.00923]\n",
      "Epoch: 77/100: 100%|██████████| 158/158 [00:01<00:00, 91.31it/s, train_loss=0.00809, valid_loss=0.00926]\n",
      "Epoch: 78/100: 100%|██████████| 158/158 [00:01<00:00, 90.60it/s, train_loss=0.00812, valid_loss=0.00924]\n",
      "Epoch: 79/100: 100%|██████████| 158/158 [00:01<00:00, 92.28it/s, train_loss=0.00959, valid_loss=0.00924]\n",
      "Epoch: 80/100: 100%|██████████| 158/158 [00:01<00:00, 91.05it/s, train_loss=0.00805, valid_loss=0.00926]\n",
      "Epoch: 81/100: 100%|██████████| 158/158 [00:01<00:00, 91.31it/s, train_loss=0.00929, valid_loss=0.00924]\n",
      "Epoch: 82/100: 100%|██████████| 158/158 [00:01<00:00, 90.97it/s, train_loss=0.0086, valid_loss=0.00924] \n",
      "Epoch: 83/100: 100%|██████████| 158/158 [00:01<00:00, 91.04it/s, train_loss=0.00794, valid_loss=0.00926]\n",
      "Epoch: 84/100: 100%|██████████| 158/158 [00:01<00:00, 90.77it/s, train_loss=0.00948, valid_loss=0.00927]\n",
      "Epoch: 85/100: 100%|██████████| 158/158 [00:01<00:00, 91.52it/s, train_loss=0.00819, valid_loss=0.00923]\n",
      "Epoch: 86/100: 100%|██████████| 158/158 [00:01<00:00, 91.02it/s, train_loss=0.0093, valid_loss=0.00926] \n",
      "Epoch: 87/100: 100%|██████████| 158/158 [00:01<00:00, 92.03it/s, train_loss=0.00866, valid_loss=0.00922]\n",
      "Epoch: 88/100: 100%|██████████| 158/158 [00:01<00:00, 90.88it/s, train_loss=0.00878, valid_loss=0.0092] \n",
      "Epoch: 89/100: 100%|██████████| 158/158 [00:01<00:00, 90.80it/s, train_loss=0.00765, valid_loss=0.00921]\n",
      "Epoch: 90/100: 100%|██████████| 158/158 [00:01<00:00, 91.29it/s, train_loss=0.00865, valid_loss=0.00922]\n",
      "Epoch: 91/100: 100%|██████████| 158/158 [00:01<00:00, 99.37it/s, train_loss=0.00831, valid_loss=0.00928] \n",
      "Epoch: 92/100: 100%|██████████| 158/158 [00:01<00:00, 90.58it/s, train_loss=0.0088, valid_loss=0.00925] \n",
      "Epoch: 93/100: 100%|██████████| 158/158 [00:01<00:00, 91.66it/s, train_loss=0.00797, valid_loss=0.00923]\n",
      "Epoch: 94/100: 100%|██████████| 158/158 [00:01<00:00, 92.40it/s, train_loss=0.00891, valid_loss=0.00925]\n",
      "Epoch: 95/100: 100%|██████████| 158/158 [00:01<00:00, 92.00it/s, train_loss=0.0093, valid_loss=0.00922] \n",
      "Epoch: 96/100: 100%|██████████| 158/158 [00:01<00:00, 90.63it/s, train_loss=0.00807, valid_loss=0.00922]\n",
      "Epoch: 97/100: 100%|██████████| 158/158 [00:01<00:00, 91.66it/s, train_loss=0.00875, valid_loss=0.00921]\n",
      "Epoch: 98/100: 100%|██████████| 158/158 [00:01<00:00, 91.18it/s, train_loss=0.00901, valid_loss=0.00921]\n",
      "Epoch: 99/100: 100%|██████████| 158/158 [00:01<00:00, 91.24it/s, train_loss=0.00827, valid_loss=0.00922]\n",
      "Epoch: 100/100: 100%|██████████| 158/158 [00:01<00:00, 90.92it/s, train_loss=0.00843, valid_loss=0.00924]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised Data: Shape of x: (6237, 72, 1), Shape of y: (6237, 24)\n",
      "MAPE:0.05404650729781903, MAE:725.595058841699, RMSE:1670.5218134095212\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvQUlEQVR4nO3de3yU9Z3o8c/3mZnM5AYBAklIULCAiHI1Al0Vad2tiG5prXVx11rc4+G4q6vWxVa77Vnb9ZzuntPTdT21cNit9uaWtlQrba3aKuOlRbkIckfCrQnXJCQhk2Qyt9/5YybDZGYSJiEwMw/f9+uVV2ae5/d7nu/zJPnmN9/nJsYYlFJK2ZeV7QCUUkqdX5rolVLK5jTRK6WUzWmiV0opm9NEr5RSNufMdgDplJeXm/Hjxw+qb0dHB8XFxUMb0AWSz7GDxp9N+Rw75Hf8uRL75s2bm4wxo9PNy8lEP378eDZt2jSovl6vlwULFgxtQBdIPscOGn825XPskN/x50rsInK4r3laulFKKZvTRK+UUjaniV4ppWwuJ2v0Sil7CQaDNDQ04Pf7084fPnw4u3fvvsBRDY0LHbvH46GmpgaXy5VxH030SqnzrqGhgdLSUsaPH4+IpMxvb2+ntLQ0C5GduwsZuzGG5uZmGhoamDBhQsb9tHSjlDrv/H4/o0aNSpvkVeZEhFGjRvX5yagvmuiVUheEJvmhMZj9mFGiF5GFIrJXROpE5LE086eIyHoR6RaR5WnmO0Rki4j8asARDsA/vflPbDi14XyuQiml8s5ZE72IOIBngJuBqcCdIjI1qdkp4EHgm30s5iHgvB+t+MY73+D9lvfP92qUUiqvZDKinwPUGWMOGGMCwGpgcWIDY8xJY8xGIJjcWURqgFuA/xiCePtliYVBH6SilOqttbWV73znOwPut2jRIlpbWwfcb+nSpaxZs2bA/c6XTM66qQbqE943AHMHsI6ngC8C/R6WFpFlwDKAiooKvF7vAFYRFYlE6A50D6pvLvD5fHkbO2j82ZTrsQ8fPpz29vY+54fD4X7nn6uGhga+/e1v87nPfS5lvQ6Ho89+P/nJTwAGHHswGKSrq+u8bZPf7x/QzzuTRJ+u8p/RsFlEbgVOGmM2i8iC/toaY1YBqwBqa2vNYO4d4XjTgeuUKyfuOzEYuXLPjMHS+LMn12PfvXt3/BTEfQ/vw7fV12v+2RLu2ZTMLGHSU5P6nP/kk09y8OBBrr/+elwuFyUlJVRVVbF161Z27drFpz71Kerr6/H7/Tz00EMsW7YMOHPfLZ/Px80338x1113HH/7wB6qrq3nppZcoLCxMe3qly+WisLCQ0tJSXn/9dZYvX04oFOKaa65hxYoVuN1uHnvsMdauXYvT6eQTn/gE3/zmN/nZz37G1772NRwOB8OHD+ett95Kuz0ej4dZs2ZlvH8ySfQNwLiE9zXA0QyXfy3wSRFZBHiAYSLyI2PMXRlHOBB+MJ1aulFK9fbP//zP7Nixg61bt+L1ernlllvYsWNH/Fz0Z599lpEjR9LV1cU111zDZz7zGUaNGtVrGfv27ePHP/4x//7v/84dd9zBz3/+c+66q/9U5vf7Wbp0Ka+//jqTJ0/m7rvvZsWKFdx99928+OKL7NmzBxGJl4e+/vWv8+qrr1JdXT2oklFfMkn0G4FJIjIBOAIsAf4yk4UbYx4HHgeIjeiXn7ckHxMxkfO5eKXUOUo38r7QF0zNmTOn1wVHTz/9NC+++CIA9fX17Nu3LyXRT5gwgZkzZwJw9dVXc+jQobOuZ+/evUyYMIHJkycD8PnPf55nnnmGBx54AI/Hw7333sstt9zCrbfeCsC1117L0qVLueOOO7jtttuGYEujznow1hgTAh4AXiV65sxPjTE7ReQ+EbkPQEQqRaQBeAT4iog0iMiwIYsyQ4JkWFRSSl3MEu8f7/V6+d3vfsf69ev54IMPmDVrVtoLktxud/y1w+EgFAqddT3GpE9ITqeTDRs28JnPfIZf/OIXLFy4EICVK1fy5JNPUl9fz8yZM2lubh7opqVfXyaNjDEvAy8nTVuZ8Po40ZJOf8vwAt4BRzgAYkTPulFKpSgtLe3zwGhbWxsjRoygqKiIPXv28O677w7ZeqdMmcKhQ4eoq6tj4sSJ/PCHP+SGG27A5/PR2dnJokWLmDdvHhMnTgRg//79zJ07l7lz5/LLX/6S+vr6lE8Wg2Gre91YWH3+B1VKXbxGjRrFtddey1VXXUVhYSEVFRXxeQsXLmTlypVMnz6dyy+/nHnz5g3Zej0eD8899xyf/exn4wdj77vvPk6dOsXixYvx+/0YY/jXf/1XAB599FH27duHMYYbb7yRGTNmDEkctkr0gI7olVJp/ed//mfa6W63m9/85jdp5/XU4cvLy9mxY0d8+vLlKTcA6OV73/te/PWNN97Ili1bes2vqqpiw4bUq/hfeOGFfpc7WLa6140Y0RG9UkolsdWIXks3SqkL6f777+ftt9/Gss6MmR966CHuueeeLEaVylaJXtCDsUqpC+eZZ57Ji3vp26p0A1qjV0qpZLZK9FqjV0qpVLZK9BYWRjTRK6VUIlsler1gSimlUtkq0YPW6JVS566kpASAo0ePcvvtt6dts2DBAjZt2tTnMsaPH09TU9N5iW+gbJXoLaMPHlFKDZ2xY8fm1ANEBktPr1RKXVAPv/IwW49v7TXtXO9HP7NyJk8tfKrP+V/60pe49NJL+du//VsAnnjiCUSEt956i5aWFoLBIE8++SSLF/d6eB6HDh3i1ltvZceOHXR1dXHPPfewa9currjiCrq6ujKO71vf+hbPPvssAPfeey8PP/wwHR0d3HHHHTQ0NBAOh/nqV7/KX/zFX6S9T/250kSvlLK9JUuW8PDDD8cT/U9/+lNeeeUVvvCFLzBs2DCampqYN28en/zkJxFJ96wlWLFiBUVFRWzbto1t27Yxe/bsjNa9efNmnnvuOd577z2MMcydO5cbbriBAwcOMHbsWH79618D0ZurnTp1Ku196s+VrRI9aI1eqVyXbuR9vi86mjVrFidPnuTo0aM0NjYyYsQIqqqq+MIXvsBbb72FZVkcOXKEEydOUFlZmXYZb731Fg8++CAA06dPZ/r06Rmt+5133uHTn/50/NbIt912G2+//TYLFy5k+fLlfOlLX+LWW2/l+uuvJxQKpb1P/bmyXY1eKaXSuf3221mzZg0/+clPWLJkCc8//zyNjY1s3ryZrVu3UlFRkfY+9In6Gu33p69reyZPnszmzZuZNm0ajz/+OF//+tf7vE/9ubJVZhSECPqEKaVUqiVLlrB69WrWrFnD7bffTltbG2PGjMHlcrFu3ToOHz7cb//58+fz/PPPA7Bjxw62bduW0Xrnz5/PL37xCzo7O+no6ODFF1/k+uuv5+jRoxQVFXHXXXexfPly3n//fXw+H21tbSxatIinnnqKrVu3nutmAzYr3QiiF0wppdK68soraW9vp7q6mqqqKv7qr/6KP//zP6e2tpaZM2cyZcqUfvv/zd/8Dffccw/Tp09n5syZzJkzJ6P1zp49m6VLl8bb33vvvcyaNYtXX32VRx99FMuycLlcrFixgvb29rT3qT9Xtkr0Wp5XSvVn+/bt8dfl5eWsX78+bTufzwdEz4XvuQ99YWEhq1evTmnb15OrEp8p+8gjj/DII4/0mn/TTTdx0003pfRLd5/6c2Wr0o2FpaUbpZRKYqsRvTDwAyVKKXUuPvaxj6U8KPyHP/wh06ZNy1JEqeyV6PVeN0rlLGPMoM5ayXXr1q27oPejH8wdejMq3YjIQhHZKyJ1IvJYmvlTRGS9iHSLyPKE6eNEZJ2I7BaRnSLy0IAjHAA9GKtUbvJ4PDQ3N+ttxM+RMYbm5mY8Hs+A+p11RC8iDuAZ4M+ABmCjiKw1xuxKaHYKeBD4VFL3EPD3xpj3RaQU2Cwiv03qO2T0ylilclNNTQ0NDQ00Njamne/3+wecvHLFhY7d4/FQU1MzoD6ZlG7mAHXGmAMAIrIaWAzEk7Ux5iRwUkRuSexojDkGHIu9bheR3UB1Yt+hpIleqdzkcrmYMGFCn/O9Xi+zZs26gBENnXyIPZNEXw3UJ7xvAOYOdEUiMh6YBbzXx/xlwDKAiooKvF7vQFdBJBwhYiKD6psLfD5f3sYOGn825XPskN/x50PsmST6dEdPBjRsFpES4OfAw8aY0+naGGNWAasAamtrzYIFCwayCgCcv3BCJHqf6Hzk9XrzNnbQ+LMpn2OH/I4/H2LP5GBsAzAu4X0NcDTTFYiIi2iSf94Y88LAwhsYPRirlFKpMkn0G4FJIjJBRAqAJcDaTBYu0XOpvgvsNsZ8a/BhZkZr9EopleqspRtjTEhEHgBeBRzAs8aYnSJyX2z+ShGpBDYBw4CIiDwMTAWmA58DtovI1tgiv2yMeXnItwR9wpRSSqWT0QVTscT8ctK0lQmvjxMt6SR7h/Q1/vNGE71SSvVmq3vdaOlGKaVSaaJXSimbs1Wit4x1gQtFSimV+2yV6PUJU0oplcpWiR70YKxSSiWzVaK37LU5Sik1JGyVGQUhIlq6UUqpRPZK9PrgEaWUSmGvRK+n3CilVArbJXod0SulVG+2S/Rao1dKqd5sl+iVUkr1ZqtEb6F3r1RKqWS2SvSAlm6UUiqJrRK9GC3dKKVUMnslej3rRimlUtgq0WuNXimlUtkq0evDwZVSKpX9Er2O6JVSqhdN9EopZXMZJXoRWSgie0WkTkQeSzN/ioisF5FuEVk+kL5DSUs3SimV6qyJXkQcwDPAzcBU4E4RmZrU7BTwIPDNQfQdMjqiV0qpVJmM6OcAdcaYA8aYALAaWJzYwBhz0hizEQgOtO9Q0kSvlFKpnBm0qQbqE943AHMzXH7GfUVkGbAMoKKiAq/Xm+EqzggFQhi3GVTfXODz+fI2dtD4symfY4f8jj8fYs8k0ae73DTTYXPGfY0xq4BVALW1tWbBggUZruKMf1nzLxgxDKZvLvB6vXkbO2j82ZTPsUN+x58PsWdSumkAxiW8rwGOZrj8c+k7YFq6UUqpVJkk+o3AJBGZICIFwBJgbYbLP5e+A2YZK/1nCKWUuoidtXRjjAmJyAPAq4ADeNYYs1NE7ovNXykilcAmYBgQEZGHganGmNPp+p6nbUFEiKB3r1RKqUSZ1OgxxrwMvJw0bWXC6+NEyzIZ9T1f9Dx6pZRKZbsrY5VSSvVmr0Rv9GCsUkols1eiF304uFJKJbNXotfSjVJKpbBdotfSjVJK9WarRG9haelGKaWS2CrRa+lGKaVS2SrRA3oevVJKJbFVoteHgyulVCpbJXq9MlYppVLZL9HriF4ppXrRRK+UUjZnq0RvYWnpRimlktgq0QM6oldKqSS2SvQiejBWKaWS2SrRW0ZPr1RKqWS2SvR6eqVSSqWyV6IXPetGKaWS2SvR6+mVSimVwnaJXu9rppRSvWWU6EVkoYjsFZE6EXkszXwRkadj87eJyOyEeV8QkZ0iskNEfiwinqHcgF5xoE+YUkqpZGdN9CLiAJ4BbgamAneKyNSkZjcDk2Jfy4AVsb7VwINArTHmKsABLBmy6JPoTc2UUipVJiP6OUCdMeaAMSYArAYWJ7VZDPzARL0LlIlIVWyeEygUESdQBBwdothT6P3olVIqlTODNtVAfcL7BmBuBm2qjTGbROSbwB+BLuA1Y8xr6VYiIsuIfhqgoqICr9eb0QYk6uzoJFIeGVTfXODz+fI2dtD4symfY4f8jj8fYs8k0acbJifXR9K2EZERREf7E4BW4Gcicpcx5kcpjY1ZBawCqK2tNQsWLMggtN5++sJPARhM31zg9XrzNnbQ+LMpn2OH/I4/H2LPpHTTAIxLeF9DavmlrzZ/Chw0xjQaY4LAC8CfDD7c/vWUbozROr1SSvXIJNFvBCaJyAQRKSB6MHVtUpu1wN2xs2/mAW3GmGNESzbzRKRIRAS4Edg9hPH3Ek/0ekBWKaXizlq6McaEROQB4FWiZ808a4zZKSL3xeavBF4GFgF1QCdwT2zeeyKyBngfCAFbiJVnzgcr9n8rYiJYYqtLBJRSatAyqdFjjHmZaDJPnLYy4bUB7u+j7z8C/3gOMWZMSzdKKZXKVsNeLd0opVQqeyV6iSb6iNGrY5VSqoe9Er2WbpRSKoU9E72WbpRSKs5Wib7nrBsd0Sul1Bm2SvRao1dKqVT2SvRaulFKqRT2TPRaulFKqThbJnot3Sil1Bm2SvQ9tz3Q0o1SSp1hq0TfQ0s3Sil1hq0Sffz0Sh3RK6VUnK0SvdbolVIqlb0SvehZN0oplcxWiV5LN0oplcpWiV5LN0oplcpeiV5LN0oplcJeiV5vgaCUUilsleidRdEnI0ZCWrpRSqketkr0DrcDgHA4nOVIlFIqd9gq0feIRHREr5RSPTJK9CKyUET2ikidiDyWZr6IyNOx+dtEZHbCvDIRWSMie0Rkt4h8dCg3IFH8XjdhrdErpVSPsyZ6EXEAzwA3A1OBO0VkalKzm4FJsa9lwIqEef8GvGKMmQLMAHYPQdxpWVZ0c/T0SqWUOiOTEf0coM4Yc8AYEwBWA4uT2iwGfmCi3gXKRKRKRIYB84HvAhhjAsaY1qELv7f4E6bCmuiVUqqHM4M21UB9wvsGYG4GbaqBENAIPCciM4DNwEPGmI7klYjIMqKfBqioqMDr9Wa4CWc0nmyE4bBpwyaOHzg+4P7Z5vP5BrXduULjz558jh3yO/58iD2TRC9ppiUXwftq4wRmA39njHlPRP4NeAz4akpjY1YBqwBqa2vNggULMgitt+0btkMXzLp6FldOuHLA/bPN6/UymO3OFRp/9uRz7JDf8edD7JmUbhqAcQnva4CjGbZpABqMMe/Fpq8hmvjPC7G0dKOUUskySfQbgUkiMkFECoAlwNqkNmuBu2Nn38wD2owxx4wxx4F6Ebk81u5GYNdQBZ8sfq8bPb1SKaXizlq6McaEROQB4FXAATxrjNkpIvfF5q8EXgYWAXVAJ3BPwiL+Dng+9k/iQNK8IdVz1g2a55VSKi6TGj3GmJeJJvPEaSsTXhvg/j76bgVqBx9i5nrOo9fTK5VS6gxbXRkbr9Fr6UYppeLsleh77l6pV8YqpVScrRK9XhmrlFKpbJXo41fGaulGKaXi7JXotUavlFIpbJXo43evjGiNXimletgy0euIXimlzrBXorc00SulVDJbJfpCqxCAzmBnliNRSqncYatEX+QoAqAjmHIXZKWUumjZKtGXOEsA8AV9WY5EKaVyh60SfbGzGIDTgdNZjkQppXKHrRJ9hasCK2JxpPNItkNRSqmcYatE73K4GNM2hoMdB7MdilJK5QxbJXqxhLEtYzngO5DtUJRSKmfYKtFjQVVLFYc7D2c7EqWUyhn2SvRA9alqmgJNtHe3ZzsUpZTKCbZL9FUtVQAcaNHyjVJKgc0SvThFE71SSiWxV6J3CNUt1QDsb9mf5WiUUio3ZJToRWShiOwVkToReSzNfBGRp2Pzt4nI7KT5DhHZIiK/GqrA08bpFEr8JZR2leqIXimlYs6a6EXEATwD3AxMBe4UkalJzW4GJsW+lgErkuY/BOw+52jPQhzRB49UtlRqoldKqZhMRvRzgDpjzAFjTABYDSxOarMY+IGJehcoE5EqABGpAW4B/mMI405LnNFEX95ezrGWY+d7dUoplRecGbSpBuoT3jcAczNoUw0cA54CvgiU9rcSEVlG9NMAFRUVeL3eDEJLsiv6rai7iMPthwe3jCzy+Xx5F3MijT978jl2yO/48yH2TBK9pJmW/Ky+tG1E5FbgpDFms4gs6G8lxphVwCqA2tpas2BBv83TL+N6w5v3v0lhoJBgKMhglpFNXq8372JOpPFnTz7HDvkdfz7EnknppgEYl/C+BjiaYZtrgU+KyCGiJZ+Pi8iPBh3tWfTU6D1BDz6/3qpYKaUgs0S/EZgkIhNEpABYAqxNarMWuDt29s08oM0Yc8wY87gxpsYYMz7W7w1jzF1DuQHpFAYK8Rf4MUYfEq6UUmct3RhjQiLyAPAq4ACeNcbsFJH7YvNXAi8Di4A6oBO45/yFfBZ/CZ4/ejBi8If8FLoKsxaKUkrlgkxq9BhjXiaazBOnrUx4bYD7z7IML+AdcIQD5QdPwANEHymoiV4pdbGz1ZWxAPiiNXqAjoA+O1YppeyX6O/uPaJXSqmLnf0SfTXU3FID6IheKaXAjokeKJIiQEf0SikFdk/0OqJXSil7JnpXswsAX0AvmlJKKVsm+o6fRUfyTXubshyJUkplny0TfVlHGQDHOvQOlkopZctE7wl6GNU+in0N+7IdilJKZV1GV8bmo6qWKvY078l2GEoplXW2HNFf8vgljGsaR315/dkbK6WUzdky0dc8UsP4xvG0lLSw98W92Q5HKaWyypaJvqC8gEsbLwXgV/9wXp9HrpRSOc+WiR5g+uHpeAIevB/x0vRLPc1SKXXxsm2iLwwWct2e6/hV7a94+863sx2OUkpljW0TPcAnN30SgOV3L6epU0f1SqmLk60T/bQ/TuPLL3yZ+lH1TP7HyezZp6dbKqUuPrZO9AB/tu3P+Mbz36ClpIXV/7o62+EopdQFZ9tEf/Wmq+OvLz92OQAdXXo3S6XUxce2ib706lKKZxQDUBAsAKAr2JXNkJRSKisySvQislBE9opInYg8lma+iMjTsfnbRGR2bPo4EVknIrtFZKeIPDTUG9CfSU9PAsAVdmFFLGSKXMjVK6VUTjhrohcRB/AMcDMwFbhTRKYmNbsZmBT7WgasiE0PAX9vjLkCmAfcn6bveVM2vwwAQSgIFeA3/gu1aqWUyhmZjOjnAHXGmAPGmACwGlic1GYx8AMT9S5QJiJVxphjxpj3AYwx7cBuoHoI4z+rqzddzZg7x+AJeugMdV7IVSulVE7I5O6V1UDi3cEagLkZtKkG4jeEF5HxwCzgvXQrEZFlRD8NUFFRgdfrzSC0VD6fL7XvMnCvddPc1jzo5V4IaWPPIxp/9uRz7JDf8edD7Jkk+nSFbTOQNiJSAvwceNgYczrdSowxq4BVALW1tWbBggUZhJbK6/WSrq/nRQ9SKGnn5Yq+Ys8XGn/25HPskN/x50PsmZRuGoBxCe9rgKOZthERF9Ek/7wx5oXBh3puPBGP1uiVUhelTBL9RmCSiEwQkQJgCbA2qc1a4O7Y2TfzgDZjzDEREeC7wG5jzLeGNPIBchs3XRE9vVIpdfE5a+nGGBMSkQeAVwEH8KwxZqeI3BebvxJ4GVgE1AGdwD2x7tcCnwO2i8jW2LQvG2NeHtKtyIAHD11ooldKXXwyepRgLDG/nDRtZcJrA9yfpt87pK/fX3AePLSZtmyHoZRSF5xtr4xN5hEPftEavVLq4nPRJHo3brqt7myHoZRSF9xFk+g94tFEr5S6KF1Uib7TqVfGKqUuPhdNoq8yVXQ7uznannwJgFJK2dtFk+gv818GwMHmg1mORCmlLqyLJtEXvVAEwLpvrxv0MrqPdhNqDw1VSEopdUFcNIm+prmGEb4RfLX0q3T70x+U7TrQRfSSgCgTNvx+9O85/sPjAKyvXs/m2s3Recaw76F9tHhbzmvcbevbaPpVE6HTIcL+8JAuO3gqyKlXT6VMN2FDuGto1zVUgi1BOnZePE8KM8Zw+H8cxl9//k4NDrYEqfv7OiKByJAuN9IdGfJlHnvuGIETgYzbdx85txMw2n7fhokk39orNm99GyFffgz8Mrpgyg6mvTSNO79xJ99Z+B0mPTqJOfVzKKgsYHr1dKbeMRXrsEXDPQ1U/l0lI6pHcOi1QzinOFl3xTrmPzKfoueK6CjvYNy+cbS81cK++/bRubuTI08f4YbIDQCICJ2NnXRu6ASBroNdVC2t4vA/HWbsfxtLsClIoCmAa4aLYVXDMGFDpCuCs9QZ/QdzBPY9uI/KpZWUzCqBCGz5ky29tuMj3/oIo24ZRdHkIvwNfo5/7zgjPjaCxhcbad/QzpUvXEnjmkbKFpThucSDo8jByZ+cZOQtI3GWRH/cxhh237Wbk/95EoBrdlxD0ZQixBG9tu2DT3xA6xut0e2KQOvbrbir3LjHuXEUOQi2BnGVufjjN//IqFtGceT/HqHlty1wK3RUdLBx6kbELcx4bQYmZOiq62LssrHxbYgEIgQbg7jGuOjc20nJVSX4PvBRdGURIkKwOUjBmAIiwQih1hDOEU46d3VSNLWITTM20V3fzfh/Gk/wRJCJT02Mx52o+2g3zjInjiJHv78XYX+Y1nWtOMucEI72c491x/eTiND6divh02HELYz805EANL/SjH+/n849nUz8t4mEO8O0vdnGiD8dgeW2iHRHCHeFcZW5OPbdYxRUFzBq4aj4ekO+UPzn0b6lHQD3uOh6LbeF5bEQp1D/v+s5+JWDHPzKQa7vuJ6OHR0UTi7EVeYCINgcpOvgmSu+I6EIR759hLZ32rjyZ1cSvQvJGf7DfrZcv4WJT01k9G2j8R/2c+iJQxz/3nFKZpVQeVdlv/urR+BkgIIxBSnT/fV+Tv3mFO4aN9tv3Q4GarfV0vpGK5VLK2n5XQuFlxdSfGUxIhLfx+yFupfqGHvfWKRAsNwWBRUFmLDBKoiORwMnAuz9670UTi7kmh3XQCS6r3p0H+vG8li4RkT3TeOLjey8bSfTfj2NsgVl7PzMTkb/xWiqllZF9/v70f1eOrs0ZTuOPHMEq8hi71/vBWD6a9MpmVFCwZgCTMQQOBFgy59sYcQnRsDDZ36mJmgItYWiv3cCzb9qxlnmZPSnR3PypycRl1Ayo4TCywrj6zr93mki3ZH48zPOB0kcweaK2tpas2nTpkH17e9Ocl7x8sZVb/BS7Uvsqd5DwJX5yCCZO+gmIhEcEQf+guhoyxVyEXQGASjtKiVkhQhbYYq7i2kpaaGypZLm0maCziCOsIOxLWMxYhCn0ORpoqq1CmfYSUQihBwh3EE3YgQETgw/QUtJC5cdv4z68nrGNY2jrLMMKxL9RZekC5DFnHkfcAbYOmErAFOOTMEZdnKg4gAzD83EEXEQljCCcGL8CU5GTjL21FiGdQ1j48SNDAsMY8b+GXxw6QeMah9F98huag7V4PP4GH16NAWhAowYwlaYsBXm5PCTNA5rZPaB2YQcIQLOAI6Ig+LaYgLvBThdeJoxbWMIOoM4w05ai1sp7SrlxPATuENuCgOFiBEiEqG4uxi/y48z4sQZdkb3tctP4/BGKlor8Hl8DOsaRsAZwBPwUFFbQaAtwOm9pwk5QtH1ziim44MOXFNcNB9uJuAK4Ag7KO4uZnjXcIJWkLAVjsda3F3MyBtHYmHR+lorXQVdlPhLsIyFwXC66HR83xYGon+shZcU0niykVdmvcLHt38cT9AT347yxeU0vdSEGMFZ4iTSHqG5vJlNNZtoLW7ltndvI+SI/p6MaRuDEYMRw5YJW+gs6KSirYIRvhGErTAjfSMJOoOErBDOiJPRnx3NiTUncIVdbJyykbryOj735ufoKuiiMFCIZSxKrijBv8OP6woXHfs6CFthXGEXYgSfxwdAc2kzla2VFIQKKJ1TGo2h2+B/30/5LeW4J7k58N0DODoclEwooWt/V/z33Bl2EnAGECMMnzSc7t3d+J1+ThedZvTp0RgMb1z1BrUHatl2yTZmH5yNJ+hBjBC2wrQWt1LUXURBqICCUOyRnwVdNA5rpLK1EstYlN9STuOvG3FEHPHf9aAjiCPioPovq4kEItS/WE9RdxFhK0xEIgybMQwKwLfBx76qfbQVt+EKuvjIiY9Q9dEqSqeUcmTlESISodPdybDOYZRcVULR1CKaftIEQGtxK+2edsY1j0OMIAhWxKK5tJlTJaeYeHwiAO2F7UQkwvDO4fH1W8aK/m3HfldG/NkIWl9rxYiJb4cRAwUQCUbi7yd8fgKP3/v4oHKSiGw2xtSmnXcxJfrmV5rZfvN2AEJWiJaSFppLoonX5/ZxZOQRLGPhL/BH/xE4A4SsEJc0XUJZRxn15fVUtlbS7Yx+HHREHIQcIYwYAs4A3c5u3pr6FlOOTKEwUIgn6KGroItifzGvT3+dG3beQGtxK93ObgqDhZR0lUR/MawI2y/ZztSGqdGEEHbiMA463B0YDK6wi4ZRDRwdeZRZB2exZcIWavfX0lnQGU9oiUzyXaQF9lTvAaLPzxWEblc3E49NJOgIxpoIzaXNtBdGRznDOodxuih6R+nEf2AA45rGUV9ez/CO4bjC0dGTK+wiIhFOlJ0AoKK1Ih7X0ZFHcYVceIIe2gvbGeEbQcAZoCBUQFF3EZ3uTlpKoiWw6uZqOjwd8X8AVsTCHXJHk3EswTWXNlPsL6bD0xFPEgB+lx8xgiPiiP9BdRVEk5IVsYhYvcsI7qAbZ9gZ/YOD+B+8EUNEIhgxdLo7sSJWfFt6fl6egCee/LvcqfdQKvYXx5drMGdei6HbdaacUNJVgiDx/d6fnm1whB3x/Q7EBxrp2iYSE01UYcfAy3KOsGNQ/dTAjPCN4NT/Ti2nZqK/RH/RlG6AXh+dnREno0+PZvTp0UO6jsd/kf6/8Vde+MqQrkflHoNJ+WSVafuefyw9n9B6RoM9/yB6RpQ9/8QT1xMfQWLir3va9vzTEiPx6RGJRJcjnHlqhMSDii8/bIXj63ZGnIQlDBJdH0QHOj3r61lHxDqzrpAViq4zNqqNWBGcYWd0NG4c0e2PfWLt2R8RiRB0BnGFXRgMzogTg8EyFmErHF9W2ApjGYuAM4AVsSgIFfT6lNETY8++dEac0e0x0TisiIVlrPjIu2dbe/ZZz/7pibdnfUYMBaECIhKJ9+nZ/p7BhRWxeo3qe5bZ8zPr+QTd8zONrir23giR/xnBcg3t4dOLKtEDLDALOPbcsXjtbfKqyRx5+gihthDd9f0fuLGKLSIdvUdJl/3zZRx47EC//SqXVnL8e8fPHtzlwN6zN7Or4quK6diRvwdaB5Lkk9tbxur1OJ+ehJZYgutrHZY5U75zGEevtj1JN137Xh/80nywt8K9+zmMAww4OLOOnmX1fHeEz8wrCPeu4ffMS56euO7y28ppeqEpNZikeJyRaOpK/GTjCPZ/PCb+yTf5g4kh5VNxosR1nG/jvjhuyJM8XISJHqDqnirKPlaGu8aN5bQY+1+jBwr9h/2c+u0pii4vItgUpH1zO2OWjIEINK5p5NL/fimW08KEDaffPY3nMg/uKjej7xhNxB+h+IpiuvZ34RrtwjnMSbA5iDgF53AnwZYgrd5WZrw6g+JpxbT9oY2iKUW4q6MH4EQEr9fL9XOux7fNR/EVxYhT8G3zUTixkK66Lvbcs4fhHx3OpGcmEe4Mc+CLByioKqBochEFlQV07utk1KJROIodHPjyAUbeNJKS2SUUTSyiY1cHh544hOW2OPGjE5TMKmHSdyZROKGQP1T+gZKZJdRuqaXx543sWrKLyasmM/KmkUS6owdES2aWEDgeoO2dNhwlDk7++CRTvjcFhPgBP6/Xy/Tu6WxbuI1Z78zi6KqjVPxVBcOvG064PUz30W523rYT/yE/VpHF3A/nsr5mPRD9B2yM4fCTh6m4q4LuI924q928d9mZJ09O+cEUKj9XiYkYTjx/gj13R8tRs9bPomRmCeIUNkzZwKX/cCmeSz34D/oxEUPXh10MmzeM1jdbGffoOBylDn4/4vcAzNk7B894D8GmIOvXr+eGT9/Aphmb6NjRwfgnxlN8VTEmbDjxoxOUf7qcYR8dRuBoAHe1mw1TNlDz9zVMeHICXR920bimkfFfG093QzfBxiCnXjtFycwSTq8/TXd9N8efO07J7BKq/msVlXdX8nbx2/FtD7YG2fXZXYz681GM+csxFJQX0PlhJxsu3xDd9u9Pif4umuhZUVahFd/vTb9sYsevd8D/iw48LvnSJUD04KWJGNxVbjbN3oT/oJ8Zb8xg+63bmfbraZTOLOXYc8coqCqgbH4Zm6/ZTOfeznginB+Yj+WyCLWH4gej299rp31zOzUP1fBO2Tvxn83Vm6+mdHYp3Ue6OfTEIcZ9aRziENzj3BxbdYzi6cWUXVfW6+9w7317Ofb/jjHq1lE0P9LM/GvnIy7hyLePUPdgXfQEguFOSmaWcOCL0cGUc6ST2vdr2TBlA6VzS2l7M3pH2o986yPsf2Q/APMOzSPSHaFgbAH7v7Cfso+XUTipkBPfP8G4R8cROBmg5XcteC7x4B7nZuv8rUz6ziSG/8lwNs2MloyveukqnGVOtt6wNfp78uEcXKNdnPj+CQLHA7jKXRRPL2bbJ7bBZ2Ha56dx5JkjjP/aeN6f8368z4bJG3COclK7uZbODzvZdccuJn17Es4RTrbfEi0jX9d6Ha1vtuIocTDi4yMGms4yY4zJua+rr77aDNa6desG3TfbshV7x4cdJtQVOuflZBJ/JBIxgZZA/L1vp890He7qt0+4O5x2eveJbhNoDqSddzad+zvN6S2ne0073/u/Y2/v/dyxr8P4j/n77RMJR0wkEjnrsjPd95nwN/jNyRdPZrS801tOm4bvNGS03HR8O3wmEo6cNf5IOGIO/8th49vl6zU97A/3+n06V+FA2ISDZ37fmn7TZDr2dPTZPtQVMuveWNdrWseHHSbsjy4jcCpggu3BtH3r/63etG9tP+eYewCbTB859aIc0aveiiYVXbB1iUj81ECA4qnFZ+3Tc3pdsnSn92Uq8fS2C6Vocu/9XDTx7PtdrKF7nEPyqZZ9cVe7GV199mNXIkLpzFJKZ6aenpip4ivP/vOH6H645IuXpEy33FavUyzPVXLZJPG4XjoOjyPliRuJf089p3qmU/NgzcADHKSL5oIppZS6WGmiV0opm9NEr5RSNqeJXimlbE4TvVJK2ZwmeqWUsjlN9EopZXOa6JVSyuZy8u6VItIIHB5k93Ig/c0ycl8+xw4afzblc+yQ3/HnSuyXGmPSXumWk4n+XIjIJtPHrTpzXT7HDhp/NuVz7JDf8edD7Fq6UUopm9NEr5RSNmfHRL8q2wGcg3yOHTT+bMrn2CG/48/52G1Xo1dKKdWbHUf0SimlEmiiV0opm7NNoheRhSKyV0TqROSxbMfTFxE5JCLbRWSriGyKTRspIr8VkX2x7yMS2j8e26a9InLTBY71WRE5KSI7EqYNOFYRuTq2zXUi8rRk+gSM8xP/EyJyJLb/t4rIolyMX0TGicg6EdktIjtF5KHY9LzY//3En/P7X0Q8IrJBRD6Ixf612PS82Pdp9fXoqXz6AhzAfuAyoAD4AJia7bj6iPUQUJ407X8Bj8VePwb8S+z11Ni2uIEJsW10XMBY5wOzgR3nEiuwAfgo0Wfx/Aa4OYvxPwEsT9M2p+IHqoDZsdelwIexGPNi//cTf87v/9h6SmKvXcB7wLx82ffpvuwyop8D1BljDhhjAsBqYHGWYxqIxcD3Y6+/D3wqYfpqY0y3MeYgUEd0Wy8IY8xbwKmkyQOKVUSqgGHGmPUm+pv/g4Q+51Uf8fclp+I3xhwzxrwfe90O7AaqyZP930/8fcmZ+E2UL/bWFfsy5Mm+T8cuib4aqE9430D/v1TZZIDXRGSziCyLTaswxhyD6B8IMCY2PRe3a6CxVsdeJ0/PpgdEZFustNPz8Ttn4xeR8cAsoiPLvNv/SfFDHux/EXGIyFbgJPBbY0xe7vsedkn06epeuXre6LXGmNnAzcD9IjK/n7b5tF19xZpr27AC+AgwEzgG/J/Y9JyMX0RKgJ8DDxtjTvfXNM20XIw/L/a/MSZsjJkJ1BAdnV/VT/Ocij0duyT6BmBcwvsa4GiWYumXMeZo7PtJ4EWipZgTsY95xL6fjDXPxe0aaKwNsdfJ07PCGHMi9kccAf6dM6WwnItfRFxEk+TzxpgXYpPzZv+niz+f9j+AMaYV8AILyaN9n8wuiX4jMElEJohIAbAEWJvlmFKISLGIlPa8Bj4B7CAa6+djzT4PvBR7vRZYIiJuEZkATCJ6cCebBhRr7CNuu4jMi51xcHdCnwuu5w815tNE9z/kWPyxdX0X2G2M+VbCrLzY/33Fnw/7X0RGi0hZ7HUh8KfAHvJk36eVjSPA5+MLWET0yP5+4B+yHU8fMV5G9Oj8B8DOnjiBUcDrwL7Y95EJff4htk17ucBH7IEfE/14HSQ6Ovkvg4kVqCX6B70f+DaxK7KzFP8Pge3ANqJ/oFW5GD9wHdGP+duArbGvRfmy//uJP+f3PzAd2BKLcQfw32PT82Lfp/vSWyAopZTN2aV0o5RSqg+a6JVSyuY00SullM1poldKKZvTRK+UUjaniV4ppWxOE71SStnc/wdFEvlankS/ygAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAPE, MAE, RMSE, load_pred, load_true = run_model_retraining()\n",
    "print('MAPE:{}, MAE:{}, RMSE:{}'.format(MAPE, MAE, RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "78a6ed1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-27T06:34:41.676047Z",
     "start_time": "2021-12-27T06:34:41.669896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE:0.05404650729781903, MAE:725.595058841699, RMSE:1670.5218134095212\n"
     ]
    }
   ],
   "source": [
    "print('MAPE:{}, MAE:{}, RMSE:{}'.format(MAPE, MAE, RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a32f2d",
   "metadata": {},
   "source": [
    "## figure plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9c056506",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-27T06:34:46.026376Z",
     "start_time": "2021-12-27T06:34:45.882783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5c1b078760>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "load_pred = load_pred.reshape(-1, 24)\n",
    "load_true = load_true.reshape(-1, 24)\n",
    "plt.plot(load_pred[:240, 0], 'r')\n",
    "plt.plot(load_true[:240, 0], 'g')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "332.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
