{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2d7190a",
   "metadata": {},
   "source": [
    "# Transformer for forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f25fcf6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-02T08:27:49.246286Z",
     "start_time": "2022-01-02T08:27:48.318282Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBRegressor\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"\n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed6a0cd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-02T08:27:49.251045Z",
     "start_time": "2022-01-02T08:27:49.247999Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_seed_set(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.random.manual_seed(seed)\n",
    "    torch.cuda.random.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70af0591",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "843e72e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-02T08:27:49.338757Z",
     "start_time": "2022-01-02T08:27:49.252271Z"
    }
   },
   "outputs": [],
   "source": [
    "url = '../data/beijing.csv'\n",
    "data = pd.read_csv(url, sep=',', index_col='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca66e80",
   "metadata": {},
   "source": [
    "## normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6195db2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-02T08:27:49.343880Z",
     "start_time": "2022-01-02T08:27:49.340637Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalization(data):\n",
    "    \"\"\"\n",
    "    data: original data with load\n",
    "    return: normalized data, scaler of load\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_data = scaler.fit_transform(data)\n",
    "    scaler_y = MinMaxScaler()\n",
    "    scaler_y.fit_transform(data[[data.columns[-1]]])\n",
    "    return normalized_data, scaler, scaler_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffb58c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T07:45:44.192666Z",
     "start_time": "2021-12-22T07:45:44.188985Z"
    }
   },
   "source": [
    "## build supervised dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eafcd0f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-02T08:27:49.349238Z",
     "start_time": "2022-01-02T08:27:49.345314Z"
    }
   },
   "outputs": [],
   "source": [
    "def series_to_supervise(data, seq_len, target_len):\n",
    "    \"\"\"\n",
    "    convert series data to supervised data\n",
    "    :param data: original data\n",
    "    :param seq_len: length of input sequence\n",
    "    :param target_len: length of ouput sequence\n",
    "    :return: return two ndarrays-- input and output in format suitable to feed to LSTM\n",
    "    \"\"\"\n",
    "    dim_0 = data.shape[0] - seq_len - target_len + 1\n",
    "    dim_1 = data.shape[1]\n",
    "    x = np.zeros((dim_0, seq_len, dim_1))\n",
    "    y = np.zeros((dim_0, target_len, dim_1))\n",
    "    for i in range(dim_0):\n",
    "        x[i] = data[i:i + seq_len]\n",
    "        y[i] = data[i + seq_len:i + seq_len + target_len, :]\n",
    "    print(\"supervised data: shape of x: {}, shape of y: {}\".format(\n",
    "        x.shape, y.shape))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0820115",
   "metadata": {},
   "source": [
    "## 5-folds TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9388760",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-02T08:27:49.354363Z",
     "start_time": "2022-01-02T08:27:49.350901Z"
    }
   },
   "outputs": [],
   "source": [
    "def time_series_split(X, Y, n_split=5):\n",
    "    \"\"\"\n",
    "    X: features, size * seq_len * feature_num\n",
    "    Y: labels, size * target_len\n",
    "    return: list of train_x, test_x, train_y, test_y\n",
    "    \"\"\"\n",
    "    tscv = TimeSeriesSplit(n_splits=n_split)\n",
    "    train_x_list = list()\n",
    "    valid_x_list = list()\n",
    "    train_y_list = list()\n",
    "    valid_y_list = list()\n",
    "    for train_index, valid_index in tscv.split(X):\n",
    "        train_x_list.append(X[train_index])\n",
    "        train_y_list.append(Y[train_index])\n",
    "        valid_x_list.append(X[valid_index])\n",
    "        valid_y_list.append(Y[valid_index])\n",
    "    return train_x_list, train_y_list, valid_x_list, valid_y_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717cdfdf",
   "metadata": {},
   "source": [
    "## Transform model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff19285",
   "metadata": {},
   "source": [
    "### PositionalEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "648945e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-02T08:27:49.360731Z",
     "start_time": "2022-01-02T08:27:49.355699Z"
    }
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"位置编码\"\"\"\n",
    "    def __init__(self, num_hiddens, dropout, max_len=500):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # 创建一个足够长的 `P`\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1) / torch.pow(10000, torch.arange(\n",
    "            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        self.P[:, :, 0::2] = torch.sin(X)\n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12db0ff",
   "metadata": {},
   "source": [
    "### DotProduct Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85383ccd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-02T08:27:49.369620Z",
     "start_time": "2022-01-02T08:27:49.362235Z"
    }
   },
   "outputs": [],
   "source": [
    "def sequence_mask(X, valid_len, value=0):\n",
    "    \"\"\"在序列中屏蔽不相关的项\"\"\"\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                        device=X.device)[None, :] < valid_len[:, None]\n",
    "    X[~mask] = value\n",
    "    return X\n",
    "\n",
    "\n",
    "def masked_softmax(X, valid_lens):\n",
    "    \"\"\"通过在最后一个轴上掩蔽元素来执行 softmax 操作\"\"\"\n",
    "    # `X`: 3D张量，`valid_lens`: 1D或2D 张量\n",
    "    # valid_lens 为 None 正常softmax\n",
    "    if valid_lens is None:\n",
    "        return nn.functional.softmax(X, dim=-1)\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1)\n",
    "        # 最后一轴上被掩蔽的元素使用一个非常大的负值替换，从而其softmax输出为0\n",
    "        X = sequence_mask(X.reshape(-1, shape[-1]), valid_lens, value=-1e6)\n",
    "        return nn.functional.softmax(X.reshape(shape), dim=-1)\n",
    "\n",
    "\n",
    "class DotProductAttention(nn.Module):\n",
    "    \"\"\"缩放点积注意力\"\"\"\n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # `queries` 的形状：(`batch_size`，查询的个数，`d`)\n",
    "    # `keys` 的形状：(`batch_size`，“键－值”对的个数，`d`)\n",
    "    # `values` 的形状：(`batch_size`，“键－值”对的个数，值的维度)\n",
    "    # `valid_lens` 的形状: (`batch_size`，) 或者 (`batch_size`，查询的个数)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        d = queries.shape[-1]\n",
    "        # 设置 `transpose_b=True` 为了交换 `keys` 的最后两个维度\n",
    "        scores = torch.bmm(queries, keys.transpose(1, 2)) / math.sqrt(d)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aab25c",
   "metadata": {},
   "source": [
    "### MultiHead Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50ab04d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-02T08:27:49.379430Z",
     "start_time": "2022-01-02T08:27:49.371035Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"多头注意力\"\"\"\n",
    "    def __init__(self,\n",
    "                 key_size,\n",
    "                 query_size,\n",
    "                 value_size,\n",
    "                 num_hiddens,\n",
    "                 num_heads,\n",
    "                 dropout,\n",
    "                 bias=False,\n",
    "                 **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = DotProductAttention(dropout)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
    "        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        # `queries`，`keys`，`values` 的形状:\n",
    "        # (`batch_size`，查询或者“键－值”对的个数，`num_hiddens`)\n",
    "        # `valid_lens`　的形状:\n",
    "        # (`batch_size`，) 或 (`batch_size`，查询的个数)\n",
    "        # 经过变换后，输出的 `queries`，`keys`，`values`　的形状:\n",
    "        # (`batch_size` * `num_heads`，查询或者“键－值”对的个数，\n",
    "        # `num_hiddens` / `num_heads`)\n",
    "        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n",
    "        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n",
    "        values = transpose_qkv(self.W_v(values), self.num_heads)\n",
    "\n",
    "        if valid_lens is not None:\n",
    "            # 在轴 0，将第一项（标量或者矢量）复制 `num_heads` 次，\n",
    "            # 然后如此复制第二项，然后诸如此类。\n",
    "            valid_lens = torch.repeat_interleave(valid_lens,\n",
    "                                                 repeats=self.num_heads,\n",
    "                                                 dim=0)\n",
    "\n",
    "        # `output` 的形状: (`batch_size` * `num_heads`，查询的个数，\n",
    "        # `num_hiddens` / `num_heads`)\n",
    "        output = self.attention(queries, keys, values, valid_lens)\n",
    "\n",
    "        # `output_concat` 的形状: (`batch_size`，查询的个数，`num_hiddens`)\n",
    "        output_concat = transpose_output(output, self.num_heads)\n",
    "        return self.W_o(output_concat)\n",
    "\n",
    "\n",
    "def transpose_qkv(X, num_heads):\n",
    "    \"\"\"为了多注意力头的并行计算而变换形状。\"\"\"\n",
    "    # 输入 `X` 的形状: (`batch_size`，查询或者“键－值”对的个数，`num_hiddens`)\n",
    "    # 输出 `X` 的形状: (`batch_size`，查询或者“键－值”对的个数，`num_heads`，\n",
    "    # `num_hiddens` / `num_heads`)\n",
    "    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
    "\n",
    "    # 输出 `X` 的形状: (`batch_size`，`num_heads`，查询或者“键－值”对的个数,\n",
    "    # `num_hiddens` / `num_heads`)\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "\n",
    "    # 最终输出的形状: (`batch_size` * `num_heads`, 查询或者“键－值”对的个数,\n",
    "    # `num_hiddens` / `num_heads`)\n",
    "    return X.reshape(-1, X.shape[2], X.shape[3])\n",
    "\n",
    "\n",
    "def transpose_output(X, num_heads):\n",
    "    \"\"\"逆转 `transpose_qkv` 函数的操作。\"\"\"\n",
    "    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(X.shape[0], X.shape[1], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86499b4d",
   "metadata": {},
   "source": [
    "### PositionWiseFFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "820a386e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-02T08:27:49.385237Z",
     "start_time": "2022-01-02T08:27:49.381794Z"
    }
   },
   "outputs": [],
   "source": [
    "class PositionWiseFFN(nn.Module):\n",
    "    \"\"\"基于位置的前馈网络\"\"\"\n",
    "    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,\n",
    "                 **kwargs):\n",
    "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73b9899",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-01T11:19:45.611064Z",
     "start_time": "2022-01-01T11:19:45.606777Z"
    }
   },
   "source": [
    "### Add&Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fa099a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-02T08:27:49.389762Z",
     "start_time": "2022-01-02T08:27:49.386327Z"
    }
   },
   "outputs": [],
   "source": [
    "class AddNorm(nn.Module):\n",
    "    \"\"\"残差连接后进行层规范化\"\"\"\n",
    "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
    "        super(AddNorm, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(normalized_shape)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcd4655",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94502906",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-02T08:27:49.398917Z",
     "start_time": "2022-01-02T08:27:49.391057Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"transformer编码器块\"\"\"\n",
    "    def __init__(self,\n",
    "                 key_size,\n",
    "                 query_size,\n",
    "                 value_size,\n",
    "                 num_hiddens,\n",
    "                 norm_shape,\n",
    "                 ffn_num_input,\n",
    "                 ffn_num_hiddens,\n",
    "                 num_heads,\n",
    "                 dropout,\n",
    "                 use_bias=False,\n",
    "                 **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        self.attention = MultiHeadAttention(key_size, query_size, value_size,\n",
    "                                            num_hiddens, num_heads, dropout,\n",
    "                                            use_bias)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, valid_lens):\n",
    "        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n",
    "        return self.addnorm2(Y, self.ffn(Y))\n",
    "    \n",
    "    \n",
    "class TransformerEncoder(nn.Module):\n",
    "    \"\"\"transformer编码器\"\"\"\n",
    "    def __init__(self, input_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, use_bias=False, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = nn.Linear(input_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),\n",
    "                EncoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                             norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                             num_heads, dropout, use_bias))\n",
    "\n",
    "    def forward(self, X, valid_lens=None, *args):\n",
    "        # 因为位置编码值在 -1 和 1 之间，\n",
    "        # 因此嵌入值乘以嵌入维度的平方根进行缩放，\n",
    "        # 然后再与位置编码相加。\n",
    "        # pdb.set_trace()\n",
    "        # X shape (batch_size, num_steps, input_size)\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X = blk(X, valid_lens)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec466448",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00d2917e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-02T08:27:49.409776Z",
     "start_time": "2022-01-02T08:27:49.400233Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"解码器中第 i 个块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, i, **kwargs):\n",
    "        super(DecoderBlock, self).__init__(**kwargs)\n",
    "        self.i = i\n",
    "        self.attention1 = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.attention2 = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens,\n",
    "                                   num_hiddens)\n",
    "        self.addnorm3 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        enc_outputs, enc_valid_lens = state[0], state[1]\n",
    "        # 训练阶段，输出序列的所有词元都在同一时间处理，\n",
    "        # 因此 `state[2][self.i]` 初始化为 `None`。\n",
    "        # 预测阶段，输出序列是通过词元一个接着一个解码的，\n",
    "        # 因此 `state[2][self.i]` 包含着直到当前时间步第 `i` 个块解码的输出表示\n",
    "        if state[2][self.i] is None:\n",
    "            key_values = X\n",
    "        else:\n",
    "            key_values = torch.cat((state[2][self.i], X), axis=1)\n",
    "        state[2][self.i] = key_values\n",
    "        if self.training:\n",
    "            batch_size, num_steps, _ = X.shape\n",
    "            # `dec_valid_lens` 的开头: (`batch_size`, `num_steps`),\n",
    "            # 其中每一行是 [1, 2, ..., `num_steps`]\n",
    "            dec_valid_lens = torch.arange(\n",
    "                1, num_steps + 1, device=X.device).repeat(batch_size, 1)\n",
    "        else:\n",
    "            dec_valid_lens = None\n",
    "\n",
    "        # 自注意力\n",
    "        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)\n",
    "        Y = self.addnorm1(X, X2)\n",
    "        # 编码器－解码器注意力。\n",
    "        # `enc_outputs` 的开头: (`batch_size`, `num_steps`, `num_hiddens`)\n",
    "        Y2 = self.attention2(Y, enc_outputs, enc_outputs)\n",
    "        Z = self.addnorm2(Y, Y2)\n",
    "        return self.addnorm3(Z, self.ffn(Z)), state\n",
    "\n",
    "    \n",
    "class TransformerDecoder(nn.Module):\n",
    "    \"\"\"transformer解码器\"\"\"\n",
    "    def __init__(self, input_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Linear(input_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),\n",
    "                DecoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                             norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                             num_heads, dropout, i))\n",
    "        self.dense = nn.Linear(num_hiddens, 1)\n",
    "\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        # X shape (batch_size, num_steps, input_size)\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X, state = blk(X, state)\n",
    "        return self.dense(X), state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a933819b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T13:06:00.226758Z",
     "start_time": "2021-12-22T13:06:00.223732Z"
    }
   },
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "21cfad54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-02T11:45:40.287474Z",
     "start_time": "2022-01-02T11:45:40.270375Z"
    }
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \"\"\"完整transformer模型\"\"\"\n",
    "    def __init__(self, input_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, **kwargs):\n",
    "        super(Transformer, self).__init__(**kwargs)\n",
    "        self.num_layers = num_layers\n",
    "        self.encoder = TransformerEncoder(input_size, key_size, query_size,\n",
    "                                          value_size, num_hiddens,\n",
    "                                          norm_shape[0], ffn_num_input,\n",
    "                                          ffn_num_hiddens, num_heads,\n",
    "                                          num_layers, dropout)\n",
    "        self.decoder = TransformerDecoder(input_size, key_size, query_size,\n",
    "                                          value_size, num_hiddens,\n",
    "                                          norm_shape[1], ffn_num_input,\n",
    "                                          ffn_num_hiddens, num_heads,\n",
    "                                          num_layers, dropout)\n",
    "\n",
    "    def forward(self, enc_inputs, dec_inputs):\n",
    "        enc_outputs = self.encoder(enc_inputs)\n",
    "        state = [enc_outputs, None, [None] * self.num_layers]\n",
    "\n",
    "        outputs = []\n",
    "        # without teacher forcing\n",
    "        # if self.training:\n",
    "        #    outputs, state = self.decoder(dec_inputs, state)\n",
    "        # else:\n",
    "        for i in range(dec_inputs.shape[1]):\n",
    "            if i:\n",
    "                x = torch.cat((dec_inputs[:, i:i + 1, :-1], out.detach()),\n",
    "                              dim=-1)\n",
    "            else:\n",
    "                x = dec_inputs[:, i:i+1, :]\n",
    "            out, state = self.decoder(x, state)\n",
    "            outputs.append(out)\n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "        return outputs.reshape(outputs.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32450ab4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-02T07:13:57.924618Z",
     "start_time": "2022-01-02T07:13:57.920233Z"
    }
   },
   "source": [
    "### model tets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a5025e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-02T08:27:49.523097Z",
     "start_time": "2022-01-02T08:27:49.417954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 24])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = Transformer(16, 32, 32, 32, 32, ([32], [32]), 32, 64, 4, 2, 0.1)\n",
    "# decoder = TransformerDecoder(16, 32, 32, 32, 32, [24, 32], 32, 64, 4, 2, 0.1)\n",
    "enc_inputs = torch.randn(10, 72, 16)\n",
    "dec_inputs = torch.randn(10, 24, 16)\n",
    "# enc_outputs = torch.randn(10, 72, 32)\n",
    "# state = [enc_outputs, None, [None] * 2]\n",
    "transformer.eval()\n",
    "outputs = transformer(enc_inputs, dec_inputs)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa73b30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T08:30:19.661769Z",
     "start_time": "2021-12-22T08:30:19.656770Z"
    }
   },
   "source": [
    "## model training for HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8272c9fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-02T12:17:22.060821Z",
     "start_time": "2022-01-02T12:17:22.034498Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train_model_hpo(train_x_list, train_y_list, valid_x_list, valid_y_list,\n",
    "                    input_size, seq_len, target_len, mse_thresh, d_model,\n",
    "                    nhead, n_layers, number_epoch, batch_size, lr, drop_prob):\n",
    "    \"\"\"寻找超参数的训练函数，有early stop\"\"\"\n",
    "    valid_steps = 5\n",
    "    valid_loss_list = []\n",
    "    for num in range(len(train_x_list)):\n",
    "        while (1):\n",
    "            model = Transformer(input_size, d_model, d_model, d_model, d_model,\n",
    "                                ([d_model], [d_model]),\n",
    "                                d_model, 2 * d_model, nhead, n_layers,\n",
    "                                drop_prob)\n",
    "            model = model.to(device)\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                         lr=lr,\n",
    "                                         betas=(0.9, 0.98),\n",
    "                                         eps=1e-9)\n",
    "            scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                        step_size=1,\n",
    "                                                        gamma=0.98)\n",
    "            valid_loss_min = np.Inf\n",
    "            print('train dataset {}'.format(num))\n",
    "            train_x = train_x_list[num]\n",
    "            train_y = train_y_list[num]\n",
    "            valid_x = valid_x_list[num]\n",
    "            valid_y = valid_y_list[num]\n",
    "            train_dataset = TensorDataset(torch.FloatTensor(train_x),\n",
    "                                          torch.FloatTensor(train_y))\n",
    "            valid_dataset = TensorDataset(torch.FloatTensor(valid_x),\n",
    "                                          torch.FloatTensor(valid_y))\n",
    "\n",
    "            train_loader = DataLoader(dataset=train_dataset,\n",
    "                                      batch_size=batch_size,\n",
    "                                      shuffle=True,\n",
    "                                      drop_last=True)\n",
    "            valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                                      batch_size=batch_size,\n",
    "                                      shuffle=True,\n",
    "                                      drop_last=True)\n",
    "            train_losses = list()\n",
    "\n",
    "            num_without_imp = 0\n",
    "\n",
    "            #train\n",
    "            for epoch in range(1, number_epoch + 1):\n",
    "                loop = tqdm(enumerate(train_loader),\n",
    "                            total=len(train_loader),\n",
    "                            leave=True, ncols=100)\n",
    "                for i, (inputs, labels) in loop:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    # train                    \n",
    "                    model.train()\n",
    "                    enc_inputs = inputs\n",
    "                    dec_inputs = torch.cat((inputs[:, -1:, :], labels[:, :-1, :]), dim=1)\n",
    "                    outputs = model(enc_inputs, dec_inputs)\n",
    "                    loss = criterion(outputs, labels[:, :, -1])\n",
    "                    train_losses.append(loss.item)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # eval\n",
    "                    if i % valid_steps == 0:\n",
    "                        num_without_imp = num_without_imp + 1\n",
    "                        valid_losses = list()\n",
    "                        model.eval()\n",
    "                        for inp, lab in valid_loader:\n",
    "                            inp = inp.to(device)\n",
    "                            lab = lab.to(device)\n",
    "                            enc_inputs = inp\n",
    "                            dec_inputs = torch.cat((inp[:, -1:, :], lab[:, :-1, :]), dim=1)\n",
    "                            out = model(enc_inputs, dec_inputs)\n",
    "                            valid_loss = criterion(out, lab[:, :, -1])\n",
    "                            valid_losses.append(valid_loss.item())\n",
    "                        loop.set_description(\"Epoch: {}/{}...\".format(\n",
    "                            epoch, number_epoch))\n",
    "                        loop.set_postfix(train_loss=loss.item(),\n",
    "                                         valid_loss=np.mean(valid_losses))\n",
    "                        if np.mean(valid_losses) < valid_loss_min:\n",
    "                            num_without_imp = 0\n",
    "                            valid_loss_min = np.mean(valid_losses)\n",
    "                scheduler.step()\n",
    "                if num_without_imp > 50:\n",
    "                    pass\n",
    "                    # break\n",
    "            if valid_loss_min < mse_thresh:\n",
    "                valid_loss_list.append(valid_loss_min)\n",
    "                break\n",
    "    return np.mean(valid_loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a5bea1",
   "metadata": {},
   "source": [
    "## hyper-parameters config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9716d0d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T08:52:23.347397Z",
     "start_time": "2022-01-03T08:52:23.335133Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_len = 72\n",
    "target_len = 24\n",
    "mse_thresh = 0.05\n",
    "\n",
    "\n",
    "def model_config():\n",
    "    batch_sizes = [256]\n",
    "    lrs = [0.01, 0.005, 0.001]\n",
    "    number_epochs = [40]\n",
    "    d_models = [32, 64, 96]\n",
    "    n_layers = [2, 3]\n",
    "    drop_prob = [0.5]\n",
    "    nhead = [4, 8]\n",
    "    configs = list()\n",
    "    for i in batch_sizes:\n",
    "        for j in lrs:\n",
    "            for k in number_epochs:\n",
    "                for l in d_models:\n",
    "                    for m in n_layers:\n",
    "                        for n in drop_prob:\n",
    "                            for o in nhead:\n",
    "                                configs.append({\n",
    "                                    'batch_size': i,\n",
    "                                    'lr': j,\n",
    "                                    'number_epoch': k,\n",
    "                                    'd_model': l,\n",
    "                                    'n_layers': m,\n",
    "                                    'drop_prob': n,\n",
    "                                    'nhead': o\n",
    "                                })\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b1f9d3",
   "metadata": {},
   "source": [
    "## random search for HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7ae6ee73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T08:52:42.582511Z",
     "start_time": "2022-01-03T08:52:42.565727Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_model_hpo(seq_len=seq_len,\n",
    "                  target_len=target_len,\n",
    "                  mse_thresh=mse_thresh):\n",
    "    train_data = data[:int(0.8 * len(data))]\n",
    "    train_data, _, _ = normalization(train_data)\n",
    "    train_x, train_y = series_to_supervise(train_data, seq_len, target_len)\n",
    "    train_x_list, train_y_list, valid_x_list, valid_y_list = time_series_split(\n",
    "        train_x, train_y)\n",
    "    #         with enough data\n",
    "    train_x_list = train_x_list[-1:]\n",
    "    train_y_list = train_y_list[-1:]\n",
    "    valid_x_list = valid_x_list[-1:]\n",
    "    valid_y_list = valid_y_list[-1:]\n",
    "\n",
    "    configs = model_config()\n",
    "    records = []\n",
    "    input_size = train_x.shape[2]\n",
    "    for i in range(18):\n",
    "        config = random.choice(configs)\n",
    "        configs.remove(config)\n",
    "        batch_size = config['batch_size']\n",
    "        lr = config['lr']\n",
    "        number_epoch = config['number_epoch']\n",
    "        d_model = config['d_model']\n",
    "        n_layers = config['n_layers']\n",
    "        drop_prob = config['drop_prob']\n",
    "        nhead = config['nhead']\n",
    "        print(\n",
    "            \"model config: batch_size-{}, lr-{}, number_epoch-{}, d_model-{}, n_layers-{},drop_prob-{},nhead-{}\"\n",
    "            .format(batch_size, lr, number_epoch, d_model, n_layers, drop_prob,\n",
    "                    nhead))\n",
    "        valid_loss = train_model_hpo(train_x_list, train_y_list, valid_x_list,\n",
    "                                     valid_y_list, input_size, seq_len,\n",
    "                                     target_len, mse_thresh, d_model, nhead,\n",
    "                                     n_layers, number_epoch, batch_size, lr,\n",
    "                                     drop_prob)\n",
    "        records.append({\n",
    "            'batch_size': batch_size,\n",
    "            'lr': lr,\n",
    "            'number_epoch': number_epoch,\n",
    "            'd_model': d_model,\n",
    "            'n_layers': n_layers,\n",
    "            'drop_prob': drop_prob,            \n",
    "            'nhead': nhead,\n",
    "            'valid_loss': valid_loss,\n",
    "        })\n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380c2090",
   "metadata": {},
   "source": [
    "## run random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97319de",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-01-03T08:50:07.279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervised data: shape of x: (25232, 72, 16), shape of y: (25232, 24, 16)\n",
      "model config: batch_size-256, lr-0.001, number_epoch-40, d_model-32, n_layers-2,drop_prob-0.5,nhead-8\n",
      "train dataset 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/40...: 100%|█████████| 82/82 [00:24<00:00,  3.34it/s, train_loss=0.0279, valid_loss=0.0315]\n",
      "Epoch: 2/40...: 100%|█████████| 82/82 [00:24<00:00,  3.33it/s, train_loss=0.0159, valid_loss=0.0266]\n",
      "Epoch: 3/40...: 100%|█████████| 82/82 [00:24<00:00,  3.30it/s, train_loss=0.0132, valid_loss=0.0242]\n",
      "Epoch: 4/40...: 100%|██████████| 82/82 [00:24<00:00,  3.29it/s, train_loss=0.0105, valid_loss=0.019]\n",
      "Epoch: 5/40...: 100%|███████████| 82/82 [00:24<00:00,  3.30it/s, train_loss=0.0082, valid_loss=0.01]\n",
      "Epoch: 6/40...: 100%|████████| 82/82 [00:24<00:00,  3.29it/s, train_loss=0.00628, valid_loss=0.0117]\n",
      "Epoch: 7/40...: 100%|███████| 82/82 [00:25<00:00,  3.24it/s, train_loss=0.00561, valid_loss=0.00902]\n",
      "Epoch: 8/40...: 100%|███████| 82/82 [00:25<00:00,  3.27it/s, train_loss=0.00506, valid_loss=0.00988]\n",
      "Epoch: 9/40...: 100%|███████| 82/82 [00:25<00:00,  3.25it/s, train_loss=0.00434, valid_loss=0.00878]\n",
      "Epoch: 10/40...: 100%|███████| 82/82 [00:24<00:00,  3.29it/s, train_loss=0.00445, valid_loss=0.0105]\n",
      "Epoch: 11/40...: 100%|██████| 82/82 [00:25<00:00,  3.24it/s, train_loss=0.00397, valid_loss=0.00809]\n",
      "Epoch: 12/40...: 100%|██████| 82/82 [00:25<00:00,  3.25it/s, train_loss=0.00385, valid_loss=0.00817]\n",
      "Epoch: 13/40...: 100%|██████| 82/82 [00:25<00:00,  3.21it/s, train_loss=0.00366, valid_loss=0.00792]\n",
      "Epoch: 14/40...: 100%|██████| 82/82 [00:25<00:00,  3.23it/s, train_loss=0.00367, valid_loss=0.00726]\n",
      "Epoch: 15/40...: 100%|████████| 82/82 [00:25<00:00,  3.23it/s, train_loss=0.00349, valid_loss=0.007]\n",
      "Epoch: 16/40...: 100%|██████| 82/82 [00:25<00:00,  3.22it/s, train_loss=0.00337, valid_loss=0.00681]\n",
      "Epoch: 17/40...: 100%|██████| 82/82 [00:25<00:00,  3.20it/s, train_loss=0.00341, valid_loss=0.00714]\n",
      "Epoch: 18/40...: 100%|██████| 82/82 [00:25<00:00,  3.19it/s, train_loss=0.00311, valid_loss=0.00644]\n",
      "Epoch: 19/40...: 100%|██████| 82/82 [00:25<00:00,  3.21it/s, train_loss=0.00316, valid_loss=0.00645]\n",
      "Epoch: 20/40...:  49%|██▉   | 40/82 [00:12<00:09,  4.44it/s, train_loss=0.00293, valid_loss=0.00607]"
     ]
    }
   ],
   "source": [
    "random_seed_set(42)\n",
    "records = run_model_hpo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20ab287",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T08:52:06.844501Z",
     "start_time": "2021-12-22T08:52:06.830928Z"
    }
   },
   "source": [
    "## find the best hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7b6ebd7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T15:19:52.039442Z",
     "start_time": "2022-01-03T15:19:52.008662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>number_epoch</th>\n",
       "      <th>d_model</th>\n",
       "      <th>n_layers</th>\n",
       "      <th>drop_prob</th>\n",
       "      <th>nhead</th>\n",
       "      <th>valid_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>40</td>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.002061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>40</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.002103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>256</td>\n",
       "      <td>0.010</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>40</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.002181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>40</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>40</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.003925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>256</td>\n",
       "      <td>0.005</td>\n",
       "      <td>40</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.004980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>256</td>\n",
       "      <td>0.005</td>\n",
       "      <td>40</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.005084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>256</td>\n",
       "      <td>0.010</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.006543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>256</td>\n",
       "      <td>0.005</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.007178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>256</td>\n",
       "      <td>0.005</td>\n",
       "      <td>40</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.030187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>256</td>\n",
       "      <td>0.005</td>\n",
       "      <td>40</td>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.034122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>256</td>\n",
       "      <td>0.010</td>\n",
       "      <td>40</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.034368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>256</td>\n",
       "      <td>0.005</td>\n",
       "      <td>40</td>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.034370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256</td>\n",
       "      <td>0.010</td>\n",
       "      <td>40</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.034402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>256</td>\n",
       "      <td>0.010</td>\n",
       "      <td>40</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.034453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    batch_size     lr  number_epoch  d_model  n_layers  drop_prob  nhead  \\\n",
       "6          256  0.001            40       96         3        0.5      8   \n",
       "3          256  0.001            40       64         3        0.5      8   \n",
       "17         256  0.010            40       32         2        0.5      4   \n",
       "12         256  0.001            40       96         2        0.5      8   \n",
       "8          256  0.001            40       32         2        0.5      4   \n",
       "1          256  0.001            40       64         2        0.5      4   \n",
       "0          256  0.001            40       32         2        0.5      8   \n",
       "15         256  0.001            40       64         3        0.5      4   \n",
       "5          256  0.005            40       64         3        0.5      4   \n",
       "9          256  0.005            40       64         2        0.5      8   \n",
       "7          256  0.010            40       32         2        0.5      8   \n",
       "4          256  0.005            40       32         2        0.5      8   \n",
       "13         256  0.005            40       96         2        0.5      8   \n",
       "14         256  0.005            40       96         3        0.5      4   \n",
       "10         256  0.010            40       64         2        0.5      8   \n",
       "16         256  0.005            40       96         3        0.5      8   \n",
       "2          256  0.010            40       96         2        0.5      4   \n",
       "11         256  0.010            40       64         3        0.5      8   \n",
       "\n",
       "    valid_loss  \n",
       "6     0.002061  \n",
       "3     0.002103  \n",
       "17    0.002152  \n",
       "12    0.002181  \n",
       "8     0.002566  \n",
       "1     0.002612  \n",
       "0     0.003784  \n",
       "15    0.003925  \n",
       "5     0.004980  \n",
       "9     0.005084  \n",
       "7     0.006543  \n",
       "4     0.007178  \n",
       "13    0.030187  \n",
       "14    0.034122  \n",
       "10    0.034368  \n",
       "16    0.034370  \n",
       "2     0.034402  \n",
       "11    0.034453  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = pd.DataFrame(records).sort_values(by='valid_loss')\n",
    "records.to_csv('./records/transformer_records.csv', mode='a', index=False, header=False)\n",
    "records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be35c016",
   "metadata": {},
   "source": [
    "## retrain a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edc95689",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-02T09:14:55.583795Z",
     "start_time": "2022-01-02T09:14:55.557071Z"
    },
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "def train_model(train_x, train_y, valid_x, valid_y, input_size, seq_len,\n",
    "                target_len, mse_thresh, d_model, nhead, n_layers, number_epoch,\n",
    "                batch_size, lr, drop_prob):\n",
    "    while (1):\n",
    "        model = Transformer(input_size, d_model, d_model, d_model, d_model,\n",
    "                                ([d_model], [d_model]),\n",
    "                                d_model, 2 * d_model, nhead, n_layers,\n",
    "                                drop_prob)\n",
    "        model = model.to(device)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                     lr=lr,\n",
    "                                     betas=(0.9, 0.98),\n",
    "                                     eps=1e-9)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                    step_size=1,\n",
    "                                                    gamma=0.98)\n",
    "        valid_loss_min = np.Inf\n",
    "        train_dataset = TensorDataset(torch.FloatTensor(train_x),\n",
    "                                      torch.FloatTensor(train_y))\n",
    "        valid_dataset = TensorDataset(torch.FloatTensor(valid_x),\n",
    "                                      torch.FloatTensor(valid_y))\n",
    "\n",
    "        train_loader = DataLoader(dataset=train_dataset,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=True,\n",
    "                                  drop_last=True)\n",
    "        valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=True,\n",
    "                                  drop_last=True)\n",
    "        train_loss_list = []\n",
    "        valid_loss_list = []\n",
    "        num_without_imp = 0\n",
    "\n",
    "        #train\n",
    "        for epoch in range(1, number_epoch + 1):\n",
    "            loop = tqdm(enumerate(train_loader),\n",
    "                        total=len(train_loader),\n",
    "                        leave=True, ncols=100)\n",
    "            for i, (inputs, labels) in loop:\n",
    "                model.train()\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                # train\n",
    "                # pdb.set_trace()\n",
    "                enc_inputs = inputs\n",
    "                dec_inputs = torch.cat((inputs[:, -1:, :], labels[:, :-1, :]), dim=1)\n",
    "                outputs = model(enc_inputs, dec_inputs)\n",
    "                loss = criterion(outputs, labels[:, :, -1])\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # eval\n",
    "                if i % 5 == 0:\n",
    "                    num_without_imp = num_without_imp + 1\n",
    "                    valid_losses = list()\n",
    "                    model.eval()\n",
    "                    for inp, lab in valid_loader:\n",
    "                        inp = inp.to(device)\n",
    "                        lab = lab.to(device)\n",
    "                        enc_inputs = inp\n",
    "                        dec_inputs = torch.cat((inp[:, -1:, :], lab[:, :-1, :]), dim=1)\n",
    "                        out = model(enc_inputs, dec_inputs)\n",
    "                        valid_loss = criterion(out, lab[:, :, -1])\n",
    "                        valid_losses.append(valid_loss.item())\n",
    "                    loop.set_description(\"Epoch: {}/{}...\".format(\n",
    "                        epoch, number_epoch))\n",
    "                    loop.set_postfix(train_loss=loss.item(),\n",
    "                                     valid_loss=np.mean(valid_losses))\n",
    "                    train_loss_list.append(loss.item())\n",
    "                    valid_loss_list.append(np.mean(valid_losses))\n",
    "                    if np.mean(valid_losses) < valid_loss_min:\n",
    "                        num_without_imp = 0\n",
    "                        torch.save(model.state_dict(),\n",
    "                                   \"./model/transformer_state_dict.pt\")\n",
    "                        valid_loss_min = np.mean(valid_losses)\n",
    "            scheduler.step()\n",
    "        if valid_loss_min < mse_thresh:\n",
    "            break\n",
    "    return model, train_loss_list, valid_loss_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eff3c7e",
   "metadata": {},
   "source": [
    "## test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "045b28ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-02T09:14:57.878277Z",
     "start_time": "2022-01-02T09:14:57.862502Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def test_model(model, test_x, test_y, scaler_y, seq_len, target_len,\n",
    "               batch_size):\n",
    "    test_dataset = TensorDataset(torch.FloatTensor(test_x),\n",
    "                                 torch.FloatTensor(test_y))\n",
    "    test_loader = DataLoader(dataset=test_dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=False,\n",
    "                             drop_last=True)\n",
    "    model.load_state_dict(torch.load('./model/transformer_state_dict.pt'))\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for inp, lab in test_loader:\n",
    "            inp = inp.to(device)\n",
    "            lab = lab.to(device)\n",
    "            enc_inputs = inp\n",
    "            dec_inputs = torch.cat((inp[:, -1:, :], lab[:, :-1, :]), dim=1)\n",
    "            out = model(enc_inputs, dec_inputs)\n",
    "            y_pred += out.cpu().numpy().flatten().tolist()\n",
    "            y_true += lab[:, :, -1].cpu().numpy().flatten().tolist()\n",
    "    y_pred = np.array(y_pred).reshape(-1, 1)\n",
    "    y_true = np.array(y_true).reshape(-1, 1)\n",
    "    load_pred = scaler_y.inverse_transform(y_pred)\n",
    "    load_true = scaler_y.inverse_transform(y_true)\n",
    "    MAPE = np.mean(np.abs(load_true - load_pred) / load_true)\n",
    "    MAE = np.mean(np.abs(load_true - load_pred))\n",
    "    RMSE = np.sqrt(np.mean(np.square(load_true - load_pred)))\n",
    "    return MAPE, MAE, RMSE, load_pred, load_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7af9244",
   "metadata": {},
   "source": [
    "## run model retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c65355ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T02:05:20.515189Z",
     "start_time": "2022-01-04T02:05:20.497092Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_model_retraining(seq_len=seq_len,\n",
    "                         target_len=target_len,\n",
    "                         mse_thresh=mse_thresh):\n",
    "    train_data = data[:int(0.8 * len(data))]\n",
    "    train_data, scaler, scaler_y = normalization(train_data)\n",
    "    train_x, train_y = series_to_supervise(train_data, seq_len, target_len)\n",
    "\n",
    "    valid_x = train_x[int(0.8 * len(train_x)):]\n",
    "    valid_y = train_y[int(0.8 * len(train_y)):]\n",
    "    train_x = train_x[:int(0.8 * len(train_x))]\n",
    "    train_y = train_y[:int(0.8 * len(train_y))]\n",
    "    input_size = train_x.shape[2]\n",
    "\n",
    "    #     hyper-parameters define\n",
    "    batch_size = 256\n",
    "    lr = 0.001\n",
    "    number_epoch = 40\n",
    "    d_model = 64\n",
    "    n_layers = 2\n",
    "    drop_prob = 0.5\n",
    "    nhead = 8\n",
    "    mse_thresh = 0.1\n",
    "\n",
    "    model, train_loss_list, valid_loss_list = train_model(\n",
    "        train_x, train_y, valid_x, valid_y, input_size, seq_len, target_len,\n",
    "        mse_thresh, d_model, nhead, n_layers, number_epoch, batch_size, lr,\n",
    "        drop_prob)\n",
    "    # plot training process\n",
    "    plt.plot(train_loss_list[10:], 'm', label='train_loss')\n",
    "    plt.plot(valid_loss_list[10:], 'g', label='valid_loss')\n",
    "    plt.grid('both')\n",
    "    plt.legend()\n",
    "    # test\n",
    "    test_data = data[int(0.8 * len(data)):]\n",
    "    test_data = scaler.transform(test_data)\n",
    "    test_x, test_y = series_to_supervise(test_data, seq_len, target_len)\n",
    "    MAPE, MAE, RMSE, load_pred, load_true = test_model(model, test_x, test_y,\n",
    "                                                       scaler_y, seq_len,\n",
    "                                                       target_len, batch_size)\n",
    "    return MAPE, MAE, RMSE, load_pred, load_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3d364bc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T02:23:04.253467Z",
     "start_time": "2022-01-04T02:05:22.601712Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervised data: shape of x: (25232, 72, 16), shape of y: (25232, 24, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/40...: 100%|█████████| 78/78 [00:26<00:00,  2.93it/s, train_loss=0.0319, valid_loss=0.0337]\n",
      "Epoch: 2/40...: 100%|█████████| 78/78 [00:26<00:00,  2.93it/s, train_loss=0.0147, valid_loss=0.0191]\n",
      "Epoch: 3/40...: 100%|█████████| 78/78 [00:26<00:00,  2.94it/s, train_loss=0.0127, valid_loss=0.0163]\n",
      "Epoch: 4/40...: 100%|███████████| 78/78 [00:26<00:00,  2.93it/s, train_loss=0.01, valid_loss=0.0157]\n",
      "Epoch: 5/40...: 100%|████████| 78/78 [00:26<00:00,  2.95it/s, train_loss=0.00753, valid_loss=0.0117]\n",
      "Epoch: 6/40...: 100%|████████| 78/78 [00:26<00:00,  2.95it/s, train_loss=0.00612, valid_loss=0.0113]\n",
      "Epoch: 7/40...: 100%|███████| 78/78 [00:26<00:00,  2.94it/s, train_loss=0.00546, valid_loss=0.00851]\n",
      "Epoch: 8/40...: 100%|███████| 78/78 [00:26<00:00,  2.95it/s, train_loss=0.00469, valid_loss=0.00912]\n",
      "Epoch: 9/40...: 100%|███████| 78/78 [00:26<00:00,  2.95it/s, train_loss=0.00409, valid_loss=0.00949]\n",
      "Epoch: 10/40...: 100%|██████| 78/78 [00:26<00:00,  2.93it/s, train_loss=0.00391, valid_loss=0.00532]\n",
      "Epoch: 11/40...: 100%|██████| 78/78 [00:26<00:00,  2.95it/s, train_loss=0.00351, valid_loss=0.00812]\n",
      "Epoch: 12/40...: 100%|██████| 78/78 [00:26<00:00,  2.95it/s, train_loss=0.00316, valid_loss=0.00666]\n",
      "Epoch: 13/40...: 100%|██████| 78/78 [00:26<00:00,  2.94it/s, train_loss=0.00307, valid_loss=0.00672]\n",
      "Epoch: 14/40...: 100%|████████| 78/78 [00:26<00:00,  2.95it/s, train_loss=0.00269, valid_loss=0.004]\n",
      "Epoch: 15/40...: 100%|███████| 78/78 [00:26<00:00,  2.95it/s, train_loss=0.00245, valid_loss=0.0042]\n",
      "Epoch: 16/40...: 100%|██████| 78/78 [00:26<00:00,  2.94it/s, train_loss=0.00238, valid_loss=0.00368]\n",
      "Epoch: 17/40...: 100%|██████| 78/78 [00:26<00:00,  2.95it/s, train_loss=0.00206, valid_loss=0.00396]\n",
      "Epoch: 18/40...: 100%|███████| 78/78 [00:26<00:00,  2.95it/s, train_loss=0.00197, valid_loss=0.0037]\n",
      "Epoch: 19/40...: 100%|██████| 78/78 [00:26<00:00,  2.93it/s, train_loss=0.00197, valid_loss=0.00321]\n",
      "Epoch: 20/40...: 100%|██████| 78/78 [00:26<00:00,  2.95it/s, train_loss=0.00179, valid_loss=0.00468]\n",
      "Epoch: 21/40...: 100%|██████| 78/78 [00:26<00:00,  2.95it/s, train_loss=0.00167, valid_loss=0.00348]\n",
      "Epoch: 22/40...: 100%|██████| 78/78 [00:26<00:00,  2.92it/s, train_loss=0.00171, valid_loss=0.00652]\n",
      "Epoch: 23/40...: 100%|██████| 78/78 [00:26<00:00,  2.95it/s, train_loss=0.00145, valid_loss=0.00301]\n",
      "Epoch: 24/40...: 100%|██████| 78/78 [00:26<00:00,  2.95it/s, train_loss=0.00153, valid_loss=0.00331]\n",
      "Epoch: 25/40...: 100%|██████| 78/78 [00:26<00:00,  2.94it/s, train_loss=0.00147, valid_loss=0.00431]\n",
      "Epoch: 26/40...: 100%|██████| 78/78 [00:26<00:00,  2.95it/s, train_loss=0.00141, valid_loss=0.00333]\n",
      "Epoch: 27/40...: 100%|██████| 78/78 [00:26<00:00,  2.95it/s, train_loss=0.00138, valid_loss=0.00292]\n",
      "Epoch: 28/40...: 100%|██████| 78/78 [00:26<00:00,  2.93it/s, train_loss=0.00134, valid_loss=0.00473]\n",
      "Epoch: 29/40...: 100%|███████| 78/78 [00:26<00:00,  2.95it/s, train_loss=0.00125, valid_loss=0.0043]\n",
      "Epoch: 30/40...: 100%|██████| 78/78 [00:26<00:00,  2.96it/s, train_loss=0.00131, valid_loss=0.00348]\n",
      "Epoch: 31/40...: 100%|██████| 78/78 [00:26<00:00,  2.95it/s, train_loss=0.00117, valid_loss=0.00271]\n",
      "Epoch: 32/40...: 100%|██████| 78/78 [00:26<00:00,  2.94it/s, train_loss=0.00113, valid_loss=0.00361]\n",
      "Epoch: 33/40...: 100%|██████| 78/78 [00:26<00:00,  2.94it/s, train_loss=0.00115, valid_loss=0.00338]\n",
      "Epoch: 34/40...: 100%|██████| 78/78 [00:26<00:00,  2.95it/s, train_loss=0.00114, valid_loss=0.00338]\n",
      "Epoch: 35/40...: 100%|███████| 78/78 [00:26<00:00,  2.95it/s, train_loss=0.0012, valid_loss=0.00317]\n",
      "Epoch: 36/40...: 100%|██████| 78/78 [00:26<00:00,  2.95it/s, train_loss=0.00132, valid_loss=0.00299]\n",
      "Epoch: 37/40...: 100%|██████| 78/78 [00:26<00:00,  2.94it/s, train_loss=0.00115, valid_loss=0.00354]\n",
      "Epoch: 38/40...: 100%|██████| 78/78 [00:26<00:00,  2.93it/s, train_loss=0.00106, valid_loss=0.00294]\n",
      "Epoch: 39/40...: 100%|██████| 78/78 [00:26<00:00,  2.95it/s, train_loss=0.00106, valid_loss=0.00342]\n",
      "Epoch: 40/40...: 100%|██████| 78/78 [00:26<00:00,  2.94it/s, train_loss=0.00107, valid_loss=0.00352]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervised data: shape of x: (6237, 72, 16), shape of y: (6237, 24, 16)\n",
      "MAPE:0.05084572387857614, MAE:647.523400409149, RMSE:866.8882102514918\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_seed_set(42)\n",
    "MAPE, MAE, RMSE, load_pred, load_true = run_model_retraining()\n",
    "print('MAPE:{}, MAE:{}, RMSE:{}'.format(MAPE, MAE, RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "81749911",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T02:23:37.449958Z",
     "start_time": "2022-01-04T02:23:37.444063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE:0.05084572387857614, MAE:647.523400409149, RMSE:866.8882102514918\n"
     ]
    }
   ],
   "source": [
    "print('MAPE:{}, MAE:{}, RMSE:{}'.format(MAPE, MAE, RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d86b91",
   "metadata": {},
   "source": [
    "## figure plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a092bf6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-01-04T02:24:14.719Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 20178.594054892717)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "load_pred = load_pred.reshape(-1, 24)\n",
    "load_true = load_true.reshape(-1, 24)\n",
    "plt.plot(load_pred[:240, 0], 'm')\n",
    "plt.plot(load_true[:240, 0], 'g')\n",
    "plt.ylim(ymin=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "215.359px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
